<html><body><div><div class="entry-content">
						<p><img class="alignleft wp-image-184 size-medium" src="https://khashtamov.com/wp-content/uploads/2016/02/celery-300x200.jpg" alt="Python Celery" srcset="https://khashtamov.com/wp-content/uploads/2016/02/celery-300x200.jpg 300w, https://khashtamov.com/wp-content/uploads/2016/02/celery-768x512.jpg 768w, https://khashtamov.com/wp-content/uploads/2016/02/celery.jpg 800w" sizes="(max-width: 300px) 100vw, 300px"/><br/>
В этой статье мне хотелось бы поделиться с читателями своим опытом работы с таким замечательным инструментом в Python как Celery.</p>
<p>Celery это ничто иное как распределённая очередь заданий, реализованная на языке Python. На момент написания этой статьи, самой последней версией является 3.1.20. Неосведомлённый читатель может не знать для чего вообще нужна система очередей задач наподобие Celery, поэтому кратко поясню этот момент.</p>
<h2>Что такое Celery и зачем оно нам?</h2>
<p>Часто ли вам приходилось сталкиваться с типовыми задачами в веб-приложениях вроде отправки электронного письма посетителю или обработки загруженных данных. Чаще всего такого рода манипуляции не требуют участия конечного пользователя вашего проекта, то есть их можно выполнять в фоновом режиме. Те из нас, кто реализует выполнение этих задач в одном из процессов веб-сервера, «тормозят» тем самым его работу, увеличивая время отклика и ухудшают user experience.</p>
<p>В данной заметке я опущу вводную информацию по установке и настройке Celery в вашем проекте. Кстати, Celery из коробки умеет работать с Django. Ранее был отдельный python пакет, соединяющий Django и Celery,<span id="more-148"/> именовался он <a href="https://github.com/celery/django-celery/" target="_blank">django-celery</a>. Сейчас он заброшен, так как последнее обновление было более года назад. Стоит отметить, что django-celery не работает Django 1.9 из-за изменений в работе cache backend. Исправленную версию можно посмотреть в <a href="https://github.com/adilkhash/django-celery" target="_blank">моём форке</a>. Одной из удобных фич django-celery является интеграция с Django Admin по части управления periodic tasks.</p>
<h2>Советы по работе с Celery</h2>
<h3><strong>Не используйте базу данных в качестве broker/backend</strong></h3>
<p><strong>Брокер</strong> отвечает за передачу сообщений (задач) между так называемыми исполнителями (workers). Проблема использования базы данных заключается в её ограничениях — она просто не предназначена для этого. Дело в том, что с ростом количества исполнителей, нагрузка на базу будет только возрастать, а учитывая тот факт, что каждый worker имеет ещё ряд потоков, ситуация может стать катастрофической даже при малых нагрузках. Всё это приведёт к бутылочному горлышку в виде затыка на I/O, потере задач, а возможно и неоднократному их исполнению (два воркера могут получить одну и ту же задачу на исполнение). Отличным production-ready решением является использование RabbitMQ или Redis для этой роли.</p>
<p><strong>Бэкэнд </strong>в случае с Celery выступает в качестве хранилища результатов выполнения задач (task). Одной из причин создания django-celery как раз являлась возможность подключения БД для сохранения результатов. Признаюсь, что в самом начале работы с Celery я неоднократно в проектах использовал этот подход. <strong>Пожалуйста, не повторяйте мою ошибку</strong>. С ростом нагрузки на приложение проблемы будут расти словно грибы после дождя (более того, «из коробки» celery не чистит базу от «устаревших» результатов) . Правда тут есть нюансы касательно вашего приложения. Об этом читайте ниже. Production-ready решением для роли backend неплохо зарекомендовал себя демон memcached. Пользуемся более 2-х лет, проблем ни разу не было.</p>
<h3><strong>Разделяйте задачи по очередям</strong></h3>
<p>Это очень важный момент. По мере развития вашего приложения, в проекте будут появляться критичные для выполнения задачи: проверка статуса платежа, формирование отчёта, отправка электронных писем и так далее. Терять их недопустимо. Если все задачи складировать в одну очередь, то в один прекрасный момент она может забиться, поставив под угрозу выполнение критически важного кода. Мой подход: <strong>разделяйте очереди по приоритетам</strong>.</p>

<p>Несомненно очередей может быть больше, тут всё на усмотрение разработчика и архитектуры его приложения.</p>
<p>В базовых настройках Celery это выглядит следующим образом:</p>
<pre><code class="python">CELERY_QUEUES = (
    Queue('high', Exchange('high'), routing_key='high'),
    Queue('normal', Exchange('normal'), routing_key='normal'),
    Queue('low', Exchange('low'), routing_key='low'),
)

CELERY_DEFAULT_QUEUE = 'normal'
CELERY_DEFAULT_EXCHANGE = 'normal'
CELERY_DEFAULT_ROUTING_KEY = 'normal'

CELERY_ROUTES = {
    # -- HIGH PRIORITY QUEUE -- #
    'myapp.tasks.check_payment_status': {'queue': 'high'},
    # -- LOW PRIORITY QUEUE -- #
    'myapp.tasks.close_session': {'queue': 'low'},
}
</code></pre>
<p>В данном конкретном примере объявлена очередь по-умолчанию под названием <strong>normal</strong>. То есть задачи явно не указанные в списке будут автоматически распределены в эту очередь. В <strong>high</strong> попадает задача под названием <em>check_payment_status</em>, а в <strong>low</strong> задача <em>close_session</em>.</p>
<p>Запускать исполнителей Celery для этих очередей необходимо следующим образом:</p>
<pre><code class="bash">celery worker -E -l INFO -n worker.high -Q high
celery worker -E -l INFO -n worker.normal -Q normal
celery worker -E -l INFO -n worker.low -Q low
</code></pre>
<p>Здесь мы явно задаём имена исполнителей и названия очередей в которых необходимо мониторить задачи на исполнение.</p>
<p><strong>ВАЖНО! </strong>Если вы явно указали для задачи очередь в которую ей нужно будет падать, и при этом запустили одного из исполнителей Celery без явного указания очереди, например вот так:</p>
<pre><code class="bash">celery worker -E -l INFO -n worker.whatever
</code></pre>
<p>То при наступлении ситуации, когда все исполнители очереди high будут заняты, Celery автоматически перенаправит новую задачу исполнителям без конкретной очереди. Поэтому при использовании раздельных очередей задач, не запускайте исполнителей без указания для них явного наименования очереди.</p>
<h3><strong>Логгируйте ошибки</strong></h3>
<p><strong>Логгирование ошибок</strong> и своевременный их анализ это <strong>основа надёжных приложений</strong>. Очень важно иметь полную картину происходящего внутри вашего кода. По-умолчанию Celery все ошибки пишет в stderr, а прочая информация, связанная с исполнением попадает в stdout. Контролировать вывод ошибок можно через стандартный python logging, достаточно повесить свой handler на logger под названием «celery». Практика развёртывания боевых приложений, использующих Celery, показывает, что в качестве процесс-менеджера используют supervisord. В его настройках можно задавать путь до файла в который он будет складировать всю информацию, генерируемую демоном. Но вручную анализировать текстовые логи на предмет ошибок неудобно и неэффективно. Лично я использую для этих целей <strong>Sentry</strong>. Вот как выглядит у меня logging config:</p>
<pre><code class="python">CELERYD_HIJACK_ROOT_LOGGER = False

LOGGING = {
    'handlers': {
        'celery_sentry_handler': {
            'level': 'ERROR',
            'class': 'core.log.handlers.CelerySentryHandler'
        }
    },

    'loggers': {
        'celery': {
            'handlers': ['celery_sentry_handler'],
            'level': 'ERROR',
            'propagate': False,
        },
    }
}
</code></pre>
<p>Важной опцией здесь является наличие <em>CELERYD_HIJACK_ROOT_LOGGER = False</em>. По-умолчанию значение этой переменной является <em>True</em>, что позволяет celery «перекрывать» все ранее объявленные кастомные обработчики logging.</p>
<p>При указанном выше подходе нет необходимости дополнительно в коде задач (task) логгировать ошибки/исключения отдельно. О том что такое Sentry, для чего оно используется и как его настроить я напишу отдельную статью немного позже.</p>
<h3><strong>Пишите задачи маленькими</strong></h3>
<p>При написании задач старайтесь придерживаться принципа минимализма кода. То есть не нужно в самом celery task описывать бизнес логику задачи. Например, если вам необходимо генерировать и отправлять отчёт, то не нужно в самом task писать код генерации и отправки. Разбейте его на 3 части:</p>
<ol>
<li>Код генерации отчёта</li>
<li>Код отправки письма</li>
<li>Задача (task) по выполнению этих действий</li>
</ol>
<pre><code class="python">from .utils import generate_report, send_email

@app.task(bind=True)
def send_report():
    filename = generate_report()
    send_email(subject, message, attachments=[filename])

</code></pre>
<p>Это, во-первых, позволит легче читать код (есть явное разделение на подзадачи). Во-вторых, тестировать такой код намного легче (привет модульным тестам!). В-третьих, отлавливать ошибки также будет намного легче и прозрачнее.</p>
<h3><strong>«Гасите» задачи вовремя</strong></h3>
<p>Явно указывайте лимит на выполнение задачи. Это можно сделать несколькими способами:</p>
<ul>
<li>Через декоратор @app.task, передавая soft_time_limit, time_limit.</li>
<li>Глобально задать таймлимит при запуске исполнителя (worker), передав ему соответствующие аргументы (их можно найти в документации к Celery). В этом случае для всех задач, попадающих в заданную очередь будет один и тот же таймлимит.</li>
</ul>
<p>Указание таймлимита очень важно, так как в некоторых случаях его отсутствие попросту приведёт к «зависанию» исполнителя при выполнении неоднозначных задач (требующих длительного времени, коннект к внешнему сервису и так далее).</p>
<h3><strong>Не храните результаты исполнения без необходимости</strong></h3>
<p>В большинстве случаев результат выполнения вашей задачи вам не нужен (например, если происходит отправка письма). В такой ситуации вам нет необходимости хранить что-то. Если ваши задачи полностью попадают в эту категорию, то в настройках Celery можно задать глобальный параметр <em>CELERY_IGNORE_RESULT = True</em>, который будет игнорировать результат исполнения всех ваших task-функций.</p>
<h3><strong>Используйте Flower для мониторинга исполнения задач</strong></h3>
<p><strong>Всегда используйте <a href="https://github.com/mher/flower" target="_blank">Flower</a> при работе с Celery</strong>. Всегда! Данный инструмент это небольшое веб приложение, написанное с использованием микрофреймворка Flask, а также Tornado для поддержки веб-сокетов. Flower позволяет вам всегда быть в курсе того как исполняются ваши задачи. Немного скриншотов:</p>
<p><a href="https://khashtamov.com/wp-content/uploads/2016/02/2016-02-09-23-24-46-Skrinshot-yekrana.png" rel="attachment wp-att-179"><img class="alignnone size-medium wp-image-179" src="https://khashtamov.com/wp-content/uploads/2016/02/2016-02-09-23-24-46-Skrinshot-yekrana-300x177.png" alt="Celery Flower Monitoring" srcset="https://khashtamov.com/wp-content/uploads/2016/02/2016-02-09-23-24-46-Skrinshot-yekrana-300x177.png 300w, https://khashtamov.com/wp-content/uploads/2016/02/2016-02-09-23-24-46-Skrinshot-yekrana-768x453.png 768w, https://khashtamov.com/wp-content/uploads/2016/02/2016-02-09-23-24-46-Skrinshot-yekrana.png 942w" sizes="(max-width: 300px) 100vw, 300px"/></a></p>
<p><a href="https://khashtamov.com/wp-content/uploads/2016/02/2016-02-09-23-26-44-Skrinshot-yekrana.png" rel="attachment wp-att-180"><img class="alignnone size-medium wp-image-180" src="https://khashtamov.com/wp-content/uploads/2016/02/2016-02-09-23-26-44-Skrinshot-yekrana-300x41.png" alt="Flower Dashboard" srcset="https://khashtamov.com/wp-content/uploads/2016/02/2016-02-09-23-26-44-Skrinshot-yekrana-300x41.png 300w, https://khashtamov.com/wp-content/uploads/2016/02/2016-02-09-23-26-44-Skrinshot-yekrana-768x105.png 768w, https://khashtamov.com/wp-content/uploads/2016/02/2016-02-09-23-26-44-Skrinshot-yekrana-1024x140.png 1024w" sizes="(max-width: 300px) 100vw, 300px"/></a></p>
<p>Не поленитесь и потратьте время на его изучение. Оно окупится многократно!</p>
<h3><strong>Не передавайте ORM объекты в качестве аргументов</strong></h3>
<p>Я пару раз попадался на этом хитром трюке, который потрепал мне изрядно нервы. Рассмотрим вот такой код:</p>
<pre><code class="python">from .models import Profile

@app.task(bind=True):
def send_notification(profile):
    send_email(profile.user.email, subject, message_body)
    profile.notified = True
    profile.save()

def notify_user():
    profile = Profile.objects.get(id=1)
    check_smthng()
    send_notification.delay(profile)
    profile.activated = True
    profile.save()
</code></pre>
<p>Не самый лучший пример для демонстрации побочного эффекта при передаче ORM объекта, но всё же. В данной ситуации код, описанный в send_notification, сохранит объект, изменив лишь notified = True, но activated останется по-прежнему равен False. Лучшим решением будет передача идентификатора объекта в базе данных, а в самой task функции необходимо непосредственно обращаться к объекту через его id.</p>
<p> </p>
<h2>Полезные ссылки</h2>

											</div>


					</div></body></html>