<html><body><div><div class="section" id="processing-text-files-in-python-3">
<span id="py3k-text-files"/><h1>Processing Text Files in Python 3<a class="headerlink" href="#processing-text-files-in-python-3" title="Permalink to this headline">¶</a></h1>
<p>A recent discussion on the python-ideas mailing list made it clear that we
(i.e. the core Python developers) need to provide some clearer guidance on
how to handle text processing tasks that trigger exceptions by default in
Python 3, but were previously swept under the rug by Python 2’s blithe
assumption that all files are encoded in “latin-1”.</p>
<p>While we’ll have something in the official docs <a class="reference external" href="http://bugs.python.org/issue13997">before too long</a>, this is
my own preliminary attempt at summarising the options for processing text
files, and the various trade-offs between them.</p>

<div class="section" id="what-changed-in-python-3">

<p>The obvious question to ask is what changed in Python 3 so that the common
approaches that developers used to use for text processing in Python 2 have
now started to throw <code class="docutils literal"><span class="pre">UnicodeDecodeError</span></code> and <code class="docutils literal"><span class="pre">UnicodeEncodeError</span></code> in
Python 3.</p>
<p>The key difference is that the default text processing behaviour in Python 3
aims to detect text encoding problems as early as possible - either when
reading improperly encoded text (indicated by <code class="docutils literal"><span class="pre">UnicodeDecodeError</span></code>) or when
being asked to write out a text sequence that cannot be correctly represented
in the target encoding (indicated by <code class="docutils literal"><span class="pre">UnicodeEncodeError</span></code>).</p>
<p>This contrasts with the Python 2 approach which allowed data corruption by
default and strict correctness checks had to be requested explicitly. That
could certainly be <em>convenient</em> when the data being processed was
predominantly ASCII text, and the occasional bit of data corruption was
unlikely to be even detected, let alone cause problems, but it’s hardly a
solid foundation for building robust multilingual applications (as anyone
that has ever had to track down an errant <code class="docutils literal"><span class="pre">UnicodeError</span></code> in Python 2 will
know).</p>
<p>However, Python 3 does provide a number of mechanisms for relaxing the default
strict checks in order to handle various text processing use cases (in
particular, use cases where “best effort” processing is acceptable, and strict
correctness is not required). This article aims to explain some of them by
looking at cases where it would be appropriate to use them.</p>
<p>Note that many of the features I discuss below are available in Python 2
as well, but you have to explicitly access them via the <code class="docutils literal"><span class="pre">unicode</span></code> type
and the <code class="docutils literal"><span class="pre">codecs</span></code> module. In Python 3, they’re part of the behaviour of
the <code class="docutils literal"><span class="pre">str</span></code> type and the <code class="docutils literal"><span class="pre">open</span></code> builtin.</p>
</div>
<div class="section" id="unicode-basics">

<p>To process text effectively in Python 3, it’s necessary to learn at least a
tiny amount about Unicode and text encodings:</p>
<ol class="arabic simple">
<li>Python 3 always stores text strings as sequences of Unicode <em>code points</em>.
These are values in the range 0-0x10FFFF. They <em>don’t</em> always correspond
directly to the characters you read on your screen, but that distinction
doesn’t matter for most text manipulation tasks.</li>
<li>To store text as binary data, you must specify an <em>encoding</em> for that text.</li>
<li>The process of converting from a sequence of bytes (i.e. binary data)
to a sequence of code points (i.e. text data) is <em>decoding</em>, while the
reverse process is <em>encoding</em>.</li>
<li>For historical reasons, the most widely used encoding is <code class="docutils literal"><span class="pre">ascii</span></code>, which
can only handle Unicode code points in the range 0-0x7F (i.e. ASCII is a
7-bit encoding).</li>
<li>There are a wide variety of ASCII <em>compatible</em> encodings, which ensure that
any appearance of a valid ASCII value in the binary data refers to the
corresponding ASCII character.</li>
<li>“utf-8” is becoming the preferred encoding for many applications, as it is
an ASCII-compatible encoding that can encode any valid Unicode code point.</li>
<li>“latin-1” is another significant ASCII-compatible encoding, as it maps byte
values directly to the first 256 Unicode code points. (Note that Windows
has it’s own “latin-1” variant called cp1252, but, unlike the ISO
“latin-1” implemented by the Python codec with that name, the Windows
specific variant doesn’t map all 256 possible byte values)</li>
<li>There are also many ASCII <em>incompatible</em> encodings in widespread use,
particularly in Asian countries (which had to devise their own solutions before
the rise of Unicode) and on platforms such as Windows, Java and the .NET CLR,
where many APIs accept text as UTF-16 encoded data.</li>
<li>The <code class="docutils literal"><span class="pre">locale.getpreferredencoding()</span></code> call reports the encoding that Python
will use by default for most operations that require an encoding (e.g.
reading in a text file without a specified encoding). This is designed to
aid interoperability between Python and the host operating system, but can
cause problems with interoperability between systems (if encoding issues
are not managed consistently).</li>
<li>The <code class="docutils literal"><span class="pre">sys.getfilesystemencoding()</span></code> call reports the encoding that Python
will use by default for most operations that both require an encoding and
involve textual metadata in the filesystem (e.g. determining the results
of <code class="docutils literal"><span class="pre">os.listdir()</span></code>)</li>
<li>If you’re a native English speaker residing in an English speaking country
(like me!) it’s tempting to think “but Python 2 works fine, why are you
bothering me with all this Unicode malarkey?”. It’s worth trying to remember
that we’re actually a minority on this planet and, for most people on Earth,
ASCII and <code class="docutils literal"><span class="pre">latin-1</span></code> can’t even handle their <em>name</em>, let alone any other
text they might want to write or process in their native language.</li>
</ol>
</div>
<div class="section" id="unicode-error-handlers">

<p>To help standardise various techniques for dealing with Unicode encoding and
decoding errors, Python includes a concept of Unicode error handlers that
are automatically invoked whenever a problem is encountered in the process
of encoding or decoding text.</p>
<p>I’m not going to cover all of them in this article, but three are of
particular significance:</p>
<ul class="simple">
<li><code class="docutils literal"><span class="pre">strict</span></code>: this is the default error handler that just raises
<code class="docutils literal"><span class="pre">UnicodeDecodeError</span></code> for decoding problems and <code class="docutils literal"><span class="pre">UnicodeEncodeError</span></code> for
encoding problems.</li>
<li><code class="docutils literal"><span class="pre">surrogateescape</span></code>: this is the error handler that Python uses for most
OS facing APIs to gracefully cope with encoding problems in the data
supplied by the OS. It handles decoding errors by squirreling the data away
in a little used part of the Unicode code point space (For those interested
in more detail, see <a class="reference external" href="http://www.python.org/dev/peps/pep-0383/">PEP 383</a>). When encoding, it translates those hidden
away values back into the exact original byte sequence that failed to
decode correctly. Just as this is useful for OS APIs, it can make it easier
to gracefully handle encoding problems in other contexts.</li>
<li><code class="docutils literal"><span class="pre">backslashreplace</span></code>: this is an encoding error handler that converts
code points that can’t be represented in the target encoding to the
equivalent Python string numeric escape sequence. It makes it easy to
ensure that <code class="docutils literal"><span class="pre">UnicodeEncodeError</span></code> will never be thrown, but doesn’t lose
much information while doing so losing (since we don’t want encoding
problems hiding error output, this error handler is enabled on
<code class="docutils literal"><span class="pre">sys.stderr</span></code> by default).</li>
</ul>
</div>
<div class="section" id="the-binary-option">

<p>One alternative that is always available is to open files in binary mode and
process them as bytes rather than as text. This can work in many cases,
especially those where the ASCII markers are embedded in genuinely arbitrary
binary data.</p>
<p>However, for both “text data with unknown encoding” and “text data with known
encoding, but potentially containing encoding errors”, it is often
preferable to get them into a form that can be handled as text strings. In
particular, some APIs that accept both bytes and text may be very strict
about the encoding of the bytes they accept (for example, the
<code class="docutils literal"><span class="pre">urllib.urlparse</span></code> module accepts only pure ASCII data for processing as
bytes, but will happily process text strings containing non-ASCII
code points).</p>
</div>
<div class="section" id="text-file-processing">

<p>This section explores a number of use cases that can arise when processing
text. Text encoding is a sufficiently complex topic that there’s no one
size fits all answer - the right answer for a given application will depend
on factors like:</p>
<ul class="simple">
<li>how much control you have over the text encodings used</li>
<li>whether avoiding program failure is more important than avoiding data
corruption or vice-versa</li>
<li>how common encoding errors are expected to be, and whether they need to
be handled gracefully or can simply be rejected as invalid input</li>
</ul>
<div class="section" id="files-in-an-ascii-compatible-encoding-best-effort-is-acceptable">

<p><strong>Use case:</strong> the files to be processed are in an ASCII compatible encoding,
but you don’t know exactly which one. <em>All</em> files must be processed without
triggering any exceptions, but some risk of data corruption is deemed
acceptable (e.g. collating log files from multiple sources where some
data errors are acceptable, so long as the logs remain largely intact).</p>
<p><strong>Approach:</strong> use the “latin-1” encoding to map byte values directly to the
first 256 Unicode code points. This is the closest equivalent Python 3
offers to the permissive Python 2 text handling model.</p>
<p><strong>Example:</strong> <code class="docutils literal"><span class="pre">f</span> <span class="pre">=</span> <span class="pre">open(fname,</span> <span class="pre">encoding="latin-1")</span></code></p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">While the Windows <code class="docutils literal"><span class="pre">cp1252</span></code> encoding is also sometimes referred to as
“latin-1”, it doesn’t map all possible byte values, and thus needs
to be used in combination with the <code class="docutils literal"><span class="pre">surrogateescape</span></code> error handler to
ensure it never throws <code class="docutils literal"><span class="pre">UnicodeDecodeError</span></code>. The <code class="docutils literal"><span class="pre">latin-1</span></code> encoding
in Python implements ISO_8859-1:1987 which maps all possible byte values
to the first 256 Unicode code points, and thus ensures decoding errors
will never occur regardless of the configured error handler.</p>
</div>
<p><strong>Consequences:</strong></p>
<ul class="simple">
<li>data will <em>not</em> be corrupted if it is simply read in, processed as ASCII
text, and written back out again.</li>
<li>will never raise UnicodeDecodeError when reading data</li>
<li>will still raise UnicodeEncodeError if codepoints above 0xFF (e.g. smart
quotes copied from a word processing program) are added to the text string
before it is encoded back to bytes. To prevent such errors, use the
<code class="docutils literal"><span class="pre">backslashreplace</span></code> error handler (or one of the other error handlers
that replaces Unicode code points without a representation in the target
encoding with sequences of ASCII code points).</li>
<li>data corruption may occur if the source data is in an ASCII incompatible
encoding (e.g. UTF-16)</li>
<li>corruption may occur if data is written back out using an encoding other
than <code class="docutils literal"><span class="pre">latin-1</span></code></li>
<li>corruption may occur if the non-ASCII elements of the string are modified
directly (e.g. for a variable width encoding like UTF-8 that has been
decoded as <code class="docutils literal"><span class="pre">latin-1</span></code> instead, slicing the string at an arbitrary point
may split a multi-byte character into two pieces)</li>
</ul>
</div>
<div class="section" id="files-in-an-ascii-compatible-encoding-minimise-risk-of-data-corruption">

<p><strong>Use case:</strong> the files to be processed are in an ASCII compatible encoding,
but you don’t know exactly which one. <em>All</em> files must be processed without
triggering any exceptions, but some Unicode related errors are acceptable in
order to reduce the risk of data corruption (e.g. collating log files from
multiple sources, but wanting more explicit notification when the collated
data is at risk of corruption due to programming errors that violate the
assumption of writing the data back out only in its original encoding)</p>
<p><strong>Approach:</strong> use the <code class="docutils literal"><span class="pre">ascii</span></code> encoding with the <code class="docutils literal"><span class="pre">surrogateescape</span></code> error
handler.</p>
<p><strong>Example:</strong> <code class="docutils literal"><span class="pre">f</span> <span class="pre">=</span> <span class="pre">open(fname,</span> <span class="pre">encoding="ascii",</span> <span class="pre">errors="surrogateescape")</span></code></p>
<p><strong>Consequences:</strong></p>
<ul class="simple">
<li>data will <em>not</em> be corrupted if it is simply read in, processed as ASCII
text, and written back out again.</li>
<li>will never raise UnicodeDecodeError when reading data</li>
<li>will still raise UnicodeEncodeError if codepoints above 0xFF (e.g. smart
quotes copied from a word processing program) are added to the text string
before it is encoded back to bytes. To prevent such errors, use the
<code class="docutils literal"><span class="pre">backslashreplace</span></code> error handler (or one of the other error handlers
that replaces Unicode code points without a representation in the target
encoding with sequences of ASCII code points).</li>
<li>will also raise UnicodeEncodeError if an attempt is made to encode a text
string containing escaped bytes values without enabling the
<code class="docutils literal"><span class="pre">surrogateescape</span></code> error handler (or an even more tolerant handler like
<code class="docutils literal"><span class="pre">backslashreplace</span></code>).</li>
<li>some Unicode processing libraries that ensure a code point sequence is
valid text may complain about the escaping mechanism used (I’m not going
to explain what it means here, but the phrase “lone surrogate” is a hint
that something along those lines may be happening - the fact that
“surrogate” also appears in the name of the error handler is not a
coincidence).</li>
<li>data corruption may still occur if the source data is in an ASCII
incompatible encoding (e.g. UTF-16)</li>
<li>data corruption is also still possible if the escaped portions of the
string are modified directly</li>
</ul>
</div>
<div class="section" id="files-in-a-typical-platform-specific-encoding">

<p><strong>Use case:</strong> the files to be processed are in a consistent encoding, the
encoding can be determined from the OS details and locale settings and it
is acceptable to refuse to process files that are not properly encoded.</p>
<p><strong>Approach:</strong> simply open the file in text mode. This use case describes the
default behaviour in Python 3.</p>
<p><strong>Example:</strong> <code class="docutils literal"><span class="pre">f</span> <span class="pre">=</span> <span class="pre">open(fname)</span></code></p>
<p><strong>Consequences:</strong></p>
<ul class="simple">
<li><code class="docutils literal"><span class="pre">UnicodeDecodeError</span></code> may be thrown when reading such files (if the data is not
actually in the encoding returned by <code class="docutils literal"><span class="pre">locale.getpreferredencoding()</span></code>)</li>
<li><code class="docutils literal"><span class="pre">UnicodeEncodeError</span></code> may be thrown when writing such files (if attempting to
write out code points which have no representation in the target encoding).</li>
<li>the <code class="docutils literal"><span class="pre">surrogateescape</span></code> error handler can be used to be more tolerant of
encoding errors if it is necessary to make a best effort attempt to process
files that contain such errors instead of rejecting them outright as invalid
input.</li>
</ul>
</div>
<div class="section" id="files-in-a-consistent-known-encoding">

<p><strong>Use case:</strong> the files to be processed are nominally in a consistent
encoding, you know the exact encoding in advance and it is acceptable to
refuse to process files that are not properly encoded. This is becoming more
and more common, especially with many text file formats beginning to
standardise on UTF-8 as the preferred text encoding.</p>
<p><strong>Approach:</strong> open the file in text mode with the appropriate encoding</p>
<p><strong>Example:</strong> <code class="docutils literal"><span class="pre">f</span> <span class="pre">=</span> <span class="pre">open(fname,</span> <span class="pre">encoding="utf-8")</span></code></p>
<p><strong>Consequences:</strong></p>
<ul class="simple">
<li><code class="docutils literal"><span class="pre">UnicodeDecodeError</span></code> may be thrown when reading such files (if the data is not
actually in the specified encoding)</li>
<li><code class="docutils literal"><span class="pre">UnicodeEncodeError</span></code> may be thrown when writing such files (if attempting to
write out code points which have no representation in the target encoding).</li>
<li>the <code class="docutils literal"><span class="pre">surrogateescape</span></code> error handler can be used to be more tolerant of
encoding errors if it is necessary to make a best effort attempt to process
files that contain such errors instead of rejecting them outright as invalid
input.</li>
</ul>
</div>
<div class="section" id="files-with-a-reliable-encoding-marker">

<p><strong>Use case:</strong> the files to be processed include markers that specify the
nominal encoding (with a default encoding assumed if no marker is present)
and it is acceptable to refuse to process files that are not properly encoded.</p>
<p><strong>Approach:</strong> first open the file in binary mode to look for the encoding
marker, then reopen in text mode with the identified encoding.</p>
<p><strong>Example:</strong> <code class="docutils literal"><span class="pre">f</span> <span class="pre">=</span> <span class="pre">tokenize.open(fname)</span></code> uses PEP 263 encoding markers to
detect the encoding of Python source files (defaulting to UTF-8 if no
encoding marker is detected)</p>
<p><strong>Consequences:</strong></p>
<ul class="simple">
<li>can handle files in different encodings</li>
<li>may still raise UnicodeDecodeError if the encoding marker is incorrect</li>
<li>must ensure marker is set correctly when writing such files</li>
<li>even if it is not the default encoding, individual files can still be
set to use UTF-8 as the encoding in order to support encoding almost
all Unicode code points</li>
<li>the <code class="docutils literal"><span class="pre">surrogateescape</span></code> error handler can be used to be more tolerant of
encoding errors if it is necessary to make a best effort attempt to process
files that contain such errors instead of rejecting them outright as invalid
input.</li>
</ul>
</div>
</div>
</div>


</div></body></html>