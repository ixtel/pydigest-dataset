<html><body><div><div class="post-body entry-content" id="post-body-8112835754173496183" itemprop="description articleBody">
<div><p>
This post is about generating machine code directly and make it run in Python. (At least, </p><a href="http://nickdesaulniers.github.io/blog/2014/04/18/lets-write-some-x86-64/">i'm not the first one</a><p> to do something similar.) Since we've left any hope for portability by using machine code, we'll support </p><i>my</i><p> processor, which implements the (not so pretty) standard </p><a href="http://en.wikipedia.org/wiki/X86-64">x86-64 instruction set</a><p>.</p></div>
<h3>
Jumping down the abstraction layers</h3>
<div>
<div><p>
First of all, how do you even execute arbitrary x86-64 instructions in Python? (Note: doing it in Python is mandatory, mainly because I want it to. And it's simpler to develop and debug.) Well, diving into the </p><a href="https://docs.python.org/3/library/ctypes.html">ctypes module</a><p> gives us half the answer: we can write a byte string that contains the executable code and then cast it into a </p><a href="https://docs.python.org/3/library/ctypes.html#ctypes.CFUNCTYPE">CFUNCTYPE</a><p> object.</p></div>
</div>

<div>
<div><p>
But an portability issue arises. CFUNCTYPE states that it will call the function using the standard C convention (what we call an ABI)... But </p><a href="http://en.wikipedia.org/wiki/X86_calling_conventions">which x86 calling convention</a><p>? The answer is: the one that is used by the compiler with which Python was compiled. Luckily, most x86-64 calling conventions (there are two: </p><a href="http://msdn.microsoft.com/en-us/library/ms235286.aspx">Microsoft-flavored</a><p> for Windows-based systems and </p><a href="http://www.x86-64.org/documentation/abi.pdf">System V-flavored</a><p> for anything else) are pretty similar. Another lucky fact: we only have to take care of the volatile registers and the parameter passing registers and return registers.</p></div>
</div>

<div>
<div><p>
Next, we must know the machine code that does what we want. It is worth noting that an </p><a href="http://gcc.godbolt.org/">interactive compiler</a><p> and an </p><a href="https://defuse.ca/online-x86-assembler.htm#disassembly">online assembler</a><p> are useful to generate the machine code sequence. The same output is achieved using gcc to compile a file containing a simple function as such:</p></div>
<div class="gistLoad" data-id="340c0d948620ce463683" id="gist-340c0d948620ce463683">
<p>
Loading... Please enable Javascript</p>
</div>
<div><p>
Note that this invocation of gcc won't execute the linker, so every call, jump or other reference to a label (an address) won't be defined - they will be set to 0. This won't hinder us as our addresses won't be the same as the sample C code anyway. To better understand what we are dealing with, it is possible to check out the opcodes in an </p><a href="http://ref.x86asm.net/coder.html">an x86-64 opcode reference chart</a><p>, or the </p><a href="http://www.intel.com/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-software-developer-manual-325462.pdf">intel architecture software developer manual</a><p> if the gory details are needed.</p></div>
<p>
<br/></p>
<p>
Ok, everything should be fine now! Let's try to cast a simple return. This operands only returns from a function call without doing anything.</p>
<div class="gistLoad" data-id="fbda329a1b78f1188bab" id="gist-fbda329a1b78f1188bab">
<p>
Loading... Please enable Javascript</p>
</div>
<p>
And... That gives a segmentation fault.</p>
<p>
<br/></p>
<div><p>
Which is pretty logical: the string is contained in a segment of the memory that have the read and write flags, but not the execution flag. Luckily, this particular problem was </p><a href="http://stackoverflow.com/questions/275207/python-ctypes-and-function-calls">solved on stackoverflow</a><p>. This gives us the following (x86-64 Linux only) code:</p></div>
<div class="gistLoad" data-id="d936ad17913d2636810f" id="gist-d936ad17913d2636810f">
<p>
Loading... Please enable Javascript</p>
</div>
<p>
At last, it works! Or, at least, doesn't explode upon execution.</p>
<p>
<br/></p>
<div><p>
So, basically, if I want to perform an addition, </p><a href="https://docs.python.org/3/library/ctypes.html#ctypes.CFUNCTYPE">the documentation</a><p> says to interface the "C function" this way (to replace the end of the previous code snippet):</p></div>
</div>
<div class="gistLoad" data-id="8a5a15bbe3853a4ffeb6" id="gist-8a5a15bbe3853a4ffeb6">
<p>
Loading... Please enable Javascript</p>
</div>
<div>
<p>
Great, it works! But how did we come up with the machine code f2 0f 58 c1 c3 ? (the prefix \x before every byte is only to signify to Python that it's hexadecimal.) Here we go:</p>
</div>
<div class="gistLoad" data-id="8e94a42d46cc6d616ace" id="gist-8e94a42d46cc6d616ace">
<p>
Loading... Please enable Javascript</p>
</div>
<h3>
The missing link</h3>
<div><p>
Now that the hassle of explaining evolutionary algorithms, genetic programming and their need for fast execution </p><a href="http://multigrad.blogspot.ca/2014/06/fun-with-python-bytecode.html">has been done by my colleague</a><p>, let's push it a step further using the aforementioned notions . Marc-André brought you on the edge of the cliff; we'll now take a big step forward. While he used Python bytecode, which is an awesome and versatile idea that supports any hardware for which Python was ported, we'll use machine code.</p></div>
<p>
<br/></p>
<p>
Now that we know how we are going to execute arbitrary machine code, we can focus on the problem beforehand: generate machine code from a program tree. Let's take for example the tree for the equation <span>$ (x - 1) + 4 $ :</span></p>
<p>
<br/></p>
<p>
<br/></p>

<p class="separator">
Figure 1: Example of the tree representing the expression $ (x - 1) + 4 $.</p>
<p>
<br/></p>
<p>
Since the processor execution is based on a stack, the easiest way to traverse this three is depth-first. Indeed, by appending every node of the tree when traversing depth-first, it generates the inverted order of execution of the tree. Here's how it works:</p>


<p class="separator">
Figure 2: Example of depth-first traversing with call stack</p>
<p>
<br/></p>
<p>
As we traverse the tree, we pile up the calls or parameters on the stack. As you can see from the figure, it generates a call stack that, when executed bottom-up, is exactly the order that the x86_64 processor needs. We notice that it is different from the Python bytecode stack Marc-André showed: arguments positions are reversed and <span>LOAD_GLOBAL </span>is replaced by the call to the function.</p>
<p>
<br/></p>
<p>
All that seems well, but there is a problem. x86_64 calling convention passes the floating-point parameters of a function on XMM0, XMM1, XMM2 and so on. These registers are volatile, meaning that their content may well be modified when we call a function. Let's take the tree showed in the previous figure for the sake of example and assume we're dealing with floats. X will be put on XMM0, 1.0f on XMM1 and <span>sub()</span><span> will be called. This call will return its result on XMM0. Perfect, that's where we want our first argument for the call to </span><span>add()</span><span>, along with 4.0f previously put in XMM1. Uh-oh. </span><span>sub()</span> needs 1.0f in XMM1 while <span>add()</span> needs 4.0f. This can be visualized here:</p>



<table class="data-table">
    <tbody>
<tr>
        <th class="border-top border-bottom border-left border-right">Instruction</th>
        <th class="border-top border-bottom border-right centered-text">XMM0</th>
        <th class="border-top border-bottom border-right centered-text">XMM1</th>
    </tr>
<tr>
        <td class="border-bottom border-left border-right">Put 4.0f in XMM1</td>
        <td class="border-bottom border-right centered-text">-</td>
        <td class="border-bottom border-right centered-text">4.0f</td>
    </tr>
<tr>
        <td class="border-bottom border-left border-right">Put 1.0f in XMM1</td>
        <td class="border-bottom border-right centered-text">-</td>
        <td class="border-bottom border-right centered-text">1.0f</td>
    </tr>
<tr>
        <td class="border-bottom border-left border-right">Put x in XMM0</td>
        <td class="border-bottom border-right centered-text">x</td>
        <td class="border-bottom border-right centered-text">1.0f</td>
    </tr>
<tr>
        <td class="border-bottom border-left border-right">Call sub()</td>
        <td class="border-bottom border-right centered-text">x - 1.0f</td>
        <td class="border-bottom border-right centered-text">1.0f (?)</td>
    </tr>
<tr>
        <td class="border-bottom border-left border-right">Call add()</td>
        <td class="border-bottom border-right centered-text">(x - 1.0f) + ?</td>
        <td class="border-bottom border-right centered-text">1.0f (?)</td>
    </tr>
</tbody></table>
<p>
<br/></p>
<div><p>
You'll probably say "hey, this is easy, simply put node 5 before node 2, problem solved!" Don't. Do. That. </p><a href="http://www.amazon.com/Haribo-Gummi-Bears-Sugar-Free/product-reviews/B000EVQWKC">All hell will break loose</a><p> and </p><a href="http://www.youtube.com/watch?v=MaYmZ5mw0DM#t=168">you will not enjoy this</a><p>. This kind of tweaking will lead you to hours and hours of wondering why it works in some cases but won't in such or such cases. (Says the guy who produces executable machine code in Python.) As I said earlier: this should be simple, an x86_64 CPU is based on a stack! Let's use it! We'll simply push every argument needed on the CPU stack when we traverse its node and then pop it back when it's needed. If we feel adventurous, we realize that the first argument (next node after a call) won't need to push/pop if the arguments are compatible: the result will already be in XMM0 (for floats and doubles), ready to be used. This gives us this:</p></div>
<table class="data-table">
    <tbody>
<tr>
        <th class="border-top border-bottom border-left border-right">Instruction</th>
        <th class="border-top border-bottom border-right centered-text">XMM0</th>
        <th class="border-top border-bottom border-right centered-text">XMM1</th>
    </tr>
<tr>
        <td class="border-bottom border-left border-right">Push 4.0f on stack</td>
        <td class="border-bottom border-right centered-text">-</td>
        <td class="border-bottom border-right centered-text">-</td>
    </tr>
<tr>
        <td class="border-bottom border-left border-right">Push 1.0f on stack</td>
        <td class="border-bottom border-right centered-text">-</td>
        <td class="border-bottom border-right centered-text">-</td>
    </tr>
<tr>
        <td class="border-bottom border-left border-right">Put x in XMM0</td>
        <td class="border-bottom border-right centered-text">x</td>
        <td class="border-bottom border-right centered-text">-</td>
    </tr>
<tr>
        <td class="border-bottom border-left border-right">Pop stack in XMM1</td>
        <td class="border-bottom border-right centered-text">x</td>
        <td class="border-bottom border-right centered-text">1.0f</td>
    </tr>
<tr>
        <td class="border-bottom border-left border-right">Call sub()</td>
        <td class="border-bottom border-right centered-text">x - 1.0f</td>
        <td class="border-bottom border-right centered-text">?</td>
    </tr>
<tr>
        <td class="border-bottom border-left border-right">Pop stack in XMM1</td>
        <td class="border-bottom border-right centered-text">x - 1.0f</td>
        <td class="border-bottom border-right centered-text">4.0f</td>
    </tr>
<tr>
        <td class="border-bottom border-left border-right">Call add()</td>
        <td class="border-bottom border-right centered-text">(x - 1.0f) + 4.0f</td>
        <td class="border-bottom border-right centered-text">?</td>
    </tr>
</tbody></table>
<p>
<br/></p>
<p>
As we can see, this generates quite a lot of unnecessary pushes (for example argument 2 of <span>sub()</span>). Eliminating these unnecessary stack usage is a potential optimization that we may discuss in another article.</p>
<p>
<br/></p>
<div><p>
Before rambling into a </p><i>non sequitur</i><p> madness of idea flow almost disconnected from the subject, I'll present you the symbolic regression program with individuals evaluated in x86_64 machine code using </p><a href="https://github.com/DEAP/deap">deap</a><p>. It is located </p><a href="https://gist.github.com/soravux/1fe0992a79fc07a23d27">here</a><p>. Feel free to fork it, mess with it and be curious around it.</p></div>
<p>
<br/></p>
<div><p>
I haven't implemented the division (had to deal with divisions by zeros) nor cos / sin, but feel free to be </p><a href="http://gamedev.stackexchange.com/questions/4779/is-there-a-faster-sine-function">inspired</a><p> and fork the code!</p></div>
<p>
<br/></p>
<div><p>
You may be tempted to print out the machine code generated and understand it. To better understand it, it is possible to copy it in an </p><a href="http://onlinedisassembler.com/odaweb/">online disassembler</a><p> which will provide the almost human-readable assembly translation.</p></div>
<h3>
To the Infinity and beyond</h3>
<div><p>
In the context of genetic programming, a way better idea than generating the machine code at each evaluation as the previous example did is to represent the individuals in deap as its machine code and evolve it. It's not that I am wary of the tortuous path toward a stable implementation of this representation. It would require the writing of a mutation and crossover function which needs pointers to mark the beginning and end of each node in the machine code representation. No, the only reason I don't dig further in this </p><a href="http://www.youtube.com/watch?v=FWBUl7oT9sA&amp;feature=kp">general direction</a><p> is because I won't offend you by serving some old reheated matter. Marc-André already showed how it's done </p><a href="http://multigrad.blogspot.ca/2014/06/fun-with-python-bytecode.html">in its previous post</a><p>. (This has also nothing to do with the fact that it's an unmaintainable piece of code that won't ever be published as-is in a working project.)
</p><p>
At first, this proposed idea was tagged "useless waste of time" by colleagues and friends. But as the idea developed, we realized it could be used to circumvent security features. Calling obscure opcodes, low-level functions, software interruptions or similar are now available directly in pure Python. Furthermore, it would enable the execution of dynamic libraries that are not flagged as executable. You only have to read the exported symbols of a .so library, load them in memory, apply this method and </p><i>voilà</i><p>, you can execute its functions.</p></div>
<p>
<br/></p>
<div><p>
An interesting lead from this point is to make a compiler for generic Python functions. Some </p><a href="https://github.com/eliben/pycparser">pretty module</a><p> would get us near a C compiler, but I won't insult the dedication and hard work of Donald Knuth by proposing half an article written on a napkin on compiler creation. But I don't mind being familiar and even </p><i>tutoyer</i><p> Python optimizations packages. Can we perform better than </p><a href="http://numba.pydata.org/">Numba</a><p> or even </p><a href="http://cython.org/">Cython</a><p> and </p><a href="http://pypy.org/">PyPy</a><p>? Stay tuned for Part II were we'll try as-generic-as-possible Python-to-Machine-Code translation.</p></div>
<p>
<br/></p>
<p>
<br/></p>
<p>
<br/></p>
<h3>
</h3>
<p/>
</div>
</div></body></html>