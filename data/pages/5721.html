<html><body><div><div class="starter-template">
          <div class="post-title">
  
    
  
  
  
  <h1>Switching Eds: Face swapping with Python, dlib, and OpenCV</h1>
  
  
</div>

<p><img src="/assets/switching-eds/header.jpg" alt="Header" class="img-responsive"/></p>

<p><sup><a href="#image_credits">Image credit</a></sup></p>

<h2 id="introduction">Introduction</h2>

<p>In this post I’ll describe how I wrote a short (200 line) Python script to
automatically replace facial features on an image of a face, with the facial
features from a second image of a face.</p>

<p>The process breaks down into four steps:</p>

<ul>
  <li>Detecting facial landmarks.</li>
  <li>Rotating, scaling, and translating the second image to fit over the first.</li>
  <li>Adjusting the colour balance in the second image to match that of the first.</li>
  <li>Blending features from the second image on top of the first.</li>
</ul>

<p>The full source-code for the script can be <a href="https://github.com/&#10;matthewearl/faceswap/blob/master/faceswap.py">found here</a>.</p>

<h2 id="using-dlib-to-extract-facial-landmarks">1. Using dlib to extract facial landmarks</h2>

<p>The script uses <a href="http://dlib.net/">dlib</a>’s Python bindings to extract facial
landmarks:</p>

<p><img src="/assets/switching-eds/landmarks.jpg" alt="Landmarks" class="img-responsive"/></p>

<p><sup><a href="#image_credits">Image credit</a></sup></p>

<p>Dlib implements the algorithm described in the paper <a href="http://www.csc.kth.se/~vahidk/papers/KazemiCVPR14.pdf">One Millisecond Face
Alignment with an Ensemble of Regression Trees</a>, by Vahid Kazemi and
Josephine Sullivan. The algorithm itself is very complex, but dlib’s interface
for using it is incredibly simple:</p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">PREDICTOR_PATH</span> <span class="o">=</span> <span class="s">"/home/matt/dlib-18.16/shape_predictor_68_face_landmarks.dat"</span>

<span class="n">detector</span> <span class="o">=</span> <span class="n">dlib</span><span class="o">.</span><span class="n">get_frontal_face_detector</span><span class="p">()</span>
<span class="n">predictor</span> <span class="o">=</span> <span class="n">dlib</span><span class="o">.</span><span class="n">shape_predictor</span><span class="p">(</span><span class="n">PREDICTOR_PATH</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">get_landmarks</span><span class="p">(</span><span class="n">im</span><span class="p">):</span>
    <span class="n">rects</span> <span class="o">=</span> <span class="n">detector</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">rects</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">TooManyFaces</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">rects</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">NoFaces</span>

    <span class="k">return</span> <span class="n">numpy</span><span class="o">.</span><span class="n">matrix</span><span class="p">([[</span><span class="n">p</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">y</span><span class="p">]</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">predictor</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">rects</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">parts</span><span class="p">()])</span></code></pre></div>

<p>The function <code>get_landmarks()</code> takes an image in the form of a numpy array, and
returns a 68x2 element matrix, each row of which corresponding with the
x, y coordinates of a particular feature point in the input image.</p>

<p>The feature extractor (<code>predictor</code>) requires a rough bounding box as input to
the algorithm. This is provided by a traditional face detector (<code>detector</code>)
which returns a list of rectangles, each of which corresponding with a face in
the image.</p>

<p>To make the predictor a pre-trained model is required. Such a model can be
<a href="http://sourceforge.net/&#10;projects/dclib/files/dlib/v18.10/shape_predictor_68_face_landmarks.dat.bz2">downloaded from the dlib sourceforge repository</a>.</p>

<h2 id="aligning-faces-with-a-procrustes-analysis">2. Aligning faces with a procrustes analysis</h2>

<p>So at this point we have our two landmark matrices, each row having coordinates
to a particular facial feature (eg. the 30th row gives the coordinates of the
tip of the nose). We’re now going to work out how to rotate, translate, and
scale the points of the first vector such that they fit as closely as possible
to the points in the second vector, the idea being that the same transformation
can be used to overlay the second image over the first.</p>

<p>To put it more mathematically, we seek \( T \), \( s \), and \( R \) such
that:</p>



<p>is minimized, where \( R \) is an orthogonal 2x2 matrix, \( s \) is a
scalar, \( T \) is a 2-vector, and \( p_i \) and \( q_i \) are the rows
of the landmark matrices calculated above.</p>

<p>It turns out that this sort of problem can be solved with an
<a href="https://en.wikipedia.org/wiki/&#10;Procrustes_analysis#Ordinary_Procrustes_analysis">Ordinary Procrustes Analysis</a>:</p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">transformation_from_points</span><span class="p">(</span><span class="n">points1</span><span class="p">,</span> <span class="n">points2</span><span class="p">):</span>
    <span class="n">points1</span> <span class="o">=</span> <span class="n">points1</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="n">points2</span> <span class="o">=</span> <span class="n">points2</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="n">c1</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">points1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">c2</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">points2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">points1</span> <span class="o">-=</span> <span class="n">c1</span>
    <span class="n">points2</span> <span class="o">-=</span> <span class="n">c2</span>

    <span class="n">s1</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">points1</span><span class="p">)</span>
    <span class="n">s2</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">points2</span><span class="p">)</span>
    <span class="n">points1</span> <span class="o">/=</span> <span class="n">s1</span>
    <span class="n">points2</span> <span class="o">/=</span> <span class="n">s2</span>

    <span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">Vt</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">points1</span><span class="o">.</span><span class="n">T</span> <span class="o">*</span> <span class="n">points2</span><span class="p">)</span>
    <span class="n">R</span> <span class="o">=</span> <span class="p">(</span><span class="n">U</span> <span class="o">*</span> <span class="n">Vt</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>

    <span class="k">return</span> <span class="n">numpy</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">numpy</span><span class="o">.</span><span class="n">hstack</span><span class="p">(((</span><span class="n">s2</span> <span class="o">/</span> <span class="n">s1</span><span class="p">)</span> <span class="o">*</span> <span class="n">R</span><span class="p">,</span>
                                       <span class="n">c2</span><span class="o">.</span><span class="n">T</span> <span class="o">-</span> <span class="p">(</span><span class="n">s2</span> <span class="o">/</span> <span class="n">s1</span><span class="p">)</span> <span class="o">*</span> <span class="n">R</span> <span class="o">*</span> <span class="n">c1</span><span class="o">.</span><span class="n">T</span><span class="p">)),</span>
                         <span class="n">numpy</span><span class="o">.</span><span class="n">matrix</span><span class="p">([</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">])])</span></code></pre></div>

<p>Stepping through the code:</p>

<ol>
  <li>Convert the input matrices into floats. This is required for the operations
that are to follow.</li>
  <li>Subtract the centroid form each of the point sets. Once an optimal scaling
and rotation has been found for the resulting point sets, the centroids <code>c1</code>
and <code>c2</code> can be used to find the full solution.</li>
  <li>Similarly, divide each point set by its standard deviation. This removes the
scaling component of the problem.</li>
  <li>Calculate the rotation portion using the <a href="https://en.wikipedia.org/wiki/Singular_value_decomposition">Singular Value
Decomposition</a>.
See the wikipedia article on the <a href="https://en.wikipedia.org/wiki/Orthogonal_Procrustes_problem">Orthogonal Procrustes Problem</a> for details of
how this works.</li>
  <li>Return the complete transformaton as an <a href="https://en.wikipedia.org/wiki/Transformation_matrix#Affine_transformations">affine transformation matrix</a>.</li>
</ol>

<p>The result can then be plugged into OpenCV’s <code>cv2.warpAffine</code> function to map
the second image onto the first:</p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">warp_im</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">dshape</span><span class="p">):</span>
    <span class="n">output_im</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">dshape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">im</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">cv2</span><span class="o">.</span><span class="n">warpAffine</span><span class="p">(</span><span class="n">im</span><span class="p">,</span>
                   <span class="n">M</span><span class="p">[:</span><span class="mi">2</span><span class="p">],</span>
                   <span class="p">(</span><span class="n">dshape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">dshape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
                   <span class="n">dst</span><span class="o">=</span><span class="n">output_im</span><span class="p">,</span>
                   <span class="n">borderMode</span><span class="o">=</span><span class="n">cv2</span><span class="o">.</span><span class="n">BORDER_TRANSPARENT</span><span class="p">,</span>
                   <span class="n">flags</span><span class="o">=</span><span class="n">cv2</span><span class="o">.</span><span class="n">WARP_INVERSE_MAP</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">output_im</span></code></pre></div>

<p>Which produces the following alignment:</p>

<p><img src="/assets/switching-eds/aligned-faces.gif" alt="Aligned faces" class="img-responsive"/></p>

<p><sup><a href="#image_credits">Image credit</a></sup></p>

<h2 id="colour-correcting-the-second-image">3. Colour correcting the second image</h2>

<p>If we tried to overlay facial features at this point, we’d soon see we have a
problem:</p>

<p><img src="/assets/switching-eds/non-colour-corrected-overlay.jpg" alt="Non colour-corrected overlay" class="img-responsive"/></p>

<p><sup><a href="#image_credits">Image credit</a></sup></p>

<p>The issue is that differences in skin-tone and lighting between the two images
is causing a discontinuity around the edges of the overlaid region. Let’s try
to correct that:</p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">COLOUR_CORRECT_BLUR_FRAC</span> <span class="o">=</span> <span class="mf">0.6</span>
<span class="n">LEFT_EYE_POINTS</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">42</span><span class="p">,</span> <span class="mi">48</span><span class="p">))</span>
<span class="n">RIGHT_EYE_POINTS</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">36</span><span class="p">,</span> <span class="mi">42</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">correct_colours</span><span class="p">(</span><span class="n">im1</span><span class="p">,</span> <span class="n">im2</span><span class="p">,</span> <span class="n">landmarks1</span><span class="p">):</span>
    <span class="n">blur_amount</span> <span class="o">=</span> <span class="n">COLOUR_CORRECT_BLUR_FRAC</span> <span class="o">*</span> <span class="n">numpy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span>
                              <span class="n">numpy</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">landmarks1</span><span class="p">[</span><span class="n">LEFT_EYE_POINTS</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">-</span>
                              <span class="n">numpy</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">landmarks1</span><span class="p">[</span><span class="n">RIGHT_EYE_POINTS</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
    <span class="n">blur_amount</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">blur_amount</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">blur_amount</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">blur_amount</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">im1_blur</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">GaussianBlur</span><span class="p">(</span><span class="n">im1</span><span class="p">,</span> <span class="p">(</span><span class="n">blur_amount</span><span class="p">,</span> <span class="n">blur_amount</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">im2_blur</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">GaussianBlur</span><span class="p">(</span><span class="n">im2</span><span class="p">,</span> <span class="p">(</span><span class="n">blur_amount</span><span class="p">,</span> <span class="n">blur_amount</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>

    <span class="c"># Avoid divide-by-zero errors.</span>
    <span class="n">im2_blur</span> <span class="o">+=</span> <span class="mi">128</span> <span class="o">*</span> <span class="p">(</span><span class="n">im2_blur</span> <span class="o">&lt;=</span> <span class="mf">1.0</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">(</span><span class="n">im2</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span> <span class="o">*</span> <span class="n">im1_blur</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span> <span class="o">/</span>
                                                <span class="n">im2_blur</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">))</span></code></pre></div>

<p>And the result:</p>

<p><img src="/assets/switching-eds/colour-corrected.jpg" alt="Colour corrected" class="img-responsive"/></p>

<p><sup><a href="#image_credits">Image credit</a></sup></p>

<p>This function attempts to change the colouring of <code>im2</code> to match that of <code>im1</code>.
It does this by dividing <code>im2</code> by a gaussian blur of <code>im2</code>, and then
multiplying by a gaussian blur of <code>im1</code>. The idea here is that of a <a href="https://en.wikipedia.org/wiki/Color_balance#&#10;Scaling_monitor_R.2C_G.2C_and_B">RGB
scaling
colour-correction</a>, but instead of a constant scale factor across
all of the image, each pixel has its own localised scale factor.</p>

<p>With this approach differences in lighting between the two images can be
accounted for, to some degree. For example, if image 1 is lit from one side
but image 2 has uniform lighting then the colour corrected image 2 will 
appear darker on the unlit side aswell.</p>

<p>That said, this is a fairly crude solution to the problem and an appropriate
size gaussian kernel is key. Too small and facial features from the first
image will show up in the second. Too large and kernel strays outside of the
face area for pixels being overlaid, and discolouration occurs. Here a kernel
of 0.6 * the pupillary distance is used.</p>

<h2 id="blending-features-from-the-second-image-onto-the-first">4. Blending features from the second image onto the first</h2>

<p>A mask is used to select which parts of image 2 and which parts of image 1
should be shown in the final image:</p>

<p><img src="/assets/switching-eds/mask.png" alt="Mask" class="img-responsive"/></p>

<p>Regions with value 1 (shown white here) correspond with areas where image 2
should show, and regions with colour 0 (shown black here) correspond with areas
where image 1 should show. Value in between 0 and 1 correspond with a mixture
of image 1 and image2.</p>

<p>Here’s the code to generate the above:</p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">LEFT_EYE_POINTS</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">42</span><span class="p">,</span> <span class="mi">48</span><span class="p">))</span>
<span class="n">RIGHT_EYE_POINTS</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">36</span><span class="p">,</span> <span class="mi">42</span><span class="p">))</span>
<span class="n">LEFT_BROW_POINTS</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">22</span><span class="p">,</span> <span class="mi">27</span><span class="p">))</span>
<span class="n">RIGHT_BROW_POINTS</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">17</span><span class="p">,</span> <span class="mi">22</span><span class="p">))</span>
<span class="n">NOSE_POINTS</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">27</span><span class="p">,</span> <span class="mi">35</span><span class="p">))</span>
<span class="n">MOUTH_POINTS</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">48</span><span class="p">,</span> <span class="mi">61</span><span class="p">))</span>
<span class="n">OVERLAY_POINTS</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">LEFT_EYE_POINTS</span> <span class="o">+</span> <span class="n">RIGHT_EYE_POINTS</span> <span class="o">+</span> <span class="n">LEFT_BROW_POINTS</span> <span class="o">+</span> <span class="n">RIGHT_BROW_POINTS</span><span class="p">,</span>
    <span class="n">NOSE_POINTS</span> <span class="o">+</span> <span class="n">MOUTH_POINTS</span><span class="p">,</span>
<span class="p">]</span>
<span class="n">FEATHER_AMOUNT</span> <span class="o">=</span> <span class="mi">11</span>

<span class="k">def</span> <span class="nf">draw_convex_hull</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">points</span><span class="p">,</span> <span class="n">color</span><span class="p">):</span>
    <span class="n">points</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">convexHull</span><span class="p">(</span><span class="n">points</span><span class="p">)</span>
    <span class="n">cv2</span><span class="o">.</span><span class="n">fillConvexPoly</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">points</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">get_face_mask</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">landmarks</span><span class="p">):</span>
    <span class="n">im</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">im</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">OVERLAY_POINTS</span><span class="p">:</span>
        <span class="n">draw_convex_hull</span><span class="p">(</span><span class="n">im</span><span class="p">,</span>
                         <span class="n">landmarks</span><span class="p">[</span><span class="n">group</span><span class="p">],</span>
                         <span class="n">color</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">im</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">im</span><span class="p">,</span> <span class="n">im</span><span class="p">,</span> <span class="n">im</span><span class="p">])</span><span class="o">.</span><span class="n">transpose</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>

    <span class="n">im</span> <span class="o">=</span> <span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">GaussianBlur</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="p">(</span><span class="n">FEATHER_AMOUNT</span><span class="p">,</span> <span class="n">FEATHER_AMOUNT</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.0</span>
    <span class="n">im</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">GaussianBlur</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="p">(</span><span class="n">FEATHER_AMOUNT</span><span class="p">,</span> <span class="n">FEATHER_AMOUNT</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">im</span>

<span class="n">mask</span> <span class="o">=</span> <span class="n">get_face_mask</span><span class="p">(</span><span class="n">im2</span><span class="p">,</span> <span class="n">landmarks2</span><span class="p">)</span>
<span class="n">warped_mask</span> <span class="o">=</span> <span class="n">warp_im</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">im1</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">combined_mask</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">max</span><span class="p">([</span><span class="n">get_face_mask</span><span class="p">(</span><span class="n">im1</span><span class="p">,</span> <span class="n">landmarks1</span><span class="p">),</span> <span class="n">warped_mask</span><span class="p">],</span>
                          <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></code></pre></div>

<p>Let’s break this down:</p>

<ul>
  <li>A routine <code>get_face_mask()</code> is defined to generate a mask for an image and a
landmark matrix. It draws two convex polygons in white: One surrounding the
eye area, and one surrounding the nose and mouth area. It then feathers the
edge of the mask outwards by 11 pixels. The feathering helps hide any
remaning discontinuities.</li>
  <li>Such a face mask is generated for both images. The mask for the second is
transformed into image 1’s coordinate space, using the same transformation as
in step 2.</li>
  <li>The masks are then combined into one by taking an element-wise maximum.
Combining both masks ensures that the features from image 1 are covered up,
and that the features from image 2 show through.</li>
</ul>

<p>Finally, the mask is applied to give the final image:</p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">output_im</span> <span class="o">=</span> <span class="n">im1</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">combined_mask</span><span class="p">)</span> <span class="o">+</span> <span class="n">warped_corrected_im2</span> <span class="o">*</span> <span class="n">combined_mask</span></code></pre></div>

<p><img src="/assets/switching-eds/final.jpg" alt="Final" class="img-responsive"/></p>

<p><sup><a href="#image_credits">Image credit</a></sup></p>

<h2 id="credits">Credits</h2>

<p><a id="image_credits"/>
<a href="https://commons.wikimedia.org/&#10;wiki/File:Ed_Miliband.jpg">Original Ed Miliband image</a> by the Department of Energy, licensed under the 
<a href="https://www.nationalarchives.gov.uk/doc/&#10;open-government-licence/version/1/">Open Government License v1.0</a>.</p>

<p><a href="https://&#10;commons.wikimedia.org/wiki/File:Eddie_Van_Halen_(1993).jpg">Original Eddie Van Halen image</a> by Alan Light,
licensed under the <a href="https://&#10;creativecommons.org/licenses/by/2.0/deed.en">Creative Commons Attribution 2.0 Generic license</a></p>

          <hr/>
          
          
          

          
            <nav>
              
            </nav>
          
          











      </div>
    </div></body></html>