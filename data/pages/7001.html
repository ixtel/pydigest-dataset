<html><body><div><div class="content html_format">
      <img alt="Попробуй выбери, какая их них лучше? :)" title="Попробуй выбери, какая их них лучше? :)" src="https://habrastorage.org/files/d32/920/b51/d32920b513b149649fdaf96d38b1f772.jpg"/>
<p>
Пошел я как-то на курсы по BigData, по рекомендации друзей и мне посчастливилось поучаствовать в соревновании. Не буду рассказывать об обучении на курсе, а расскажу о библиотеке </p><a href="http://www.mymedialite.net/">MyMediaLite</a><p> на .Net и о том, как я ее использовал.
</p><a name="habracut"/>
<h4>Прелюдие</h4><p>
На носу была завершающая лабораторная работа. В течении всего курса не особо вступал в конкуренцию на лабораторных работах, ближе к концу жизнь заставила побороться — чтобы получить сертификат, надо было зарабатывать баллы. Последняя лекция была не сильно информативная, скорее обзорная и я решил не терять время, параллельно заняться последней лабкой. К сожалению, у меня не было на тот момент, своего кластера с установленным Apache Spark. На учебном кластере, так как все ринулись делать лабораторную, шансов и ресурсов на успех оставалось мало. Мой выбор пал на </p><a href="http://www.mymedialite.net/">MyMediaLite</a><p> на C#.Net. К счастью, был рабочий сервак, не сильно загруженный и выделенный для экспериментов, довольно неплохой, с двумя процами и 16 Gb оперативной памяти.

</p><h4>Условия задачи</h4><p>
Нам были предоставлены следующие данные: 

</p><ul>
<li>таблица рейтингов фильмов <b>train.csv</b> (поля userId,movieId,rating,timestamp). На растерзание отдается добрая половина выборки (произвольно отсортированная по movieId и userId), вторая половина остается у супервизора курса, для оценки качества рекомендательной системы</li>
<li>таблица <b>tags.csv</b> (поля userId,movieId,tag,timestamp) с тэгами к фильмам</li>
<li>таблица <b>movies.csv</b> (поля movieId,title,genres) с названием фильма и его жанром</li>
<li>таблица <b>links.csv</b> (поля movieId,imdbId,tmdbId) соответствие идентификатора фильма в базах данных imdb и themoviedb (там можно найти дополнительные характеристики фильмов)</li>
<li>таблица <b>test.csv</b> (поля userId, movieId и rating) собственно, вторая половина выборки, но без рейтингов.</li>
</ul><p>
Необходимо предсказать рейтинги фильмов в таблице test.csv, сформировать результирующий файл, который содержит данные в формате: userId, movieId, rating и залить в чекер. Качество рекомендаций будет оцениваться по </p><a href="https://en.wikipedia.org/wiki/Root-mean-square_deviation">RMSE</a><p> и оно должно быть не хуже (значит не более) 0.9 для зачета. Далее будет идти борьба за лучший результат.
</p><p>
Все файлы данных доступны тут </p><a href="https://goo.gl/iVEbfA">https://goo.gl/iVEbfA</a><p>
Отличная статья про то, как считать </p><a href="http://www.australianweathernews.com/verify/example.htm">RMSE</a>

<h4>Мое решение</h4><p>
Последний вариант </p><a href="https://github.com/nodirmcsd/lab10">кода</a><p> доступен в гихабе.
</p><p>
Ну кто же в бой идет без разведки? Были получены «разведывательные данные» на перерывах лекций и оказалось, что нам подсунули :) пресловутый </p><a href="http://grouplens.org/datasets/movielens/">movielens 1m</a><p>, с подмешиванием какого-то другого набора данных. Те, кто уже справился с лабой хвалили </p><a href="https://en.wikipedia.org/wiki/Singular_value_decomposition">SVD</a><p>++.
</p><p>
Как правило, любое машинное обучение состоит из трех частей:

</p><ul>
<li>Representation</li>
<li>Evaluation </li>
<li>Optimization</li>
</ul><p>
Я тоже пошел по этому пути и разделил выборку на две части, 70% и 30% соответственно. Вторая часть выборки нужна для проверки точности модели. Был написан самый первый вариант кода, по результатам которого лабораторная работа была успешно сдана. Результат </p><i>0.880360573502</i><p> на модели </p><i>BiasedMatrixFactorization</i><p>. Всю мишуру с тегами и линками отмёл сразу, они могли быть использованы в виде дополнительных фич, для получения лучшего результата. Не стал тратить на это время и это было верным решением, IMHO. Отсутствовавшие в обучающей выборке пользователи тоже были смело проигнорированы, а рейтинги были проставлены неизвестными значениями, которые возвращал класс BiasedMatrixFactorization. Эта была серьезная ошибка, которая стоила мне первого места. На модели </p><i>SVD++</i><p>, был получен результат </p><i>0.872325203952</i><p>. Чекер показывал первое место и я со спокойной душой, репетируя речь победителя пошел спать. Но, как говорится, цыплят считают по осени. 

</p><h4>Итоги соревнования</h4><p>
Буду краток, победное место переходило из рук в руки несколько раз. В итоге, на момент дедлайна мой товарищ получил первое место, а я — второе. Мы, программеры — упрямый народ, удалось все-таки выжать лучший результат на </p><i>BiasedMatrixFactorization</i><p>. Увы после дедлайна.

</p><img src="https://habrastorage.org/files/1b0/b7f/124/1b0b7f12481e4383a7c1540c81e318c6.png" alt="image"/>

<h4>Альтернативное решение</h4><p>
Мой товарищ  </p><a href="http://habrahabr.ru/users/wenk/" class="user_link">wenk</a><p>, получивший первое место, любезно согласился предоставить свой код. Его решение было реализовано на кластере с Apache Spark, используя ALS из scikit-learn. 

</p><pre><code class="python"># coding: utf-8
# In[1]:
import os
import sys
os.environ["PYSPARK_SUBMIT_ARGS"]=' --driver-memory 5g --packages com.databricks:spark-csv_2.10:1.1.0  pyspark-shell'
sys.path.insert(0, os.environ.get('SPARK_HOME', None) + "/python")
import py4j
from pyspark import SparkContext,SparkConf,SQLContext
conf = (SparkConf().setMaster("spark://bd-m:7077")
    .setAppName("lab09")
    .set("spark.executor.memory", "50g")
    .set("spark.driver.maxResultSize","5g")
    .set("spark.driver.memory","2g")
    .set("spark.cores.max", "26"))
sc = SparkContext(conf=conf)
sqlCtx = SQLContext(sc)
# In[2]:
ratings_src=sc.textFile('/lab10/train.csv',26)
ratings=ratings_src.map(lambda r: r.split(",")).filter(lambda x: x[0]!='userId').map(lambda x: (int(x[0]),int(x[1]),float(x[2])))
ratings.take(5)
# In[3]:
test_src=sc.textFile('/lab10/test.csv',26)
test=test_src.map(lambda r: r.split(",")).filter(lambda x: x[0]!='userId').map(lambda x: (int(x[0]),int(x[1])))
test.take(5)
# In[4]:
from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel
from pyspark.mllib.recommendation import Rating
rat = ratings.map(lambda r: Rating(int(r[0]),int(r[1]),float(r[2])))
rat.cache()
rat.first()
# In[14]:
training,validation,testing = rat.randomSplit([0.6,0.2,0.2])
# In[15]:
print training.count()
print validation.count()
print testing.count()
# In[16]:
training.cache()
validation.cache()
# In[17]:
import math
def evaluate_model(model, dataset):
    testdata = dataset.map(lambda x: (x[0],x[1]))
    predictions = model.predictAll(testdata).map(lambda r: ((r[0], r[1]), r[2]))
    ratesAndPreds = dataset.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)
    MSE = ratesAndPreds.map(lambda r: (r[1][0] - r[1][1])**2).reduce(lambda x, y: x + y) / ratesAndPreds.count()
    RMSE = math.sqrt(MSE)
    return {'MSE':MSE, 'RMSE':RMSE}
# In[12]:
rank=20
numIterations=30
# In[28]:
model = ALS.train(training, rank, numIterations)
# In[ ]:
numIterations=30
lambda_=0.085
ps = []
for rank in range(25,500,25):
    model = ALS.train(training, rank, numIterations,lambda_)
    metrics = evaluate_model(model, validation)
    print("Rank = " + str(rank) + " MSE = " + str(metrics['MSE']) + " RMSE = " + str(metrics['RMSE']))
    ps.append((rank,metrics['RMSE']))
# In[10]:
ls = []
rank=2
numIterations = 30
for lambda_ in [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]:
    model = ALS.train(training, rank, numIterations, lambda_)
    metrics = evaluate_model(model, validation)
    print("Lambda = " + str(lambda_) + " MSE = " + str(metrics['MSE']) + " RMSE = " + str(metrics['RMSE']))
    ls.append((lambda_,metrics['RMSE']))
# In[23]:
ls = []
rank=250
numIterations = 30
for lambda_ in [0.085]:
    model = ALS.train(training, rank, numIterations, lambda_)
    metrics = evaluate_model(model, validation)
    print("Lambda = " + str(lambda_) + " MSE = " + str(metrics['MSE']) + " RMSE = " + str(metrics['RMSE']))
    ls.append((lambda_,metrics['RMSE']))
#Lambda = 0.1 MSE = 0.751080178965 RMSE = 0.866648821014
#Lambda = 0.075 MSE = 0.750219897276 RMSE = 0.866152352232
#Lambda = 0.07 MSE = 0.750033337876 RMSE = 0.866044651202
#Lambda = 0.08 MSE = 0.749335888762 RMSE = 0.865641894066
#Lambda = 0.09 MSE = 0.749929174577 RMSE = 0.865984511742
#rank 200 Lambda = 0.085 MSE = 0.709501168484 RMSE = 0.842318923261
get_ipython().run_cell_magic(u'time', u'', u'rank=400\nnumIterations=30\nlambda_=0.085\nmodel = ALS.train(rat, rank, numIterations,lambda_)\npredictions = model.predictAll(test).map(lambda r: (r[0], r[1], r[2]))')
# In[7]:
te=test.collect()
base=sorted(te,key=lambda x: x[0]*1000000+x[1])
# In[8]:
pred=predictions.collect()
# In[9]:
t_=predictions.map(lambda x: (x[0], {x[1]:x[2]})).reduceByKey(lambda a,b: dict(a.items()+b.items())).collect()
t={}
for i in t_:
    t[i[0]]=i[1]
s="userId,movieId,rating\r\n"
for i in base:
    if t.has_key(i[0]):
        u=t[i[0]]
        if u.has_key(i[1]):
            s+=str(i[0])+","+str(i[1])+","+str(u[i[1]])+"\r\n"
        else:
            s+=str(i[0])+","+str(i[1])+",3.67671059005\r\n"
    else:
        s+=str(i[0])+","+str(i[1])+",3.67671059005\r\n"
# In[12]:
text_file = open("lab10.csv", "w")
text_file.write(s)
text_file.close()
</code></pre>

<h4>Мой опыт</h4><p>
Для себя отметил некоторые факты: 

</p><ul>
<li>Всегда надо внимательно изучать данные, не «забивать на пропуски», а стараться заполнять их близкими значениями. Например, средний рейтинг по выборке вместо пустых значений, существенно улучшил результат</li>
<li>Округление результата (рейтинга) снизило точность предсказания, нежели длинный хвост</li>
<li>Лучший вариант был рассчитан на всей выборке, без валидации. Был использован метод <b>DoCrossValidation</b></li>
<li>В идеале надо было построить график зависимости параметров (количества итераций и т.п) и результата RMSE. Двигаться к победе не в слепую, а зряче</li>
<li>Apache Spark дает выигрыш по времени вычисления, так как оно идет на нескольких машинах. Если критично время — используйте спарк</li>
<li>MyMediaLite вполне себе достойная библиотека, для небольших, не критичных по времени вычисления задач. Может себя оправдать, когда невыгодно поднимать кластер со спарком</li>
</ul><p>
Ах, если бы я знал все это раньше, стал бы победителем… Признателен за ваше мнение и советы друзья, сильно не пинайте…

      
      </p><p class="clear"/>
    </div>

    
  </div></body></html>