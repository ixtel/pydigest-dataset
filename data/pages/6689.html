<html><body><div><article class="col-md-10 col-md-offset-1">
            


<p>It's been somewhat of a sharky summer these past 3 months: there were a smattering of attacks up and down the east coast of the US, professional surfer Mick Fanning, had a <a href="https://www.youtube.com/watch?v=kaoPDzRw8nQ">close call at a competition in South Africa</a>, and several beaches were closed in California after a <a href="http://www.scpr.org/news/2015/08/31/54086/shark-sightings-close-2-california-beaches-1-remai/">Great White took a bite out of a surfboard!</a> So now with the end of summer officially here (at least in the northern hemisphere), we thought it would be interesting to dig into some shark attack data.  In this post, we'll look through the <a href="http://www.sharkattackfile.net/">Global Shark Attack File</a>, checkout some of the characteristics of shark attacks and then <em>dive in</em> to some geo-plotting with Matplotlib Basemap.</p>
<p>The Github repo with relevant files for this post <a href="https://github.com/coristig/sharks">is here</a></p>
<p><img src="../static/img/shark_cover.jpg"/>
</p><center>Watch out for Landsharks!</center>
<h3>The Data</h3>
<p>Let's get a quick feel for our data.  After downloading the Excel file from the ISAF, <a href="http://www.sharkattackfile.net/spreadsheets/GSAF5.xls">available here</a> we can read in the file and start looking around.  Some important things to note:</p>
<ul>
    <li>There are 5759 events in the dataset</li>
    <li>Attacks date back to 1845</li>
    <li>Attack Types and counts are:
        <ul>
            <li>Unprovoked - 4239</li>
            <li>Provoked - 521</li>
            <li>Invalid - 489</li>
            <li>Boating - 291</li>
            <li>Sea Disaster - 219</li>
        </ul>
    </li>
    <li>1527 Fatal Attacks</li>
    <li>The database is actively maintained by researchers at the <a href="http://www.flmnh.ufl.edu/fish/sharks/isaf/isaf.htm" target="_blank">ISAF</a></li>
</ul>

<pre><code>import pandas as pd
import numpy as np
import re

# read in xls as a dataframe
df = pd.read_excel('GSAF5.xls')

# clean our columns
df['Activity'] = df['Activity'].str.lower()
df['Activity'] = df['Activity'].str.replace('-','')
df['Species '] = df['Species '].str.lower()
df['Country'] = df['Country'].str.upper()

df.rename(columns={'Fatal (Y/N)':'Fatal','Species ':'Species','Sex ':'Sex'}, inplace=True)
df.drop(['Case Number.1', 'original order', 'Unnamed: 21', 'Unnamed: 22','pdf', 'href formula', 'href'],inplace=True, axis=1)

df.head()
</code></pre>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th/>
      <th>Case Number</th>
      <th>Date</th>
      <th>Year</th>
      <th>Type</th>
      <th>Country</th>
      <th>Area</th>
      <th>Location</th>
      <th>Activity</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>Injury</th>
      <th>Fatal</th>
      <th>Time</th>
      <th>Species</th>
      <th>Investigator or Source</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>ND.0001</td>
      <td>1845-1853</td>
      <td>0</td>
      <td>Unprovoked</td>
      <td>CEYLON (SRI LANKA)</td>
      <td>Eastern Province</td>
      <td>Below the English fort, Trincomalee</td>
      <td>swimming</td>
      <td>male</td>
      <td>M</td>
      <td>15</td>
      <td>FATAL. "Shark bit him in half...</td>
      <td>Y</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>S.W. Baker</td>
    </tr>
    <tr>
      <th>1</th>
      <td>ND.0002</td>
      <td>1883-1889</td>
      <td>0</td>
      <td>Unprovoked</td>
      <td>PANAMA</td>
      <td>NaN</td>
      <td>Panama Bay 8ºN, 79ºW</td>
      <td>NaN</td>
      <td>Jules Patterson</td>
      <td>M</td>
      <td>NaN</td>
      <td>FATAL</td>
      <td>Y</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>The Sun, 10/20/1938</td>
    </tr>
    <tr>
      <th>2</th>
      <td>ND.0003</td>
      <td>1900-1905</td>
      <td>0</td>
      <td>Unprovoked</td>
      <td>USA</td>
      <td>North Carolina</td>
      <td>Ocracoke Inlet</td>
      <td>swimming</td>
      <td>Coast Guard personnel</td>
      <td>M</td>
      <td>NaN</td>
      <td>FATAL</td>
      <td>Y</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>F. Schwartz, p.23; C. Creswell, GSAF</td>
    </tr>
    <tr>
      <th>3</th>
      <td>ND.0004</td>
      <td>Before 1903</td>
      <td>0</td>
      <td>Unprovoked</td>
      <td>AUSTRALIA</td>
      <td>Western Australia</td>
      <td>NaN</td>
      <td>pearl diving</td>
      <td>Ahmun</td>
      <td>M</td>
      <td>NaN</td>
      <td>FATAL</td>
      <td>Y</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>H. Taunton; N. Bartlett,  pp. 233-234</td>
    </tr>
    <tr>
      <th>4</th>
      <td>ND.0005</td>
      <td>Before 1903</td>
      <td>0</td>
      <td>Unprovoked</td>
      <td>AUSTRALIA</td>
      <td>Western Australia</td>
      <td>Roebuck Bay</td>
      <td>diving</td>
      <td>male</td>
      <td>M</td>
      <td>NaN</td>
      <td>FATAL</td>
      <td>Y</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>H. Taunton; N. Bartlett,  p. 234</td>
    </tr>
  </tbody>
</table>

<p>Before we start getting into our analyses, we'll need to do a bit of cleaning...</p>
<pre><code># clean our Fatal column up
def clean_Fatal(x):
    if x == 'Y':
        return True
    elif x == 'UNKNOWN':
        return ''
    else:
        return False

df.Fatal = df.Fatal.map(clean_Fatal)

# these functions are included in the github repo
df['year'] = df['Date'].map(year)
df['month'] = df['Date'].map(month)
df['day'] = df['Date'].map(day)
</code></pre>
<h3>Attacks by Activity</h3>
<p>The activity column in this dataset is both useful but difficult.  Below is a smattering of attack descriptions:</p>
<pre><code>    df.Activity.value_counts()

    surfing              854
    swimming             779
    fishing              383
    spearfishing         303
    bathing              152
    wading               134
    diving               120
    standing              96
    snorkeling            74
    scuba diving          74
    body boarding         54
    body surfing          47
    swimming              47
    boogie boarding       42
    treading water        32
    pearl diving          32
    ....
    spearfishing           7
    kayak fishing          7
    kite surfing           6
    fishing for mackerel   6
    spearfishing on scuba  6
    murder                 6
</code></pre>
<p>Tragically, six people have been killed by sharks by being thrown or forced overboard:</p>
<pre><code>df[(df.Activity=='murder')][['Date','Country','Activity','Injury']]
</code></pre>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th/>
      <th>Date</th>
      <th>Country</th>
      <th>Activity</th>
      <th>Injury</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>146</th>
      <td>Reported 1776</td>
      <td>GUINEA</td>
      <td>murder</td>
      <td>FATAL</td>
    </tr>
    <tr>
      <th>546</th>
      <td>Reported      20-Oct-1893</td>
      <td>INDIA</td>
      <td>murder</td>
      <td>FATAL</td>
    </tr>
    <tr>
      <th>3254</th>
      <td>17-Mar-1984</td>
      <td>SOMALIA</td>
      <td>murder</td>
      <td>Forced at gunpoint to jump overboard. Presume...</td>
    </tr>
    <tr>
      <th>4720</th>
      <td>Oct-2006</td>
      <td>GULF OF ADEN</td>
      <td>murder</td>
      <td>FATAL,  beaten &amp; thrown overboard by smugglers...</td>
    </tr>
    <tr>
      <th>4752</th>
      <td>22-Mar-2007</td>
      <td>YEMEN</td>
      <td>murder</td>
      <td>FATAL,  beaten &amp; thrown overboard by smugglers...</td>
    </tr>
    <tr>
      <th>4780</th>
      <td>Jul-2007</td>
      <td>SENEGAL</td>
      <td>murder</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>

<p>While the granularity of the Activity column is good to have, it makes it fairly difficult to group attacks by type.  For example, let's say we decided that "diving" was a distinct activity type.  Below we see that there are 194 different "Activities" that contain the word diving!  From here, we'd need to decide whether the various types of diving are different, i.e. is "diving for <a href="https://en.wikipedia.org/wiki/B%C3%AAche-de-mer">Bêche-de-mer</a>" vs "diving for <a href="https://en.wikipedia.org/wiki/Trochus">trochus"</a> different, or somehow related to the frequency in which sharks attack divers, and should therefore be considered a separate "activity".</p>
<p/><center> Trochus vs. some nice, dried Bêche-de-mer (or Sea Cucumbers for our non-French readers) </center>
<img src="../static/img/dried_seacucumber.png"/>
<pre><code>    len(df[df['Activity'].str.contains('diving')==True]['Activity'].value_counts())

    194

    diving                                                                 120
    scuba diving                                                            74
    pearl diving                                                            32
    free diving                                                             26
    freediving                                                              12
    ...
    diving for trochus                                                       9
    free diving / modeling                                                   1
    pearl diving from lugger whyalla                                         1
    diving from the lugger san, operated by the protector of the aborigines  1
    diving for bechedemer                                                    1
</code></pre>
<p>To better group the more common activity types, I've created a function to handle for specific cases: its messy and long, so I've included it in the repo.</p>
<p>But now that we have usable activity types, we can make some plots!</p>
<pre><code># create a list of top 10 Activities where the attack type is 'Unprovoked'
top_activities = df[df.Type=='Unprovoked'].Activity.value_counts().index.tolist()[:10]
df_top_activities = df[df.Activity.isin(top_activities) &amp; (df.year &gt;1950) &amp; (df.Type=='Unprovoked')].dropna(axis=0,subset=['year'])
df_top_activities.groupby(['Activity','year']).count().reset_index()

# because we have years without attacks, we need to fill them with 0's
years = range(1950, 2016)
activities = df_top_activities.Activity.unique()

import itertools

# http://stackoverflow.com/questions/12130883/r-expand-grid-function-in-python
def expandgrid(*itrs):
   product = list(itertools.product(*itrs))
   return {'Var{}'.format(i+1):[x[i] for x in product] for i in range(len(itrs))}

all_combos = expandgrid(activities, years)
all_combos = pd.DataFrame(all_combos)
all_combos.columns = ["Activity", "year"]
all_years = pd.merge(all_combos, df_top_activities, on=["year", "Activity"], how='left')
all_years = all_years.groupby(['Activity','year']).count().reset_index()

from ggplot import *

ggplot(aes(x='year', y='Case Number', color='Activity'),all_years) + geom_line() + ylab("Number of Attacks") +\
    xlab("Year") + ggtitle("Shark Attacks by Activity Type")
</code></pre>
<p><img src="../static/img/shark_activities.png"/></p>
<p>The most significant trend we can see here is the increase in the number of attacks on surfers over the past 65 years.  This is likely due to the increase in the popularity in surfing in places such as Australia, South Africa, and the USA, where sharks such as Great Whites and Bull Sharks are fairly common.</p>
<p>We can also filter this data to look just at fatal attacks.  Based on the two charts, we see that despite rate of attacks on surfers and swimmers increasing over the past 65 years, fatal attacks have not increased at the same rate. </p>
<p><img src="../static/img/fatal_shark_attacks_by_activity.png"/></p>
<h3>Where do shark attacks occur?</h3>
<p>The ocean...duh brah!...but let's get a bit more specific.  As you'll note from the table above, we have columns indicating the Country, Area and Location of the attacks, but no numerical or geo-spacial data to plot attacks with.  Thankfully, the python package <a href="https://geopy.readthedocs.org/en/1.10.0/">GeoPy</a> has some great features for accessing API's such as the Google Maps API to pull in coordinates of points.  We'll use the text descriptions of the attack location in combination with the API to get the longitude and latitude.</p>
<pre><code>import time
from geopy.geocoders import GoogleV3
from geopy.geocoders import Nominatim
geolocator = GoogleV3()
geolocator2 = Nominatim()
</code></pre>
<p>As a quick example, I'll query the coordinates of the Yhat office:</p>
<pre><code>geolocator.geocode('66 w 39th street new york city')

Location(66 West 39th Street, New York, NY 10018, USA, (40.7526707, -73.98517, 0.0))
</code></pre>
<p>Bam! Fast, super easy <em>and</em> accurate!  Scaling this concept out, I've created a function to take the text descriptions of the attack locations, query the API for the coordinates and then write the results back to a <code>latitude</code> and <code>longitude</code> column.  I've used two geocoders here in case of a timeout or some sort of error.  This way, we should get a coordinates of each event.</p>
<pre><code># plotting unprovoked attacks in the USA post 1900
df2 = df[(df.Country=='USA') &amp; (df.year&gt;1900) &amp; (df.Type=='Unprovoked')]

def get_location(row):
    time.sleep(.02)
    loc = str(row.Location) + ', ' + str(row.Area) + ', ' + str(row.Country)
    for _ in range(1):
        try:
            # try our first geocoder
            location = geolocator.geocode(loc)
            print(location)
            print(row.index)
            if not location==None:
                lat = location[1][0]
                long = location[1][1]
                return lat, long
            else:
                try:
                    # try our second geocoder if first one fails
                    location = geolocator.geocode2(loc)
                    print(location)
                    print(row.index)
                    if not location==None:
                        lat = location[1][0]
                        long = location[1][1]
                        return lat, long
                    else:
                        return None, None
                except:
                    return None, None
                    continue
        except:
            return None, None
            continue
        return row.latitude, row.longitude

# get our coordinates
df2['latitude'], df2['longitude'] = zip(*df2.apply(get_location,axis=1))

# write to a csv for future use b/c the API lookups take a longggg time
df2.to_csv('./sharks_coords.csv',index=False)
</code></pre>
<p>Taking a look at our results:</p>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th/>
      <th>Area</th>
      <th>Location</th>
      <th>Country</th>
      <th>latitude</th>
      <th>longitude</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>North Carolina</td>
      <td>Somewhere between Hatteras and Beaufort</td>
      <td>USA</td>
      <td>34.718217</td>
      <td>-76.663819</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Florida</td>
      <td>Gadsden Point, Tampa Bay</td>
      <td>USA</td>
      <td>27.822248</td>
      <td>-82.473150</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Florida</td>
      <td>Palm Beach, Palm Beach County</td>
      <td>USA</td>
      <td>26.705621</td>
      <td>-80.036430</td>
    </tr>
    <tr>
      <th>3</th>
      <td>California</td>
      <td>Capistrano, Orange County</td>
      <td>USA</td>
      <td>33.723150</td>
      <td>-117.776661</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Florida</td>
      <td>Mosquito Inlet (Ponce Inlet), Volusia County</td>
      <td>USA</td>
      <td>29.096373</td>
      <td>-80.936998</td>
    </tr>
  </tbody>
</table>

<h3>Now for some geo-plotting</h3>
<p>To simplify things, we're only going to look at attacks in the USA.  For plotting, we'll use the <a href="http://matplotlib.org/basemap/users/installing.html">Matplotlib Basemap</a> library.  Matplotlib Basemap isn't as pretty as something like D3, (something to potentially revisit in a future post), but it's really easy to use and quickly lets us start visualizing our data.</p>
<pre><code># lets plot our attacks in the USA
from mpl_toolkits.basemap import Basemap
import matplotlib.pyplot as plt
%matplotlib inline

# create a new df with only locations we have coords for 
dfc = df2.dropna(axis=0, subset=['latitude'])

# USA Plot
USA_map = Basemap(projection='mill', resolution = 'l', llcrnrlon=-180, llcrnrlat=2, urcrnrlon=-62, urcrnrlat=60)

plt.figure(figsize=(18,18))

x1,y1 = USA_map(dfc['longitude'].tolist(), dfc['latitude'].tolist())
USA_map.plot(x1,y1, 'bo', markersize=7)

USA_map.drawlsmask(lakes=False)
USA_map.drawcoastlines(color='gray')
USA_map.fillcontinents(color = 'lightgrey')
USA_map.drawmapboundary()
USA_map.drawstates()
USA_map.bluemarble(alpha=.2)
USA_map.drawcountries()
</code></pre>
<p><img src="../static/img/USA_sharks.png"/>
</p><center>Nice!!! Shark attacks seem to be pretty coastal....</center>
<h3>Dealing with Landsharks!</h3>
<p>Looking at our map above a bit more closely, we might notice some strange behavior....LANDSHARKS!</p>
<p><a href="http://www.nbc.com/saturday-night-live/video/landshark/2832305" target="_blank">
  <img src="../static/img/landshark.png"/>
</a>
</p><center>Landsharks, as seen in the <a href="http://www.nbc.com/saturday-night-live/video/landshark/2832305" target="_blank">1975 SNL sketch</a></center>
<p>As comical as the idea of landsharks may be, <strong>they actually do exist!</strong> </p>
<p>Well kinda.  </p>
<p>A specific species of shark, the <a href="https://en.wikipedia.org/wiki/Bull_shark">Bull Shark</a> is one of the only species of sharks that can swim in brackish water.  They're commonly found in bays and canals around Sydney, Australia, have been found over 2,500 miles inland up the Amazon River, been held responsible for nibbles in the Ganges River in India, and even been seen in <a href="http://www.in-fisherman.com/news/sharks-in-illinois/">Alton, Illinois</a>, 1,750 miles from the coast. </p>
<p>Frankly, its terrifying.  </p>
<p>But it also complicates our analyses as we can no longer assume with complete confidence that <em>all</em> shark attacks occur on the coast.</p>
<p>Despite this possibility of a "landshark shark attack" occurring, we can reasonably assume that the vast <em>majority</em> of attacks occur in the ocean.  To start detecting our geographic outliers, we'll use a clustering algorithm that builds on this assumption.</p>
<p><strong>Note:</strong> There are <em>tons</em> of different ways to do this.  Outlier detection is a science in itself and I encourage readers to test out other methods and models to better capture landshark outliers! </p>
<p>For outlier detection, we're going to use an algorithm called KDTree.  Put simply, KDTree (k-dimensional tree), builds a k-dimensional binary search tree, that we can use to determine neighbors and distances between neighbors.  <a href="http://web.stanford.edu/class/cs106l/handouts/assignment-3-kdtree.pdf">More detail on the algorithm can be found here</a>.</p>
<p>The plan is to use this algorithm to:</p>
<ol>
<li>Create a tree of N-nearest neighbors</li>
<li>Create a vector with the distance to N-nearest neighbors for each attack </li>
<li>Sum the distances and sort them to determine the points furthest from all others</li>
</ol>
<p>The assumption is that the landshark points are furthest from all other points, so the sum of their nearest neighbors should be largest.</p>
<pre><code>from sklearn import neighbors

coords = np.column_stack((dfc.latitude,dfc.longitude))

# create our tree
tree = neighbors.KDTree(coords,leaf_size=2)
dist, ind = tree.query(coords[7], k=6) # look at row 7    
print(ind[0])  # indices of 5 closest neighbors
print(sum(dist[0][1:]))  # distances to 5 closest neighbors, excluding the point itself

[  7 379 251 152 420]
0.130272705615

# to add the sum of distances, we'll loop through our list 
sums = []
for i in range(len(coords)):
    dist, ind = tree.query(coords[i], k=6)
    sums.append(sum(dist[0][1:]))

# add the sums back to our dataframe
dfc['dist_sums'] = pd.Series(sums, index=dfc.index)

#sort them so we can find the outlier-est outlier
outliers = dfc.sort(['dist_sums'], ascending=False)
</code></pre>
<p>Now that we've create our sorted outlier list, we can plot them to see how many we've nabbed.</p>
<pre><code># USA Plot
USA_map = Basemap(projection='mill', resolution = 'l', llcrnrlon=-180, llcrnrlat=2, urcrnrlon=-62, urcrnrlat=60)

plt.figure(figsize=(18,18))

# we'll plot the top 25 outliers in red and the rest in blue
x1,y1 = USA_map(outliers['longitude'][25:].tolist(), outliers['latitude'][25:].tolist())
x2,y2 = USA_map(outliers['longitude'][:25].tolist(), outliers['latitude'][:25].tolist())

USA_map.plot(x1,y1, 'bo', markersize=7, alpha=.2)
USA_map.plot(x2,y2, 'ro', markersize=7)

USA_map.drawlsmask(lakes=False)
USA_map.drawcoastlines(color='gray')
USA_map.fillcontinents(color = 'lightgrey')
USA_map.drawmapboundary()
USA_map.drawcountries()
USA_map.drawstates()
USA_map.bluemarble(alpha=.2)
</code></pre>
<p><img src="../static/img/shark_outliers.png"/></p>
<p>Not bad.  We've clearly more work to do but this definitely gets us well on our way.</p>
<p>We can also look specific areas in more detail simply by changing the longitude and latitude of the map corners.</p>
<pre><code>CA_map = Basemap(projection='mill', resolution='l',
llcrnrlon=-128, llcrnrlat=33,
urcrnrlon=-113, urcrnrlat=44)

plt.figure(figsize=(18,10))

# coords for fatal attacks 
x1,y1 = CA_map(outliers[(outliers.Area=='California')]['longitude'][:10].tolist(),outliers[(outliers.Area=='California')]['latitude'][:10].tolist())
x2,y2 = CA_map(outliers[(outliers.Area=='California')]['longitude'][10:].tolist(),outliers[(outliers.Area=='California')]['latitude'][10:].tolist())


CA_map.plot(x2,y2, 'bo', markersize=5,alpha=.5)
CA_map.plot(x1,y1, 'ro', markersize=5)

CA_map.drawlsmask(lakes=False)
CA_map.drawcoastlines(color='gray')
CA_map.fillcontinents(color = 'lightgrey')
CA_map.drawmapboundary()
CA_map.drawstates()
CA_map.bluemarble(alpha=.2)

plt.show()
</code></pre>
<p><img src="../static/img/california_sharks.png"/></p>
<p>Again, we'll need to improve our outlier detection algorithm a bit, or perhaps use a different model altogether, but we've definitely made some solid progress.</p>
<h3>Final Thoughts</h3>
<p>Sharks are fascinating, incredible animals and I would be remiss to not mention in this post how dramatically disproportionate our fear of them is.  Tens of millions of people go swimming, surfing, and diving every year and on average, only 7 people are killed by sharks every year in unprovoked attacks.   </p>
<p>Geoplotting/mapping is a <em>huge</em> field and there are tons of fantastic resources out there to get started plotting things.</p>
<p>Python: <a href="https://basemaptutorial.readthedocs.org">Basemap tutorials</a></p>
<p>For more advanced plotting:</p>
<p>Python: <a href="http://sensitivecities.com/so-youd-like-to-make-a-map-using-python-EN.html#.VfSxeJ1Viko">So You’d Like To Make a Map Using Python</a> by Sensitive Cities</p>
<p>D3: <a href="http://bost.ocks.org/mike/map/">Let's Make a Map</a>,from the legendary Mike Bostock</p>
<p><a href="https://source.opennews.org/en-US/guides/better-mapping/">The Source Guide to Better Mapping</a> from Open News</p>
<p>For all the scripts used to make this post, visit the <a href="https://github.com/coristig/sharks">github repo</a></p>

        </article>
    </div></body></html>