<html><body><div><div class="post-content">
    <blockquote>
  <p>This is the 2nd article in a two part series on similarity search. See <a href="/posts/similarity-search-101-part-1/"><strong>part 1</strong></a> for an overview of the subject.</p>
</blockquote>

<p>In this second installment of my series on similarity search we’ll figure out how to improve on the speed and efficiency of querying our database for nearest neighbors using a data structure known as a “vantage point tree”.</p>

<p>We previously used a brute force approach by computing pairwise distances between our query and all points in our dataset so that we could find items that were close to it.</p>

<p>Unfortunately, this technique scales in  time which is prohibitively expensive on even modestly sized datasets.</p>

<p><a href="https://en.wikipedia.org/wiki/K-d_tree">Kd-trees</a>, and more recently <a href="https://en.wikipedia.org/wiki/Vantage-point_tree">vantage point trees</a> (a.k.a vp-trees), have gained popularity within the machine learning community for their efficacy in reducing the computational cost of similarity search over large datasets.</p>

<p>For this article, we’ll focus on examining how a vp-tree works.</p>

<h3 id="what-is-a-vantage-point-tree-and-how-do-we-construct-one">What is a vantage point tree and how do we construct one?</h3>

<p>In a nutshell, a vantage point tree structure allows us to store the elements of our dataset in such a way that during query time, we can quickly exclude from examination large portions of our data without having to perform any distance computations on the elments of that excluded portions.</p>

<p>Let’s take a look at the basic structure of a vp-tree because it will allow us to understand how we can prune data from a search at query time.</p>

<p>By definition, each node in a vp-tree stores at a minimum 5 pieces of information:</p>

<ol>
  <li>A list of elements sampled from our dataset</li>
  <li>A vantage point element chosen randomly from the list of elements above</li>
  <li>A distance called <em>mu</em></li>
  <li>A “left” child node</li>
  <li>A “right” child node</li>
</ol>

<p>I’ll explain soon how all of these compoenents relate, but in the meantime here’s an illustration of the vp-tree concept:</p>

<p><img src="/media/3016/vptree.png" alt="vantage point tree"/></p>

<p>At the root node of our tree, the list of elements consists of <em>every</em> single item in our data set. From this list of items, we choose one element and designate it as our <em>vangate point</em>.</p>

<p>To choose , we compute the median distance between our vantage point  and all other elements  in the current node .</p>



<p>We select all points within a distance  from the vantage point to assign elements to the <em>left child node</em>.  And similarly, we can assign all points outside of  to the <em>right child node</em>.</p>

<p><img src="/media/3016/left_right_child.png" alt="elements for left and right child"/></p>

<p>Since  is the median distance between the vantage point and all other points, this procedure effectively divides into half the elements we assign to the left and right child nodes.</p>

<p>Finally, to construct the rest of the tree, we recursively follow this same procedure for each child node, until there are no more elements to assign to child nodes.</p>

<p>Here is some pseudo code to build the tree:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python">class VPNode:
    elements
    left_child
    right_child
    mu

def build_vp_tree(elements):
    node = new VPNode()
    node.vp = select_random(elements)
    node.mu = median(distance(vp,e) for e in elements)
    left_elements = [e for e in elements where distance(vp, e) &lt; mu]
    right_elements = [e for e in elements where distance(vp, e) &gt; mu]
    node.left_child = build_vp_tree(left_elements)
    node.right_child = build_vp_tree(right_elements)
    return node</code></pre></figure>

<h3 id="nearest-neighbor-search-with-the-vantage-point-tree">Nearest neighbor search with the vantage point tree</h3>

<p>For a dataset encoded as a vantage point tree and a query point , how can we find the closest  points in our dataset without running distance computations for every single element?</p>

<p>One approach we could take is to say that for every  there is some threshold distance  where <em>all</em> of its closest  neighbors are contained within this threshold. You can imagine this area as an enclsosed circle as depcited below:</p>

<p><img src="/media/3016/querypoint.png" alt="query point and tau"/></p>

<p>There are three scenarios for how this query-tau area can relate to any node within our vantage point tree.</p>

<h5 id="pruning-the-left-child-node">Pruning the left child node</h5>

<p>The first scenario is if the area lies <em>completely</em> outside of our vantage-point-mu radius as depicted below. If this is the case, we can safely assume that if we are to find ’s nearest neighbors we can forego looking in our node’s left child, which contains all elements within the mu radius of this vantage point.</p>

<p><img src="/media/3016/disjoint_vp_q.png" alt="query-tau and vp-mu areas are disjoint"/></p>

<h5 id="pruning-the-right-child-node">Pruning the right child node</h5>

<p>The next scenario is when the query-tau area lies <em>completely</em> inside the bounds of the vantage point’s mu-radius (see below). In this case, we can ignore all points outside of  which we had conveniently assigned to the right child node.</p>

<p><img src="/media/3016/union_vp_q.png" alt="query-tau and vp-mu areas are disjoint"/></p>

<h5 id="worst-case-we-check-both-left-and-right-child-nodes">Worst case, we check both left and right child nodes</h5>

<p>What happens when the query-tau area partially intersects with our node’s vantage point’s mu-radius?</p>

<p><img src="/media/3016/intersect_vp_q.png" alt="query-tau and vp-mu areas partially intersect"/></p>

<p>In this scenario, we can’t say whether the right or left child contains the nearest neighbors, so we have to search both nodes.</p>

<h5 id="traversing-the-tree-to-find-nearest-neighbors">Traversing the tree to find nearest neighbors</h5>

<p>To summarize, when the query threshold area is <em>completely</em> outside the bounds of our node’s vantage-point mu boundary, we can exclude or “prune” the left child node from our search space. When the query threshold is <em>completely</em> inside the bounds of vantage-point mu boundary, we cans safely ignore the right child node. And finally when neither is the case, we must search both left and right child nodes.</p>

<p>Now that we know how to behave when examining a single node, we can use this knowledge to find ’s nearest neighbors by recursively shrinking  as we search down the vantage point tree.</p>

<p>More concretely, we initialize  to be infinity. And as we traverse from the root node to each child node of the vp-tree, we set  to be equal to the lesser of the distance from  to  or any previously seen .</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python">def find_nearest_neighbors(tree, q, k):
    """
    tree = the VP tree
    k    = # of nearest neighbors you wanted to find
    q    = query point
    """

    tau = infinity
    nodes_to_visit = [tree]

    # fixed size array for nearest neightbors 
    # sorted from closest to farthest neighbor
    neighbors = PriorityQueue(k)

    while nodes_to_visit.length() &gt; 0:
        node = nodes_to_visit.popleft()
        d = distance(q, node.vp)

        if d &lt; tau:
            # store node.vp as a neighbor if it's closer than any other point
            # seen so far
            neighbors.append(node.vp)

            # shrink tau
            farthest_nearest_neighbor = neighbors[-1]
            tau = distance(q, farthest_nearest_neighbor)

        # check for intersection between q-tau and vp-mu regions
        # and see which branches we absolutely must search

        if d &lt; node.mu:
            if d &lt; node.mu + tau:
                nodes_to_visit.append(node.left_child)
            if d &gt;= node.mu - tau:
                nodes_to_visit.append(node.right_child)
        else:
            if d &gt;= node.mu - tau:
                nodes_to_visit.append(node.right_child)
            if d &lt; node.mu + tau:
                nodes_to_visit.append(node.left_child)

    return neighbors</code></pre></figure>

<p>Here is the full source code for my <a href="https://github.com/huyng/algorithms/tree/master/vptree">python implementation of a vantage point tree</a>.</p>

<h5 id="references">references</h5>




    </div>

    
     
    
    </div></body></html>