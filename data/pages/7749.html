<html><body><div><article class="markdown-body entry-content" itemprop="text"><h1><a id="user-content-caffe-to-tensorflow" class="anchor" href="#caffe-to-tensorflow" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Caffe to TensorFlow</h1>

<p>Convert <a href="https://github.com/BVLC/caffe/">Caffe</a> models to <a href="https://github.com/tensorflow/tensorflow">TensorFlow</a>.</p>

<h2><a id="user-content-usage" class="anchor" href="#usage" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Usage</h2>

<p>Run <code>convert.py</code> to convert an existing Caffe model to TensorFlow.</p>

<p>Make sure you're using the latest Caffe format (see the notes section for more info).</p>

<p>The output consists of two files:</p>

<ol>
<li>A data file (in NumPy's native format) containing the model's learned parameters.</li>
<li>A Python class that constructs the model's graph.</li>
</ol>

<h3><a id="user-content-example" class="anchor" href="#example" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Example</h3>

<p>Convert the model:</p>

<pre><code>./convert.py deploy.prototxt net.caffemodel mynet.npy mynet.py
</code></pre>

<p>Inference:</p>

<div class="highlight highlight-source-python"><pre><span class="pl-c"># Import the converted model's class</span>
<span class="pl-k">from</span> mynet <span class="pl-k">import</span> MyNet

<span class="pl-c"># Create an instance, passing in the input data</span>
net <span class="pl-k">=</span> MyNet({<span class="pl-s"><span class="pl-pds">'</span>data<span class="pl-pds">'</span></span>:my_input_data})

<span class="pl-k">with</span> tf.Session() <span class="pl-k">as</span> sesh:
    <span class="pl-c"># Load the data</span>
    net.load(<span class="pl-s"><span class="pl-pds">'</span>mynet.npy<span class="pl-pds">'</span></span>, sesh)
    <span class="pl-c"># Forward pass</span>
    output <span class="pl-k">=</span> sesh.run(net.get_output(), <span class="pl-c1">...</span>)</pre></div>

<p>See <code>test.py</code> for a functioning example. It verifies the sample models (under <code>examples/</code>) against the ImageNet validation set.</p>

<h2><a id="user-content-verification" class="anchor" href="#verification" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Verification</h2>

<p>The following converted models have been verified on the ILSVRC2012 validation set.</p>



<h2><a id="user-content-notes" class="anchor" href="#notes" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Notes</h2>

<ul>
<li><p>Only the new Caffe model format is supported. If you have an old model, use the <code>upgrade_net_proto_text</code> and <code>upgrade_net_proto_binary</code> tools that ship with Caffe to upgrade them first. Also make sure you're using a fairly recent version of Caffe.</p></li>
<li><p>It appears that Caffe and TensorFlow cannot be concurrently invoked (CUDA conflicts - even with <code>set_mode_cpu</code>). This makes it a two-stage process: first extract the parameters with <code>convert.py</code>, then import it into TensorFlow.</p></li>
<li><p>Caffe is not strictly required. If PyCaffe is found in your <code>PYTHONPATH</code>, it will be used. Otherwise, a fallback will be used. However, the fallback uses the pure Python-based implementation of protobuf, which is astoundingly slow (~1.5 minutes to parse the VGG16 parameters). The experimental CPP protobuf backend doesn't particularly help here, since it runs into the file size limit (Caffe gets around this by overriding this limit in C++). A cleaner solution here would be to implement the loader as a C++ module.</p></li>
<li><p>Only a subset of Caffe layers and accompanying parameters are currently supported. </p></li>
<li><p>Not all Caffe models can be converted to TensorFlow. For instance, Caffe supports arbitrary padding whereas TensorFlow's support is currently restricted to <code>SAME</code> and <code>VALID</code>.</p></li>
<li><p>The border values are handled differently by Caffe and TensorFlow. However, these don't appear to affect things too much.</p></li>
<li><p>Image rescaling can affect the ILSVRC2012 top 5 accuracy listed above slightly. VGG16 expects isotropic rescaling (anisotropic reduces accuracy to 88.45%) whereas BVLC's implementation of GoogLeNet expects anisotropic (isotropic reduces accuracy to 87.7%).</p></li>
<li><p>The support class <code>kaffe.tensorflow.Network</code> has no internal dependencies. It can be safely extracted and deployed without the rest of this library.</p></li>
</ul>
</article>
  </div></body></html>