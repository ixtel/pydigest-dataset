<html><body><div><tr class="commit js-details-container js-socket-channel js-updatable-content" data-channel="Bjornwolf/language-model:commit:8ee69bb556edec76c488d4f47557df0a6eacd4f7" data-url="/Bjornwolf/language-model/commit/8ee69bb556edec76c488d4f47557df0a6eacd4f7/show_partial?partial=commit%2Fcondensed">
  <td class="commit-icon">
    <svg aria-hidden="true" class="octicon octicon-git-commit" role="img" version="1.1" viewbox="0 0 14 16"><path d="M10.86 7c-0.45-1.72-2-3-3.86-3s-3.41 1.28-3.86 3H0v2h3.14c0.45 1.72 2 3 3.86 3s3.41-1.28 3.86-3h3.14V7H10.86zM7 10.2c-1.22 0-2.2-0.98-2.2-2.2s0.98-2.2 2.2-2.2 2.2 0.98 2.2 2.2-0.98 2.2-2.2 2.2z"/></svg>
  </td>

  <td class="commit-gravatar">
      <img alt="" class="avatar avatar-small" src="https://0.gravatar.com/avatar/08a13649d8d39568432b64a2cee527aa?d=https%3A%2F%2Fassets-cdn.github.com%2Fimages%2Fgravatars%2Fgravatar-user-420.png&amp;r=x&amp;s=140"/>

  </td>

  <td class="commit-author">
    <strong><span class="author">Filip Chudy</span></strong>
  </td>

  <td class="commit-message">
    <code><a href="/Bjornwolf/language-model/commit/8ee69bb556edec76c488d4f47557df0a6eacd4f7" class="message" data-pjax="true" title="Squashed 'libs/Theano/' changes from c89e1bc..94c6aff&#10;&#10;94c6aff Merge pull request #3378 from nouiz/gpu_elemwise_non_contiguous_fix&#10;d714304 fix gh-3377 bug introduced by 41a8e89b63f5 merged by 7320e1b. GpuElemwise with non contiguous inputs give bad results&#10;e25b4c7 Merge pull request #2958 from nouiz/default&#10;5ecbbde Merge pull request #3364 from seanprime7/drvapi&#10;16f37f4 Move the definition of ceil_intdiv to c_support_code.&#10;0a4ca26 GpuConv doesn't inherit from a CPU op, hence HideC is not needed.&#10;752f1f7 Merge pull request #3284 from abergeron/doctest&#10;80264d0 Fix remaining test problems in documentation.&#10;f747933 Add testcode for typed_list and get rid of test_tutorial.py&#10;87025fc Fixup remaining files.&#10;3a6d2fc Fixup tutorial/using_gpu.txt&#10;a3d76ad Fixup doc/library/*&#10;b1f7979 Fixup extending/* and delete associated tests.&#10;3e303fc Fixup tutorial/* and remove matching tests.&#10;a5e7075 testcode for doc/install_windows.txt&#10;b0cf8f3 testcode for doc/install.txt&#10;b5b45f2 testcode for doc/faq.txt&#10;aebc4e7 testcode for python.txt&#10;91d0e7d testcode for tensor/nnet/nnet.txt&#10;270fd90 testcode for tensor/nnet/conv.txt&#10;fa49116 testcode for doc/library/compile/shared.txt&#10;9ccd5d3 testcode for doc/library/compile/profilemode.txt&#10;1c2dfb8 testcode for doc/library/compile/nanguardmode.txt&#10;0f79103 testcode for doc/library/compile/io.txt&#10;2ddadd2 testcode for doc/library/compile/debugmode.txt&#10;f8b377f testcode for doc/library/scan.txt&#10;08aa59e testcode for doc/extending/unittest.txt&#10;42c0e2f testcode for doc/extending/type.txt&#10;889dbcf testcode for doc/extending/tips.txt&#10;092ad94 testcode for doc/extending/other_ops.txt&#10;cee71c3 testcode for doc/extending/optimization.txt&#10;ee43bd1 testcode for doc/extending/op.txt&#10;8e3dd3d testcode for doc/extending/inplace.txt&#10;8b0980b testcode for doc/extending/graphstructures.txt&#10;4b8b6ee testcode for doc/extending/fibby.txt&#10;c25e846 testcode for doc/extending/ctype.txt&#10;4959dd2 testcode for doc/extending/cop.txt&#10;7826b44 testcode for doc/tutorial/using_gpu.txt&#10;ce3ca94 testcode for doc/tutorial/symbolic_graphs.txt&#10;5dcad44 testcode for doc/tutorial/modes.txt&#10;b0c8223 testcode for doc/tutorial/loop.txt&#10;be01a30 testcode for doc/tutorial/loading_and_saving.txt&#10;e08c1db testcode for doc/tutorial/gradients.txt&#10;7f27b9c testcode for doc/tutorial/gpu_data_convert.txt&#10;88d73dd testcode for doc/tutorial/extending_theano_c.txt&#10;6dedf85 testcode for doc/tutorial/extending_theano.txt&#10;236f754 testcode for doc/tutorial/examples.txt&#10;c4147fa testcode for doc/tutorial/debug_faq.txt&#10;762cb0d testcode for doc/tutorial/conditions.txt&#10;af235f4 testcode for doc/tutorial/aliasing.txt&#10;cf7c062 testcode for doc/tutorial/adding.txt&#10;955d880 Enable docgen.py to work on a subset of files.  This is mostly useful for --test.&#10;81f27ce Move imports to the top of the file.&#10;c042a9c Merge pull request #3362 from Thrandis/gpu_reshape&#10;8ceb131 Corrected test mode.&#10;41daf4a Use the CUDA Driver API for conv operations&#10;0d5cffb Force instantiate kernel templates&#10;89f584b Use the CUDA driver API for CUDA gpuarray operations.&#10;82c804c Merge pull request #3360 from abergeron/calm_flake8&#10;315e890 Merge pull request #3305 from lamblin/fix_setsubtensor1_nan&#10;2ed29b2 GpuReshape opt.&#10;7852531 Merge pull request #3357 from Thrandis/gpu_reshape&#10;46696cf Add some of the default ignores back.&#10;c42a18c Merge pull request #3358 from nouiz/tests&#10;2a2ae62 Better error message&#10;2fc09a0 More info in tests error&#10;b996738 make lib.cnmem=1 work more frequently&#10;b800881 Gpu reshape opt.&#10;a4bc662 Fix test in FAST_COMPILE&#10;dc13bfc Merge pull request #3339 from nouiz/davikrehalt-master&#10;4668024 Merge pull request #3348 from nouiz/CoulombeC-master&#10;f9e65e0 Merge pull request #3337 from nouiz/ignore_border&#10;616d786 Update cudnn v3 config flag&#10;709403a flake8&#10;81b563b use str as we use everywhere else&#10;a9c44a8 Fix crash in pydotprint&#10;4c39c3f flake8&#10;9dc5d70 Make the check for arm more generic&#10;b3fa118 made compatible with Raspberry Pi 1&#10;5afe6f9 pep8&#10;79a353d Update docstring and warning message following review&#10;87f8c5a Merge pull request #3344 from nouiz/cycle&#10;ca8d85d Merge pull request #3290 from mohammadpz/prod_dimshuffle_opt&#10;d537add Deactivate merge of assert as it cause cycle in the graph&#10;85a7535 FusionOptimizer added for solve FAST_COMPILE issue&#10;59b8455 more tests + comments&#10;0686893 Logical tests added&#10;303cc80 compatible dimes are now fixed&#10;ae53db8 numerical tests added&#10;6aa9d88 optimization for prod added&#10;856aa0b Merge pull request #3267 from koningrobot/tensordot-as-dot&#10;2fa005b Warn about pending ignore_border default value change.&#10;77f6b2b Merge pull request #3334 from abergeron/delete_old_crap&#10;7320e1b Merge pull request #3288 from abergeron/nouiz_mixed&#10;7f43e9f Fix some typos and phrasings.&#10;bcfe70c Remove remnants of theano modules that were deleted in 0.7.&#10;43d58c1 Delete the old unmaintained copy of scan in sandbox.&#10;c79e0cf Flake8 fix.&#10;0b5ee2f hash tuple instead of xor them&#10;1bc1c0f Remove deprecated comment&#10;233e781 If a reduce upcast the input, don't move it to the GPU.&#10;0b5aa21 Add config var NanGuardMode.{nan,inf,big}_is_error&#10;6c4738d Make NanGuardMode not raise an error with theano.sandbox.rng_mrg.GPU_mrg_uniform&#10;fdbe417 Make flag mode=NanGuardMode work and make it user provided optimizer&#10;5922a93 Update following code review&#10;5f3b4fa Doc about cudnn v3&#10;b5aeafc Don't make opt return errors with bad user graph. The run time error will be better.&#10;b08d5cb Remove useless gpu opt warning when dtype isn't float32&#10;ce0a3f0 If the gpu isn't working don't raise an error uselessly&#10;d6b799f Add assert to see better problems&#10;ccfeeb2 pep8&#10;9790a08 Don't try to move to the new back-end elemwise with multiple output(not yet supported)&#10;944fd8e remove print&#10;e4abbe9 Make inplace elemwise opt support multiple output&#10;1a6e03c Fix dtype for Elemwise.perform with multiple output&#10;350edca Make Composite raise an error for case not supported&#10;41a8e89 Make GpuElemwise work with multiple output, (new back-end raise an error)&#10;2595fea Better test&#10;f9a2e45 Allow transfer type to hardcode the output dtype&#10;a579c1e Make opt not crash with multi output CPU elemwise&#10;6319e9d Fix crash with pycuda example&#10;01be570 Print the number of element used. and long line&#10;614a656 Doc how to pip install a given commit&#10;c35eccc Better test error message&#10;9611e48 Make the example force double to work what ever is floatX. This example is before we talk about floatX. fix gh-3240&#10;50d5f65 Add in the license file that we have CnMeM with the same lisence and add its copyright&#10;1d13344 Merge pull request #3323 from SinaHonari/issue3031&#10;2802ac1 improving test&#10;17e5737 Merge pull request #3325 from johnarevalo/patch-1&#10;cb040b2 Fix AttributeError: 'builtin_function_or_method'&#10;402bba5 adding a unit test for theano.tensor.constant reshape&#10;565650e Merge pull request #3311 from bouthilx/sparse_block_dot&#10;f646ff7 correcting a flake8 format error&#10;26d6d1c improving coding&#10;d2f8104 making code compatible to flake8&#10;0ed1085 theano.tensor.constant reshape fix&#10;aeb8c03 Fix optimizations&#10;76b7101 Flake8 and inplace removed from sparse_block_dot.&#10;a759089 Add Sphinx documentation and image to illustrate sparse block dot&#10;5b604a4 Fix a few pep8 errors&#10;1e0da36 Move sandbox/test_* to folder sandbox/tests/&#10;7748ec1 Add tests for BlockSparse gemv and outer&#10;658bf2e Add optimizations and relativ tests&#10;ed4e009 Add a meta op BlockSparseDot&#10;7ba9c05 Merge pull request #3055 from ChienliMa/swapSV&#10;cc0670e pep 8 style fix&#10;8dae1fb comply with PEP8&#10;8d2c066 implement batched_tensordot in terms of batched_dot&#10;09be448 Modify to fit python3&#10;74cdb5d small fix&#10;b91192d Cannot swap non sharedvariable&#10;dd86da1 small fix for python 3&#10;c624c7b small change to fix python3&#10;2ddb82a Fix typos&#10;35f9643 Delete white space in black line&#10;66780ec Add test for param givens&#10;7252071 delete extra line&#10;43320ef swap input storage in in instances; put modification of fg.inputs outside fg.replace() cause some error occor&#10;f303478 Delete update should be done after swap sv&#10;876507f fgraph.inptus should be modified if we replace an inputs variable&#10;d71a80f add test for sharedvar&#10;51ff431 Restore deleted assertion of inputs&#10;809e6ad modify test to assert SharedVariables are shared&#10;35677c9 delete test that not work&#10;5dd41d9 Delete copy of SharedVariable's storage, for they should have same value among different function&#10;52a7a4d dtype should be same as config.floatX&#10;83d631f Fix type error in testcase with given&#10;d82fab6 extra test case of copy_swap_sv with given values&#10;81d9975 Only seperate input storage of mutable SharedVariable&#10;de6cd0a fix assert grammer error&#10;ac86ad3 coding style fix&#10;bbf84ee comment typo&#10;e8689fc Just use better name&#10;8464ed7 Fix profiling and add name to Function.copy()&#10;2ba562a Fix crash with profiling and fct copy&#10;255cc30 Typo fix in error message and comment&#10;8bb9d77 delete space&#10;96cb8c1 pep 8 fix&#10;8eb39b7 Change param order in profilemaker&#10;2d3bd2f pep 8 fix&#10;47ff978 Delete test for whether output_storage is shared. For they are bound to be shared through shared intermediate storages.&#10;f4fb1e5 Fit Profile_maker.create() with param storage_map&#10;c5949e3 Update docs of param swap&#10;b0e4cae raise ValueError when SharedVariable not found&#10;b176037 Outs share borrow attribute.&#10;b080380 move a line out of loop and fix typo&#10;e06a4c6 add type conversion for map to fit higher version python.&#10;5ce66fe pep-8 style fix&#10;6c218ad delete debug code&#10;a8a12e8 Allow to swap SharedVariable by SharedVariable Instances and update corresponding docs.&#10;5220122 Rewrap Outs to avoid deepcopy whole graph&#10;b6c5be0 Move '__swapSV' inline.&#10;04f5090 Update docs( Fix typo and remove outdated docs )&#10;6469437 Update docs; Delete debug code.&#10;09fe88b pep8 coding style fix and return 'del a' line in test_leak2&#10;0c1cdd8 Add feature 'delete_update'. Merge three features in one function. Add test cases.&#10;3055ab4 finish swapSV and test&#10;af1fb49 Swap vairable in Ins and improve docs&#10;2e7c259 small modification&#10;6400064 Start writting a test&#10;dc36c99 Finish draft, it work. Start working on test and improve the code&#10;81f7134 draft of swaping sharedvariable&#10;127d36c delete unused variable in test&#10;3754bb9 fix indentation&#10;aaac6d2 merge function.copy() with function.__copy__() and fix #3049&#10;be58f8b Update docs&#10;0563dc8 Add test for VM_Linker; Add test for SharedVariable with/without updates; Simplify codes and delete extra line.&#10;55815f1 add doc for function&#10;599d637 Add assertion in map_storage to assert storage given by input/output_storage and storage_map is the same.&#10;cbdb431 fix typo&#10;8198dbf Perfect the docs of copy()&#10;d243b92 reset commits&#10;e7480f6 delete extra line&#10;e43be99 Change of Ins/Outs copy strategy&#10;eff0d6a add a varaible to avoid separating line&#10;1cf16a2 new ins and old ins should shared value if value is unchanged otherwise not.&#10;de0ded7 swap condition in Clinker.__compile__&#10;0999205 change indent&#10;af1f404 Add ```storage_map```argument for Profile_Maker;CLinker new support ```storage_map```(without testing)&#10;af1e743 format change&#10;85beeac delete extra line&#10;691a113 add argument ```storage_map``` to other makers except ```Profile_Maker```&#10;91c6f9e Add argument ```storage_map``` to the rest of theano linker&#10;bacfd4d Format Change; Modify inproper comment;Change constructor class;Add test for output storage.&#10;931de93 typo&#10;b3d98cd Fix a bug: While initializing a clone graph it should not be cloned again, otherwise the equiv doesn't work.&#10;d3c5723 Add some docs to FunctionGraph and minor changes of function_module.copy()&#10;df77628 minor modification in test_function_module.py&#10;0f599ff Small modification to copy(). Testcase is finished. Start debuging.&#10;466a75f Correct typo. Add stoarge_map to PerformLinker.make_thunk(). Now it works!&#10;fb60762 Minor fixes of typos and reverse modiication of test_reallocation()&#10;5aa1237 Delete extra line&#10;116fff5 Change interface of FunctionMaker.create()&#10;1299708 Finish draft of Function.copy()&#10;5ffc4ce change of variable name and some some docs in test_reallocation()&#10;86d8127 Add some docs to map_storage()&#10;c134e60 Fix a bug: While initializing a clone graph it should not be cloned again, otherwise the equiv doesn't work.&#10;55277c4 Add some docs to FunctionGraph and minor changes of function_module.copy()&#10;4846173 minor modification in test_function_module.py&#10;dfe644b Small modification to copy(). Testcase is finished. Start debuging.&#10;9101711 Minor fixes of typos and reverse modiication of test_reallocation()&#10;b061ce2 Delete extra line&#10;a8955e3 Modify link.map_storage() so that it make use of given storage_map&#10;f6c74fc Finish draft of Function.copy()&#10;e3ce7c8 change of variable name and some some docs in test_reallocation()&#10;7bbfe9c pep8! fix code format&#10;6d0539d add argument ```storage_map``` to other makers except ```Profile_Maker```&#10;3a3a8f0 Add argument ```storage_map``` to the rest of theano linker&#10;e2f3ceb Format Change; Modify inproper comment;Change constructor class;Add test for output storage.&#10;cc53776 typo&#10;aee78e7 Fix a bug: While initializing a clone graph it should not be cloned again, otherwise the equiv doesn't work.&#10;ce29622 Add some docs to FunctionGraph and minor changes of function_module.copy()&#10;c6c3d45  Modift FunctionGraph.clone_get_equiv() to enable avoiding attach feature&#10;7c2223f minor modification in test_function_module.py&#10;32a83c0 Small modification to copy(). Testcase is finished. Start debuging.&#10;aa701ea Correct typo. Add stoarge_map to PerformLinker.make_thunk(). Now it works!&#10;724ba41 Minor fixes of typos and reverse modiication of test_reallocation()&#10;2572163 Delete extra line&#10;e4a67cd start writing the test.&#10;bcc3bd8 PerformLinker.make_all() can accepts storage_map&#10;1616cb1 Modify link.map_storage() so that it make use of given storage_map&#10;82e09e8 Change interface of FunctionMaker.create()&#10;90d490c Finish draft of Function.copy()&#10;98127db change of variable name and some some docs in test_reallocation()&#10;c00ccdd Add some docs to map_storage()&#10;00f184d Merge pull request #3308 from ivdorelian/patch-1&#10;6304a06 Merge pull request #3293 from harlouci/numpydoc_tensor&#10;4d918e9 Update sandbox/cuda/dnn_base.c to check malloc&#10;5e53685 Merge pull request #3299 from harlouci/numpydoc_gof&#10;8aaf5a5 Merge pull request #3309 from harlouci/numpydoc_conf&#10;8e88a29 Corrected flake8 errors in theano/tensor/blas.py&#10;65febf3 Corrected flake8 errors in theano/gof/type.py&#10;ccbe857 Merge pull request #3303 from harlouci/numpydoc_sparse&#10;1211db8 Merge pull request #3302 from harlouci/numpydoc_scan_module&#10;690d362 Merge pull request #3301 from harlouci/numpydoc_compile&#10;e8ecd0f Merge pull request #3296 from harlouci/numpydoc_typedList_scalar&#10;d39e2e0 Merge pull request #3295 from harlouci/sandbox_cuda_dnn&#10;931f4e9 Merge pull request #3297 from harlouci/numpydoc_sandbox_2&#10;d1eba87 Merge pull request #3294 from harlouci/numpydoc_sandbox_1&#10;a66610b Update sandbox/cuda/dnn_base.c to work on Windows&#10;477fd7c Merge pull request #3307 from f0k/patch-1&#10;0450d99 Correct config.lib.cnmem name in documentation&#10;2da2c1d Do not read infinite value from output in advanced setsubtensor1&#10;462e0fd numpydoc for theano/sparse/type.py&#10;f347877 numpydoc for theano/sparse/sharedvar.py&#10;38e3c3b numpydoc for theano/sparse/opt.py&#10;48ef7fd numpydoc for theano/sparse/basic.py&#10;02b6e41 numpydoc for theano/scan_module/scan_views.py&#10;b7cf793 numpydoc for theano/scan_module/scan_utils.py&#10;deabd34 numpydoc for theano/scan_module/scan_opt.py&#10;ad86dfd numpydoc for theano/scan_module/scan_op.py&#10;cacd26a numpydoc for theano/scan_module/__init__.py&#10;a234c12 numpydoc for theano/scan_module/scan.py&#10;533f5da Fixed Returns.&#10;bacd93a numpydoc for theano/sandbox/scan_module/scan_utils.py&#10;8d4e690 numpydoc for theano/sandbox/scan_module/scan_op.py&#10;8c514f5 numpydoc for theano/sandbox/scan_module/scan.py&#10;63577e4 numpydoc for theano/sandbox/scan_module/__init__.py&#10;8b28afc numpydoc for theano/sandbox/linalg/ops.py&#10;7f1b3bb flake8 corrections for theano/sandbox/gpuarray/opt.py&#10;e2777e5 numpydoc for theano/sandbox/gpuarray/type.py&#10;6f424ab numpydoc for theano/sandbox/gpuarray/subtensor.py&#10;8c4c9d6 numpydoc for theano/sandbox/gpuarray/opt.py&#10;2f22839 numpydoc for theano/sandbox/gpuarray/nnet.py&#10;f772ce5 numpydoc for theano/sandbox/gpuarray/kernel_codegen.py&#10;d438c2d flake8 corrections in theano/sandbox/gpuarray/dnn.py&#10;6b9b3f2 flake8 corrections in theano/sandbox/cuda/GpuConv3D.py&#10;88716ac Fixed Returns.&#10;32f0f6d flake8 corrections for theano/gof/cc.py&#10;b73195a Fixed all Returns&#10;d25dac2 Small fixes in extra_ops.py, Conv3D.py and conv3d2d.py&#10;bed6f01 numpydoc for theano/compile/sharedvalue.py&#10;33a899b numpydoc for theano/compile/profiling.py&#10;8d57251 numpydoc for theano/compile/profilemode.py&#10;8129b74 numpydoc for theano/compile/pfunc.py&#10;8feaa75 numpydoc for theano/compile/ops.py&#10;1077f41 numpydoc for theano/compile/nanguardmode.py&#10;a61580d numpydoc for theano/compile/monitormode.py&#10;cdddc7d numpydoc for theano/compile/mode.py&#10;3ca1e9a numpydoc for theano/compile/io.py&#10;c537f5e numpydoc for theano/compile/function_module.py&#10;0f00c10 numpydoc for theano/compile/function.py&#10;e6ecae1 numpydoc for theano/compile/debugmode.py&#10;d10856f numpydoc for theano/compile/builders.py&#10;cdba68a numpydoc for theano/gof/vm.py&#10;c99f5cb numpydoc for theano/gof/utils.py&#10;9260f71 numpydoc for theano/gof/unify.py&#10;54160cd numpydoc for theano/gof/type.py&#10;4289537 numpydoc for theano/gof/toolbox.py&#10;17429f3 numpydoc for theano/gof/sched.py&#10;b70504c numpydoc for theano/gof/optdb.py&#10;46d46d7 numpydoc for theano/gof/opt.py&#10;ae99f41 numpydoc for theano/gof/op.py&#10;24d214f numpydoc for theano/gof/null_type.py&#10;ba7a952 numpydoc for theano/gof/link.py&#10;fa6d41d numpydoc for theano/gof/__init__.py&#10;fa75ad6 numpydoc for theano/gof/graph.py&#10;75e573d numpydoc for theano/gof/fg.py&#10;18c54ec numpydoc for theano/gof/destroyhandler.py&#10;5da33fd numpydoc for theano/gof/cutils.py&#10;438995e numpydoc for theano/gof/compilelock.py&#10;80f8652 numpydoc for theano/gof/compiledir.py&#10;ee6a799 numpydoc for theano/gof/cmodule.py&#10;b61e972 numpydoc for theano/tensor/type.py&#10;c621d24 numpydoc for theano/tensor/signal/downsample.py&#10;81a13dc numpydoc for theano/tensor/signal/conv.py&#10;7e822db numpydoc for theano/tensor/nnet/sigm.py&#10;430561a numpydoc for theano/tensor/nnet/nnet.py&#10;5858621 numpydoc for theano/tensor/nnet/neighbours.py&#10;c0ef606 numpydoc for theano/tensor/nnet/ConvTransp3D.py&#10;880f6f8 numpydoc for theano/tensor/nnet/ConvGrad3D.py&#10;9ef3814 numpydoc for theano/tensor/nnet/Conv3D.py&#10;e16273c numpydoc for theano/tensor/nnet/conv3d2d.py&#10;61280f0 numpydoc for theano/tensor/nnet/conv.py&#10;e29c2b1 numpydoc for theano/tensor/xlogx.py&#10;15ba1e4 numpydoc for theano/tensor/var.py&#10;ab2c91c numpydoc for theano/tensor/utils.py&#10;56fd9af numpydoc for theano/tensor/type_other.py&#10;d8835a5 numpydoc for theano/gof/cc.py&#10;2450483 numpydoc for theano/sandbox/gpuarray/elemwise.py&#10;c739cc8 numpydoc for theano/sandbox/gpuarray/dnn.py&#10;45f18ba numpydoc for theano/sandbox/gpuarray/conv.py&#10;acebecd numpydoc for theano/sandbox/gpuarray/comp.py&#10;fd0b1f0 numpydoc for theano/sandbox/gpuarray/basic_ops.py&#10;1e7b212 numpydoc for theano/sandbox/cuda/var.py&#10;a5eb228 numpydoc for theano/sandbox/cuda/rng_curand.py&#10;a5b4de5 Merge pull request #3292 from carriepl/scan_0_steps&#10;909aa3d numpydoc for theano/sandbox/cuda/type.py&#10;f464af1 Merge pull request #3278 from abergeron/doc&#10;49af6ef numpydoc for theano/sandbox/cuda/opt.py&#10;e9235e2 numpydoc for theano/sandbox/cuda/nvcc_compiler.py&#10;1ca77e1 numpydoc for theano/sandbox/cuda/nnet.py&#10;fd25c9c numpydoc for theano/sandbox/cuda/kernel_codegen.py&#10;c489c64 numpydoc for theano/sandbox/cuda/__init__.py&#10;44639e2 numpydoc for theano/sandbox/cuda/GpuConvTransp3D.py&#10;cdcbda6 numpydoc for theano/sandbox/cuda/GpuConvGrad3D.py&#10;7691524 numpydoc for theano/sandbox/cuda/GpuConv3D.py&#10;2d9e40e numpydoc for theano/sandbox/cuda/fftconv.py&#10;3e1612d numpydoc for theano/sandbox/cuda/extra_ops.py&#10;472f91a numpydoc for theano/sandbox/cuda/elemwise.py&#10;c0f6279 Merge pull request #3232 from t13m/merge_assert&#10;e76d6bc numpydoc for theano/sandbox/cuda/dnn.py&#10;a9a1db3 numpydoc for theano/sandbox/cuda/cula.py&#10;25f7768 numpydoc for theano/sandbox/cuda/blocksparse.py&#10;1a9da25 Added corrections to numpydoc for theano/sandbox/cuda/basic_ops.py&#10;c413589 numpydoc for theano/sandbox/cuda/blas.py&#10;257d4b5 numpydoc for theano/sandbox/cuda/basic_ops.py&#10;a663afd numpydoc for theano/sandbox/theano_object.py&#10;47ea038 numpydoc for theano/sandbox/test_rng_mrg.py&#10;8befdc6 numpydoc for theano/sandbox/solve.py&#10;0454676 numpydoc for theano/sandbox/scan.py&#10;966aa9b numpydoc for theano/sandbox/rng_mrg.py&#10;f2c57a5 numpydoc for theano/sandbox/neighbourhoods.py&#10;69911d9 numpydoc for theano/sandbox/multinomial.py&#10;7e74bc3 numpydoc for theano/sandbox/fourier.py&#10;1023b22 numpydoc for theano/scalar/sharedvar.py&#10;631ef39 numpydoc for theano/scalar/basic_sympy.py&#10;a0ae981 numpydoc for theano/scalar/basic_scipy.py&#10;69d6991 numpydoc for theano/scalar/basic.py&#10;3389e78 numpydoc for theano/typed_list/type.py&#10;b4536dc numpydoc for theano/typed_list/basic.py&#10;8609f69 Add test case&#10;56bb06e Prevent ScanSaveMem from generating 0-steps scans&#10;1765e4e numpydoc for theano/tensor/subtensor.py&#10;306ee2c numpydoc for theano/tensor/sort.py&#10;a8983c9 numpydoc for theano/tensor/slinalg.py&#10;be386f5 numpydoc for theano/tensor/sharedvar.py&#10;356653b numpydoc for theano/tensor/shared_randomstreams.py&#10;3ff5c1b numpydoc for raw_random.py&#10;b8856a5 1 correction added to theano/tensor/extra_ops.py&#10;9f2240d 2 corrections added in theano/tensor/elemwise.py&#10;e8a979c Removal of an invisible character in theano/tensor/basic.py&#10;ff7c816 numpydoc for theano/tensor/opt_uncanonicalize.py&#10;f6141a6 numpydoc for theano/tensor/opt.py&#10;7f31218 numpydoc for theano/tensor/nlinalg.py&#10;ee4eedc numpydoc for theano/tensor/io.py&#10;c172b4c numpydoc for theano/tensor/extra_ops.py&#10;48de5a3 numpydoc for theano/tensor/elemwise_cgen.py&#10;a5604ec numpydoc for theano/tensor/elemwise.py&#10;a2913d3 numpydoc for theano/tensor/blas_headers.py&#10;0c1711f numpydoc for theano/tensor/blas.py&#10;47bf742 numpydoc for theano/tensor/basic.py&#10;0a7415d Merge pull request #3289 from abergeron/disable_softmaxgrad_v3&#10;9783d9a Disable the optimization to use DnnSoftmaxGrad for cuDNN v3 since it is broken for (n, c 1, 1) shapes at the moment.&#10;6e7a904 Merge pull request #3139 from sebastien-j/average_pooling&#10;ab71241 Add napoleon to extensions for numpydoc docstring parsing.&#10;079181c Merge pull request #3275 from abergeron/fix_buildbot&#10;5381bbd Make broadcast fixup in filter_variable() depend on an argument and stop doing it for shared variables.&#10;b2f62a1 Fix type conversion in TensorType and expand it to other similar types.&#10;8298b5b Always apply optimization&#10;1b377a3 Small visual changes (blue color)&#10;682385f Make a scan test take less than 3 hours on the buildbot in DEBUG_MODE.&#10;9fd9e64 Add an :orphan: tag to documents that are not in the toctree so that sphinx doesn't complain anymore.&#10;a994cf7 Fix format mistakes in the docs.&#10;9de8616 Stop painting over broadcastable differences (since this could lead to a bug).&#10;5f2c912 Make filter_variable correct safe broadcastable differences.&#10;d27f239 Fix bug in get_scalar_constant value of Subtensor(Shape(Rebroadcast(v)))&#10;02c218f Don't run test_gpu_memory_usage in DebugMode since it uses an enormous amount of memory.&#10;44518ac Adjust memory increase since GpuAllocEmpty does not need a constant.&#10;3f0f841 Make sure to disable C code in CAReduceDtype if the accumulator is in float16.&#10;15c90dd Merge pull request #3270 from lamblin/windows_trace&#10;10f2615 Also match Windows version of paths&#10;65dda20 fix test case &quot;test_both_assert_merge_1&quot;&#10;0add5fb verbose assert in gof test_opt MergeOptimizer test&#10;5e3e851 add test case for reversed order&#10;2228990 Merge pull request #3268 from pallegro/cudnn-python3-fix&#10;01a4a9e python 3 fix in dnn.py&#10;72b8b16 Merge pull request #3264 from Theano/pydot_ng&#10;0efc781 Move down conditional import to keep flake8 happy&#10;dd5cfff Use optimization with FAST_COMPILE too&#10;8bcd326 Make pydotprint work with pydot_ng&#10;2445d58 Merge pull request #3255 from cvangysel/master&#10;8aa3dc1 Merge pull request #3256 from mop/allow-sections-with-dots&#10;ecf4a8a Merge pull request #3260 from carriepl/cudnn_fixes2&#10;8b640d3 Fix time_once and guess_once CuDNN options&#10;de787b0 enable dots in section names&#10;162306f Minor changes&#10;e6a86a0 Exempt np.random.mtrand.RandomState from NaN/inf/big_number checking in NanGuardMode.&#10;33f5b71 Add optimization for pooling gradient&#10;1efbddc Fix indentation&#10;51a26ad Merge pull request #3253 from carriepl/cudnn_fixes&#10;fc1d668 Drop support for CuDNN v1&#10;434ac02 Add info on behaviour of guess_* and time_* values&#10;fd1e668 Change description for 'large' implementation&#10;6e221a6 Merge pull request #3246 from lucasb-eyer/pydot-graphviz-missing-message&#10;adbcbfc Merge pull request #3251 from f0k/fix-cudnn-copypaste-bug&#10;e94e34b Merge pull request #3252 from f0k/patch-2&#10;45adc6e Merge pull request #3250 from f0k/fix-cudnn-performance&#10;df61d3b Fix metaoptimizer for cudnn&#10;7524108 Fix copy/paste bug for cuDNN time_on_shape_change mode&#10;8da3449 Fix GpuDnnConvGradI not being inserted automatically&#10;8cb9d50 Merge pull request #3245 from carriepl/v3&#10;929628d Clearer error message for missing pydot/graphviz.&#10;4d4be31 Doc update&#10;91f7135 pep8&#10;d36faf2 Flake8 on dnn.py&#10;d4d3ae5 Flake8 on test_dnn.py&#10;397394d Remove DnnPoolGrad fix for max pooling (not necessary with public RC)&#10;9839a00 Fix typo&#10;f2e2a7b Modify dnn.conv.algo_fwd flag to support timing feature&#10;fc1ed89 Modify GpuDnnConvGradI to support timing feature&#10;c4df0b9 Modify GpuDnnConvGradW to support timing feature&#10;a5fe8e3 In __setstate__ use flag value as default value&#10;349378f Skip certain tests when using CuDNN with a version older than v3&#10;32ad87b Don't run certain 2d convolution tests with CuDNN older than v3&#10;4850f92 Include comments in #if-#endif condition&#10;814ae6a Add error message for versions before v3&#10;689ce21 Skip certain conv3d test when using cudnn v3&#10;191de4e Change default implementation in Conv3d and Conv3dGrads to one supported in both V2 and V3&#10;557c3fd Add checks for guess options in GpuDnnConv&#10;178ad15 Update CuDNN optimizations to use new config flags&#10;2b6ef54 Update dnn_conv3d to use new config flags&#10;6f80c3b Update dnn_conv to use new config flags&#10;5e6820a Update GpuDnnConv3dGradI to use new config flags&#10;c586d80 Update GpuDnnConvGradI to use new config flags&#10;14b8178 Update GpuDnnConv3dGradW to use new config flags&#10;319cf62 Update GpuDnnConvGradW to use new config flags&#10;e0eaa39 Update GpuDnnConv3d to use new config flags&#10;28f72bb Update GpuDnnConv to use new config flags&#10;d740f88 Change name of flags to control CuDNN convolution implementation&#10;2389c49 Update checks for self.workmem value in GpuDnnConv&#10;8c7ab09 Add 'guess_once' option for DnnConv3dGrad algo selection&#10;8919980 Add 'time_once' and 'guess_once' options for DnnConv3d algo selection&#10;680d203 Update docstring to reflect removed special case&#10;05dc20d Ensure direction hint has valid value&#10;564cd12 Adjust input values in conv bgrad test&#10;8cee9f4 Fix TestDnnInferShapes.test_conv3d_gradi test&#10;8368945 Only initialize output memory when max-pooling&#10;2b8457d Init output memory for DnnPoolGrad&#10;6a63844 Restrict conv2d special case to CuDNN v1&#10;e9dcf6d Remove 3d convolution special case&#10;50bee24 Adjust conditions for skipping tests in InferShapeTester&#10;c2703ca Update CuDNN conv3d tests conditions for skipping&#10;9b757b1 Reduce sizes of conv3d tests to limit rounding error&#10;d24f599 Test conv3d also with integer subsample values&#10;e4f276a Add shape test for conv3d gradi&#10;bf40961 Add shape test for conv3d gradw&#10;dbeb46f Avoid shapes with duplicate values&#10;ad3cc2f Add shape tests for 3d fwd convolution&#10;6babe38 Fix typos in grad methods of CuDNN 3d convolution&#10;906f4ea Add test cases for fwd and bwd 3d convolution&#10;8ff1685 Make GpuDnnConvDesc support 2 and 3 dimensions. Remove GpuDnnConv3dDesc.&#10;bc65b24 Change default DnnConvGrad implementation&#10;ebf020a Add comment to explain usage of check_isfinite=False&#10;3009ff4 Skip test_pooling3d if cudnn not recent enough&#10;b094c0b Merge test_log_softmax and test_log_softmax_opt&#10;b09557a Remove 'nd' param from GpuDnnPoolDesc&#10;912d125 Standardize CuDNN RuntimeError messages&#10;486b760 Remove nb_dim param from dnn convolutions&#10;b9e2976 Remove dim param from c_set_tensorNd and c_set_kernelNd&#10;01706da Make dnn grad convolutions compatible with both V2 and V3&#10;17bfc49 Support V2 in GpuDnnConv&#10;3fdad2b Make dnn softmax compatible with V2&#10;2ef334c Add tests for dnn_pool(..., nd=3)&#10;8d45fea Add comment in test_log_softmax_opt&#10;8df74d4 Add test for CuDNN log-softmax&#10;268bc91 Extend the current pooling op to support 3d pooling.&#10;525c9c8 c_set_tensor4d -&gt; c_set_tensorNd to be more generic (in C code).&#10;4eb4a89 Add unit test for log-softmax optimization&#10;2827eb5 Add opt for Dnn LogSoftmax&#10;371fe99 small fix&#10;806d27a update according to pull request commetns&#10;f365f07 Fix TestDnnInferShapes.test_conv_gradi&#10;f748cf8 fix rebase issues&#10;822c06d fix guess/time workmem bug&#10;7f78fce make cudnn conv3d gradI and gradW works&#10;6117f98 add cudnnv3 conv3d&#10;3422324 Add support for 'log' mode in GpuDnnSoftmax&#10;bab0640 Make deterministic implementation the default in GradW and GradI&#10;f62d6cf Refactor code&#10;9f23176 Default to safe algo when fft is not supported&#10;ad9646b Implement implementation selection for GpuDnnConvGradI&#10;221fb06 Integrate v3 in GpuDnnConvGradW&#10;813bc1e Add config flag for algo selection for gradient convolution&#10;65eb53a Only extract chosen algo after checking for success&#10;07931d2 Add attributes for implementation selection in the gradient convolution&#10;552fb9d Set requestedCount to 1&#10;755429d Update comment in GpuDnnConv&#10;2597dcd Add support for implementation timing&#10;f9b85e1 Implement cudnn implementation selection for FWD pass&#10;2b83b6a Merge pull request #3238 from f0k/fix-corrmm-docstring&#10;9685f1d add 3 new test cases for different cases of merging asserts; bug fix&#10;07e9332 Merge pull request #3242 from abergeron/memmap_windows&#10;f446396 Fix memmap test error on windows.&#10;62b3bbd Merge pull request #3241 from abergeron/nan_gpu&#10;5860e07 Add definition of NAN to cuda_ndarray.cuh.&#10;fbf3dcd Fix outdated description of border_mode in GpuCorrMM constructor&#10;c2cd739 Merge pull request #3229 from nouiz/nanguardmode&#10;35c19ad Merge pull request #3237 from nouiz/python_rng&#10;01e2ff6 new test case added; fix bug (create new assert node when different condition)&#10;3517d36 Don't use python random generator durint Theano compilation&#10;0172bb1 MergeOptimizer merge nodes with assert input&#10;4b1194a Merge pull request #3230 from nouiz/stack_trace&#10;088de5f If no stack trace, keep this as an empty list&#10;161787e code clean up&#10;4ff6f28 Speed up nanguardmode&#10;077accb Make NanGuardMode not crash for cdatatype&#10;948f726 Merge pull request #3224 from nouiz/mixed3&#10;71e9f54 typo&#10;9c6d217 Add time in profiling output&#10;0177c84 Skip dnn test if it isn't avail&#10;de6791f Fix gpuarray test&#10;3113e86 Doc to use the c linker to lower overhead&#10;23cc676 Better error message&#10;63718d5 Add timming&#10;5a70f9a Merge pull request #3221 from carriepl/scan_opt_bug&#10;c8394fb Merge pull request #3147 from harlouci/props_compile&#10;a384448 Merge pull request #3160 from harlouci/props_tensor&#10;b3fc2a3 Merge pull request #3178 from harlouci/props_misc&#10;8d2a084 Make sure change_flags decorator leaves the decorated function's name unchanged&#10;dd22ded Reuse old Rebroadcast.__hash__ as it was working well&#10;00c376d Change test to use change_flags decorator&#10;f4c031c Removed inappropriate props in theano/tensor/basic.py&#10;6485dbb Merge pull request #3213 from nouiz/pydotprint&#10;154cc79 Add test case for optimization fix&#10;630e194 Mark node to be deleted once it's certain it will be deleted&#10;7d23a4c Align indentation&#10;f171691 Removed a couple of self._info in theano/tensor/io.py&#10;b3faaf5 force pydotprint id to be string&#10;0a090a2 fix flake8 and remove assert as we now use id to separate node, not label.&#10;bb533b5 Merge pull request #3219 from nouiz/2g&#10;d854329 Fix copy to/from the gpu of size bigger then 2g&#10;6686a05 Fix GpuSubtensor for index higher then 2g&#10;c4d27c8 use apply node id to remove crush from the label.&#10;6c89a79 use pydotprint label on variable to allow multiple node with same visible string&#10;b6dc9a8 update edge is now blue&#10;46926f0 change var name&#10;44b5965 Make the update var a separate var in pydotprint&#10;9a653e3 Merge pull request #3150 from caglar/theano_shared_zero2&#10;b27c3d9 Removed some errors related to props in theano/tensor/subtensor.py&#10;573689a Added props to MPISend and MPIRecv in theano/tensor/io.py&#10;273ccd4 Removed redundant props in theano/tensor/extra_ops.py&#10;2d2ab8c Removed two methods related to props in theano/tensor/basic.py&#10;d62c777 Merge pull request #3215 from nouiz/cnmem&#10;5894477 Integrate the latest version of CNMEM&#10;09762a8 Make intermediate var as a box as input/output/shared var&#10;7830b42 Remove type on edge that go to output node or shared var&#10;2dfec94 Merge pull request #3125 from harlouci/flake8_v7&#10;498e765 Remove type on edge when the variable have it.&#10;bc93de3 Merge pull request #3168 from SinaHonari/issue3024&#10;b73758e Fix pydotprint update of shared var. Make the a new color cyan.&#10;b7f4e2c Fix pydotprint when the fgraph.outputs is reused.&#10;514c7de Merge pull request #3205 from nouiz/mixed2&#10;6f4542f Merge pull request #3083 from caglar/minor_scan_opt_optimizations&#10;677ead9 Added dtype='int16' for debugprint2 and 'int8' for debugprint3&#10;755ba97 Merge pull request #3189 from nouiz/fix_nan&#10;4377b8e Small correction in  theano/misc/check_blas.py&#10;b8f23cc Small correction in theano/misc/gh_api.py&#10;bbcc697 small test update following code review&#10;e7d00de Merge pull request #3204 from nouiz/cnmem_windows&#10;354d7b5 Merge pull request #2629 from abergeron/fix_merge_opts&#10;5a5bf5f Docstring typo reported by Xinyu Zhou. fix gh-3209&#10;23d188f Merge dnn conv desc correctly.&#10;9da4c13 Merge pull request #3208 from aflaxman/numpy_interface&#10;f671bca Merge pull request #3202 from craffel/symbolic_slicing&#10;c2af7c8 Merge pull request #3207 from nouiz/pep8_master&#10;128e3f5 pep8 fix in master&#10;bc96ed1 ENH: allow numpy.*(theano_var) to build a graph&#10;9400253 removing axis=None from sort Op&#10;2964727 Merge pull request #3153 from harlouci/flake8_gof_sequel&#10;5f6e897 Add test for slicing symbolic vars&#10;27ecbc0 Allow slicing of tensor variables to return symbolic shape refs&#10;21471c1 Merge pull request #3077 from julianser/new_stacktrace_fix&#10;208acb3 Fix test code to not depend on ordering of inputs to addition.&#10;e7f91a1 Add missing client check to the copy in gpuarray too.&#10;478c688 Revert the change that would broadcast the output if necessary and just don't apply the opt in that case.&#10;66cd79b Add missing client check.&#10;426795d Flake8 fix.&#10;c355374 Make the test easier to read/understand.&#10;e0bf503 Avoid digging through nodes that have multiple clients.&#10;7e2b9fc Fix comment.&#10;d285487 Test for broadcasted output merge.&#10;f08b1cd Add test for multiple clients of convolution.&#10;bcbcc1b Don't apply alpha_merge and output_merge when the proc node has more than one client.  Also apply output_merge in the case when the new output has to be broadcasted.&#10;8dbb181 Removed 'name' from the props in theano/misc/pycuda_example.py&#10;a5be81c props to theano/misc/pycuda_example.py&#10;c4ff11f Fix gpuarray test&#10;d1e98ce Imported six to settle flake8 errors&#10;56f1c0d Make travis fail when the first part fail. Not sure if this kill/don't start not started part. But should tell the user more rapidly in github interface&#10;d8f8934 Try to put slower travis part first&#10;1856586 Try to fix duplicate key by making sure the hash is valid&#10;7f35631 pep8&#10;808da4a removed to_keep and changed the reconstruction of to_keep_set&#10;5816665 to_remove_add function fixes.&#10;e4209e3 fixed a small comment.&#10;04a0760 flake8 changes and made the comment more visible.&#10;5f2ae03 changed the order in the if condition and remove the while loop.&#10;6fe5f21 few other cosmetic changes.&#10;dff25cb changed syntax for dict and few cosmetic changes.&#10;cbb487d more datastructure related changes.&#10;1e86bc8 replaced list concat with append.&#10;18ed49d existent_nodes -&gt; set&#10;377b1be replaced set update to set add.&#10;c05cf1c use python-native functions instead of numpy, which are faster.&#10;a1c1f05 removed unncessary import.&#10;e456487 various refactoring and fixes.&#10;61b3939 Added the easy optimizations for the scan.&#10;3ecc426 Fix compilation on windows with VS 2012&#10;d7d722f Merge pull request #3200 from t13m/inline_opt_destroyhandler&#10;6a39a8e Merge pull request #3199 from abergeron/gpuarray_opt&#10;ca465be Merge pull request #3198 from nouiz/cumem3&#10;23c5a0f Added 4 corrections related to Python3&#10;080a11f Fix visiblity and windows problems in cnmem (tested only on Linux)&#10;3a7cb5a Make following methods in destroyhandler.py inline:  - getroot  - add_impact  - get_impact&#10;562ee27 Fix bad change to gpuarray optimizations.&#10;f68df7f Small modif follow code review&#10;a14ed23 Don't hide symbol only when using cnmem and raise error on mac for now.&#10;81eba6e Use CNMeM more frequently&#10;3e40d56 cuda cnmem at one more place cublas batcheddot&#10;2ddaca0 Merge pull request #3117 from ChienliMa/infer_shape&#10;4e70bd8 Document cnmem&#10;ed1fca7 update lib.cnmem to be a float with new definition&#10;840f101 Acknowledge CNMeM&#10;95522df Add file modif time check to recompile cuda_ndarray&#10;7868934 make lib.cnmem be the memory to start&#10;fe6afee Set devices[i].streamSizes to NULL as per Frederic's comment&#10;a32109e Remove CNMEM_STATUS_MEMORY_LEAK from cuda_ndarray.cu&#10;2d9aff7 Update the version of CNMeM&#10;130d2ce Add support for CNMeM library.&#10;389c4ab Tmp fix to make cumem work with the reduced visibility&#10;1e0992f Print to stderr info about cumem&#10;712bef3 Make cumem with with device=gpu&#10;4345523 Add a Theano flags to enable cumem&#10;4ae044b Correctly init all fields for cumem device object&#10;f029445 Make Python error&#10;7eb5835 First cumem version&#10;8b13614 flake8 for theano/misc/check_blas.py&#10;eb742dd commenting out and unused var in theano/misc/pycuda_example.py&#10;28765bd flake8 for theano/misc/check_duplicate_key.py&#10;6ed8518 flake8 for theano/misc/pycuda_init.py&#10;c2a746f flake8 for theano/misc/safe_asarray.py&#10;94059e3 flake8 for theano/misc/may_share_memory.py&#10;0050109 flake8 for theano/misc/gnumpy_utils.py&#10;0325205 flake8 for theano/misc/strutil.py&#10;31c0fd7 flake8 for theano/misc/ordered_set.py&#10;f09999c flake8 for theano/misc/pycuda_example.py; 2 E left&#10;41e7e36 flake8 for theano/misc/pycuda_utils.py&#10;3c346fa flake8 for theano/misc/cudamat_utils.py&#10;f3028c4 flake8 for theano/misc/latence_gpu_transfert.py&#10;941f3e0 flake8 for theano/misc/check_blas.py&#10;eff5625 flake8 for theano/misc/gh_api.py&#10;d40710c flake8 for theano/misc/elemwise_openmp_speedup.py&#10;03e7723 Merge pull request #3095 from harlouci/flake8_v4&#10;9b45737 Fix indentation problem introduced in this PR&#10;871f387 pep8 and python3 fix&#10;d590f3d pep8&#10;2d169da Fix circular import&#10;ebcb444 flake8 for theano/tensor/nnet/neighbours.py&#10;b92c918 flake8 for theano/tensor/nnet/conv.py&#10;1fef942 flake8 fortheano/tensor/nnet/conv3d2d.py&#10;80a8289 flake8 for theano/tensor/nnet/ConvGrad3D.py&#10;7841649 flake8 for theano/tensor/nnet/sigm.py&#10;72fc02e flake8 for theano/tensor/nnet/ConvTransp3D.py&#10;692f901 flake8 for theano/tensor/nnet/Conv3D.py&#10;70b5f2c flake8 for tensor/nnet/nnet.py&#10;08ac04b clean up&#10;c9e0b2c flake8&#10;5965fc1 Fix bad var name found by flake8&#10;956aba0 flake8 and don't fix a file with special way of handling thing&#10;9a11eb6 flake8 of theano/gof/unify.py; 3 E left&#10;a294194 flake8 of theano/gof/op.py; 3 E left&#10;d916608 flake8 of theano/gof/graph.py; 1 E left&#10;3e66f33 Allow dict to be passed in props&#10;357c85b Move hash_from_dict and make it better support OrderedDict&#10;05e550d flake8 for theano/tensor/nlinalg.py&#10;7f5b5d9 flake8 for theano/tensor/io.py&#10;ca89624 flake8 for theano/tensor/blas.py&#10;faee3e7 flake8 for theano/tensor/basic.py&#10;735bac9 Restored str method in theano/tensor/basic.py&#10;1bdd2a0 __props__ for theano/tensor/type_other.py&#10;c91992f __props__ for theano/tensor/subtensor.py&#10;40b93f1 __props__ for theano/tensor/sort.py&#10;e08072c __props__ for theano/tensor/slinalg.py&#10;95022ce __props__ for theano/tensor/raw_random.py&#10;1a45cf8 __props__ for theano/tensor/opt.py&#10;1d07f91 __props__ for theano/tensor/nlinalg.py&#10;a622f3b __props for theano/tensor/io.py&#10;69894eb __props__ for theano/tensor/fourier.py&#10;cf2b6b2 __props__ for theano/tensor/extra_ops.py&#10;dc01863 __props__ for theano/tensor/elemwise.py&#10;576c75d __props__ for theano/tensor/blas.py&#10;b877527 __props__ for theano/tensor/basic.py&#10;143c2f9 Make ShapeFeature report the error to the user, but continue the execution.&#10;de54f16 Allow to unpickle again GpuConv&#10;5ef9acd Port some for GpuConv change to the new back-end. (fix test error in new back-end.&#10;a25d68f small doc update&#10;f4edcc5 Merge pull request #3186 from nouiz/mixed&#10;1b6e3b7 Fixed trailing white spaces.&#10;406e9fe Merge pull request #3193 from carriepl/gpu_reshape_memory_leak&#10;98b2d66 remove unused variable and add import&#10;b3f0311 Free new_shape before exiting in gpu_reshape&#10;3f60f2f Add comment for complicated implementation&#10;d8e7531 small fix from code review&#10;62fcda8 Reuse test_comparison in gpuarray to test sgn() isnan on GPU. Make gpuarray better handle nan. At the same time, enable c code for EQ with complex.&#10;9ccbda5 Merge pull request #3066 from t13m/debug_flag_print_rejected_optimizations&#10;64a7b4e Clone only once&#10;c50df51 Fix Sng handling of nan and fix related test&#10;669cf0d Merge pull request #3183 from kelvinxu/cpu_contiguous_fix&#10;77d2f91 Fix DotTester.test_good in debugmode, make *allocempty accept non finite value&#10;67a8b17 update comment&#10;7047353 check dims&#10;7c7c4b8 Don't put useless stuff in the graph&#10;66b2924 Fixed stack trace copying for several local optimizations according to Pascal's advice.&#10;21d7028 Implemented stack trace copying for several local optimizations.&#10;8b0ea4a Fixed minor bug.&#10;b700138 Further work on issue #3018.&#10;02be7a2 Better doc about using mrg on gpu&#10;fd79bce Add reshape test with size of 0, reused by new gpu back-end&#10;63a18e7 Keep variable creation stack trace&#10;c5cef8b Better doc&#10;891236a Merge pull request #3176 from mjwillson/CudaNdarray_reshape_zero_dims&#10;dfb52b3 Merge pull request #3155 from harlouci/props_gof_tests&#10;70e35eb Remove the restriction on zero target dimensions when reshaping a CudaNdarray&#10;f35669b pep-8 style fix&#10;4cbfea7 resotre clone after utils.infer_shape()&#10;c5e8a93 Merge pull request #3181 from harlouci/props_sandbox&#10;124cffe push special case&#10;664d0a9 delete clone before and after infer_shape&#10;fe50c10 Merge pull request #3180 from harlouci/props_sandbox_gpuarray&#10;ddacf68 Merge pull request #3179 from harlouci/props_sparse_sandbox&#10;f40bf43 Merge pull request #3169 from nouiz/GpuAdvancedIncSubtensor1_dev20&#10;1df11a0 flake8 for theano/gof/tests/test_cmodule.py&#10;b90c39c flake8 for theano/gof/tests/test_fg.py&#10;1e73a0b flake8 for theano/gof/tests/test_graph_opt_caching.py&#10;7cb9d72 flake8 for theano/gof/tests/test_link.py&#10;76d1591 flake8 for theano/gof/tests/test_cc.py&#10;be1c592 flake8 for theano/gof/tests/test_lazy.py&#10;80da6e4 flake8 for theano/gof/tests/test_sched.py&#10;1ace144 flake8 for theano/gof/tests/test_toolbox.py&#10;f3afa55 flake8 for theano/gof/tests/test_compute_test_value.py&#10;8cdeff0 flake8 for theano/gof/tests/test_destroyhandler.py&#10;daabc68 flake8 for theano/gof/tests/test_op.py&#10;adaea20 flake8 for theano/gof/tests/test_graph.py&#10;3dc1250 flake8 for theano/gof/tests/test_graph.py&#10;8c6c750 flake8 for theano/gof/tests/test_opt.py&#10;fc7be5b flake8 for theano/gof/tests/test_vm.py&#10;cd2272f Merge pull request #3145 from harlouci/props_tensor_nnet&#10;1f5f607 pep8&#10;777d79b Init err_var at the right place&#10;13627c5 correcting flake8 error&#10;ea889f4 Fix GpuAdvancedIncSubtensor1_dev20 with negative index in new back-end&#10;11ebaeb Better indentation&#10;10d9a03 Better indentation&#10;09f4c33 change tab to space&#10;d08a40f refactore the new code&#10;574e796 Make GpuAdvancedIncSubtensor1_dev20 return user index error&#10;102f212 Missing comma added to theano/tensor/nnet/neighbours.py&#10;eb37ade Correction for parameter axis at theano/compile/ops.py&#10;cb526ca pep8 and flake8 checking&#10;c74da33 Merge pull request #3151 from carriepl/local_sum_mul_by_scalar&#10;f8a4ee5 Merge pull request #3165 from carriepl/scan_pushout_opt_err&#10;80f5dea Merge pull request #3144 from harlouci/props_typed_list&#10;b8374e2 Merge pull request #3157 from harlouci/props_tests&#10;9dc0dc8 Merge pull request #3140 from JesseLivezey/check_blas&#10;2eb732e Merge pull request #3141 from harlouci/props_corrige2&#10;7b7d6d9 removing a bug&#10;fa34faf improving the code&#10;b27b75c improvement&#10;18d155d changing sort to work with other ndim&#10;ebbaae5 Fix GpuAdvancedIncSubtensor1_dev20 with negative index&#10;3f3bf14 Merge pull request #3120 from lamblin/fix_clinker&#10;6f3970e Merge pull request #3148 from harlouci/props_sparse&#10;98229fd Merge pull request #3159 from nouiz/tests&#10;93437b1 flake8&#10;04d1273 pep8&#10;9ffec77 Add tests for broadcastable pattern of flatten output&#10;4d65954 Fix broadcastable pattern of flatten output&#10;7f36ca7 Merge pull request #2930 from carriepl/gpuarray_elemwise_pow&#10;bbca839 Merge pull request #3161 from lamblin/misc_fixes&#10;09446af Merge pull request #3135 from nouiz/lock&#10;4ae1e1a props added to doc/tutorial/using_gpu.txt&#10;4fc583c props added to doc/tutorial/gpu_data_convert.txt&#10;f9db2ea Update comments&#10;a514bca Correction (axis) to theano/compile/ops.py&#10;400f677 Merge pull request #3164 from nouiz/fix_crash_amdlibm&#10;3746efc Fix crash, the amdlibm hack to remove it for nvcc change the hash./memtestCL --gpu 0 4000 10000 This also make use keep the lock for less time.&#10;7e1277e props to theano/sparse/sandbox/sp2.py&#10;59ea16b props to theano/sparse/sandbox/sp.py&#10;0660048 Fixes following code review&#10;ebfd181 props to theano/sandbox/gpuarray/dnn.py&#10;cc43bae props to theano/sandbox/gpuarray/basic_ops.py&#10;ed0e5b2 Shape should be computed by outer_input&#10;fa7441f props to theano/sandbox/rng_mrg.py&#10;d4b71ff props to theano/sandbox/neighbourhoods.py&#10;852050b props to theano/sandbox/multinomial.py&#10;36abf1c props to theano/sandbox/fourier.py&#10;1367e77 Synchronised with doc/extending/*.txt&#10;427daa0 Remove force fast_run mode&#10;58b0847 Whitespaces removed to theano/sparse/basic.py&#10;8897fcf Avoid inserting useless nodes in the graph during optimization&#10;f20c1c4 whitespaces removed at theano/gof/tests/test_destroyhandler.py&#10;4bfa10d Refactor code&#10;d330930 Fix badge. change web site, seem frequent problems with it: https://github.com/badges/pypipins/issues/37&#10;71e7c84 Fix some doc generation warnings/errors&#10;8522acb Update doc&#10;c356183 Merge pull request #3152 from carriepl/scan_aswhile_opt&#10;d124466 remove duplicated tests&#10;9df4e5d Merge pull request #3154 from harlouci/props_compile_tests&#10;3d3fd1c doc the new config value&#10;ae2999a Make sure to use the same pep8 and pyflakes as the last one. To be consistent with what we have here.&#10;116eeca make test compatible with floatX=float32&#10;98f6fde Test case data type should be same as config&#10;15a0111 Delete unused import&#10;846409e delete unused import&#10;7227f66 add missing changes&#10;3673950 infer_shape reuse scan.utils.infer_shape&#10;4725426 pep style fix&#10;e169558 Another implementation without error&#10;a51c6ec draft of infer_shape&#10;88e6c00 removed 2k default&#10;4786b8e Create files in a tmp dir, clean up afterwards&#10;fc35684 Remove nanguardmode output during tests&#10;5736476 Corrections to theano/tensor/nnet/conv3d2d.py&#10;29abb70 Correction to theano/sparse/opt.py&#10;36b69d5 theano/gof/tests/test_vm.py&#10;07d465c correction to theano/gof/tests/test_destroyhandler.py&#10;5956b40 Fix test in debug mode&#10;143dd81 Remove printing during test&#10;32f00eb Remove useless code&#10;64eb011 Merge pull request #3158 from nouiz/pep8_master&#10;b152e5b [TESTS] this fix a test while having concurrent PR that force pep8.&#10;b58b7cc __props__ for theano/tests/test_tutorial.py&#10;fe81821 __props__ for theano/tests/test_rop.py&#10;6a01c31 __props__ for theano/tests/test_gradient.py&#10;d88ebe2 removed cuda versions and gpus from new timing&#10;80e2bba Update comment&#10;9f361a0 Use the config flag instead of always True&#10;0d0b7e7 More general check&#10;c318153 Expand test&#10;a1530fe Fix when a variable is both an input and an output&#10;1b3afdf Test for that issue, that brings up a new one&#10;8734632 Fix case where 'output' is a client&#10;c71ac8a Add tests case for modification&#10;0c0dada Fix typo&#10;a893ae0 __props__ for theano/gof/tests/test_vm.py&#10;8239cf4 __props__ for theano/gof/tests/test_toolbox.py&#10;be4379c __props__ for theano/gof/tests/test_op.py&#10;de0cd14 __props__ for theano/gof/tests/test_link.py&#10;cdeaa76 __props__ for theano/gof/tests/test_graph.py&#10;29c4979 __props__ for theano/gof/tests/test_destroyhandler.py&#10;6193e53 __props__ for theano/gof/tests/test_compute_test_value.py&#10;e668144 __props__ for theano/gof/tests/test_cc.py&#10;4577347 __props__ for theano/compile/tests/test_debugmode.py&#10;c4c90d3 Added corrections to ops.py&#10;2d09814 Don't push out the outputs of an 'as_while' Scan&#10;2fd838b Update docstring in local_sum_prod_mul_by_scalar&#10;7f80efc Update local_sum_prod_mul_by_scalar to work correctly with products&#10;fbef885 Add test for local_sum_prod_mul_by_scalar&#10;227be8b Added multiple corrections to basic.py&#10;7279878 Commas in tuples...&#10;38ef043 This commas inside tuples...&#10;0f2d0a5 Added commas to one-element tuples&#10;ab9078d Added corrections to ops.py&#10;36edbef fred's suggestions.&#10;c210ef5 Added corrections to builders.py&#10;4704a39 Remove useless import&#10;b1dc85b added the shared variable zero fn.&#10;bfecee3 Minor changes&#10;c09aad1 Added __props__ to theano/sparse/opt.py&#10;0cbbd63 Added __props__ in class TrueDot&#10;b82123d __props__ to theano/sparse/basic.py&#10;14bd131 Additional corrections for __props__ in theano/tensor/nnet/conv3d2d.py&#10;cc754fa Additional corrections for __props__ in theano/tensor/nnet/nnet.py&#10;3380651 props E corrected in theano/tensor/nnet/Conv3D.py&#10;3e15fae props E corrected in theano/tensor/nnet/neighbours.py&#10;4670fdb __props__ to theano/compile/ops.py, one doubt with parameter of type *axis&#10;0a1e50e __props__ to theano/compile/builders.py&#10;715eae9 __props__ to theano/tensor/nnet/nnet.py&#10;51c960b __props__ to theano/tensor/nnet/neighbours.py&#10;a24188f __props__ to theano/tensor/nnet/ConvTransp3D.py&#10;603ed74 __props__ to theano/tensor/nnet/ConvGrad3D.py&#10;e28a57c __props__ to theano/tensor/nnet/conv3d2d.py&#10;9188880 __props__ to theano/tensor/nnet/Conv3D.py&#10;87fd014 __props__ to basic.py&#10;b730df3 Only transfer the exponential elemwise to the gpu if the out dtype is floating point&#10;20d3ed4 flake8 for theano/tensor/extra_ops.py&#10;6187e96 Added __props__ and removed __eq__, __hash__ to extra_ops.py&#10;e0afde9 Address nouiz's comments&#10;01f4490 Fix flake8&#10;bbdbbb3 add larger matrix for check_blas&#10;2aadc8e Fix import and gpuarray/dnn&#10;a638895 Grad of grad (with tests)&#10;12ace37 Also test with float16&#10;ecd547f Document float16 issue with GpuElemwise&#10;a532d4e Fix indentation&#10;836a4eb Add test for GpuElemwise(pow)&#10;a1e6c81 Fix typos in gpuarray&#10;258b0da Alter local_gpu_elemwise to ensure Pow is done in floats&#10;85f08bf Split DownsampleFactorMaxGrad&#10;1ddcd73 Do not remove the lock if taken by another process. Remove __del__ as it is not useful, it is registered atexit&#10;5d93f83 Don't delete the lock if we don't have it.&#10;d5b1d26 Revert &quot;remove printing in replace_all_validate&quot;&#10;39b6e18 remove printing in replace_all_validate&#10;7733f27 if verbose is false, no need for other information&#10;e8a8c98 fix for case that caller of validate_ doesn't have varaible verbose or r&#10;4f035b4 make Validator.validate_(fgraph) print out information itself&#10;d7e4677 remove the new flag just added&#10;e6ab6ba make replace_validate print out the exception and reason when fails&#10;64dffff add new config var named list_rejected_optimizers&#10;464677a Change default value of reoptimize_unpickled_function&#10;&#10;git-subtree-dir: libs/Theano&#10;git-subtree-split: 94c6aff4493090d3c849470b560b1cacee4c948c">Squashed 'libs/Theano/' changes from c89e1bc..94c6aff</a></code>

      <span class="hidden-text-expander inline">
        <button type="button" class="ellipsis-expander js-details-target">…</button>
      </span>
      <div class="commit-desc"><pre class="text-small">94c6aff Merge pull request #3378 from nouiz/gpu_elemwise_non_contiguous_fix
d714304 fix gh-3377 bug introduced by 41a8e89b63f5 merged by 7320e1b. GpuElemwise with non contiguous inputs give bad results
e25b4c7 Merge pull request #2958 from nouiz/default
5ecbbde Merge pull request #3364 from seanprime7/drvapi
16f37f4 Move the definition of ceil_intdiv to c_support_code.
0a4ca26 GpuConv doesn't inherit from a CPU op, hence HideC is not needed.
752f1f7 Merge pull request #3284 from abergeron/doctest
80264d0 Fix remaining test problems in documentation.
f747933 Add testcode for typed_list and get rid of test_tutorial.py
87025fc Fixup remaining files.
3a6d2fc Fixup tutorial/using_gpu.txt
a3d76ad Fixup doc/library/*
b1f7979 Fixup extending/* and delete associated tests.
3e303fc Fixup tutorial/* and remove matching tests.
a5e7075 testcode for doc/install_windows.txt
b0cf8f3 testcode for doc/install.txt
b5b45f2 testcode for doc/faq.txt
aebc4e7 testcode for python.txt
91d0e7d testcode for tensor/nnet/nnet.txt
270fd90 testcode for tensor/nnet/conv.txt
fa49116 testcode for doc/library/compile/shared.txt
9ccd5d3 testcode for doc/library/compile/profilemode.txt
1c2dfb8 testcode for doc/library/compile/nanguardmode.txt
0f79103 testcode for doc/library/compile/io.txt
2ddadd2 testcode for doc/library/compile/debugmode.txt
f8b377f testcode for doc/library/scan.txt
08aa59e testcode for doc/extending/unittest.txt
42c0e2f testcode for doc/extending/type.txt
889dbcf testcode for doc/extending/tips.txt
092ad94 testcode for doc/extending/other_ops.txt
cee71c3 testcode for doc/extending/optimization.txt
ee43bd1 testcode for doc/extending/op.txt
8e3dd3d testcode for doc/extending/inplace.txt
8b0980b testcode for doc/extending/graphstructures.txt
4b8b6ee testcode for doc/extending/fibby.txt
c25e846 testcode for doc/extending/ctype.txt
4959dd2 testcode for doc/extending/cop.txt
7826b44 testcode for doc/tutorial/using_gpu.txt
ce3ca94 testcode for doc/tutorial/symbolic_graphs.txt
5dcad44 testcode for doc/tutorial/modes.txt
b0c8223 testcode for doc/tutorial/loop.txt
be01a30 testcode for doc/tutorial/loading_and_saving.txt
e08c1db testcode for doc/tutorial/gradients.txt
7f27b9c testcode for doc/tutorial/gpu_data_convert.txt
88d73dd testcode for doc/tutorial/extending_theano_c.txt
6dedf85 testcode for doc/tutorial/extending_theano.txt
236f754 testcode for doc/tutorial/examples.txt
c4147fa testcode for doc/tutorial/debug_faq.txt
762cb0d testcode for doc/tutorial/conditions.txt
af235f4 testcode for doc/tutorial/aliasing.txt
cf7c062 testcode for doc/tutorial/adding.txt
955d880 Enable docgen.py to work on a subset of files.  This is mostly useful for --test.
81f27ce Move imports to the top of the file.
c042a9c Merge pull request #3362 from Thrandis/gpu_reshape
8ceb131 Corrected test mode.
41daf4a Use the CUDA Driver API for conv operations
0d5cffb Force instantiate kernel templates
89f584b Use the CUDA driver API for CUDA gpuarray operations.
82c804c Merge pull request #3360 from abergeron/calm_flake8
315e890 Merge pull request #3305 from lamblin/fix_setsubtensor1_nan
2ed29b2 GpuReshape opt.
7852531 Merge pull request #3357 from Thrandis/gpu_reshape
46696cf Add some of the default ignores back.
c42a18c Merge pull request #3358 from nouiz/tests
2a2ae62 Better error message
2fc09a0 More info in tests error
b996738 make lib.cnmem=1 work more frequently
b800881 Gpu reshape opt.
a4bc662 Fix test in FAST_COMPILE
dc13bfc Merge pull request #3339 from nouiz/davikrehalt-master
4668024 Merge pull request #3348 from nouiz/CoulombeC-master
f9e65e0 Merge pull request #3337 from nouiz/ignore_border
616d786 Update cudnn v3 config flag
709403a flake8
81b563b use str as we use everywhere else
a9c44a8 Fix crash in pydotprint
4c39c3f flake8
9dc5d70 Make the check for arm more generic
b3fa118 made compatible with Raspberry Pi 1
5afe6f9 pep8
79a353d Update docstring and warning message following review
87f8c5a Merge pull request #3344 from nouiz/cycle
ca8d85d Merge pull request #3290 from mohammadpz/prod_dimshuffle_opt
d537add Deactivate merge of assert as it cause cycle in the graph
85a7535 FusionOptimizer added for solve FAST_COMPILE issue
59b8455 more tests + comments
0686893 Logical tests added
303cc80 compatible dimes are now fixed
ae53db8 numerical tests added
6aa9d88 optimization for prod added
856aa0b Merge pull request #3267 from koningrobot/tensordot-as-dot
2fa005b Warn about pending ignore_border default value change.
77f6b2b Merge pull request #3334 from abergeron/delete_old_crap
7320e1b Merge pull request #3288 from abergeron/nouiz_mixed
7f43e9f Fix some typos and phrasings.
bcfe70c Remove remnants of theano modules that were deleted in 0.7.
43d58c1 Delete the old unmaintained copy of scan in sandbox.
c79e0cf Flake8 fix.
0b5ee2f hash tuple instead of xor them
1bc1c0f Remove deprecated comment
233e781 If a reduce upcast the input, don't move it to the GPU.
0b5aa21 Add config var NanGuardMode.{nan,inf,big}_is_error
6c4738d Make NanGuardMode not raise an error with theano.sandbox.rng_mrg.GPU_mrg_uniform
fdbe417 Make flag mode=NanGuardMode work and make it user provided optimizer
5922a93 Update following code review
5f3b4fa Doc about cudnn v3
b5aeafc Don't make opt return errors with bad user graph. The run time error will be better.
b08d5cb Remove useless gpu opt warning when dtype isn't float32
ce0a3f0 If the gpu isn't working don't raise an error uselessly
d6b799f Add assert to see better problems
ccfeeb2 pep8
9790a08 Don't try to move to the new back-end elemwise with multiple output(not yet supported)
944fd8e remove print
e4abbe9 Make inplace elemwise opt support multiple output
1a6e03c Fix dtype for Elemwise.perform with multiple output
350edca Make Composite raise an error for case not supported
41a8e89 Make GpuElemwise work with multiple output, (new back-end raise an error)
2595fea Better test
f9a2e45 Allow transfer type to hardcode the output dtype
a579c1e Make opt not crash with multi output CPU elemwise
6319e9d Fix crash with pycuda example
01be570 Print the number of element used. and long line
614a656 Doc how to pip install a given commit
c35eccc Better test error message
9611e48 Make the example force double to work what ever is floatX. This example is before we talk about floatX. fix gh-3240
50d5f65 Add in the license file that we have CnMeM with the same lisence and add its copyright
1d13344 Merge pull request #3323 from SinaHonari/issue3031
2802ac1 improving test
17e5737 Merge pull request #3325 from johnarevalo/patch-1
cb040b2 Fix AttributeError: 'builtin_function_or_method'
402bba5 adding a unit test for theano.tensor.constant reshape
565650e Merge pull request #3311 from bouthilx/sparse_block_dot
f646ff7 correcting a flake8 format error
26d6d1c improving coding
d2f8104 making code compatible to flake8
0ed1085 theano.tensor.constant reshape fix
aeb8c03 Fix optimizations
76b7101 Flake8 and inplace removed from sparse_block_dot.
a759089 Add Sphinx documentation and image to illustrate sparse block dot
5b604a4 Fix a few pep8 errors
1e0da36 Move sandbox/test_* to folder sandbox/tests/
7748ec1 Add tests for BlockSparse gemv and outer
658bf2e Add optimizations and relativ tests
ed4e009 Add a meta op BlockSparseDot
7ba9c05 Merge pull request #3055 from ChienliMa/swapSV
cc0670e pep 8 style fix
8dae1fb comply with PEP8
8d2c066 implement batched_tensordot in terms of batched_dot
09be448 Modify to fit python3
74cdb5d small fix
b91192d Cannot swap non sharedvariable
dd86da1 small fix for python 3
c624c7b small change to fix python3
2ddb82a Fix typos
35f9643 Delete white space in black line
66780ec Add test for param givens
7252071 delete extra line
43320ef swap input storage in in instances; put modification of fg.inputs outside fg.replace() cause some error occor
f303478 Delete update should be done after swap sv
876507f fgraph.inptus should be modified if we replace an inputs variable
d71a80f add test for sharedvar
51ff431 Restore deleted assertion of inputs
809e6ad modify test to assert SharedVariables are shared
35677c9 delete test that not work
5dd41d9 Delete copy of SharedVariable's storage, for they should have same value among different function
52a7a4d dtype should be same as config.floatX
83d631f Fix type error in testcase with given
d82fab6 extra test case of copy_swap_sv with given values
81d9975 Only seperate input storage of mutable SharedVariable
de6cd0a fix assert grammer error
ac86ad3 coding style fix
bbf84ee comment typo
e8689fc Just use better name
8464ed7 Fix profiling and add name to Function.copy()
2ba562a Fix crash with profiling and fct copy
255cc30 Typo fix in error message and comment
8bb9d77 delete space
96cb8c1 pep 8 fix
8eb39b7 Change param order in profilemaker
2d3bd2f pep 8 fix
47ff978 Delete test for whether output_storage is shared. For they are bound to be shared through shared intermediate storages.
f4fb1e5 Fit Profile_maker.create() with param storage_map
c5949e3 Update docs of param swap
b0e4cae raise ValueError when SharedVariable not found
b176037 Outs share borrow attribute.
b080380 move a line out of loop and fix typo
e06a4c6 add type conversion for map to fit higher version python.
5ce66fe pep-8 style fix
6c218ad delete debug code
a8a12e8 Allow to swap SharedVariable by SharedVariable Instances and update corresponding docs.
5220122 Rewrap Outs to avoid deepcopy whole graph
b6c5be0 Move '__swapSV' inline.
04f5090 Update docs( Fix typo and remove outdated docs )
6469437 Update docs; Delete debug code.
09fe88b pep8 coding style fix and return 'del a' line in test_leak2
0c1cdd8 Add feature 'delete_update'. Merge three features in one function. Add test cases.
3055ab4 finish swapSV and test
af1fb49 Swap vairable in Ins and improve docs
2e7c259 small modification
6400064 Start writting a test
dc36c99 Finish draft, it work. Start working on test and improve the code
81f7134 draft of swaping sharedvariable
127d36c delete unused variable in test
3754bb9 fix indentation
aaac6d2 merge function.copy() with function.__copy__() and fix #3049
be58f8b Update docs
0563dc8 Add test for VM_Linker; Add test for SharedVariable with/without updates; Simplify codes and delete extra line.
55815f1 add doc for function
599d637 Add assertion in map_storage to assert storage given by input/output_storage and storage_map is the same.
cbdb431 fix typo
8198dbf Perfect the docs of copy()
d243b92 reset commits
e7480f6 delete extra line
e43be99 Change of Ins/Outs copy strategy
eff0d6a add a varaible to avoid separating line
1cf16a2 new ins and old ins should shared value if value is unchanged otherwise not.
de0ded7 swap condition in Clinker.__compile__
0999205 change indent
af1f404 Add ```storage_map```argument for Profile_Maker;CLinker new support ```storage_map```(without testing)
af1e743 format change
85beeac delete extra line
691a113 add argument ```storage_map``` to other makers except ```Profile_Maker```
91c6f9e Add argument ```storage_map``` to the rest of theano linker
bacfd4d Format Change; Modify inproper comment;Change constructor class;Add test for output storage.
931de93 typo
b3d98cd Fix a bug: While initializing a clone graph it should not be cloned again, otherwise the equiv doesn't work.
d3c5723 Add some docs to FunctionGraph and minor changes of function_module.copy()
df77628 minor modification in test_function_module.py
0f599ff Small modification to copy(). Testcase is finished. Start debuging.
466a75f Correct typo. Add stoarge_map to PerformLinker.make_thunk(). Now it works!
fb60762 Minor fixes of typos and reverse modiication of test_reallocation()
5aa1237 Delete extra line
116fff5 Change interface of FunctionMaker.create()
1299708 Finish draft of Function.copy()
5ffc4ce change of variable name and some some docs in test_reallocation()
86d8127 Add some docs to map_storage()
c134e60 Fix a bug: While initializing a clone graph it should not be cloned again, otherwise the equiv doesn't work.
55277c4 Add some docs to FunctionGraph and minor changes of function_module.copy()
4846173 minor modification in test_function_module.py
dfe644b Small modification to copy(). Testcase is finished. Start debuging.
9101711 Minor fixes of typos and reverse modiication of test_reallocation()
b061ce2 Delete extra line
a8955e3 Modify link.map_storage() so that it make use of given storage_map
f6c74fc Finish draft of Function.copy()
e3ce7c8 change of variable name and some some docs in test_reallocation()
7bbfe9c pep8! fix code format
6d0539d add argument ```storage_map``` to other makers except ```Profile_Maker```
3a3a8f0 Add argument ```storage_map``` to the rest of theano linker
e2f3ceb Format Change; Modify inproper comment;Change constructor class;Add test for output storage.
cc53776 typo
aee78e7 Fix a bug: While initializing a clone graph it should not be cloned again, otherwise the equiv doesn't work.
ce29622 Add some docs to FunctionGraph and minor changes of function_module.copy()
c6c3d45  Modift FunctionGraph.clone_get_equiv() to enable avoiding attach feature
7c2223f minor modification in test_function_module.py
32a83c0 Small modification to copy(). Testcase is finished. Start debuging.
aa701ea Correct typo. Add stoarge_map to PerformLinker.make_thunk(). Now it works!
724ba41 Minor fixes of typos and reverse modiication of test_reallocation()
2572163 Delete extra line
e4a67cd start writing the test.
bcc3bd8 PerformLinker.make_all() can accepts storage_map
1616cb1 Modify link.map_storage() so that it make use of given storage_map
82e09e8 Change interface of FunctionMaker.create()
90d490c Finish draft of Function.copy()
98127db change of variable name and some some docs in test_reallocation()
c00ccdd Add some docs to map_storage()
00f184d Merge pull request #3308 from ivdorelian/patch-1
6304a06 Merge pull request #3293 from harlouci/numpydoc_tensor
4d918e9 Update sandbox/cuda/dnn_base.c to check malloc
5e53685 Merge pull request #3299 from harlouci/numpydoc_gof
8aaf5a5 Merge pull request #3309 from harlouci/numpydoc_conf
8e88a29 Corrected flake8 errors in theano/tensor/blas.py
65febf3 Corrected flake8 errors in theano/gof/type.py
ccbe857 Merge pull request #3303 from harlouci/numpydoc_sparse
1211db8 Merge pull request #3302 from harlouci/numpydoc_scan_module
690d362 Merge pull request #3301 from harlouci/numpydoc_compile
e8ecd0f Merge pull request #3296 from harlouci/numpydoc_typedList_scalar
d39e2e0 Merge pull request #3295 from harlouci/sandbox_cuda_dnn
931f4e9 Merge pull request #3297 from harlouci/numpydoc_sandbox_2
d1eba87 Merge pull request #3294 from harlouci/numpydoc_sandbox_1
a66610b Update sandbox/cuda/dnn_base.c to work on Windows
477fd7c Merge pull request #3307 from f0k/patch-1
0450d99 Correct config.lib.cnmem name in documentation
2da2c1d Do not read infinite value from output in advanced setsubtensor1
462e0fd numpydoc for theano/sparse/type.py
f347877 numpydoc for theano/sparse/sharedvar.py
38e3c3b numpydoc for theano/sparse/opt.py
48ef7fd numpydoc for theano/sparse/basic.py
02b6e41 numpydoc for theano/scan_module/scan_views.py
b7cf793 numpydoc for theano/scan_module/scan_utils.py
deabd34 numpydoc for theano/scan_module/scan_opt.py
ad86dfd numpydoc for theano/scan_module/scan_op.py
cacd26a numpydoc for theano/scan_module/__init__.py
a234c12 numpydoc for theano/scan_module/scan.py
533f5da Fixed Returns.
bacd93a numpydoc for theano/sandbox/scan_module/scan_utils.py
8d4e690 numpydoc for theano/sandbox/scan_module/scan_op.py
8c514f5 numpydoc for theano/sandbox/scan_module/scan.py
63577e4 numpydoc for theano/sandbox/scan_module/__init__.py
8b28afc numpydoc for theano/sandbox/linalg/ops.py
7f1b3bb flake8 corrections for theano/sandbox/gpuarray/opt.py
e2777e5 numpydoc for theano/sandbox/gpuarray/type.py
6f424ab numpydoc for theano/sandbox/gpuarray/subtensor.py
8c4c9d6 numpydoc for theano/sandbox/gpuarray/opt.py
2f22839 numpydoc for theano/sandbox/gpuarray/nnet.py
f772ce5 numpydoc for theano/sandbox/gpuarray/kernel_codegen.py
d438c2d flake8 corrections in theano/sandbox/gpuarray/dnn.py
6b9b3f2 flake8 corrections in theano/sandbox/cuda/GpuConv3D.py
88716ac Fixed Returns.
32f0f6d flake8 corrections for theano/gof/cc.py
b73195a Fixed all Returns
d25dac2 Small fixes in extra_ops.py, Conv3D.py and conv3d2d.py
bed6f01 numpydoc for theano/compile/sharedvalue.py
33a899b numpydoc for theano/compile/profiling.py
8d57251 numpydoc for theano/compile/profilemode.py
8129b74 numpydoc for theano/compile/pfunc.py
8feaa75 numpydoc for theano/compile/ops.py
1077f41 numpydoc for theano/compile/nanguardmode.py
a61580d numpydoc for theano/compile/monitormode.py
cdddc7d numpydoc for theano/compile/mode.py
3ca1e9a numpydoc for theano/compile/io.py
c537f5e numpydoc for theano/compile/function_module.py
0f00c10 numpydoc for theano/compile/function.py
e6ecae1 numpydoc for theano/compile/debugmode.py
d10856f numpydoc for theano/compile/builders.py
cdba68a numpydoc for theano/gof/vm.py
c99f5cb numpydoc for theano/gof/utils.py
9260f71 numpydoc for theano/gof/unify.py
54160cd numpydoc for theano/gof/type.py
4289537 numpydoc for theano/gof/toolbox.py
17429f3 numpydoc for theano/gof/sched.py
b70504c numpydoc for theano/gof/optdb.py
46d46d7 numpydoc for theano/gof/opt.py
ae99f41 numpydoc for theano/gof/op.py
24d214f numpydoc for theano/gof/null_type.py
ba7a952 numpydoc for theano/gof/link.py
fa6d41d numpydoc for theano/gof/__init__.py
fa75ad6 numpydoc for theano/gof/graph.py
75e573d numpydoc for theano/gof/fg.py
18c54ec numpydoc for theano/gof/destroyhandler.py
5da33fd numpydoc for theano/gof/cutils.py
438995e numpydoc for theano/gof/compilelock.py
80f8652 numpydoc for theano/gof/compiledir.py
ee6a799 numpydoc for theano/gof/cmodule.py
b61e972 numpydoc for theano/tensor/type.py
c621d24 numpydoc for theano/tensor/signal/downsample.py
81a13dc numpydoc for theano/tensor/signal/conv.py
7e822db numpydoc for theano/tensor/nnet/sigm.py
430561a numpydoc for theano/tensor/nnet/nnet.py
5858621 numpydoc for theano/tensor/nnet/neighbours.py
c0ef606 numpydoc for theano/tensor/nnet/ConvTransp3D.py
880f6f8 numpydoc for theano/tensor/nnet/ConvGrad3D.py
9ef3814 numpydoc for theano/tensor/nnet/Conv3D.py
e16273c numpydoc for theano/tensor/nnet/conv3d2d.py
61280f0 numpydoc for theano/tensor/nnet/conv.py
e29c2b1 numpydoc for theano/tensor/xlogx.py
15ba1e4 numpydoc for theano/tensor/var.py
ab2c91c numpydoc for theano/tensor/utils.py
56fd9af numpydoc for theano/tensor/type_other.py
d8835a5 numpydoc for theano/gof/cc.py
2450483 numpydoc for theano/sandbox/gpuarray/elemwise.py
c739cc8 numpydoc for theano/sandbox/gpuarray/dnn.py
45f18ba numpydoc for theano/sandbox/gpuarray/conv.py
acebecd numpydoc for theano/sandbox/gpuarray/comp.py
fd0b1f0 numpydoc for theano/sandbox/gpuarray/basic_ops.py
1e7b212 numpydoc for theano/sandbox/cuda/var.py
a5eb228 numpydoc for theano/sandbox/cuda/rng_curand.py
a5b4de5 Merge pull request #3292 from carriepl/scan_0_steps
909aa3d numpydoc for theano/sandbox/cuda/type.py
f464af1 Merge pull request #3278 from abergeron/doc
49af6ef numpydoc for theano/sandbox/cuda/opt.py
e9235e2 numpydoc for theano/sandbox/cuda/nvcc_compiler.py
1ca77e1 numpydoc for theano/sandbox/cuda/nnet.py
fd25c9c numpydoc for theano/sandbox/cuda/kernel_codegen.py
c489c64 numpydoc for theano/sandbox/cuda/__init__.py
44639e2 numpydoc for theano/sandbox/cuda/GpuConvTransp3D.py
cdcbda6 numpydoc for theano/sandbox/cuda/GpuConvGrad3D.py
7691524 numpydoc for theano/sandbox/cuda/GpuConv3D.py
2d9e40e numpydoc for theano/sandbox/cuda/fftconv.py
3e1612d numpydoc for theano/sandbox/cuda/extra_ops.py
472f91a numpydoc for theano/sandbox/cuda/elemwise.py
c0f6279 Merge pull request #3232 from t13m/merge_assert
e76d6bc numpydoc for theano/sandbox/cuda/dnn.py
a9a1db3 numpydoc for theano/sandbox/cuda/cula.py
25f7768 numpydoc for theano/sandbox/cuda/blocksparse.py
1a9da25 Added corrections to numpydoc for theano/sandbox/cuda/basic_ops.py
c413589 numpydoc for theano/sandbox/cuda/blas.py
257d4b5 numpydoc for theano/sandbox/cuda/basic_ops.py
a663afd numpydoc for theano/sandbox/theano_object.py
47ea038 numpydoc for theano/sandbox/test_rng_mrg.py
8befdc6 numpydoc for theano/sandbox/solve.py
0454676 numpydoc for theano/sandbox/scan.py
966aa9b numpydoc for theano/sandbox/rng_mrg.py
f2c57a5 numpydoc for theano/sandbox/neighbourhoods.py
69911d9 numpydoc for theano/sandbox/multinomial.py
7e74bc3 numpydoc for theano/sandbox/fourier.py
1023b22 numpydoc for theano/scalar/sharedvar.py
631ef39 numpydoc for theano/scalar/basic_sympy.py
a0ae981 numpydoc for theano/scalar/basic_scipy.py
69d6991 numpydoc for theano/scalar/basic.py
3389e78 numpydoc for theano/typed_list/type.py
b4536dc numpydoc for theano/typed_list/basic.py
8609f69 Add test case
56bb06e Prevent ScanSaveMem from generating 0-steps scans
1765e4e numpydoc for theano/tensor/subtensor.py
306ee2c numpydoc for theano/tensor/sort.py
a8983c9 numpydoc for theano/tensor/slinalg.py
be386f5 numpydoc for theano/tensor/sharedvar.py
356653b numpydoc for theano/tensor/shared_randomstreams.py
3ff5c1b numpydoc for raw_random.py
b8856a5 1 correction added to theano/tensor/extra_ops.py
9f2240d 2 corrections added in theano/tensor/elemwise.py
e8a979c Removal of an invisible character in theano/tensor/basic.py
ff7c816 numpydoc for theano/tensor/opt_uncanonicalize.py
f6141a6 numpydoc for theano/tensor/opt.py
7f31218 numpydoc for theano/tensor/nlinalg.py
ee4eedc numpydoc for theano/tensor/io.py
c172b4c numpydoc for theano/tensor/extra_ops.py
48de5a3 numpydoc for theano/tensor/elemwise_cgen.py
a5604ec numpydoc for theano/tensor/elemwise.py
a2913d3 numpydoc for theano/tensor/blas_headers.py
0c1711f numpydoc for theano/tensor/blas.py
47bf742 numpydoc for theano/tensor/basic.py
0a7415d Merge pull request #3289 from abergeron/disable_softmaxgrad_v3
9783d9a Disable the optimization to use DnnSoftmaxGrad for cuDNN v3 since it is broken for (n, c 1, 1) shapes at the moment.
6e7a904 Merge pull request #3139 from sebastien-j/average_pooling
ab71241 Add napoleon to extensions for numpydoc docstring parsing.
079181c Merge pull request #3275 from abergeron/fix_buildbot
5381bbd Make broadcast fixup in filter_variable() depend on an argument and stop doing it for shared variables.
b2f62a1 Fix type conversion in TensorType and expand it to other similar types.
8298b5b Always apply optimization
1b377a3 Small visual changes (blue color)
682385f Make a scan test take less than 3 hours on the buildbot in DEBUG_MODE.
9fd9e64 Add an :orphan: tag to documents that are not in the toctree so that sphinx doesn't complain anymore.
a994cf7 Fix format mistakes in the docs.
9de8616 Stop painting over broadcastable differences (since this could lead to a bug).
5f2c912 Make filter_variable correct safe broadcastable differences.
d27f239 Fix bug in get_scalar_constant value of Subtensor(Shape(Rebroadcast(v)))
02c218f Don't run test_gpu_memory_usage in DebugMode since it uses an enormous amount of memory.
44518ac Adjust memory increase since GpuAllocEmpty does not need a constant.
3f0f841 Make sure to disable C code in CAReduceDtype if the accumulator is in float16.
15c90dd Merge pull request #3270 from lamblin/windows_trace
10f2615 Also match Windows version of paths
65dda20 fix test case "test_both_assert_merge_1"
0add5fb verbose assert in gof test_opt MergeOptimizer test
5e3e851 add test case for reversed order
2228990 Merge pull request #3268 from pallegro/cudnn-python3-fix
01a4a9e python 3 fix in dnn.py
72b8b16 Merge pull request #3264 from Theano/pydot_ng
0efc781 Move down conditional import to keep flake8 happy
dd5cfff Use optimization with FAST_COMPILE too
8bcd326 Make pydotprint work with pydot_ng
2445d58 Merge pull request #3255 from cvangysel/master
8aa3dc1 Merge pull request #3256 from mop/allow-sections-with-dots
ecf4a8a Merge pull request #3260 from carriepl/cudnn_fixes2
8b640d3 Fix time_once and guess_once CuDNN options
de787b0 enable dots in section names
162306f Minor changes
e6a86a0 Exempt np.random.mtrand.RandomState from NaN/inf/big_number checking in NanGuardMode.
33f5b71 Add optimization for pooling gradient
1efbddc Fix indentation
51a26ad Merge pull request #3253 from carriepl/cudnn_fixes
fc1d668 Drop support for CuDNN v1
434ac02 Add info on behaviour of guess_* and time_* values
fd1e668 Change description for 'large' implementation
6e221a6 Merge pull request #3246 from lucasb-eyer/pydot-graphviz-missing-message
adbcbfc Merge pull request #3251 from f0k/fix-cudnn-copypaste-bug
e94e34b Merge pull request #3252 from f0k/patch-2
45adc6e Merge pull request #3250 from f0k/fix-cudnn-performance
df61d3b Fix metaoptimizer for cudnn
7524108 Fix copy/paste bug for cuDNN time_on_shape_change mode
8da3449 Fix GpuDnnConvGradI not being inserted automatically
8cb9d50 Merge pull request #3245 from carriepl/v3
929628d Clearer error message for missing pydot/graphviz.
4d4be31 Doc update
91f7135 pep8
d36faf2 Flake8 on dnn.py
d4d3ae5 Flake8 on test_dnn.py
397394d Remove DnnPoolGrad fix for max pooling (not necessary with public RC)
9839a00 Fix typo
f2e2a7b Modify dnn.conv.algo_fwd flag to support timing feature
fc1ed89 Modify GpuDnnConvGradI to support timing feature
c4df0b9 Modify GpuDnnConvGradW to support timing feature
a5fe8e3 In __setstate__ use flag value as default value
349378f Skip certain tests when using CuDNN with a version older than v3
32ad87b Don't run certain 2d convolution tests with CuDNN older than v3
4850f92 Include comments in #if-#endif condition
814ae6a Add error message for versions before v3
689ce21 Skip certain conv3d test when using cudnn v3
191de4e Change default implementation in Conv3d and Conv3dGrads to one supported in both V2 and V3
557c3fd Add checks for guess options in GpuDnnConv
178ad15 Update CuDNN optimizations to use new config flags
2b6ef54 Update dnn_conv3d to use new config flags
6f80c3b Update dnn_conv to use new config flags
5e6820a Update GpuDnnConv3dGradI to use new config flags
c586d80 Update GpuDnnConvGradI to use new config flags
14b8178 Update GpuDnnConv3dGradW to use new config flags
319cf62 Update GpuDnnConvGradW to use new config flags
e0eaa39 Update GpuDnnConv3d to use new config flags
28f72bb Update GpuDnnConv to use new config flags
d740f88 Change name of flags to control CuDNN convolution implementation
2389c49 Update checks for self.workmem value in GpuDnnConv
8c7ab09 Add 'guess_once' option for DnnConv3dGrad algo selection
8919980 Add 'time_once' and 'guess_once' options for DnnConv3d algo selection
680d203 Update docstring to reflect removed special case
05dc20d Ensure direction hint has valid value
564cd12 Adjust input values in conv bgrad test
8cee9f4 Fix TestDnnInferShapes.test_conv3d_gradi test
8368945 Only initialize output memory when max-pooling
2b8457d Init output memory for DnnPoolGrad
6a63844 Restrict conv2d special case to CuDNN v1
e9dcf6d Remove 3d convolution special case
50bee24 Adjust conditions for skipping tests in InferShapeTester
c2703ca Update CuDNN conv3d tests conditions for skipping
9b757b1 Reduce sizes of conv3d tests to limit rounding error
d24f599 Test conv3d also with integer subsample values
e4f276a Add shape test for conv3d gradi
bf40961 Add shape test for conv3d gradw
dbeb46f Avoid shapes with duplicate values
ad3cc2f Add shape tests for 3d fwd convolution
6babe38 Fix typos in grad methods of CuDNN 3d convolution
906f4ea Add test cases for fwd and bwd 3d convolution
8ff1685 Make GpuDnnConvDesc support 2 and 3 dimensions. Remove GpuDnnConv3dDesc.
bc65b24 Change default DnnConvGrad implementation
ebf020a Add comment to explain usage of check_isfinite=False
3009ff4 Skip test_pooling3d if cudnn not recent enough
b094c0b Merge test_log_softmax and test_log_softmax_opt
b09557a Remove 'nd' param from GpuDnnPoolDesc
912d125 Standardize CuDNN RuntimeError messages
486b760 Remove nb_dim param from dnn convolutions
b9e2976 Remove dim param from c_set_tensorNd and c_set_kernelNd
01706da Make dnn grad convolutions compatible with both V2 and V3
17bfc49 Support V2 in GpuDnnConv
3fdad2b Make dnn softmax compatible with V2
2ef334c Add tests for dnn_pool(..., nd=3)
8d45fea Add comment in test_log_softmax_opt
8df74d4 Add test for CuDNN log-softmax
268bc91 Extend the current pooling op to support 3d pooling.
525c9c8 c_set_tensor4d -&gt; c_set_tensorNd to be more generic (in C code).
4eb4a89 Add unit test for log-softmax optimization
2827eb5 Add opt for Dnn LogSoftmax
371fe99 small fix
806d27a update according to pull request commetns
f365f07 Fix TestDnnInferShapes.test_conv_gradi
f748cf8 fix rebase issues
822c06d fix guess/time workmem bug
7f78fce make cudnn conv3d gradI and gradW works
6117f98 add cudnnv3 conv3d
3422324 Add support for 'log' mode in GpuDnnSoftmax
bab0640 Make deterministic implementation the default in GradW and GradI
f62d6cf Refactor code
9f23176 Default to safe algo when fft is not supported
ad9646b Implement implementation selection for GpuDnnConvGradI
221fb06 Integrate v3 in GpuDnnConvGradW
813bc1e Add config flag for algo selection for gradient convolution
65eb53a Only extract chosen algo after checking for success
07931d2 Add attributes for implementation selection in the gradient convolution
552fb9d Set requestedCount to 1
755429d Update comment in GpuDnnConv
2597dcd Add support for implementation timing
f9b85e1 Implement cudnn implementation selection for FWD pass
2b83b6a Merge pull request #3238 from f0k/fix-corrmm-docstring
9685f1d add 3 new test cases for different cases of merging asserts; bug fix
07e9332 Merge pull request #3242 from abergeron/memmap_windows
f446396 Fix memmap test error on windows.
62b3bbd Merge pull request #3241 from abergeron/nan_gpu
5860e07 Add definition of NAN to cuda_ndarray.cuh.
fbf3dcd Fix outdated description of border_mode in GpuCorrMM constructor
c2cd739 Merge pull request #3229 from nouiz/nanguardmode
35c19ad Merge pull request #3237 from nouiz/python_rng
01e2ff6 new test case added; fix bug (create new assert node when different condition)
3517d36 Don't use python random generator durint Theano compilation
0172bb1 MergeOptimizer merge nodes with assert input
4b1194a Merge pull request #3230 from nouiz/stack_trace
088de5f If no stack trace, keep this as an empty list
161787e code clean up
4ff6f28 Speed up nanguardmode
077accb Make NanGuardMode not crash for cdatatype
948f726 Merge pull request #3224 from nouiz/mixed3
71e9f54 typo
9c6d217 Add time in profiling output
0177c84 Skip dnn test if it isn't avail
de6791f Fix gpuarray test
3113e86 Doc to use the c linker to lower overhead
23cc676 Better error message
63718d5 Add timming
5a70f9a Merge pull request #3221 from carriepl/scan_opt_bug
c8394fb Merge pull request #3147 from harlouci/props_compile
a384448 Merge pull request #3160 from harlouci/props_tensor
b3fc2a3 Merge pull request #3178 from harlouci/props_misc
8d2a084 Make sure change_flags decorator leaves the decorated function's name unchanged
dd22ded Reuse old Rebroadcast.__hash__ as it was working well
00c376d Change test to use change_flags decorator
f4c031c Removed inappropriate props in theano/tensor/basic.py
6485dbb Merge pull request #3213 from nouiz/pydotprint
154cc79 Add test case for optimization fix
630e194 Mark node to be deleted once it's certain it will be deleted
7d23a4c Align indentation
f171691 Removed a couple of self._info in theano/tensor/io.py
b3faaf5 force pydotprint id to be string
0a090a2 fix flake8 and remove assert as we now use id to separate node, not label.
bb533b5 Merge pull request #3219 from nouiz/2g
d854329 Fix copy to/from the gpu of size bigger then 2g
6686a05 Fix GpuSubtensor for index higher then 2g
c4d27c8 use apply node id to remove crush from the label.
6c89a79 use pydotprint label on variable to allow multiple node with same visible string
b6dc9a8 update edge is now blue
46926f0 change var name
44b5965 Make the update var a separate var in pydotprint
9a653e3 Merge pull request #3150 from caglar/theano_shared_zero2
b27c3d9 Removed some errors related to props in theano/tensor/subtensor.py
573689a Added props to MPISend and MPIRecv in theano/tensor/io.py
273ccd4 Removed redundant props in theano/tensor/extra_ops.py
2d2ab8c Removed two methods related to props in theano/tensor/basic.py
d62c777 Merge pull request #3215 from nouiz/cnmem
5894477 Integrate the latest version of CNMEM
09762a8 Make intermediate var as a box as input/output/shared var
7830b42 Remove type on edge that go to output node or shared var
2dfec94 Merge pull request #3125 from harlouci/flake8_v7
498e765 Remove type on edge when the variable have it.
bc93de3 Merge pull request #3168 from SinaHonari/issue3024
b73758e Fix pydotprint update of shared var. Make the a new color cyan.
b7f4e2c Fix pydotprint when the fgraph.outputs is reused.
514c7de Merge pull request #3205 from nouiz/mixed2
6f4542f Merge pull request #3083 from caglar/minor_scan_opt_optimizations
677ead9 Added dtype='int16' for debugprint2 and 'int8' for debugprint3
755ba97 Merge pull request #3189 from nouiz/fix_nan
4377b8e Small correction in  theano/misc/check_blas.py
b8f23cc Small correction in theano/misc/gh_api.py
bbcc697 small test update following code review
e7d00de Merge pull request #3204 from nouiz/cnmem_windows
354d7b5 Merge pull request #2629 from abergeron/fix_merge_opts
5a5bf5f Docstring typo reported by Xinyu Zhou. fix gh-3209
23d188f Merge dnn conv desc correctly.
9da4c13 Merge pull request #3208 from aflaxman/numpy_interface
f671bca Merge pull request #3202 from craffel/symbolic_slicing
c2af7c8 Merge pull request #3207 from nouiz/pep8_master
128e3f5 pep8 fix in master
bc96ed1 ENH: allow numpy.*(theano_var) to build a graph
9400253 removing axis=None from sort Op
2964727 Merge pull request #3153 from harlouci/flake8_gof_sequel
5f6e897 Add test for slicing symbolic vars
27ecbc0 Allow slicing of tensor variables to return symbolic shape refs
21471c1 Merge pull request #3077 from julianser/new_stacktrace_fix
208acb3 Fix test code to not depend on ordering of inputs to addition.
e7f91a1 Add missing client check to the copy in gpuarray too.
478c688 Revert the change that would broadcast the output if necessary and just don't apply the opt in that case.
66cd79b Add missing client check.
426795d Flake8 fix.
c355374 Make the test easier to read/understand.
e0bf503 Avoid digging through nodes that have multiple clients.
7e2b9fc Fix comment.
d285487 Test for broadcasted output merge.
f08b1cd Add test for multiple clients of convolution.
bcbcc1b Don't apply alpha_merge and output_merge when the proc node has more than one client.  Also apply output_merge in the case when the new output has to be broadcasted.
8dbb181 Removed 'name' from the props in theano/misc/pycuda_example.py
a5be81c props to theano/misc/pycuda_example.py
c4ff11f Fix gpuarray test
d1e98ce Imported six to settle flake8 errors
56f1c0d Make travis fail when the first part fail. Not sure if this kill/don't start not started part. But should tell the user more rapidly in github interface
d8f8934 Try to put slower travis part first
1856586 Try to fix duplicate key by making sure the hash is valid
7f35631 pep8
808da4a removed to_keep and changed the reconstruction of to_keep_set
5816665 to_remove_add function fixes.
e4209e3 fixed a small comment.
04a0760 flake8 changes and made the comment more visible.
5f2ae03 changed the order in the if condition and remove the while loop.
6fe5f21 few other cosmetic changes.
dff25cb changed syntax for dict and few cosmetic changes.
cbb487d more datastructure related changes.
1e86bc8 replaced list concat with append.
18ed49d existent_nodes -&gt; set
377b1be replaced set update to set add.
c05cf1c use python-native functions instead of numpy, which are faster.
a1c1f05 removed unncessary import.
e456487 various refactoring and fixes.
61b3939 Added the easy optimizations for the scan.
3ecc426 Fix compilation on windows with VS 2012
d7d722f Merge pull request #3200 from t13m/inline_opt_destroyhandler
6a39a8e Merge pull request #3199 from abergeron/gpuarray_opt
ca465be Merge pull request #3198 from nouiz/cumem3
23c5a0f Added 4 corrections related to Python3
080a11f Fix visiblity and windows problems in cnmem (tested only on Linux)
3a7cb5a Make following methods in destroyhandler.py inline:  - getroot  - add_impact  - get_impact
562ee27 Fix bad change to gpuarray optimizations.
f68df7f Small modif follow code review
a14ed23 Don't hide symbol only when using cnmem and raise error on mac for now.
81eba6e Use CNMeM more frequently
3e40d56 cuda cnmem at one more place cublas batcheddot
2ddaca0 Merge pull request #3117 from ChienliMa/infer_shape
4e70bd8 Document cnmem
ed1fca7 update lib.cnmem to be a float with new definition
840f101 Acknowledge CNMeM
95522df Add file modif time check to recompile cuda_ndarray
7868934 make lib.cnmem be the memory to start
fe6afee Set devices[i].streamSizes to NULL as per Frederic's comment
a32109e Remove CNMEM_STATUS_MEMORY_LEAK from cuda_ndarray.cu
2d9aff7 Update the version of CNMeM
130d2ce Add support for CNMeM library.
389c4ab Tmp fix to make cumem work with the reduced visibility
1e0992f Print to stderr info about cumem
712bef3 Make cumem with with device=gpu
4345523 Add a Theano flags to enable cumem
4ae044b Correctly init all fields for cumem device object
f029445 Make Python error
7eb5835 First cumem version
8b13614 flake8 for theano/misc/check_blas.py
eb742dd commenting out and unused var in theano/misc/pycuda_example.py
28765bd flake8 for theano/misc/check_duplicate_key.py
6ed8518 flake8 for theano/misc/pycuda_init.py
c2a746f flake8 for theano/misc/safe_asarray.py
94059e3 flake8 for theano/misc/may_share_memory.py
0050109 flake8 for theano/misc/gnumpy_utils.py
0325205 flake8 for theano/misc/strutil.py
31c0fd7 flake8 for theano/misc/ordered_set.py
f09999c flake8 for theano/misc/pycuda_example.py; 2 E left
41e7e36 flake8 for theano/misc/pycuda_utils.py
3c346fa flake8 for theano/misc/cudamat_utils.py
f3028c4 flake8 for theano/misc/latence_gpu_transfert.py
941f3e0 flake8 for theano/misc/check_blas.py
eff5625 flake8 for theano/misc/gh_api.py
d40710c flake8 for theano/misc/elemwise_openmp_speedup.py
03e7723 Merge pull request #3095 from harlouci/flake8_v4
9b45737 Fix indentation problem introduced in this PR
871f387 pep8 and python3 fix
d590f3d pep8
2d169da Fix circular import
ebcb444 flake8 for theano/tensor/nnet/neighbours.py
b92c918 flake8 for theano/tensor/nnet/conv.py
1fef942 flake8 fortheano/tensor/nnet/conv3d2d.py
80a8289 flake8 for theano/tensor/nnet/ConvGrad3D.py
7841649 flake8 for theano/tensor/nnet/sigm.py
72fc02e flake8 for theano/tensor/nnet/ConvTransp3D.py
692f901 flake8 for theano/tensor/nnet/Conv3D.py
70b5f2c flake8 for tensor/nnet/nnet.py
08ac04b clean up
c9e0b2c flake8
5965fc1 Fix bad var name found by flake8
956aba0 flake8 and don't fix a file with special way of handling thing
9a11eb6 flake8 of theano/gof/unify.py; 3 E left
a294194 flake8 of theano/gof/op.py; 3 E left
d916608 flake8 of theano/gof/graph.py; 1 E left
3e66f33 Allow dict to be passed in props
357c85b Move hash_from_dict and make it better support OrderedDict
05e550d flake8 for theano/tensor/nlinalg.py
7f5b5d9 flake8 for theano/tensor/io.py
ca89624 flake8 for theano/tensor/blas.py
faee3e7 flake8 for theano/tensor/basic.py
735bac9 Restored str method in theano/tensor/basic.py
1bdd2a0 __props__ for theano/tensor/type_other.py
c91992f __props__ for theano/tensor/subtensor.py
40b93f1 __props__ for theano/tensor/sort.py
e08072c __props__ for theano/tensor/slinalg.py
95022ce __props__ for theano/tensor/raw_random.py
1a45cf8 __props__ for theano/tensor/opt.py
1d07f91 __props__ for theano/tensor/nlinalg.py
a622f3b __props for theano/tensor/io.py
69894eb __props__ for theano/tensor/fourier.py
cf2b6b2 __props__ for theano/tensor/extra_ops.py
dc01863 __props__ for theano/tensor/elemwise.py
576c75d __props__ for theano/tensor/blas.py
b877527 __props__ for theano/tensor/basic.py
143c2f9 Make ShapeFeature report the error to the user, but continue the execution.
de54f16 Allow to unpickle again GpuConv
5ef9acd Port some for GpuConv change to the new back-end. (fix test error in new back-end.
a25d68f small doc update
f4edcc5 Merge pull request #3186 from nouiz/mixed
1b6e3b7 Fixed trailing white spaces.
406e9fe Merge pull request #3193 from carriepl/gpu_reshape_memory_leak
98b2d66 remove unused variable and add import
b3f0311 Free new_shape before exiting in gpu_reshape
3f60f2f Add comment for complicated implementation
d8e7531 small fix from code review
62fcda8 Reuse test_comparison in gpuarray to test sgn() isnan on GPU. Make gpuarray better handle nan. At the same time, enable c code for EQ with complex.
9ccbda5 Merge pull request #3066 from t13m/debug_flag_print_rejected_optimizations
64a7b4e Clone only once
c50df51 Fix Sng handling of nan and fix related test
669cf0d Merge pull request #3183 from kelvinxu/cpu_contiguous_fix
77d2f91 Fix DotTester.test_good in debugmode, make *allocempty accept non finite value
67a8b17 update comment
7047353 check dims
7c7c4b8 Don't put useless stuff in the graph
66b2924 Fixed stack trace copying for several local optimizations according to Pascal's advice.
21d7028 Implemented stack trace copying for several local optimizations.
8b0ea4a Fixed minor bug.
b700138 Further work on issue #3018.
02be7a2 Better doc about using mrg on gpu
fd79bce Add reshape test with size of 0, reused by new gpu back-end
63a18e7 Keep variable creation stack trace
c5cef8b Better doc
891236a Merge pull request #3176 from mjwillson/CudaNdarray_reshape_zero_dims
dfb52b3 Merge pull request #3155 from harlouci/props_gof_tests
70e35eb Remove the restriction on zero target dimensions when reshaping a CudaNdarray
f35669b pep-8 style fix
4cbfea7 resotre clone after utils.infer_shape()
c5e8a93 Merge pull request #3181 from harlouci/props_sandbox
124cffe push special case
664d0a9 delete clone before and after infer_shape
fe50c10 Merge pull request #3180 from harlouci/props_sandbox_gpuarray
ddacf68 Merge pull request #3179 from harlouci/props_sparse_sandbox
f40bf43 Merge pull request #3169 from nouiz/GpuAdvancedIncSubtensor1_dev20
1df11a0 flake8 for theano/gof/tests/test_cmodule.py
b90c39c flake8 for theano/gof/tests/test_fg.py
1e73a0b flake8 for theano/gof/tests/test_graph_opt_caching.py
7cb9d72 flake8 for theano/gof/tests/test_link.py
76d1591 flake8 for theano/gof/tests/test_cc.py
be1c592 flake8 for theano/gof/tests/test_lazy.py
80da6e4 flake8 for theano/gof/tests/test_sched.py
1ace144 flake8 for theano/gof/tests/test_toolbox.py
f3afa55 flake8 for theano/gof/tests/test_compute_test_value.py
8cdeff0 flake8 for theano/gof/tests/test_destroyhandler.py
daabc68 flake8 for theano/gof/tests/test_op.py
adaea20 flake8 for theano/gof/tests/test_graph.py
3dc1250 flake8 for theano/gof/tests/test_graph.py
8c6c750 flake8 for theano/gof/tests/test_opt.py
fc7be5b flake8 for theano/gof/tests/test_vm.py
cd2272f Merge pull request #3145 from harlouci/props_tensor_nnet
1f5f607 pep8
777d79b Init err_var at the right place
13627c5 correcting flake8 error
ea889f4 Fix GpuAdvancedIncSubtensor1_dev20 with negative index in new back-end
11ebaeb Better indentation
10d9a03 Better indentation
09f4c33 change tab to space
d08a40f refactore the new code
574e796 Make GpuAdvancedIncSubtensor1_dev20 return user index error
102f212 Missing comma added to theano/tensor/nnet/neighbours.py
eb37ade Correction for parameter axis at theano/compile/ops.py
cb526ca pep8 and flake8 checking
c74da33 Merge pull request #3151 from carriepl/local_sum_mul_by_scalar
f8a4ee5 Merge pull request #3165 from carriepl/scan_pushout_opt_err
80f5dea Merge pull request #3144 from harlouci/props_typed_list
b8374e2 Merge pull request #3157 from harlouci/props_tests
9dc0dc8 Merge pull request #3140 from JesseLivezey/check_blas
2eb732e Merge pull request #3141 from harlouci/props_corrige2
7b7d6d9 removing a bug
fa34faf improving the code
b27b75c improvement
18d155d changing sort to work with other ndim
ebbaae5 Fix GpuAdvancedIncSubtensor1_dev20 with negative index
3f3bf14 Merge pull request #3120 from lamblin/fix_clinker
6f3970e Merge pull request #3148 from harlouci/props_sparse
98229fd Merge pull request #3159 from nouiz/tests
93437b1 flake8
04d1273 pep8
9ffec77 Add tests for broadcastable pattern of flatten output
4d65954 Fix broadcastable pattern of flatten output
7f36ca7 Merge pull request #2930 from carriepl/gpuarray_elemwise_pow
bbca839 Merge pull request #3161 from lamblin/misc_fixes
09446af Merge pull request #3135 from nouiz/lock
4ae1e1a props added to doc/tutorial/using_gpu.txt
4fc583c props added to doc/tutorial/gpu_data_convert.txt
f9db2ea Update comments
a514bca Correction (axis) to theano/compile/ops.py
400f677 Merge pull request #3164 from nouiz/fix_crash_amdlibm
3746efc Fix crash, the amdlibm hack to remove it for nvcc change the hash./memtestCL --gpu 0 4000 10000 This also make use keep the lock for less time.
7e1277e props to theano/sparse/sandbox/sp2.py
59ea16b props to theano/sparse/sandbox/sp.py
0660048 Fixes following code review
ebfd181 props to theano/sandbox/gpuarray/dnn.py
cc43bae props to theano/sandbox/gpuarray/basic_ops.py
ed0e5b2 Shape should be computed by outer_input
fa7441f props to theano/sandbox/rng_mrg.py
d4b71ff props to theano/sandbox/neighbourhoods.py
852050b props to theano/sandbox/multinomial.py
36abf1c props to theano/sandbox/fourier.py
1367e77 Synchronised with doc/extending/*.txt
427daa0 Remove force fast_run mode
58b0847 Whitespaces removed to theano/sparse/basic.py
8897fcf Avoid inserting useless nodes in the graph during optimization
f20c1c4 whitespaces removed at theano/gof/tests/test_destroyhandler.py
4bfa10d Refactor code
d330930 Fix badge. change web site, seem frequent problems with it: <a href="https://github.com/badges/pypipins/issues/37" class="issue-link js-issue-link" data-url="https://github.com/badges/pypipins/issues/37" data-id="71568816" data-error-text="Failed to load issue title" data-permission-text="Issue title is private">badges/pypipins#37</a>
71e7c84 Fix some doc generation warnings/errors
8522acb Update doc
c356183 Merge pull request #3152 from carriepl/scan_aswhile_opt
d124466 remove duplicated tests
9df4e5d Merge pull request #3154 from harlouci/props_compile_tests
3d3fd1c doc the new config value
ae2999a Make sure to use the same pep8 and pyflakes as the last one. To be consistent with what we have here.
116eeca make test compatible with floatX=float32
98f6fde Test case data type should be same as config
15a0111 Delete unused import
846409e delete unused import
7227f66 add missing changes
3673950 infer_shape reuse scan.utils.infer_shape
4725426 pep style fix
e169558 Another implementation without error
a51c6ec draft of infer_shape
88e6c00 removed 2k default
4786b8e Create files in a tmp dir, clean up afterwards
fc35684 Remove nanguardmode output during tests
5736476 Corrections to theano/tensor/nnet/conv3d2d.py
29abb70 Correction to theano/sparse/opt.py
36b69d5 theano/gof/tests/test_vm.py
07d465c correction to theano/gof/tests/test_destroyhandler.py
5956b40 Fix test in debug mode
143dd81 Remove printing during test
32f00eb Remove useless code
64eb011 Merge pull request #3158 from nouiz/pep8_master
b152e5b [TESTS] this fix a test while having concurrent PR that force pep8.
b58b7cc __props__ for theano/tests/test_tutorial.py
fe81821 __props__ for theano/tests/test_rop.py
6a01c31 __props__ for theano/tests/test_gradient.py
d88ebe2 removed cuda versions and gpus from new timing
80e2bba Update comment
9f361a0 Use the config flag instead of always True
0d0b7e7 More general check
c318153 Expand test
a1530fe Fix when a variable is both an input and an output
1b3afdf Test for that issue, that brings up a new one
8734632 Fix case where 'output' is a client
c71ac8a Add tests case for modification
0c0dada Fix typo
a893ae0 __props__ for theano/gof/tests/test_vm.py
8239cf4 __props__ for theano/gof/tests/test_toolbox.py
be4379c __props__ for theano/gof/tests/test_op.py
de0cd14 __props__ for theano/gof/tests/test_link.py
cdeaa76 __props__ for theano/gof/tests/test_graph.py
29c4979 __props__ for theano/gof/tests/test_destroyhandler.py
6193e53 __props__ for theano/gof/tests/test_compute_test_value.py
e668144 __props__ for theano/gof/tests/test_cc.py
4577347 __props__ for theano/compile/tests/test_debugmode.py
c4c90d3 Added corrections to ops.py
2d09814 Don't push out the outputs of an 'as_while' Scan
2fd838b Update docstring in local_sum_prod_mul_by_scalar
7f80efc Update local_sum_prod_mul_by_scalar to work correctly with products
fbef885 Add test for local_sum_prod_mul_by_scalar
227be8b Added multiple corrections to basic.py
7279878 Commas in tuples...
38ef043 This commas inside tuples...
0f2d0a5 Added commas to one-element tuples
ab9078d Added corrections to ops.py
36edbef fred's suggestions.
c210ef5 Added corrections to builders.py
4704a39 Remove useless import
b1dc85b added the shared variable zero fn.
bfecee3 Minor changes
c09aad1 Added __props__ to theano/sparse/opt.py
0cbbd63 Added __props__ in class TrueDot
b82123d __props__ to theano/sparse/basic.py
14bd131 Additional corrections for __props__ in theano/tensor/nnet/conv3d2d.py
cc754fa Additional corrections for __props__ in theano/tensor/nnet/nnet.py
3380651 props E corrected in theano/tensor/nnet/Conv3D.py
3e15fae props E corrected in theano/tensor/nnet/neighbours.py
4670fdb __props__ to theano/compile/ops.py, one doubt with parameter of type *axis
0a1e50e __props__ to theano/compile/builders.py
715eae9 __props__ to theano/tensor/nnet/nnet.py
51c960b __props__ to theano/tensor/nnet/neighbours.py
a24188f __props__ to theano/tensor/nnet/ConvTransp3D.py
603ed74 __props__ to theano/tensor/nnet/ConvGrad3D.py
e28a57c __props__ to theano/tensor/nnet/conv3d2d.py
9188880 __props__ to theano/tensor/nnet/Conv3D.py
87fd014 __props__ to basic.py
b730df3 Only transfer the exponential elemwise to the gpu if the out dtype is floating point
20d3ed4 flake8 for theano/tensor/extra_ops.py
6187e96 Added __props__ and removed __eq__, __hash__ to extra_ops.py
e0afde9 Address nouiz's comments
01f4490 Fix flake8
bbdbbb3 add larger matrix for check_blas
2aadc8e Fix import and gpuarray/dnn
a638895 Grad of grad (with tests)
12ace37 Also test with float16
ecd547f Document float16 issue with GpuElemwise
a532d4e Fix indentation
836a4eb Add test for GpuElemwise(pow)
a1e6c81 Fix typos in gpuarray
258b0da Alter local_gpu_elemwise to ensure Pow is done in floats
85f08bf Split DownsampleFactorMaxGrad
1ddcd73 Do not remove the lock if taken by another process. Remove __del__ as it is not useful, it is registered atexit
5d93f83 Don't delete the lock if we don't have it.
d5b1d26 Revert "remove printing in replace_all_validate"
39b6e18 remove printing in replace_all_validate
7733f27 if verbose is false, no need for other information
e8a8c98 fix for case that caller of validate_ doesn't have varaible verbose or r
4f035b4 make Validator.validate_(fgraph) print out information itself
d7e4677 remove the new flag just added
e6ab6ba make replace_validate print out the exception and reason when fails
64dffff add new config var named list_rejected_optimizers
464677a Change default value of reoptimize_unpickled_function

git-subtree-dir: libs/Theano
git-subtree-split: 94c6aff4493090d3c849470b560b1cacee4c948c</pre></div>
  </td>

  <td class="commit-meta">


    <code><a href="/Bjornwolf/language-model/commit/8ee69bb556edec76c488d4f47557df0a6eacd4f7" class="commit-id">8ee69bb</a></code>
  </td>
</tr>

    </div></body></html>