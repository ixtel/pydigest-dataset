<html><body><div><section class="post-content">
            <p>Configuring a data science environment can be a pain.  Dealing with inconsistent package versions, having to dive through obscure error messages, and having to wait hours for packages to compile can be frustrating.  This makes it hard to get started with data science in the first place, and is a completely arbitrary barrier to entry.</p>

<p>The past few years have seen the rise of technologies that help with this by creating isolated environments.  We’ll be exploring one in particular, <a href="https://www.docker.com/">Docker</a>.  Docker makes it fast and easy to create new data science environments, and use tools such as <a href="https://jupyter.org/">Jupyter</a> notebooks to explore your data.</p>

<p>With Docker, we can download an image file that contains a set of packages and data science tools.  We can then boot up a data science environment using this image within seconds, without the need to manually install packages or wait around.  This environment is called a Docker container.  Containers eliminate configuration problems – when you start a Docker container, it has a known good state, and all the packages work properly.</p>

<div>
<div class="row">
<div class="col-md-4 col-md-offset-4">
     <img class="full-width" src="/blog/images/docker_ds/docker.png"/>
     <p class="small text-center">The Docker whale is here to help</p>
     </div>
     </div>
</div>

<p>In addition to lowering the barriers to getting started with data science, Docker also makes it possible to quickly create isolated environments with different Python and package versions without having to wait for packages to install in <a href="http://docs.python-guide.org/en/latest/dev/virtualenvs/">virtual environments</a>.</p>

<p>In this post, we’ll cover the basics of Docker, how to install it, and how to leverage Docker containers to quickly get started with data science on your own machine.</p>

<h2 id="virtual-machines">Virtual machines</h2>

<p>Software that creates <a href="https://en.wikipedia.org/wiki/Virtual_machine">virtual machines</a> has existed for decades.  Virtual machines allow you to emulate other computing environments on your computer.  For example, you could run Linux in a virtual machine, even if your computer runs Windows.  This would let you use Linux without having to actually install it on your machine – it would be running virtually, so you would be able to access it from within Windows.  You’d be able to essentially click a program, and a Linux desktop would pop up in a window.  Virtual machines use images to boot up – you have to start a virtual machine with an image that corresponds to the operating system you want to use.  If you want to use Linux, you’d use an image that contains all of the necessary files to create a Linux environment.</p>

<div>
<div class="row">
<div class="col-md-6 col-md-offset-3">
     <img class="full-width" src="/blog/images/docker_ds/windows_mac.png"/>
     <p class="small">An example of using Windows in a virtual machine on a mac</p>
     </div>
     </div>
</div>

<h2 id="containers">Containers</h2>

<p>Although virtual machines enable Linux development to take place on Windows, for example, they have some downsides.  Virtual machines take a long time to boot up, they require significant system resources, and it’s hard to create a virtual machine from an image, install some packages, and then create another image.  <a href="https://en.wikipedia.org/wiki/LXC">Linux containers</a> solve this problem by enabling multiple isolated environments to run on a single machine.  Think of containers as a faster, easier way to get started with virtual machines.</p>

<p>Unfortunately, containers are a bit tricky to use, and it’s not easy to manage and distribute container images.  We want these features so we can quickly download and start data science environments with specific package and tool configurations.  For instance, you might want to be able to quickly start a container that has Jupyter notebook, spark, and pandas already installed.</p>

<h2 id="docker">Docker</h2>

<p>Docker containers are a layer over Linux containers that makes them easier to manage and distribute.  Docker makes it easy to download images that correspond to a specific set of packages, and start them quickly.  Docker is cross-platform, and works on Mac, Windows, and Linux.</p>

<p>These same advantages also apply to <a href="http://docs.python-guide.org/en/latest/dev/virtualenvs/">virtual environments</a>, a way to create isolated Python environments.  The primary advantages of Docker over virtual environments are:</p>

<ul>
  <li>Ability to quickly get started.  You don’t need to wait for packages to install when you just want to jump in and start doing analysis.</li>
  <li>Known good configuration.  Many times, Python packages will require system packages and configuration to be setup.  This can cause mysterious errors.  With Docker, the packages are already setup and ready to go.</li>
  <li>Consistently cross platform.  Python packages are cross-platform, but some behave differently on Windows vs Linux, and some have dependencies that can’t be installed on Windows.  Docker containers always run in a Linux environment, so they’re consistent.</li>
  <li>Ability to checkpoint and restore.  You can install packages into a Docker image, then create a new image of that checkpoint.  This will give you the ability to quickly undo changes or rollback configurations.</li>
</ul>

<p>Running a Docker image creates a Docker container.  For our purposes, we can run Jupyter notebook inside this container, and use a web browser to work with our data.</p>

<h2 id="installing-docker">Installing Docker</h2>

<p>The first step is installing Docker.  There’s a graphical installer for Windows and Mac that makes this easy.  Here are the instructions for each OS:</p>



<p>As part of this installation process, you’ll need to use a shell prompt.  The shell prompt, also called the terminal or the command line, is a way to run commands on your machine from a text interface instead of graphically.  For example, you can launch a text editor by double clicking on <code>notepad</code> in Windows, or by typing <code>nano</code> in a Linux shell session.  There’s a special version of the shell that comes pre-configured for using Docker commands.  Here’s how to open it:</p>

<ul>
  <li>Mac OS – launch the <em>Docker Quickstart Terminal</em> application from Launchpad.  There’s more detail <a href="https://docs.docker.com/v1.8/installation/mac/#from-the-docker-quickstart-terminal">here</a>.</li>
  <li>Linux – Launch any bash shell prompt, and <code>docker</code> will already be available.</li>
  <li>Windows – click the <em>Docker Quickstart Terminal</em> icon on your desktop.  There’s more detail <a href="https://docs.docker.com/v1.8/installation/windows/#from-the-docker-quickstart-terminal">here</a>.</li>
</ul>

<p>You’ll need to use this same shell prompt whenever the rest of this post mentions having to run a Docker command or type a specific command.</p>

<h2 id="downloading-the-image">Downloading the image</h2>

<p>The next step is to download the image you want.  Here are our currently available data science images:</p>

<ul>
  <li><code>dataquestio/python3-starter</code> – This contains a python 3 installation, jupyter notebook, and many popular data science libraries such as <code>numpy</code>, <code>pandas</code>, <code>scipy</code>, <code>scikit-learn</code>, and <code>nltk</code>.</li>
  <li><code>dataquestio/python2-starter</code> – This contains a python 2 installation, jupyter notebook, and many popular data science libraries such as <code>numpy</code>, <code>pandas</code>, <code>scrapy</code>, <code>scipy</code>, <code>scikit-learn</code>, and <code>nltk</code>.</li>
</ul>

<p>You can download the images by typing <code>docker pull IMAGE_NAME</code>.  If you wanted to pull <code>dataquestio/python3-starter</code>, you’d type <code>docker pull dataquestio/python3-starter</code> into a shell prompt.  This will download the images from <em>Docker Hub</em>, which is like Github, but for Docker images.  It will download the image files onto your machine, so you can start a container with the image.</p>

<h2 id="make-a-folder">Make a folder</h2>

<p>Make a folder on your local machine that will correspond to where you want the notebooks stored.  This folder will contain all of your work, and will persist on your local machine, even if you terminate the docker container.  For this example, we’ll make this folder at <code>/home/vik/notebooks</code>.</p>

<h2 id="running-the-image">Running the image</h2>

<p>Once you download the image, you can run it using <code>docker run</code>.  We need to pass in a few options to ensure that it’s configured properly. </p>

<ul>
  <li>The <code>-p</code> flag sets the ports so that we can access the Jupyter notebook server from our machine.  </li>
  <li>The <code>-d</code> flag runs the container in detached mode, as a background process.</li>
  <li>The <code>-v</code> flag lets us specify which directory on the local machine to store our notebooks in.</li>
</ul>

<p>The full command looks like <code>docker run -d -p 8888:8888 -v /home/vik/notebooks:/home/ds/notebooks dataquestio/python3-starter</code>.</p>

<p>You should change <code>/home/vik/notebooks</code> to whatever folder you created to store your notebooks in.  You should change <code>dataquestio/python3-starter</code> to your preferred docker image.</p>

<p>Executing <code>docker run</code> will create a Docker container.  This is isolated from your local machine, and it may be helpful to think of it as a separate computer.  Inside this container, Jupyter notebook will be running, and we’ll be able to access many data science packages.</p>

<p>The <code>docker run</code> command will print a long string.  This is the unique id of your container, and is used when modifying the container with other docker containers.  We’ll refer to it as the container id from now on.</p>

<h2 id="viewing-the-notebook-server">Viewing the notebook server</h2>

<p>If you’re running Linux, the next step is easy – just go to <code>localhost:8888</code>, and you should see the notebook running.  If you’re on Windows or OSX, and you followed the Docker installation instructions earlier, you used <code>docker-machine</code> in your docker installation process.  The name of your local machine is <code>default</code>, and running <code>docker-machine ip default</code> will tell you the ip of the docker container.  If you used a different name, like <code>dev</code>, just swap it for <code>default</code> in the command.  Then, you just visit <code>CONTAINER_IP:8888</code> to see the notebook (replace <code>CONTAINER_IP</code> with the ip of your container).</p>

<div>
<div class="row">
<div class="col-md-10 col-md-offset-1">
     <img class="full-width" src="/blog/images/docker_ds/jupyter.png"/>
     <p class="small">This is what you should see</p>
     </div>
     </div>
</div>

<h2 id="making-a-notebook">Making a notebook</h2>

<p>At this point, you can make a new Jupyter notebook to test how things are working.  Try running a scikit-learn example from <a href="http://scikit-learn.org/stable/auto_examples/plot_cv_predict.html">here</a>:</p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">import</span> <span class="n">cross_val_predict</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

<span class="n">lr</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">boston</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_boston</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">boston</span><span class="o">.</span><span class="n">target</span>

<span class="n">predicted</span> <span class="o">=</span> <span class="n">cross_val_predict</span><span class="p">(</span><span class="n">lr</span><span class="p">,</span> <span class="n">boston</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">predicted</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">y</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">y</span><span class="o">.</span><span class="n">max</span><span class="p">()],</span> <span class="p">[</span><span class="n">y</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">y</span><span class="o">.</span><span class="n">max</span><span class="p">()],</span> <span class="s">'k--'</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">'Measured'</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">'Predicted'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></code></pre></div>

<h2 id="adding-in-data-files">Adding in data files</h2>

<p>If you want to add data files into your environment, you have three options.  The first is to place them in the folder you created earlier to use for notebooks.  Any files you place in there will automatically be accessible from inside your Jupyter notebooks.</p>

<p>The second way is to use the <code>docker cp</code> command.  <a href="https://docs.docker.com/v1.8/reference/commandline/cp/">Docker cp</a> can copy files from your machine to the container, and vice versa.  Let’s say you want to copy a file at <code>/home/vik/data.csv</code> to a container with id <code>4greg24134</code>.  You would type <code>docker cp /home/vik/data.csv 4greg24134:/home/ds/notebooks</code>.  This will copy the <code>data.csv</code> file into the <code>notebooks</code> directory in the container.  You can place files anywhere you want, but putting them in the <code>notebooks</code> directory makes them easily accessible from Jupyter notebook.</p>

<p>The third way is to use the upload button at the top right of the Jupyter notebook main page.  This will let you select a file and upload it to the <code>notebooks</code> directory in the container.</p>

<p>Regardless of which method you choose, here’s how you would load the file inside a Jupyter notebook:</p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"data.csv"</span><span class="p">)</span></code></pre></div>

<h2 id="copying-data-files-from-the-container">Copying data files from the container</h2>

<p>You may also want to get files from the container onto your local machine.  The easiest way is to place the files in the <code>/home/ds/notebooks</code> folder, where they will be automatically mirrored into your local machine.</p>

<p>Another way is to again use <code>docker cp</code>.  Let’s say you want to copy a file at <code>/home/ds/notebooks/data.csv</code> from a container with id <code>4greg24134</code> to the folder <code>/home/vik/</code> on your machine.  You would type <code>docker cp 4greg24134:/home/ds/notebooks/data.csv /home/vik/data.csv</code>.</p>

<p>A final way is to use the download options in the Jupyter interface.  Clicking on a non-notebook file in the browser view will download it to your local machine.  If you’re working on a notebook, clicking “File”, then “download as” will download it to your machine.</p>

<h2 id="installing-more-packages">Installing more packages</h2>

<p>If you want to install your own packages inside the container, you can get into it and run any normal bash shell commands.  In order to get into a container, you’ll need to run <code>docker exec</code>.  Docker exec takes a specific container id, and a command to run.  For instance, typing <code>docker exec -it 4greg24134 /bin/bash</code> will open a shell prompt in the container with id <code>4greg24134</code>.  The <code>-it</code> flags ensure that we keep an input session open with the container, and can enter commands.</p>

<p>After running <code>docker exec</code>, you’ll be put into a shell prompt inside the container.  The container is running python in a virtual environment called <code>ds</code>, which should already be activated.</p>

<p>To install packages, just type <code>pip install PACKAGE_NAME</code>.  You could install <code>requests</code> with <code>pip install requests</code>.</p>

<p>When you want to exit the container shell prompt, just type <code>exit</code>.</p>

<h2 id="shutting-down-your-docker-container">Shutting down your docker container</h2>

<p>When you’re done exploring your data, you can shut down the docker container.  Use <code>docker rm -f CONTAINER_ID</code> to stop the container.  You should have your container id from earlier.  If you don’t, you can find it by running <code>docker ps</code>.  Your notebooks will still be available on your local machine, in the folder you created, even after you shut down the container.</p>

<h2 id="building-on-this">Building on this</h2>

<p>Docker images are created from <a href="https://docs.docker.com/v1.8/reference/builder/">Dockerfiles</a>.  Dockerfiles specify which packages and tools should be installed in an image.  By modifying Dockerfiles, you can change which packages and tools come with the image by default.</p>

<p>If you want to build on the images we’ve discussed in this post, you can contribute to our Github repository <a href="https://github.com/dataquestio/ds-containers">here</a>, which contains the Dockerfiles.  We welcome improvements to our current images, or the addition of new images focusing on tools other than Python.</p>


        </section>

        </div></body></html>