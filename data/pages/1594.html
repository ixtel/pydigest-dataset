<html><body><div><section id="post-content" class="e-content">
 
<p>For a <a href="http://whatshouldigetformy.com/">gift recommendation</a>
side-project of mine, I wanted to do some automatic summarization for
products. A fairly easy way to do this is TextRank, based upon
PageRank. In this example, the vertices of the graph are sentences,
and the edge weights between sentences are how similar the sentences are.</p>
<p>To go from an string of text to a list of scored sentences based upon
how much they represent the overall text, we need to go through
several steps: </p>
<ol>
<li>Tokenize the text into sentences</li>
<li>Tokenize each sentence into a collection of words</li>
<li>Convert the sentences into graphs</li>
<li>Score the sentences via pagerank</li>
</ol>
<h2>Sentence Splitting</h2>
<p>To get started, we'll need to split the document into sentences. For
this, we'll use <a href="http://nltk.googlecode.com/svn/trunk/doc/api/nltk.tokenize.punkt-module.html">nltk's included Punkt
module</a>,
and the opening paragraph of Sir Authur Conan Doyle's <em>A Scandal In Bohemia</em>.</p>
<div class="code"><div class="syntax"><pre><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">nltk.tokenize.punkt</span> <span class="kn">import</span> <span class="n">PunktSentenceTokenizer</span><br/> <br/><span class="o">&gt;&gt;&gt;</span> <span class="n">document</span> <span class="o">=</span> <span class="s">"""To Sherlock Holmes she is always the woman. I have</span><br/><span class="s">seldom heard him mention her under any other name. In his eyes she</span><br/><span class="s">eclipses and predominates the whole of her sex. It was not that he</span><br/><span class="s">felt any emotion akin to love for Irene Adler. All emotions, and that</span><br/><span class="s">one particularly, were abhorrent to his cold, precise but admirably</span><br/><span class="s">balanced mind. He was, I take it, the most perfect reasoning and</span><br/><span class="s">observing machine that the world has seen, but as a lover he would</span><br/><span class="s">have placed himself in a false position. He never spoke of the softer</span><br/><span class="s">passions, save with a gibe and a sneer. They were admirable things for</span><br/><span class="s">the observer-excellent for drawing the veil from menâs motives and</span><br/><span class="s">actions. But for the trained reasoner to admit such intrusions into</span><br/><span class="s">his own delicate and finely adjusted temperament was to introduce a</span><br/><span class="s">distracting factor which might throw a doubt upon all his mental</span><br/><span class="s">results. Grit in a sensitive instrument, or a crack in one of his own</span><br/><span class="s">high-power lenses, would not be more disturbing than a strong emotion</span><br/><span class="s">in a nature such as his. And yet there was but one woman to him, and</span><br/><span class="s">that woman was the late Irene Adler, of dubious and questionable</span><br/><span class="s">memory.</span><br/><span class="s">"""</span><br/><span class="o">&gt;&gt;&gt;</span> <span class="n">document</span> <span class="o">=</span> <span class="s">' '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">document</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">))</span><br/> <br/><span class="o">&gt;&gt;&gt;</span> <span class="n">sentence_tokenizer</span> <span class="o">=</span> <span class="n">PunktSentenceTokenizer</span><span class="p">()</span><br/><span class="o">&gt;&gt;&gt;</span> <span class="n">sentences</span> <span class="o">=</span> <span class="n">sentence_tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">document</span><span class="p">)</span><br/></pre></div></div>
<h2>Bag of Words</h2>
<p>Before we can do any analysis, we need to convert the document into
a <a href="http://en.wikipedia.org/wiki/Bag-of-words_model">bag-of-words</a>,
which is an unordered collection of word counts. </p>
<p>For the first sentence, we should have something like the following:</p>
<div class="code"><div class="syntax"><pre><span class="p">{</span><span class="s">'always'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span><br/> <span class="s">'holmes'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span><br/> <span class="s">'is'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span><br/> <span class="s">'she'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span><br/> <span class="s">'sherlock'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span><br/> <span class="s">'the'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span><br/> <span class="s">'to'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span><br/> <span class="s">'woman'</span><span class="p">:</span> <span class="mi">1</span><span class="p">}</span><br/></pre></div></div>
<p>A simple implementation for converting a sentence to a
bag-of-words can be done via the base Python datastructures:</p>
<div class="code"><div class="syntax"><pre><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span><br/> <br/><span class="k">def</span> <span class="nf">bag_of_words</span><span class="p">(</span><span class="n">sentence</span><span class="p">):</span><br/>    <span class="k">return</span> <span class="n">Counter</span><span class="p">(</span><span class="n">word</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">(</span><span class="s">'.,'</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">' '</span><span class="p">))</span><br/></pre></div></div>
<p>An alternative way to a bag-of-words is in a vector, where each column
corresponds to a word. Instead of the previous dictionary, we'd have
something like the following: </p>

<p>The package <a href="http://scikit-learn.org/stable/index.html">scikit-learn</a>
provides text feature extraction, allowing us to build SciPy matrices
out of a collections of texts.</p>
<div class="code"><div class="syntax"><pre><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span><br/> <br/><span class="o">&gt;&gt;&gt;</span> <span class="n">c</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">()</span><br/><span class="o">&gt;&gt;&gt;</span> <span class="n">bow_array</span> <span class="o">=</span> <span class="n">c</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">([</span><span class="n">sentences</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span><br/><span class="o">&gt;&gt;&gt;</span> <span class="n">bow_array</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span><br/><span class="p">[[</span><span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span><span class="p">]]</span><br/></pre></div></div>
<p>The resulting array is a bit different, since hyphens are not included
in words, and the stopword "a" is excluded.</p>
<p>We can apply this to the entire collection, and get back a matrix. </p>
<div class="code"><div class="syntax"><pre><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span><br/> <br/><span class="o">&gt;&gt;&gt;</span> <span class="n">c</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">()</span><br/><span class="o">&gt;&gt;&gt;</span> <span class="n">bow_matrix</span> <span class="o">=</span> <span class="n">c</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">sentences</span><span class="p">)</span><br/><span class="o">&gt;&gt;&gt;</span> <span class="n">bow_matrix</span><br/><span class="o">&lt;</span><span class="mi">11</span><span class="n">x127</span> <span class="n">sparse</span> <span class="n">matrix</span> <span class="n">of</span> <span class="nb">type</span> <span class="s">'&lt;type '</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="s">'&gt;'</span><br/>   <span class="k">with</span> <span class="mi">183</span> <span class="n">stored</span> <span class="n">elements</span> <span class="ow">in</span> <span class="n">COOrdinate</span> <span class="n">format</span><span class="o">&gt;</span><br/></pre></div></div>
<h2>Converting to a Graph</h2>
<p>Now we have a matrix where the rows are sentences and the
columns are words. We need to transform this into a graph relating the
sentences to each other. To do this, we'll first normalize our matrix
using Scikit-learn's <code>TfidfTransformer</code>. </p>
<div class="code"><div class="syntax"><pre><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfTransformer</span><br/><span class="o">&gt;&gt;&gt;</span> <span class="n">normalized_matrix</span> <span class="o">=</span> <span class="n">TfidfTransformer</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">bow_matrix</span><span class="p">)</span><br/></pre></div></div>
<p>This will re-weight each word is based upon its
<a href="http://en.wikipedia.org/wiki/Tf*idf">tf-idf</a>, which will dimish the
effect of words common to each sentence. </p>
<div class="code"><div class="syntax"><pre><span class="o">&gt;&gt;&gt;</span> <span class="n">similarity_graph</span> <span class="o">=</span> <span class="n">normalized_matrix</span> <span class="o">*</span> <span class="n">normalize_matrix</span><span class="o">.</span><span class="n">T</span><br/><span class="o">&gt;&gt;&gt;</span> <span class="n">similarity_graph</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span><br/><span class="n">array</span><span class="p">([[</span> <span class="mf">1.</span>        <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.13737879</span><span class="p">,</span>  <span class="mf">0.04767903</span><span class="p">,</span>  <span class="mf">0.04305016</span><span class="p">,</span><br/>         <span class="mf">0.04345599</span><span class="p">,</span>  <span class="mf">0.03330044</span><span class="p">,</span>  <span class="mf">0.05261648</span><span class="p">,</span>  <span class="mf">0.07798958</span><span class="p">,</span>  <span class="mf">0.</span>        <span class="p">,</span><br/>         <span class="mf">0.20047419</span><span class="p">],</span><br/>       <span class="p">[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">1.</span>        <span class="p">,</span>  <span class="mf">0.0842143</span> <span class="p">,</span>  <span class="mf">0.07819597</span><span class="p">,</span>  <span class="mf">0.</span>        <span class="p">,</span><br/>         <span class="mf">0.05171612</span><span class="p">,</span>  <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">,</span><br/>         <span class="mf">0.05807146</span><span class="p">],</span><br/>       <span class="p">[</span> <span class="mf">0.13737879</span><span class="p">,</span>  <span class="mf">0.0842143</span> <span class="p">,</span>  <span class="mf">1.</span>        <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.07004069</span><span class="p">,</span><br/>         <span class="mf">0.09648614</span><span class="p">,</span>  <span class="mf">0.1069042</span> <span class="p">,</span>  <span class="mf">0.06701793</span><span class="p">,</span>  <span class="mf">0.09437203</span><span class="p">,</span>  <span class="mf">0.20474295</span><span class="p">,</span><br/>         <span class="mf">0.1197599</span> <span class="p">],</span><br/>       <span class="p">[</span> <span class="mf">0.04767903</span><span class="p">,</span>  <span class="mf">0.07819597</span><span class="p">,</span>  <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">1.</span>        <span class="p">,</span>  <span class="mf">0.07558987</span><span class="p">,</span><br/>         <span class="mf">0.18678911</span><span class="p">,</span>  <span class="mf">0.05853972</span><span class="p">,</span>  <span class="mf">0.09249592</span><span class="p">,</span>  <span class="mf">0.10892262</span><span class="p">,</span>  <span class="mf">0.09110741</span><span class="p">,</span><br/>         <span class="mf">0.24159019</span><span class="p">],</span><br/>       <span class="p">[</span> <span class="mf">0.04305016</span><span class="p">,</span>  <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.07004069</span><span class="p">,</span>  <span class="mf">0.07558987</span><span class="p">,</span>  <span class="mf">1.</span>        <span class="p">,</span><br/>         <span class="mf">0.07055583</span><span class="p">,</span>  <span class="mf">0.02370685</span><span class="p">,</span>  <span class="mf">0.07272032</span><span class="p">,</span>  <span class="mf">0.17253418</span><span class="p">,</span>  <span class="mf">0.08262451</span><span class="p">,</span><br/>         <span class="mf">0.17789849</span><span class="p">],</span><br/>       <span class="p">[</span> <span class="mf">0.04345599</span><span class="p">,</span>  <span class="mf">0.05171612</span><span class="p">,</span>  <span class="mf">0.09648614</span><span class="p">,</span>  <span class="mf">0.18678911</span><span class="p">,</span>  <span class="mf">0.07055583</span><span class="p">,</span><br/>         <span class="mf">1.</span>        <span class="p">,</span>  <span class="mf">0.12952649</span><span class="p">,</span>  <span class="mf">0.06859301</span><span class="p">,</span>  <span class="mf">0.06837492</span><span class="p">,</span>  <span class="mf">0.13015945</span><span class="p">,</span><br/>         <span class="mf">0.15423071</span><span class="p">],</span><br/>       <span class="p">[</span> <span class="mf">0.03330044</span><span class="p">,</span>  <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.1069042</span> <span class="p">,</span>  <span class="mf">0.05853972</span><span class="p">,</span>  <span class="mf">0.02370685</span><span class="p">,</span><br/>         <span class="mf">0.12952649</span><span class="p">,</span>  <span class="mf">1.</span>        <span class="p">,</span>  <span class="mf">0.06307559</span><span class="p">,</span>  <span class="mf">0.03194234</span><span class="p">,</span>  <span class="mf">0.02852116</span><span class="p">,</span><br/>         <span class="mf">0.11271501</span><span class="p">],</span><br/>       <span class="p">[</span> <span class="mf">0.05261648</span><span class="p">,</span>  <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.06701793</span><span class="p">,</span>  <span class="mf">0.09249592</span><span class="p">,</span>  <span class="mf">0.07272032</span><span class="p">,</span><br/>         <span class="mf">0.06859301</span><span class="p">,</span>  <span class="mf">0.06307559</span><span class="p">,</span>  <span class="mf">1.</span>        <span class="p">,</span>  <span class="mf">0.09411725</span><span class="p">,</span>  <span class="mf">0.</span>        <span class="p">,</span><br/>         <span class="mf">0.07702234</span><span class="p">],</span><br/>       <span class="p">[</span> <span class="mf">0.07798958</span><span class="p">,</span>  <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.09437203</span><span class="p">,</span>  <span class="mf">0.10892262</span><span class="p">,</span>  <span class="mf">0.17253418</span><span class="p">,</span><br/>         <span class="mf">0.06837492</span><span class="p">,</span>  <span class="mf">0.03194234</span><span class="p">,</span>  <span class="mf">0.09411725</span><span class="p">,</span>  <span class="mf">1.</span>        <span class="p">,</span>  <span class="mf">0.12388421</span><span class="p">,</span><br/>         <span class="mf">0.14327969</span><span class="p">],</span><br/>       <span class="p">[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.20474295</span><span class="p">,</span>  <span class="mf">0.09110741</span><span class="p">,</span>  <span class="mf">0.08262451</span><span class="p">,</span><br/>         <span class="mf">0.13015945</span><span class="p">,</span>  <span class="mf">0.02852116</span><span class="p">,</span>  <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.12388421</span><span class="p">,</span>  <span class="mf">1.</span>        <span class="p">,</span><br/>         <span class="mf">0.04706138</span><span class="p">],</span><br/>       <span class="p">[</span> <span class="mf">0.20047419</span><span class="p">,</span>  <span class="mf">0.05807146</span><span class="p">,</span>  <span class="mf">0.1197599</span> <span class="p">,</span>  <span class="mf">0.24159019</span><span class="p">,</span>  <span class="mf">0.17789849</span><span class="p">,</span><br/>         <span class="mf">0.15423071</span><span class="p">,</span>  <span class="mf">0.11271501</span><span class="p">,</span>  <span class="mf">0.07702234</span><span class="p">,</span>  <span class="mf">0.14327969</span><span class="p">,</span>  <span class="mf">0.04706138</span><span class="p">,</span><br/>         <span class="mf">1.</span>        <span class="p">]])</span><br/></pre></div></div>
<p>This is a mirrored matrix, where both the rows and columns correspond
to sentences, and the elements describe how similar the two sentences
are. Scores of <code>1</code> mean that the sentences are exactly the same, while
scores of <code>0</code> mean the sentences have no overlap.</p>
<h2>Pagerank</h2>
<p>With a graph of sentences, we can use pagerank to score them. To do
this, we'll use the <code>pagerank</code> function from <a href="http://networkx.lanl.gov/">NetworkX</a>.</p>
<div class="code"><div class="syntax"><pre><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">networkx</span> <span class="kn">as</span> <span class="nn">nx</span><br/><span class="o">&gt;&gt;&gt;</span> <span class="n">nx_graph</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">from_scipy_sparse_matrix</span><span class="p">(</span><span class="n">similarity_graph</span><span class="p">)</span><br/><span class="o">&gt;&gt;&gt;</span> <span class="n">scores</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">pagerank</span><span class="p">(</span><span class="n">nx_graph</span><span class="p">)</span><br/><span class="o">&gt;&gt;&gt;</span> <span class="n">scores</span><br/><span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="mf">0.08671319149370108</span><span class="p">,</span><br/> <span class="mi">1</span><span class="p">:</span> <span class="mf">0.08316523582097997</span><span class="p">,</span><br/> <span class="mi">2</span><span class="p">:</span> <span class="mf">0.09513943890606882</span><span class="p">,</span><br/> <span class="mi">3</span><span class="p">:</span> <span class="mf">0.09440660636561657</span><span class="p">,</span><br/> <span class="mi">4</span><span class="p">:</span> <span class="mf">0.08968582008434481</span><span class="p">,</span><br/> <span class="mi">5</span><span class="p">:</span> <span class="mf">0.0949290548524502</span><span class="p">,</span><br/> <span class="mi">6</span><span class="p">:</span> <span class="mf">0.08616430411108938</span><span class="p">,</span><br/> <span class="mi">7</span><span class="p">:</span> <span class="mf">0.086273427821944</span><span class="p">,</span><br/> <span class="mi">8</span><span class="p">:</span> <span class="mf">0.09263320827229513</span><span class="p">,</span><br/> <span class="mi">9</span><span class="p">:</span> <span class="mf">0.08808392628885832</span><span class="p">,</span><br/> <span class="mi">10</span><span class="p">:</span> <span class="mf">0.10280578598265173</span><span class="p">}</span><br/></pre></div></div>
<p>This gives us a mapping of sentence indices to scores. We can use
associate these back to our original sentences and sort them. </p>
<div class="code"><div class="syntax"><pre><span class="o">&gt;&gt;&gt;</span> <span class="n">ranked</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(((</span><span class="n">scores</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">s</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sentences</span><span class="p">)),</span><br/>                <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span><br/><span class="o">&gt;&gt;&gt;</span> <span class="n">ranked</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><br/><span class="s">'And yet there was but one woman to him, and that woman was the late '</span><br/><span class="s">'Irene Adler, of dubious and questionable memory.'</span><br/></pre></div></div>
<p>We can combine all of this into one function as follows:</p>
<div class="code"><div class="syntax"><pre><span class="kn">import</span> <span class="nn">networkx</span> <span class="kn">as</span> <span class="nn">nx</span><br/><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span><br/> <br/><span class="kn">from</span> <span class="nn">nltk.tokenize.punkt</span> <span class="kn">import</span> <span class="n">PunktSentenceTokenizer</span><br/><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfTransformer</span><span class="p">,</span> <span class="n">CountVectorizer</span><br/> <br/><span class="k">def</span> <span class="nf">textrank</span><span class="p">(</span><span class="n">document</span><span class="p">):</span><br/>    <span class="n">sentence_tokenizer</span> <span class="o">=</span> <span class="n">PunktSentenceTokenizer</span><span class="p">()</span><br/>    <span class="n">sentences</span> <span class="o">=</span> <span class="n">sentence_tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">document</span><span class="p">)</span><br/> <br/>    <span class="n">bow_matrix</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">sentences</span><span class="p">)</span><br/>    <span class="n">normalized</span> <span class="o">=</span> <span class="n">TfidfTransformer</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">bow_matrix</span><span class="p">)</span><br/> <br/>    <span class="n">similarity_graph</span> <span class="o">=</span> <span class="n">normalized</span> <span class="o">*</span> <span class="n">normalized</span><span class="o">.</span><span class="n">T</span><br/> <br/>    <span class="n">nx_graph</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">from_scipy_sparse_matrix</span><span class="p">(</span><span class="n">similarity_graph</span><span class="p">)</span><br/>    <span class="n">scores</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">pagerank</span><span class="p">(</span><span class="n">nx_graph</span><span class="p">)</span><br/>    <span class="k">return</span> <span class="nb">sorted</span><span class="p">(((</span><span class="n">scores</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">s</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sentences</span><span class="p">)),</span><br/>                  <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span><br/></pre></div></div>
<p>Using this technique, we have a simple way of choosing relevant
sentences from a text. This model can also be adapted to find keywords
that are important in a text, or used as part of more sophisticated
scoring methods.</p>
 
</section>
</div></body></html>