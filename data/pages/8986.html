<html><body><div><article class="markdown-body entry-content" itemprop="text"><h1><a id="user-content-how-much-did-it-rain-ii" class="anchor" href="#how-much-did-it-rain-ii" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>How Much Did It Rain? II</h1>

<h2><a id="user-content-kaggle-competition-winning-solution" class="anchor" href="#kaggle-competition-winning-solution" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Kaggle competition winning solution</h2>

<p>This document describes how to generate the winning solution to the Kaggle competition <a href="https://www.kaggle.com/c/how-much-did-it-rain-ii"><em>How Much Did It Rain? II</em></a>.</p>

<p>Further documentation on the method can be found in this <a href="http://simaaron.github.io/Estimating-rainfall-from-weather-radar-readings-using-recurrent-neural-networks/">blog post</a>.</p>

<h2><a id="user-content-generating-the-solution" class="anchor" href="#generating-the-solution" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Generating the solution</h2>

<h3><a id="user-content-install-the-dependencies" class="anchor" href="#install-the-dependencies" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Install the dependencies</h3>

<p>The models are written in Python 2.7 and makes use of the NumPy, scikit-learn, and pandas packages. These can be installed individually via <code>pip</code> or all together in a free Python distribution such as <a href="https://www.continuum.io/downloads">Anaconda</a>.</p>

<p>Theano can be installed and configured to use any available NVIDIA GPUs by following the instructions <a href="http://deeplearning.net/software/theano/install.html">here</a> and <a href="http://deeplearning.net/software/theano/tutorial/using_gpu.html">here</a>. The Lasagne package often requires the latest version of Theano; a simple <code>pip install Theano</code> may give a version that is out-of-date (see Lasagne documentation for details).  </p>

<p>Lasagne can be installed by following the instructions <a href="http://lasagne.readthedocs.org/en/latest/user/installation.html">here</a>.</p>

<h3><a id="user-content-download-the-code" class="anchor" href="#download-the-code" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Download the code</h3>

<p>To download the code run:</p>

<pre><code>git clone git://github.com/simaaron/kaggle-Rain.git
</code></pre>

<p>Create an empty data folder</p>

<pre><code>cd kaggle-Rain
mkdir data
</code></pre>

<h3><a id="user-content-download-the-training-and-test-data" class="anchor" href="#download-the-training-and-test-data" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Download the training and test data</h3>

<p>The training and test data can be downloaded from the Kaggle competition webpage at this <a href="https://www.kaggle.com/c/how-much-did-it-rain-ii/data">link</a>. The two extracted files <code>train.csv</code> and <code>test.csv</code> should be placed in the <code>data</code> folder. </p>

<p>Note: the benchmark sample solution and code provided by Kaggle are not required.</p>

<h3><a id="user-content-preprocess-the-data" class="anchor" href="#preprocess-the-data" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Preprocess the data</h3>

<p>Replace the <code>NaN</code> entries with zeros (training and test data) and remove the outliers (training data only) by running:</p>

<pre><code>python data_preprocessing.py
</code></pre>

<p>This will also create three additional <code>train</code>, <code>valid</code>, and <code>test</code> folders. The size of the validation holdout subset and the outlier threshold expected rainfall value can be changed in the above Python script.</p>

<h3><a id="user-content-augment-the-data-sets-with-dropin-copies" class="anchor" href="#augment-the-data-sets-with-dropin-copies" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Augment the data sets with <em>dropin</em> copies</h3>

<p>Create random augmentation copies of the datasets by running:</p>

<pre><code>python data_augmentation_train.py
python data_augmentation_valid.py
python data_augmentation_test.py
</code></pre>

<p>This creates 61 randomly augmented copies of the preprocessed training and test data sets and one of the validation holdout set. Note that each copy is &gt; 2GB in size. If there is an issue with insufficient hard disk space, one should modify the training script <code>NNregression_*.py</code> and test script <code>NNprediction_*.py</code> to perform these augmentations dynamically.</p>

<p>The number of copies can be changed in the above scripts.</p>

<h3><a id="user-content-train-the-networks" class="anchor" href="#train-the-networks" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Train the networks</h3>

<p>The two best models can be trained by running:</p>

<pre><code>python NNregression_v1.py -v=1
python NNregression_v2.py -v=2
</code></pre>

<p>The list of functions corresponding to the different models can be found in the Python script <code>NN_architectures.py</code>. The remaining models can be trained by simply modifying the corresponding function import and call within either script above and then saving and running a new script:</p>

<pre><code>python NNregression_v*.py -v=*
</code></pre>

<p>The outputs from different models are continually saved into separate output folders. These include the files <code>training_scores.txt</code> and <code>validation_scores.txt</code> which, for monitoring purposes, give the evolution of the training and validation errors respectively. The file <code>model.npz</code> is the current best fitting set of model parameters (w.r.t. the validation holdout set), and the <code>last_learn_rate.txt</code> records the current (decayed) learning rate.</p>

<h3><a id="user-content-generate-predictions-from-augmented-test-sets" class="anchor" href="#generate-predictions-from-augmented-test-sets" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Generate predictions from augmented test sets</h3>

<p>The set of 61 augmented test set predictions from the model 'v1' can be obtained by running:</p>

<pre><code>for j in `seq 0 60`;
do
    python NNpredictor_v1.py -rd=$j
done
</code></pre>

<p>The predictions from the pre-trained model included in the code download can be obtained by running:</p>

<pre><code>for j in `seq 0 60`;
do
    python NNpredictor_v1.py -rd=$j -i pretrained_model_v1.npz
done
</code></pre>

<h3><a id="user-content-average-the-augmented-predictions" class="anchor" href="#average-the-augmented-predictions" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Average the augmented predictions</h3>

<p>The predictions from different augmented copies can be combined by running:</p>

<pre><code>python ensembling.py -v=1 -nr=61
</code></pre>

<p>This averages the 61 predictions of the model 'v1' and saves it to the file <code>ens_submission_v1_61ave_mean.csv</code>.</p>

<p>The individual predictions from the models 'v1' and 'v2' would place one 2nd/3rd in the competition. A straight average of the two solutions would be sufficient for 1st place. </p>
</article>
  </div></body></html>