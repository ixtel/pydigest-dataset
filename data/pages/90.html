<html><body><div><div class="content html_format"><p>
      Добрый день уважаемые читатели. В сегодняшней посте я продолжу свой цикл статей посвященный анализу данных на python c помощью модуля </p><a href="http://pandas.pydata.org/">Pandas</a><p> и расскажу один из вариантов использования данного модуля в связке с модулем для машинного обучения </p><a href="http://scikit-learn.org/stable/">scikit-learn</a><p>. Работа данной связки будет показана на примере </p><a href="https://www.kaggle.com/c/titanic-gettingStarted/data">задачи</a><p> про спасенных с "Титаника&amp;quot. Данное задание имеет большую популярность среди людей, только начинающих заниматься анализом данных и </p><a href="http://ru.wikipedia.org/wiki/%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5">машинным обучением</a><p>.
</p><a name="habracut"/>

<h4>Постановка задачи</h4><p>
Итак суть задачи состоит в том, чтобы с помощью методов машинного обучения построить модель, которая прогнозировала бы спасется человек или нет. К задаче прилагаются 2 файла:
</p><ul>
<li><i>train.csv</i> — набор данных на основании которого будет строиться модель (<i>обучающая выборка</i>)<br/>
</li>
<li><i>test.csv</i> — набор данных для проверки модели<br/>
</li>
</ul><p>
Как было написано выше, для анализ понадобятся модули Pandas и scikit-learn. С помощью </p><b>Pandas</b><p> мы проведем начальный анализ данных, а </p><b>sklearn</b><p> поможет в вычислении прогнозной модели. Итак, для начала загрузим нужные модули:</p><p>
Кроме того даются пояснения по некоторым полям:
</p><ul>
<li><b>PassengerId</b> — идентификатор пассажира<br/>
</li>
<li><b>Survival</b> — поле в котором указано спасся человек (1) или нет (0)<br/>
</li>
<li><b>Pclass</b> — содержит социально-экономический статус:<br/>
<ol>
<li>высокий</li>
<li>средний</li>
<li>низкий</li>
</ol></li>
<li><b>Name</b> — имя пассажира<br/>
</li>
<li><b>Sex</b> — пол пассажира<br/>
</li>
<li><b>Age</b> — возраст<br/>
</li>
<li><b>SibSp</b> — содержит информацию о количестве родственников 2-го порядка (муж, жена, братья, сетры)<br/>
</li>
<li><b>Parch</b> — содержит информацию о количестве родственников на борту 1-го порядка (мать, отец, дети)<br/>
</li>
<li><b>Ticket</b> — номер билета<br/>
</li>
<li><b>Fare</b> — цена билета<br/>
</li>
<li><b>Cabin</b> — каюта<br/>
</li>
<li><b>Embarked</b> — порт посадки<br/>
<ul>
<li>C — Cherbourg</li>
<li>Q — Queenstown</li>
<li>S — Southampton<br/>
</li>
</ul></li>
</ul>

<h4>Анализ входных данных</h4><p>
&gt;Итак, задача сформирована и можно приступить к ее решению.</p><p>
Для начала загрузим тестовую выборку и посмотрим как она выглядит::

</p><pre><code class="python">from pandas import read_csv, DataFrame, Series
data = read_csv('Kaggle_Titanic/Data/train.csv')</code></pre>
<table border="1">
<tr>
<th>PassengerId</th>
<th>Survived</th>
<th>Pclass</th>
<th>Name</th>
<th>Sex</th>
<th>Age</th>
<th>SibSp</th>
<th>Parch</th>
<th>Ticket</th>
<th>Fare</th>
<th>Cabin</th>
<th>Embarked</th>
</tr>
<tr>
<td>1</td>
<td>0</td>
<td>3</td>
<td>Braund, Mr. Owen Harris</td>
<td>male</td>
<td>22</td>
<td>1</td>
<td>0</td>
<td>A/5 21171</td>
<td>7.2500</td>
<td>NaN</td>
<td>S</td>
</tr>
<tr>
<td>2</td>
<td>1</td>
<td>1</td>
<td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
<td>female</td>
<td>38</td>
<td>1</td>
<td>0</td>
<td>PC 17599</td>
<td>71.2833</td>
<td>C85</td>
<td>C</td>
</tr>
<tr>
<td>3</td>
<td>1</td>
<td>3</td>
<td>Heikkinen, Miss. Laina</td>
<td>female</td>
<td>26</td>
<td>0</td>
<td>0</td>
<td>STON/O2. 3101282</td>
<td>7.9250</td>
<td>NaN</td>
<td>S</td>
</tr>
<tr>
<td>4</td>
<td>1</td>
<td>1</td>
<td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
<td>female</td>
<td>35</td>
<td>1</td>
<td>0</td>
<td>113803</td>
<td>53.1000</td>
<td>C123</td>
<td>S</td>
</tr>
<tr>
<td>5</td>
<td>0</td>
<td>3</td>
<td>Allen, Mr. William Henry</td>
<td>male</td>
<td>35</td>
<td>0</td>
<td>0</td>
<td>373450</td>
<td>8.0500</td>
<td>NaN</td>
<td>S</td>
</tr>
</table><p>
Можно предположить, что чем выше социальный статус, тем больше вероятность спасения. Давайте проверим это взглянув на количество спасшихся и утонувших в зависимости в разрезе классов. Для этого нужно построить следующую сводную:

</p><pre><code class="python">data.pivot_table('PassengerId', 'Pclass', 'Survived', 'count').plot(kind='bar', stacked=True)</code></pre>
<img src="https://habrastorage.org/getpro/habr/post_images/c64/b62/cbc/c64b62cbc06141e072d550b6b2f3ca7c.png" alt="image"/><p>
Наше вышеописанное предположение про то, что чем выше у пассажиров их социальное положение, тем выше их вероятность спасения. Теперь давайте взглянем, как количество родственников влияет на факт спасения:

</p><pre><code class="python">fig, axes = plt.subplots(ncols=2)
data.pivot_table('PassengerId', ['SibSp'], 'Survived', 'count').plot(ax=axes[0], title='SibSp')
data.pivot_table('PassengerId', ['Parch'], 'Survived', 'count').plot(ax=axes[1], title='Parch')
</code></pre>
<img src="https://habrastorage.org/getpro/habr/post_images/b86/14a/1c7/b8614a1c73db29d7173856f3e05f3c4c.png" alt="image"/><p>
Как видно из графиков наше предположение снова подтвердилось, и из людей имеющих больше 1 родственников спаслись не многие.</p><p>
Сейчас порассуждаем на предмет данных, которые находятся номера кают. Теоретически данных о каютах пользователей может не быть, так что давайте посмотрим на столько это поле заполнено:

</p><pre><code class="python">data.PassengerId[data.Cabin.notnull()].count()</code></pre>
<p>
В итоге заполнено всего 204 записи и 890, на основании этого можно сделать вывод, что данное поле при анализе можно опустить.</p><p>
Следующее поле, которое мы разберем будет поле с возрастом (</p><i>Age</i><p>). Посмотрим на сколько оно заполнено:

</p><pre><code class="python">data.PassengerId[data.Age.notnull()].count()</code></pre>
<p>
Данное поле практически все заполнено (714 непустых записей), но есть пустые значения, которые не определены. Давайте зададим ему значение равное медиане по возрасту из всей выборки. Данный шаг нужен для более точного построения модели:

</p><pre><code class="python">data.Age = data.Age.median()</code></pre><p>
У нас осталось разобраться с полями </p><i>Ticket</i><p>, </p><i>Embarked</i><p>, </p><i>Fare</i><p>, </p><i>Name</i><p>. Давайте посмотрим на поле Embarked, в котором находится порт посадки и проверим есть ли такие пассажиры у которых порт не указан:

</p><pre><code class="python">data[data.Embarked.isnull()]</code></pre>
<table border="1">
<tr>
<th>PassengerId</th>
<th>Survived</th>
<th>Pclass</th>
<th>Name</th>
<th>Sex</th>
<th>Age</th>
<th>SibSp</th>
<th>Parch</th>
<th>Ticket</th>
<th>Fare</th>
<th>Cabin</th>
<th>Embarked</th>
</tr>
<tr>
<td>62</td>
<td>1</td>
<td>1</td>
<td>Icard, Miss. Amelie</td>
<td>female</td>
<td>28</td>
<td>0</td>
<td>0</td>
<td>113572</td>
<td>80</td>
<td>B28</td>
<td>NaN</td>
</tr>
<tr>
<td>830</td>
<td>1</td>
<td>1</td>
<td>Stone, Mrs. George Nelson (Martha Evelyn)</td>
<td>female</td>
<td>28</td>
<td>0</td>
<td>0</td>
<td>113572</td>
<td>80</td>
<td>B28</td>
<td>NaN</td>
</tr>
</table>
<p>
Итак у нас нашлось 2 таких пассажира. Давайте присвоим эти пассажирам порт в котором село больше всего людей:

</p><pre><code class="python">MaxPassEmbarked = data.groupby('Embarked').count()['PassengerId']
data.Embarked[data.Embarked.isnull()] = MaxPassEmbarked[MaxPassEmbarked == MaxPassEmbarked.max()].index[0]
</code></pre>
<p>
Ну что же разобрались еще с одним полем и теперь у нас остались поля с имя пассажира, номером билета и ценой билета.</p><p>
По сути нам из этих трех полей нам нужна только цена(</p><i>Fare</i><p>), т.к. она в какой-то мере определяем ранжирование внутри классов поля </p><i>Pclass</i><p>. Т. е. например люди внутри среднего класса могут быть разделены на тех, кто ближе к первому(высшему) классу, а кто к третьему(низший). Проверим это поле на пустые значения и если таковые имеются заменим цену медианой по цене из все выборки:

</p><pre><code class="python">data.PassengerId[data.Fare.isnull()]</code></pre><p>
В нашем случае пустых записей нет.</p><p>
В свою очередь номер билета и имя пассажира нам никак не помогут, т. к. это просто справочная информация. Единственное для чего они могут пригодиться — это определение кто из пассажиров потенциально являются родственниками, но так как люди у которых есть родственники практически не спаслись (это было показано выше) можно пренебречь этими данными.</p><p>
Теперь, после удаления всех ненужных полей, наш набор выглядит так:

</p><pre><code class="python">data = data.drop(['PassengerId','Name','Ticket','Cabin'],axis=1)</code></pre>
<table border="1">
<tr>
<th>Survived</th>
<th>Pclass</th>
<th>Sex</th>
<th>Age</th>
<th>SibSp</th>
<th>Parch</th>
<th>Fare</th>
<th>Embarked</th>
</tr>
<tr>
<td>0</td>
<td>3</td>
<td>male</td>
<td>28</td>
<td>1</td>
<td>0</td>
<td>7.2500</td>
<td>S</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>female</td>
<td>28</td>
<td>1</td>
<td>0</td>
<td>71.2833</td>
<td>C</td>
</tr>
<tr>
<td>1</td>
<td>3</td>
<td>female</td>
<td>28</td>
<td>0</td>
<td>0</td>
<td>7.9250</td>
<td>S</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>female</td>
<td>28</td>
<td>1</td>
<td>0</td>
<td>53.1000</td>
<td>S</td>
</tr>
<tr>
<td>0</td>
<td>3</td>
<td>male</td>
<td>28</td>
<td>0</td>
<td>0</td>
<td>8.0500</td>
<td>S</td>
</tr>
</table>

<h4>Предварительная обработка входных данных</h4><p>
Предварительный анализ данных завершен, и по его результатам у нас получилась некая выборка, в которой содержатся несколько полей и вроде бы можно преступить к построению модели, если бы не одно «но»: наши данные содержат не только числовые, но и текстовые данные.</p><p>
Поэтому переде тем, как строить модель, нужно закодировать все наши текстовые значения.</p><p>
Можно это сделать в ручную, а можно с помощью модуля </p><a href="http://scikit-learn.org/stable/modules/preprocessing.html#preprocessing">sklearn.preprocessing</a><p>. Давайте воспользуемся вторым вариантом.</p><p>
Закодировать список с фиксированными значениями можно с помощью объекта </p><a href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html#sklearn.preprocessing.LabelEncoder">LabelEncoder()</a><p>. Суть данной функции заключается в том, что на вход ей подается список значений, который надо закодировать, на выходе получается список классов индексы которого и являются кодами элементов поданного на вход списка.

</p><pre><code class="python">from sklearn.preprocessing import LabelEncoder
label = LabelEncoder()
dicts = {}

label.fit(data.Sex.drop_duplicates()) #задаем список значений для кодирования
dicts['Sex'] = list(label.classes_)
data.Sex = label.transform(data.Sex) #заменяем значения из списка кодами закодированных элементов 

label.fit(data.Embarked.drop_duplicates())
dicts['Embarked'] = list(label.classes_)
data.Embarked = label.transform(data.Embarked)</code></pre><p>
В итоге наши исходные данные будут выглядеть так:
</p><table border="1">
<tr>
<th>Survived</th>
<th>Pclass</th>
<th>Sex</th>
<th>Age</th>
<th>SibSp</th>
<th>Parch</th>
<th>Fare</th>
<th>Embarked</th>
</tr>
<tr>
<td>0</td>
<td>3</td>
<td>1</td>
<td>28</td>
<td>1</td>
<td>0</td>
<td>7.2500</td>
<td>2</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>0</td>
<td>28</td>
<td>1</td>
<td>0</td>
<td>71.2833</td>
<td>0</td>
</tr>
<tr>
<td>1</td>
<td>3</td>
<td>0</td>
<td>28</td>
<td>0</td>
<td>0</td>
<td>7.9250</td>
<td>2</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>0</td>
<td>28</td>
<td>1</td>
<td>0</td>
<td>53.1000</td>
<td>2</td>
</tr>
<tr>
<td>0</td>
<td>3</td>
<td>1</td>
<td>28</td>
<td>0</td>
<td>0</td>
<td>8.0500</td>
<td>2</td>
</tr>
</table>
<p>
Теперь нам надо написать код для приведения проверочного файла в нужный нам вид. Для этого можно просто скопировать куски кода которые были выше(или просто написать функцию для обработки входного файла):

</p><pre><code class="python">test = read_csv('Kaggle_Titanic/Data/test.csv')
test.Age[test.Age.isnull()] = test.Age.mean()
test.Fare[test.Fare.isnull()] = test.Fare.median() #заполняем пустые значения средней ценой билета
MaxPassEmbarked = test.groupby('Embarked').count()['PassengerId']
test.Embarked[test.Embarked.isnull()] = MaxPassEmbarked[MaxPassEmbarked == MaxPassEmbarked.max()].index[0]
result = DataFrame(test.PassengerId)
test = test.drop(['Name','Ticket','Cabin','PassengerId'],axis=1)

label.fit(dicts['Sex'])
test.Sex = label.transform(test.Sex)

label.fit(dicts['Embarked'])
test.Embarked = label.transform(test.Embarked)
</code></pre>
<p>
Код описанный выше выполняет практически те же операции, что мы проделали с обучающей выборкой. Отличие в том, что добавилась строка для обработки поля </p><i>Fare</i><p>, если оно вдруг не заполнено.
</p><table border="1">
<tr>
<th>Pclass</th>
<th>Sex</th>
<th>Age</th>
<th>SibSp</th>
<th>Parch</th>
<th>Fare</th>
<th>Embarked</th>
</tr>
<tr>
<td>3</td>
<td>1</td>
<td>34.5</td>
<td>0</td>
<td>0</td>
<td>7.8292</td>
<td>1</td>
</tr>
<tr>
<td>3</td>
<td>0</td>
<td>47.0</td>
<td>1</td>
<td>0</td>
<td>7.0000</td>
<td>2</td>
</tr>
<tr>
<td>2</td>
<td>1</td>
<td>62.0</td>
<td>0</td>
<td>0</td>
<td>9.6875</td>
<td>1</td>
</tr>
<tr>
<td>3</td>
<td>1</td>
<td>27.0</td>
<td>0</td>
<td>0</td>
<td>8.6625</td>
<td>2</td>
</tr>
<tr>
<td>3</td>
<td>0</td>
<td>22.0</td>
<td>1</td>
<td>1</td>
<td>12.2875</td>
<td>2</td>
</tr>
</table>

<h4>Построение моделей классификации и их анализ</h4><p>
Ну что же, данные обработаны и можно приступить к построению модели, но для начала нужно определиться с тем, как мы будем проверять точность полученной модели. Для данной проверки мы будем использовать </p><a href="http://www.machinelearning.ru/wiki/index.php?title=%D0%A1%D0%BA%D0%BE%D0%BB%D1%8C%D0%B7%D1%8F%D1%89%D0%B8%D0%B9_%D0%BA%D0%BE%D0%BD%D1%82%D1%80%D0%BE%D0%BB%D1%8C">скользящий контроль</a><p> и </p><a href="http://ru.wikipedia.org/wiki/ROC-%D0%BA%D1%80%D0%B8%D0%B2%D0%B0%D1%8F">ROC-кривые</a><p>. Проверку будем выполнять на обучающей выборке, после чего применим ее на тестовую.</p><p>
Итак рассмотрим несколько алгоритмов машинного обучения:
</p><p>
Загрузим нужные нам библиотеки:

</p><pre><code class="python">from sklearn import cross_validation, svm
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_curve, auc
import pylab as pl
</code></pre><p>
Для начала, надо разделить нашу обучаюшую выборку на показатель, который мы исследуем, и признаки его определяющие:

</p><pre><code class="python">target = data.Survived
train = data.drop(['Survived'], axis=1) #из исходных данных убираем Id пассажира и флаг спасся он или нет
kfold = 5 #количество подвыборок для валидации
itog_val = {} #список для записи результатов кросс валидации разных алгоритмов
</code></pre><p>
Теперь наша обучающая выборка выглядит так:
</p><table border="1">
<tr>
<th>Pclass</th>
<th>Sex</th>
<th>Age</th>
<th>SibSp</th>
<th>Parch</th>
<th>Fare</th>
<th>Embarked</th>
</tr>
<tr>
<td>3</td>
<td>1</td>
<td>28</td>
<td>1</td>
<td>0</td>
<td>7.2500</td>
<td>2</td>
</tr>
<tr>
<td>1</td>
<td>0</td>
<td>28</td>
<td>1</td>
<td>0</td>
<td>71.2833</td>
<td>0</td>
</tr>
<tr>
<td>3</td>
<td>0</td>
<td>28</td>
<td>0</td>
<td>0</td>
<td>7.9250</td>
<td>2</td>
</tr>
<tr>
<td>1</td>
<td>0</td>
<td>28</td>
<td>1</td>
<td>0</td>
<td>53.1000</td>
<td>2</td>
</tr>
<tr>
<td>3</td>
<td>1</td>
<td>28</td>
<td>0</td>
<td>0</td>
<td> 8.0500</td>
<td>2</td>
</tr>
</table><p>
Теперь разобьем показатели полученные ранее на 2 подвыборки(обучающую и тестовую) для расчет ROC кривых (для скользящего контроля этого делать не надо, т.к. функция проверки это делает сама. В этом нам поможет функция </p><a href="http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.train_test_split.html#sklearn.cross_validation.train_test_split">train_test_split</a><p> модуля </p><a href="http://scikit-learn.org/stable/modules/cross_validation.html#cross-validation">cross_validation</a><p>:

</p><pre><code class="python">ROCtrainTRN, ROCtestTRN, ROCtrainTRG, ROCtestTRG = cross_validation.train_test_split(train, target, test_size=0.25) 
</code></pre><p>
В качестве параметров ей передается:
</p><ul>
<li>Массив параметров<br/>
</li>
<li>Массив значений показателей<br/>
</li>
<li>Соотношение в котором будет разбита обучающая выборка (в нашем случае для тестового набора будет выделена 1/4 часть данных исходной обучающей выборки)<br/>
</li>
</ul><p>
На выходе функция выдает 4 массива:
</p><ol>
<li>Новый обучающий массив параметров<br/>
</li>
<li>тестовый массив параметров<br/>
</li>
<li>Новый массив показателей<br/>
</li>
<li>тестовый массив показателей<br/>
</li>
</ol>
<p>
Далее представлены перечисленные методы с наилучшими параметрами подобранные опытным путем:
</p><pre><code class="python">model_rfc = RandomForestClassifier(n_estimators = 70) #в параметре передаем кол-во деревьев
model_knc = KNeighborsClassifier(n_neighbors = 18) #в параметре передаем кол-во соседей
model_lr = LogisticRegression(penalty='l1', tol=0.01) 
model_svc = svm.SVC() #по умолчанию kernek='rbf'
</code></pre><p>
Теперь проверим полученные модели с помощью скользящего контроля. Для этого нам необходимо воcпользоваться функцией </p><a href="http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.cross_val_score.html#sklearn.cross_validation.cross_val_score">cross_val_score</a>
<pre><code class="python">scores = cross_validation.cross_val_score(model_rfc, train, target, cv = kfold)
itog_val['RandomForestClassifier'] = scores.mean()
scores = cross_validation.cross_val_score(model_knc, train, target, cv = kfold)
itog_val['KNeighborsClassifier'] = scores.mean()
scores = cross_validation.cross_val_score(model_lr, train, target, cv = kfold)
itog_val['LogisticRegression'] = scores.mean()
scores = cross_validation.cross_val_score(model_svc, train, target, cv = kfold)
itog_val['SVC'] = scores.mean()
</code></pre><p>
Давайте посмотрим на графике средний показатель тестов перекрестной проверки каждой модели:

</p><pre><code class="python">DataFrame.from_dict(data = itog_val, orient='index').plot(kind='bar', legend=False)
</code></pre>
<img src="https://habrastorage.org/getpro/habr/post_images/0c4/800/17d/0c480017dfbcc82215a8e568d3db0ecb.png" alt="image"/>
<p>
Как можно увидеть из графика лучше всего себя показал алгоритм RandomForest. Теперь же давайте взглянем на графики ROC-кривых, для оценки точности работы классификатора. Графики будем рисовать с помощью библиотеки </p><a href="http://matplotlib.org/">matplotlib</a><p>:

</p><pre><code class="python">pl.clf()
plt.figure(figsize=(8,6))
#SVC
model_svc.probability = True
probas = model_svc.fit(ROCtrainTRN, ROCtrainTRG).predict_proba(ROCtestTRN)
fpr, tpr, thresholds = roc_curve(ROCtestTRG, probas[:, 1])
roc_auc  = auc(fpr, tpr)
pl.plot(fpr, tpr, label='%s ROC (area = %0.2f)' % ('SVC', roc_auc))
#RandomForestClassifier
probas = model_rfc.fit(ROCtrainTRN, ROCtrainTRG).predict_proba(ROCtestTRN)
fpr, tpr, thresholds = roc_curve(ROCtestTRG, probas[:, 1])
roc_auc  = auc(fpr, tpr)
pl.plot(fpr, tpr, label='%s ROC (area = %0.2f)' % ('RandonForest',roc_auc))
#KNeighborsClassifier
probas = model_knc.fit(ROCtrainTRN, ROCtrainTRG).predict_proba(ROCtestTRN)
fpr, tpr, thresholds = roc_curve(ROCtestTRG, probas[:, 1])
roc_auc  = auc(fpr, tpr)
pl.plot(fpr, tpr, label='%s ROC (area = %0.2f)' % ('KNeighborsClassifier',roc_auc))
#LogisticRegression
probas = model_lr.fit(ROCtrainTRN, ROCtrainTRG).predict_proba(ROCtestTRN)
fpr, tpr, thresholds = roc_curve(ROCtestTRG, probas[:, 1])
roc_auc  = auc(fpr, tpr)
pl.plot(fpr, tpr, label='%s ROC (area = %0.2f)' % ('LogisticRegression',roc_auc))
pl.plot([0, 1], [0, 1], 'k--')
pl.xlim([0.0, 1.0])
pl.ylim([0.0, 1.0])
pl.xlabel('False Positive Rate')
pl.ylabel('True Positive Rate')
pl.legend(loc=0, fontsize='small')
pl.show()
</code></pre>
<img src="https://habrastorage.org/getpro/habr/post_images/2c5/ef2/a8c/2c5ef2a8ce2d782b09a08a5036cdfa68.png" alt="image"/><p>
Как видно по результатам ROC-анализа лучший результат опять показал RandomForest. Теперь осталось только применить нашу модель к тестовой выборке:

</p><pre><code class="python">model_rfc.fit(train, target)
result.insert(1,'Survived', model_rfc.predict(test))
result.to_csv('Kaggle_Titanic/Result/test.csv', index=False)
</code></pre>

<h4>Заключение</h4><p>
В данной статье я постарался показать, как можно использовать пакет </p><b>pandas</b><p> в связке с пакетом для машинного обучения </p><b>sklearn</b><p>. Полученная модель при сабмите на Kaggle показала точность 0.77033. В статье я больше хотел показать именно работу с инструментарием и ход выполнения исследования, а не построение подробного алгоритма, как например в </p><a href="http://habrahabr.ru/post/165001/">этой</a><p> серии статей.

      
      </p><p class="clear"/>
    </div>

    
  </div></body></html>