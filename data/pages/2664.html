<html><body><div><div class="entry-content">
		<p><a href="https://impythonist.files.wordpress.com/2015/01/pcweenies_1039.jpg"><img class="aligncenter wp-image-948 " src="https://impythonist.files.wordpress.com/2015/01/pcweenies_1039.jpg?w=567&amp;h=662" alt=""/></a></p>
<p>We all scraped web pages.HTML content returned as response has our data and we scrape it for fetching certain results.If web page has JavaScript implementation, original data is obtained after rendering process. When we use normal requests package in that situation then responses those are returned  contains no data in them.Browsers know how to render and display the final result,but how a program can know?. So I came with a power pack solution to scrape any JavaScript rendered website very easily.</p>
<p>Many of us use below libraries to perform scraping.</p>
<p>1)Lxml</p>
<p>2)BeautifulSoup</p>
<p>I don’t mention scrapy or dragline frameworks here since underlying basic scraper is lxml .My favorite one is lxml.why? ,It has the element traversal methods rather than relying on regular expressions methodology like BeautifulSoup.Here I am going to take a very interesting example.I am so amazed after finding that ,my article is appeared in recent PyCoders weekly issue 147.So I am taking PyCoders weekly as an example to scrape all useful links from PyCoders archives.link to PyCoders weekly archives is here.</p>
<p><a href="http://pycoders.com/archive/" rel="nofollow">http://pycoders.com/archive/</a></p>
<p><a href="https://impythonist.files.wordpress.com/2015/01/selection_003.png"><img class="aligncenter wp-image-938 size-full" src="https://impythonist.files.wordpress.com/2015/01/selection_003.png?w=1000" alt=""/></a></p>
<p>It is totally a JavaScript rendered website.I want all links for those archives and next all links from each archive post.How to do that?. First I will show that it returned me nothing when used HTTP approach.</p>
<pre class="python highlighted_source">import requests
from lxml import html

#storing response
response = requests.get('http://pycoders.com/archive/')

#creating lxml tree from response body
tree = html.fromstring(response.text)

#Finding all anchor tags in response
print tree.xpath('//div[@class="campaign"]/a/@href')
</pre>
<p>When I run this I got following output</p>
<p><a href="https://impythonist.files.wordpress.com/2015/01/selection_004.png"><img class="aligncenter size-full wp-image-940" src="https://impythonist.files.wordpress.com/2015/01/selection_004.png?w=1000&amp;h=143" alt="Selection_004"/></a></p>
<p>So I returned with only 3 links.How is that possible,because there are nearly 133 archives of PyCoders weekly.So I got nothing in response.Now I will think about tackling the problem.</p>
<h2 id="toc_0">How can we get the content?</h2>
<p>There is one approach of getting data from JS rendered web pages.It is using Web kit library.Web kit library can do everything that a browser can perform.For some browsers Web kit will be the underground element for rendering web pages.Web kit is part of the QT library.So if you installed QT library and PyQT4 then you are ready to go.</p>
<p>You can install it by using command</p>
<pre>sudo apt-get install python-qt4</pre>
<p>Now everything is finished.We retry the fetching process,but with a different approach.</p>
<h2 id="toc_0">Here comes the solution</h2>
<p>We first give the request through the web kit.We wait until everything is loaded perfectly and then return the completed HTML to a variable.Then we scrape that HTML content using lxml and obtain results.This process is little bit slow but you will be surprised by seeing that content fetched perfectly.</p>
<h2 id="toc_0">Let us take this code for granted</h2>
<pre class="python highlighted_source">import sys  
from PyQt4.QtGui import *  
from PyQt4.QtCore import *  
from PyQt4.QtWebKit import *  
from lxml import html 

class Render(QWebPage):  
  def __init__(self, url):  
    self.app = QApplication(sys.argv)  
    QWebPage.__init__(self)  
    self.loadFinished.connect(self._loadFinished)  
    self.mainFrame().load(QUrl(url))  
    self.app.exec_()  
  
  def _loadFinished(self, result):  
    self.frame = self.mainFrame()  
    self.app.quit() 
</pre>
<p>Render class renders the web page. QWebPage is the input URL of web page to scrape.It does something,don’t bother about details.Remember that when we create Render object, it loads everything and creates a frame containing all information about the web page.</p>
<pre class="python highlighted_source">url = 'http://pycoders.com/archive/'  
#This does the magic.Loads everything
r = Render(url)  
#result is a QString.
result = r.frame.toHtml()</pre>
<p>We are storing the result HTML into variable result.It is not a string to be processed with lxml.So we need to process before using content by lxml.</p>
<pre class="python highlighted_source">#QString should be converted to string before processed by lxml
formatted_result = str(result.toAscii())

#Next build lxml tree from formatted_result
tree = html.fromstring(formatted_result)

#Now using correct Xpath we are fetching URL of archives
archive_links = tree.xpath('//div[@class="campaign"]/a/@href')
print archive_links</pre>
<p>It gives us all the links for archives and output is a very populated one.</p>
<p><a href="https://impythonist.files.wordpress.com/2015/01/selection_005.png"><img class="aligncenter size-full wp-image-941" src="https://impythonist.files.wordpress.com/2015/01/selection_005.png?w=1000&amp;h=454" alt="Selection_005"/></a></p>
<p>So next create Render objects with these links as URL and extract the required content.The power of Web kit provides us to render a web page pragmatically then fetches data.So use this technique and get data from any JavaScript rendered web page.</p>
<p>Total code looks like this.</p>
<pre class="python highlighted_source">import sys  
from PyQt4.QtGui import *  
from PyQt4.QtCore import *  
from PyQt4.QtWebKit import *  
from lxml import html 

#Take this class for granted.Just use result of rendering.
class Render(QWebPage):  
  def __init__(self, url):  
    self.app = QApplication(sys.argv)  
    QWebPage.__init__(self)  
    self.loadFinished.connect(self._loadFinished)  
    self.mainFrame().load(QUrl(url))  
    self.app.exec_()  
  
  def _loadFinished(self, result):  
    self.frame = self.mainFrame()  
    self.app.quit()  

url = 'http://pycoders.com/archive/'  
r = Render(url)  
result = r.frame.toHtml()
#This step is important.Converting QString to Ascii for lxml to process
archive_links = html.fromstring(str(result.toAscii()))
print archive_links</pre>
<p> </p>
<p>I showed you the fully functional way to scrape a JavaScript rendered web page .Apply this technique to automate any no of steps or integrate this technique and override default behavior of a scraping framework.It is slow but 100% result prone.I hope you enjoyed the post.Try now this on any website you think is tricky to scrape.</p>
<p>All the best.</p>
		<div id="jp-post-flair" class="sharedaddy sd-like-enabled sd-sharing-enabled"><div class="sharedaddy sd-block sd-like jetpack-likes-widget-wrapper jetpack-likes-widget-unloaded" id="like-post-wrapper-62549587-934-56d5b723072b7" data-src="//widgets.wp.com/likes/#blog_id=62549587&amp;post_id=934&amp;origin=impythonist.wordpress.com&amp;obj_id=62549587-934-56d5b723072b7" data-name="like-post-frame-62549587-934-56d5b723072b7"><h3 class="sd-title">Like this:</h3><p class="likes-widget-placeholder post-likes-widget-placeholder"><span class="button"><span>Like</span></span> <span class="loading">Loading...</span></p><span class="sd-text-color"/><a class="sd-link-color"/></div>
<p id="jp-relatedposts" class="jp-relatedposts">
	<h3 class="jp-relatedposts-headline"><em>Related</em></h3>
</p></div>					</div>

	</div></body></html>