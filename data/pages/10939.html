<html><body><div><article class="markdown-body entry-content" itemprop="text"><h1><a id="user-content-speech-recognition" class="anchor" href="#speech-recognition" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Speech Recognition</h1>
<a href="https://pypi.python.org/pypi/SpeechRecognition/"><img alt="Downloads" src="https://camo.githubusercontent.com/78574d7c8d3fbb1605e97acbf8c0980da9bb68aa/68747470733a2f2f696d672e736869656c64732e696f2f707970692f646d2f5370656563685265636f676e6974696f6e2e737667" data-canonical-src="https://img.shields.io/pypi/dm/SpeechRecognition.svg"/>
</a>
<a href="https://pypi.python.org/pypi/SpeechRecognition/"><img alt="Latest Version" src="https://camo.githubusercontent.com/3dd431fbb6e597e8bbb48e8646268b14fbf768f6/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f5370656563685265636f676e6974696f6e2e737667" data-canonical-src="https://img.shields.io/pypi/v/SpeechRecognition.svg"/>
</a>
<a href="https://pypi.python.org/pypi/SpeechRecognition/"><img alt="Development Status" src="https://camo.githubusercontent.com/582a574fce9cf7a842c27c949f0f668ebe5969a1/68747470733a2f2f696d672e736869656c64732e696f2f707970692f7374617475732f5370656563685265636f676e6974696f6e2e737667" data-canonical-src="https://img.shields.io/pypi/status/SpeechRecognition.svg"/>
</a>
<a href="https://pypi.python.org/pypi/SpeechRecognition/"><img alt="Supported Python Versions" src="https://camo.githubusercontent.com/115fbf6409f065c3e28d2a5ed587f2b729bfe316/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f5370656563685265636f676e6974696f6e2e737667" data-canonical-src="https://img.shields.io/pypi/pyversions/SpeechRecognition.svg"/>
</a>
<a href="https://pypi.python.org/pypi/SpeechRecognition/"><img alt="License" src="https://camo.githubusercontent.com/7512afb98796024ef050a3e49dd9c3397dc3f82f/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f5370656563685265636f676e6974696f6e2e737667" data-canonical-src="https://img.shields.io/pypi/l/SpeechRecognition.svg"/>
</a>
<p>Library for performing speech recognition with support for <a href="http://cmusphinx.sourceforge.net/wiki/">CMU Sphinx</a>, Google Speech Recognition, <a href="https://wit.ai/">Wit.ai</a>, <a href="http://www.ibm.com/smarterplanet/us/en/ibmwatson/developercloud/speech-to-text.html">IBM Speech to Text</a>, and <a href="http://developer.att.com/apis/speech">AT&amp;T Speech to Text</a>.</p>
<p><strong>Quickstart:</strong> <code>pip install SpeechRecognition</code>. See the "Installing" section for more details.</p>
<p>To quickly try it out, run <code>python -m speech_recognition</code> after installing.</p>
<p>Project links:</p>

<a name="user-content-library-reference"/>
<h2><a id="user-content-library-reference" class="anchor" href="#library-reference" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Library Reference</h2>
<p>The <a href="https://github.com/Uberi/speech_recognition/blob/master/reference/library-reference.rst">library reference</a> documents every publicly accessible object in the library. This document is also included under <code>reference/library-reference.rst</code>.</p>
<p>See <a href="https://github.com/Uberi/speech_recognition/blob/master/reference/pocketsphinx.rst">Notes on using PocketSphinx</a> for information about installing languages, compiling PocketSphinx, and building language packs from online resources. This document is also included under <code>reference/pocketsphinx.rst</code>.</p>
<a name="user-content-examples"/>
<h2><a id="user-content-examples" class="anchor" href="#examples" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Examples</h2>
<p>See the <code>examples/</code> directory for usage examples:</p>

<a name="user-content-installing"/>
<h2><a id="user-content-installing" class="anchor" href="#installing" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Installing</h2>
<p>First, make sure you have all the requirements listed in the "Requirements" section.</p>
<p>The easiest way to install this is using <code>pip install SpeechRecognition</code>.</p>
<p>Otherwise, download the source distribution from <a href="https://pypi.python.org/pypi/SpeechRecognition/">PyPI</a>, and extract the archive.</p>
<p>In the folder, run <code>python setup.py install</code>.</p>
<a name="user-content-requirements"/>
<h2><a id="user-content-requirements" class="anchor" href="#requirements" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Requirements</h2>
<p>In summary, this library requires:</p>
<ul>
<li><strong>Python</strong> 2.6, 2.7, or 3.3+</li>
<li><strong>PyAudio</strong> 0.2.9+ (required only if you need to use microphone input)</li>
<li><strong>PocketSphinx</strong> (required only if you need to use the Sphinx recognizer)</li>
<li><strong>FLAC encoder</strong> (required only if the system is not x86-based Windows/Linux/OS X)</li>
</ul>
<a name="user-content-python"/>
<h3><a id="user-content-python" class="anchor" href="#python" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Python</h3>
<p>The first software requirement is <a href="https://www.python.org/download/releases/">Python 2.6, 2.7, or Python 3.3+</a>. This is required to use the library.</p>
<a name="user-content-pyaudio-for-microphone-users"/>
<h3><a id="user-content-pyaudio-for-microphone-users" class="anchor" href="#pyaudio-for-microphone-users" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>PyAudio (for microphone users)</h3>
<p>If you want to use audio input from microphones, <a href="http://people.csail.mit.edu/hubert/pyaudio/#downloads">PyAudio</a> is also necessary. Version 0.2.9+ is required in order to avoid overflow issues with recording on certain machines.</p>
<p>If not installed, everything in the library will still work, except attempting to instantiate a <code>Microphone</code> object will throw an <code>AttributeError</code>.</p>
<p>The installation instructions are quite good as of PyAudio v0.2.9. For convenience, they are summarized below:</p>
<ul>
<li><p>On Windows, install PyAudio using <a href="https://pip.readthedocs.org/">Pip</a>: execute <code>pip install pyaudio</code> in a terminal.</p>
</li>
<li><dl>
<dt>On Debian-derived Linux distributions (like Ubuntu and Mint), install PyAudio using <a href="https://wiki.debian.org/Apt">APT</a>: execute <code>sudo apt-get install python-pyaudio python3-pyaudio</code> in a terminal.</dt>
<dd><ul>
<li>If the version in the repositories is too old, install the latest release using Pip: execute <code>sudo apt-get install portaudio19-dev python-all-dev python3-all-dev &amp;&amp; sudo pip install pyaudio</code> (replace <code>pip</code> with <code>pip3</code> if using Python 3).</li>
</ul>
</dd>
</dl>
</li>
<li><p>On OS X, install PortAudio using <a href="http://brew.sh/">Homebrew</a>: <code>brew install portaudio</code>. Then, install PyAudio using <a href="https://pip.readthedocs.org/">Pip</a>: <code>pip install pyaudio</code>.</p>
</li>
<li><p>On other POSIX-based systems, install the <code>portaudio19-dev</code> and <code>python-all-dev</code> (or <code>python3-all-dev</code> if using Python 3) packages (or their closest equivalents) using a package manager of your choice, and then install PyAudio using <a href="https://pip.readthedocs.org/">Pip</a>: <code>pip install pyaudio</code> (replace <code>pip</code> with <code>pip3</code> if using Python 3).</p>
</li>
</ul>
<p>PyAudio <a href="https://pypi.python.org/pypi/wheel">wheel packages</a> for 64-bit Python 2.7, 3.4, and 3.5 on Windows and Linux are included for convenience, under the <code>third-party/</code> directory. To install, simply run <code>pip install wheel</code> followed by <code>pip install ./third-party/WHEEL_FILENAME</code> (replace <code>pip</code> with <code>pip3</code> if using Python 3) in the project root directory.</p>
<a name="user-content-pocketsphinx-python-for-sphinx-users"/>
<h3><a id="user-content-pocketsphinx-python-for-sphinx-users" class="anchor" href="#pocketsphinx-python-for-sphinx-users" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>PocketSphinx-Python (for Sphinx users)</h3>
<p><a href="https://github.com/bambocher/pocketsphinx-python">PocketSphinx-Python</a> is required if and only if you want to use the Sphinx recognizer (<code>recognizer_instance.recognize_sphinx</code>).</p>
<p>PocketSphinx-Python <a href="https://pypi.python.org/pypi/wheel">wheel packages</a> for 64-bit Python 2.7, 3.4, and 3.5 on Windows and Linux are included for convenience, under the <code>third-party/</code> directory. To install, simply run <code>pip install wheel</code> followed by <code>pip install ./third-party/WHEEL_FILENAME</code> (replace <code>pip</code> with <code>pip3</code> if using Python 3) in the SpeechRecognition folder.</p>
<p>Note that the versions available in most package repositories are outdated and will not work with the bundled language data. Using the bundled wheel packages or building from source is recommended.</p>
<p>See <a href="https://github.com/Uberi/speech_recognition/blob/master/reference/pocketsphinx.rst">Notes on using PocketSphinx</a> for information about installing languages, compiling PocketSphinx, and building language packs from online resources. This document is also included under <code>reference/pocketsphinx.rst</code>.</p>
<a name="user-content-flac-for-some-systems"/>
<h3><a id="user-content-flac-for-some-systems" class="anchor" href="#flac-for-some-systems" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>FLAC (for some systems)</h3>
<p>A FLAC encoder is required to encode the audio data to send to the API. If using Windows, OS X, or Linux on an i385-compatible architecture, the encoder is already bundled with this library - you do not need to install anything else.</p>
<p>Otherwise, ensure that you have the <code>flac</code> command line tool, which is often available through the system package manager.</p>
<a name="user-content-troubleshooting"/>
<h2><a id="user-content-troubleshooting" class="anchor" href="#troubleshooting" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Troubleshooting</h2>
<a name="user-content-the-recognizer-tries-to-recognize-speech-even-when-i-m-not-speaking"/>
<h3><a id="user-content-the-recognizer-tries-to-recognize-speech-even-when-im-not-speaking" class="anchor" href="#the-recognizer-tries-to-recognize-speech-even-when-im-not-speaking" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>The recognizer tries to recognize speech even when I'm not speaking.</h3>
<p>Try increasing the <code>recognizer_instance.energy_threshold</code> property. This is basically how sensitive the recognizer is to when recognition should start. Higher values mean that it will be less sensitive, which is useful if you are in a loud room.</p>
<p>This value depends entirely on your microphone or audio data. There is no one-size-fits-all value, but good values typically range from 50 to 4000.</p>
<a name="user-content-the-recognizer-can-t-recognize-speech-right-after-it-starts-listening-for-the-first-time"/>
<h3><a id="user-content-the-recognizer-cant-recognize-speech-right-after-it-starts-listening-for-the-first-time" class="anchor" href="#the-recognizer-cant-recognize-speech-right-after-it-starts-listening-for-the-first-time" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>The recognizer can't recognize speech right after it starts listening for the first time.</h3>
<p>The <code>recognizer_instance.energy_threshold</code> property is probably set to a value that is too high to start off with, and then being adjusted lower automatically by dynamic energy threshold adjustment. Before it is at a good level, the energy threshold is so high that speech is just considered ambient noise.</p>
<p>The solution is to decrease this threshold, or call <code>recognizer_instance.adjust_for_ambient_noise</code> beforehand, which will set the threshold to a good value automatically.</p>
<a name="user-content-the-recognizer-doesn-t-understand-my-particular-language-dialect"/>
<h3><a id="user-content-the-recognizer-doesnt-understand-my-particular-languagedialect" class="anchor" href="#the-recognizer-doesnt-understand-my-particular-languagedialect" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>The recognizer doesn't understand my particular language/dialect.</h3>
<p>Try setting the recognition language to your language/dialect. To do this, see the documentation for <code>recognizer_instance.recognize_sphinx</code>, <code>recognizer_instance.recognize_google</code>, <code>recognizer_instance.recognize_wit</code>, <code>recognizer_instance.recognize_ibm</code>, and <code>recognizer_instance.recognize_att</code>.</p>
<p>For example, if your language/dialect is British English, it is better to use <code>"en-GB"</code> as the language rather than <code>"en-US"</code>.</p>
<a name="user-content-the-code-examples-throw-unicodeencodeerror-ascii-codec-can-t-encode-character-when-run"/>
<h3><a id="user-content-the-code-examples-throw-unicodeencodeerror-ascii-codec-cant-encode-character-when-run" class="anchor" href="#the-code-examples-throw-unicodeencodeerror-ascii-codec-cant-encode-character-when-run" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>The code examples throw <code>UnicodeEncodeError: 'ascii' codec can't encode character</code> when run.</h3>
<p>When you're using Python 2, and your language uses non-ASCII characters, and the terminal or file-like object you're printing to only supports ASCII, an error is thrown when trying to write non-ASCII characters.</p>
<p>This is because in Python 2, <code>recognizer_instance.recognize_sphinx</code>, <code>recognizer_instance.recognize_google</code>, <code>recognizer_instance.recognize_wit</code>, <code>recognizer_instance.recognize_ibm</code>, and <code>recognizer_instance.recognize_att</code> return unicode strings (<code>u"something"</code>) rather than byte strings (<code>"something"</code>). In Python 3, all strings are unicode strings.</p>
<p>To make printing of unicode strings work in Python 2 as well, replace all print statements in your code of the following form:</p>
<blockquote>
<div class="highlight highlight-source-python"><pre><span class="pl-c1">print</span> <span class="pl-c1">SOME_UNICODE_STRING</span></pre></div>
</blockquote>
<p>With the following:</p>
<blockquote>
<div class="highlight highlight-source-python"><pre><span class="pl-c1">print</span> <span class="pl-c1">SOME_UNICODE_STRING</span>.encode(<span class="pl-s"><span class="pl-pds">"</span>utf8<span class="pl-pds">"</span></span>)</pre></div>
</blockquote>
<p>This change, however, will prevent the code from working in Python 3.</p>
<a name="user-content-the-program-doesn-t-run-when-compiled-with-pyinstaller"/>
<h3><a id="user-content-the-program-doesnt-run-when-compiled-with-pyinstaller" class="anchor" href="#the-program-doesnt-run-when-compiled-with-pyinstaller" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>The program doesn't run when compiled with <a href="https://github.com/pyinstaller/pyinstaller/wiki">PyInstaller</a>.</h3>
<p>As of PyInstaller version 3.0, SpeechRecognition is supported out of the box. If you're getting weird issues when compiling your program using PyInstaller, simply update PyInstaller.</p>
<p>You can easily do this by running <code>pip install --upgrade pyinstaller</code>.</p>
<a name="user-content-on-ubuntu-debian-i-get-errors-like-jack-server-is-not-running-or-cannot-be-started-or-cannot-lock-down-byte-memory-area-cannot-allocate-memory"/>
<h3><a id="user-content-on-ubuntudebian-i-get-errors-like-jack-server-is-not-running-or-cannot-be-started-or-cannot-lock-down--byte-memory-area-cannot-allocate-memory" class="anchor" href="#on-ubuntudebian-i-get-errors-like-jack-server-is-not-running-or-cannot-be-started-or-cannot-lock-down--byte-memory-area-cannot-allocate-memory" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>On Ubuntu/Debian, I get errors like "jack server is not running or cannot be started" or "Cannot lock down [...] byte memory area (Cannot allocate memory)".</h3>
<p>The Linux audio stack is pretty fickle. There are a few things that can cause these issues.</p>
<p>First, make sure JACK is installed - to install it, run <code>sudo apt-get install multimedia-jack</code></p>
<p>You will then want to configure the JACK daemon correctly to avoid that "Cannot allocate memory" error. Run <code>sudo dpkg-reconfigure -p high jackd2</code> and select "Yes" to do so.</p>
<p>Now, you will want to make sure your current user is in the <code>audio</code> group. You can add your current user to this group by running <code>sudo adduser $(whoami) audio</code>.</p>
<p>Unfortunately, these changes will require you to reboot before they take effect.</p>
<p>After rebooting, run <code>pulseaudio --kill</code>, followed by <code>jack_control start</code>, to fix the "jack server is not running or cannot be started" error.</p>
<a name="user-content-on-ubuntu-debian-i-get-annoying-output-in-the-terminal-saying-things-like-bt-audio-service-open-connection-refused-and-various-others"/>
<h3><a id="user-content-on-ubuntudebian-i-get-annoying-output-in-the-terminal-saying-things-like-bt_audio_service_open--connection-refused-and-various-others" class="anchor" href="#on-ubuntudebian-i-get-annoying-output-in-the-terminal-saying-things-like-bt_audio_service_open--connection-refused-and-various-others" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>On Ubuntu/Debian, I get annoying output in the terminal saying things like "bt_audio_service_open: [...] Connection refused" and various others.</h3>
<p>The "bt_audio_service_open" error means that you have a Bluetooth audio device, but as a physical device is not currently connected, we can't actually use it - if you're not using a Bluetooth microphone, then this can be safely ignored. If you are, and audio isn't working, then double check to make sure your microphone is actually connected. There does not seem to be a simple way to disable these messages.</p>
<p>For errors of the form "ALSA lib [...] Unknown PCM", see <a href="http://stackoverflow.com/questions/7088672/pyaudio-working-but-spits-out-error-messages-each-time">this StackOverflow answer</a>. Basically, to get rid of an error of the form "Unknown PCM cards.pcm.rear", simply comment out <code>pcm.rear cards.pcm.rear</code> in <code>/usr/share/alsa/alsa.conf</code>, <code>~/.asoundrc</code>, and <code>/etc/asound.conf</code>.</p>
<a name="user-content-on-os-x-i-get-a-childprocesserror-saying-that-it-couldn-t-find-the-system-flac-converter-even-though-it-s-installed"/>
<h3><a id="user-content-on-os-x-i-get-a-childprocesserror-saying-that-it-couldnt-find-the-system-flac-converter-even-though-its-installed" class="anchor" href="#on-os-x-i-get-a-childprocesserror-saying-that-it-couldnt-find-the-system-flac-converter-even-though-its-installed" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>On OS X, I get a <code>ChildProcessError</code> saying that it couldn't find the system FLAC converter, even though it's installed.</h3>
<p>Installing [FLAC for OS X](<a href="https://xiph.org/flac/download.html">https://xiph.org/flac/download.html</a>) directly from the source code will not work, since it doesn't correctly add the executables to the search path.</p>
<p>Installing FLAC using [Homebrew](<a href="http://brew.sh/">http://brew.sh/</a>) ensures that the search path is correctly updated. First, ensure you have Homebrew, then run <code>brew install flac</code> to install the necessary files.</p>
<a name="user-content-developing"/>
<h2><a id="user-content-developing" class="anchor" href="#developing" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Developing</h2>
<p>To hack on this library, first make sure you have all the requirements listed in the "Requirements" section.</p>
<ul>
<li>Most of the library code lives in <code>speech_recognition/__init__.py</code>.</li>
<li>Examples live under the <code>examples/</code> directory, and the demo script lives in <code>speech_recognition/__main__.py</code>.</li>
<li>The FLAC encoder binaries are in the <code>speech_recognition/</code> directory.</li>
<li>Documentation can be found in the <code>reference/</code> directory.</li>
<li>Third-party libraries, utilities, and reference material are in the <code>third-party/</code> directory.</li>
</ul>
<p>To install/reinstall the library locally, run <code>python setup.py install</code> in the project root directory.</p>
<p>Releases are done by running either <code>build.sh</code> or <code>build.bat</code>. These are bash and batch scripts, respectively, that automatically build Python source packages and <a href="http://pythonwheels.com/">Python Wheels</a>, then upload them to PyPI.</p>
<p>Features and bugfixes should be tested, at minimum, on Python 2.7 and a recent version of Python 3. It is highly recommended to test new features on Python 2.6, 2.7, 3.3, and the latest version of Python 3.</p>
<a name="user-content-authors"/>
<h2><a id="user-content-authors" class="anchor" href="#authors" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Authors</h2>
<pre>Uberi &lt;azhang9@gmail.com&gt; (Anthony Zhang)
bobsayshilol
arvindch &lt;achembarpu@gmail.com&gt; (Arvind Chembarpu)
kevinismith &lt;kevin_i_smith@yahoo.com&gt; (Kevin Smith)
haas85
DelightRun &lt;changxu.mail@gmail.com&gt;
maverickagm
</pre>
<p>Please report bugs and suggestions at the <a href="https://github.com/Uberi/speech_recognition/issues">issue tracker</a>!</p>
<p>How to cite this library (APA style):</p>
<blockquote>
Zhang, A. (2016). Speech Recognition (Version 3.2) [Software]. Available from <a href="https://github.com/Uberi/speech_recognition#readme">https://github.com/Uberi/speech_recognition#readme</a>.</blockquote>
<p>How to cite this library (Chicago style):</p>
<blockquote>
Zhang, Anthony. 2016. <em>Speech Recognition</em> (version 3.2).</blockquote>
<p>Also check out the <a href="https://github.com/DelightRun/PyBaiduYuyin">Python Baidu Yuyin API</a>, which is based on an older version of this project, and adds support for <a href="http://yuyin.baidu.com/">Baidu Yuyin</a>.</p>
<a name="user-content-license"/>
<h2><a id="user-content-license" class="anchor" href="#license" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>License</h2>
<p>Copyright 2014-2016 <a href="https://uberi.github.io">Anthony Zhang (Uberi)</a>.</p>
<p>The source code is available online at <a href="https://github.com/Uberi/speech_recognition">GitHub</a>.</p>
<p>This program is made available under the 3-clause BSD license. See <code>LICENSE.txt</code> in the project's root directory for more information.</p>
<p>This program distributes source code, binaries, and language files from <a href="http://cmusphinx.sourceforge.net/">CMU Sphinx</a>. These files are BSD-licensed and redistributable as long as copyright notices are correctly retained. See <code>speech_recognition/pocketsphinx-data/*/LICENSE*.txt</code> and <code>third-party/LICENSE-Sphinx.txt</code> for details concerning individual files.</p>
<p>This program distributes source code and binaries from <a href="http://people.csail.mit.edu/hubert/pyaudio/">PyAudio</a>. These files are MIT-licensed and redistributable as long as copyright notices are correctly retained. See license files inside <code>third-party/LICENSE-PyAudio.txt</code> for details concerning individual files.</p>

</article>
  </div></body></html>