<html><body><div><div class="content html_format">
      <img src="https://habrastorage.org/files/592/306/b12/592306b1279b41b19995c3bf8b501674.png" align="left"/><p>Одна из отличительных особенностей языка Python — это посвящённые этому языку конференции, так называемые PyConы. Не так давно мне удалось побывать на одном таком PyCon-е — EuroPython 2014. EuroPython — это одна из наиболее крупных европейских ежегодных конференций по языку Python, которая три последних года проводилась во Флоренции, а в 2014м — первый раз в Берлине. Пока свежи воспоминания решил написать небольшой отчётик — что и как было.
</p><a name="habracut"/>
<h2>Вместо введения</h2><p>
Сразу оговорюсь, тут будут исключительно впечатления и короткие тезисы, и не будет подробного пересказа содержания докладов, так как при большом желании все их можно </p><a href="http://www.youtube.com/user/europython2014">посмотреть на YouTube</a><p> — организаторы данной конференции мало того, что не стали делать из видео выступлений какую-то коммерческую тайну, так ещё и организовали прямую трансляцию всех этих видео (кстати, видео с прошлогодних конференций тоже можно отыскать в открытом доступе на том же самом YouTube).
</p><p>
И ещё. Далеко не все доклады затрагивали Python напрямую. То есть зачастую в докладах шел обзор каких-либо полезных технологий, и немного сбоку рассказывалось, как эти технологии можно использовать в мире Python. Поэтому если в процессе прочтения некоторого абзаца данного опуса у вас возникнет мысль «так а где же тут питон? o_O» — советую сразу посмотреть видео — там все будет.
</p><p>
Начну с того, что практический каждый день конференции строился по расписанию: сутра — </p><strong>Keynotes</strong><p>, потом доклады — по 20-45 минут каждый (с перерывом на обед и кофебрейки), под вечер — </p><strong>Lightning Talks</strong><p>. Думаю, тут стоит поподробнее сказать что же такое </p><strong>Keynotes</strong><p> и </p><strong>Lightning Talks</strong><p>.

</p><strong>Keynotes</strong><p> — это такие доклады, не сильно технические, с большим обилием философии. На мой взгляд, практического применения в них мало, поэтому в своем повествовании я их упущу.
</p><p>
По поводу </p><strong>Lightning Talks</strong><p> — это такие продолжительные сессии часа так на 1.5, в течении которых любой желающий мог выйти и высказаться. На каждое выступление давалось порядка 10ти минут. Среди этих вот мини-докладиков было достаточно много флейма (реклама своих продуктов, реклама всяких event-ов, типо PyCon-а в Бразилии, какие-то общие философские мысли и т.п.). Поэтому в своем рассказе я постараюсь отразить только те выступления, которые мне показались наиболее полезными и интересными.

</p><h2>День первый (Python vs Haskell)</h2><p>
Поскольку в первый день было открытие конференции, то докладов и чего-то более-менее полезного было мало. Собственно, самый главный доклад дня: </p><a href="https://www.youtube.com/watch?v=eVChXmNjV7o">чему Python может поучиться у Haskell-а</a><p>. На самом деле, в докладе речь шла не только про один Haskell, но и немного про Erlang, но это не суть важно. Основная мысль доклада сводилась к тому, что статические анализаторы кода ни разу не отлавливают ошибки вида 1 + "1", и что всему виной динамическая строгая неявная типизация в Python, что влечет за собой проблемы рефакторинга и т.п. Варианты решения — использовать </p><a href="http://legacy.python.org/dev/peps/pep-3107/">аннотации</a><p> (привет, Python 3), использовать экспериментальный вариант интерпретатора Python: </p><a href="http://www.mypy-lang.org/">mypy</a><p>, который на уровне синтаксиса языка позволяет задавать типы у аргументов функций. То есть можно писать вот так:
</p><pre><code class="python">def fib(n: int) -&gt; None:
    a, b = 0, 1
    while a &lt; n:
        print(a)
        a, b = b, a+b
</code></pre><p>
и это будет корректно восприниматься интерпретатором. Конечно, штука довольно интересная, вот только опять-таки это работает только для кода Python 3. Я попробовал поискать </p><a href="http://www.mypy-lang.org/">mypy</a><p> в стандартных репах Debian и не нашел, а компилять вручную как-то лениво. Возможно от него был бы толк, будь он чуть более распространен, была бы поддержка на уровне IDE и т.п. (кстати докладчик активно призывал контрибьютить в этот проект). Так же прозвучали утверждения, что mutability есть зло, а так же про слабую поддержку Python-ом алгебраических типов данных. Все это на мой взгляд очень и очень спорно. Тем не менее я рекомендую посмотреть видео доклада хотя бы, чтобы иметь представление о том, что творится в других языках (ну и конечно же чтобы быть готовым к аргументированному спору в холиварах аля “какой язык лучше”).
</p><div class="spoiler"><b class="spoiler_title">Видео доклада 'What can python learn from Haskell?'</b><p class="spoiler_text"><iframe src="https://www.youtube.com/embed/eVChXmNjV7o?feature=oembed" frameborder="0" allowfullscreen="">VIDEO</iframe></p></div><p>
Так же мне запомнился один доклад из Lightning Talks, парень (кстати из России), пиарил свою </p><a href="https://github.com/maxtepkeev/architect">библиотечку под названием Architect</a><p>, главное преимущество которой — добавление возможности автоматического партицирования таблиц в БД посредством ORM (поддерживаются модели Django, SQLAlchemy, Pony). Из баз данных — MySQL и postgreSQL. Людям, кто работает с этими базами, возможно данная либа иногда может быть полезной.

</p><h2>День второй (nix, Kafka, Storm, Marconi, Logstash)</h2><p>
Прозвучал довольно интересный доклад про </p><a href="https://www.youtube.com/watch?v=Eis-WqHda20">пакетный менеджер nix</a><p>. На сам деле есть целый дистрибутив, построенный на этом пакетном менеджере. И называется он </p><a href="http://nixos.org/">NixOS</a><p>. Его полезность, если честно, мне кажется несколько сомнительной, а вот сам пакетный менеджер nix в некоторых кейсах может быть весьма полезен (особенно учитывая тот факт, что он не запрещает использование основного пакетного менеджера, т.е. yum или apt). Основная фишка данного пакетного менеджера заключается в том, что все операции, производимые им, не являются деструктивными. То есть грубо говоря при установке каждого нового пакета, предыдущая версия пакета не затирается, а создается новое пользовательское окружение, с новым набором симлинок. Это позволяет: 
</p><ul>
<li>1. в любой момент времени откатиться до некоего предыдущего состояния пользовательского окружения</li>
<li>2. одновременно использовать несколько версий пакетов (т.е. например несколько версий ffmpeg-а, или несколько версий python-а). И это все без всяких обвесок в виде виртуализаций, докеров и т.п.</li>
<li>3. при апдейтах нет вероятности поломать систему, т.к. старый пакет при обновлении не сносится, а новый пакет ставится в некоторое обособленное окружение, а в конце установки происходит переключение симлинок</li>
</ul><p>Из минусов — если хранить все версии пакетов со всеми зависимостями, то естественно места на HDD потребуется больше и в довесок мы получаем некоторую избыточность пакетов. На мой взгляд, это недостатки с которыми можно мириться. Так же в докладе кратко рассказывалось, как можно собирать свои пакеты для nix, и в частности, python-ячьи пакеты. В общем, если есть проблема </p><a href="http://archive09.linux.com/feature/155922">Dependency hell</a><p>, то nix позволяет решить эту проблему довольно элегантно.
</p><div class="spoiler"><b class="spoiler_title">Видео доклада 'Rethinking packaging, development and deployment'</b><p class="spoiler_text"><iframe src="https://www.youtube.com/embed/Eis-WqHda20?feature=oembed" frameborder="0" allowfullscreen="">VIDEO</iframe></p></div><p>
В этот же день был </p><a href="https://www.youtube.com/watch?v=uwiHZru2Wjc">доклад про потоковую обработку больших объемов данных с использованием Kafka и Storm</a><p>. Единственное полезное, что я вынес из этого доклада, это то, что </p><a href="https://storm.incubator.apache.org/">Storm</a><p> отлично подходит для обработки непрерывных потоковых данных (а не статических, в отличии от Hadoop), а </p><a href="http://kafka.apache.org/">Kafka</a><p> даст гигантскую фору rabbitMQ в плане дичайшей пропускной способности сообщений (100k+/sec сообщений на ноду против 20k/sec у rabbitMQ), но при этом проигрывает в плане топологии распределения сообщений между consumer-ами. В контексте доклада две данные технологи рассматривались вместе, и </p><a href="http://kafka.apache.org/">Kafka</a><p> выступала в качестве транспорта для доставки сообщений в </p><a href="https://storm.incubator.apache.org/">Storm</a><p>.
</p><div class="spoiler"><b class="spoiler_title">Видео доклада 'Designing NRT(NearRealTime) stream processing systems'</b><p class="spoiler_text"><iframe src="https://www.youtube.com/embed/uwiHZru2Wjc?feature=oembed" frameborder="0" allowfullscreen="">VIDEO</iframe></p></div><p>
Был </p><a href="https://www.youtube.com/watch?v=d65TtqGp-9Q">неплохой вводный доклад про Marconi</a><p> — это система messaging-а в рамках OpenStack (кто не в курсе, OpenStack полностью написан на python). Marconi используется в качестве связующего звена между компонентами облака OpenStack, а так же к качестве обособленного сервиса уведомлений. Собственно является прямым аналогом SNS и SQS от Amazon-а. Предоставляет RESTfull API, может использовать MongoDB, Redis а так же SQLAlchemy в качестве хранилища сообщений (правда SQLAlchemy не рекомендовали в production из соображений производительности), поддержки AMPQ протокола нет, но планируют добавить в будущем.
</p><div class="spoiler"><b class="spoiler_title">Видео доклада 'Marconi - OpenStack Queuing and Notification Service'</b><p class="spoiler_text"><iframe src="https://www.youtube.com/embed/d65TtqGp-9Q?feature=oembed" frameborder="0" allowfullscreen="">VIDEO</iframe></p></div><p>
Ещё был </p><a href="https://www.youtube.com/watch?v=J3ai0cDOAkY">доклад про Logstash / Elasticsearch / Kibana</a><p> — набор мегаполезных утилит для сбора, фильтрации, хранения, агрегации и отображения логов. Кстати говоря, полезность logstash несколько раз упоминалась в различных докладах от разных людей. Лично я ничего особенно нового именно из этого доклада не услышал. Одна из идей, которая рассказывалась на данном докладе — как при помощи logstash отслеживать все логи из одного request-а, а так же собирать воедино все связные по единому признаку логи от всех компонент распределённой системы. Кстати, в ходе доклада была упомянута интересная библиотечка для логирования под названием </p><a href="http://www.pocoo.org/projects/logbook/">Logbook</a><p>. Судя по описанию, достойная альтернатива стандартной библиотеке логирования в Python.
</p><div class="spoiler"><b class="spoiler_title">Видео доклада 'Log everything with logstash and elasticsearch'</b><p class="spoiler_text"><iframe src="https://www.youtube.com/embed/J3ai0cDOAkY?feature=oembed" frameborder="0" allowfullscreen="">VIDEO</iframe></p></div>
<h2>День третий (Sphinx, gevent, DevOps risk mitigation)</h2><p>
Третий день начался с </p><a href="https://www.youtube.com/watch?v=Nz8zutA55fI">написания мультиязыковой Sphinx-документации</a><p>. Данный доклад был весьма полезен для меня лично, потому что в рамках проекта, которым я сейчас занимаюсь, возникала задача поддержки двух языковых версий API документации — английской и русской, при этом хотелось бы сделать этот процесс как можно более простым и прозрачным. На самом деле все довольно просто. Есть такая замечательная GNU утилита </p><a href="https://ru.wikipedia.org/wiki/Gettext">gettext</a><p>, которая активно используется для интернационализации различных OpenSource проектов (думаю, что про gettext все и так знают без пояснений), и есть замечательный пакет </p><a href="https://pypi.python.org/pypi/sphinx-intl">sphinx-intl</a><p>. Из sphinx-овой rst-овой документации при помощи нехитрых команд готовятся *.po файлы, которые потом переводятся в специальном gettext-редакторе, и на основе которых делается документация sphinx под какой-то конкретный выбранный язык. Так же в докладе был упомянут SAAS сервис </p><a href="https://www.transifex.com/">Transifex</a><p>, который облегчает труд переводчиков. Насколько я понял, общий принцип работы сервиса такой — при помощи нехитрых консольных утилиток, можно загружать и скачивать файлы переводов на этот сервис, который предоставляет для переводчиков удобный Web-интерфейс для перевода текстов. Консольные утилитки для этого сервиса, насколько я понял, работают по принципу git push/pull. Сервис не бесплатный. Думаю всем заинтересовавшимся (кто сталкивался с проблемой интернационализации) смотреть </p><a href="https://www.youtube.com/watch?v=Nz8zutA55fI">видео доклада</a><p> необязательно, достаточно полистать </p><a href="https://speakerdeck.com/keimlink/writing-multi-language-documentation-using-sphinx-1">слайды</a><p>, чтобы все понять.
</p><div class="spoiler"><b class="spoiler_title">Видео доклада 'Writing multi-language documentation using Sphinx'</b><p class="spoiler_text"><iframe src="https://www.youtube.com/embed/Nz8zutA55fI?feature=oembed" frameborder="0" allowfullscreen="">VIDEO</iframe></p></div><p>
Из интересных докладов, которые были в этот день: </p><a href="https://www.youtube.com/watch?v=0wpYQr-_kqg">доклад про gevent</a><p> (я посчитал важным сходить на этот доклад, потому что на gevent-е чуть более чем полностью построен WebDAV-сервис проекта, которым я занимаюсь). На самом деле ничего принципиально нового не рассказали, начали с вводной по реализации асинхронности на Python и закончили собственно </p><a href="http://www.gevent.org/">gevent</a><p>-ом. Если кто не знает, что такое </p><a href="http://www.gevent.org/">gevent</a><p> — тому данный доклад возможно покажется интересным, ну а тем, кто уже знаком с данной технологией — врят ли. Из услышанных интересностей: 1. </p><a href="http://nucleon.readthedocs.org/en/latest/index.html">web-микрофреймворк</a><p>, целиком сделанный на gevent-е, с поддержкой PostgreSQL, 2. </p><a href="http://pythonhosted.org/nucleon.amqp/">AMQP-библиотечка</a><p>, также целиком сделанная на gevent-е.
</p><div class="spoiler"><b class="spoiler_title">Видео доклада 'Gevent: asynchronous I/O made easy'</b><p class="spoiler_text"><iframe src="https://www.youtube.com/embed/0wpYQr-_kqg?feature=oembed" frameborder="0" allowfullscreen="">VIDEO</iframe></p></div><p>
Ещё был весьма занятный доклад </p><a href="https://www.youtube.com/watch?v=L6TtXrLmdKA">«DevOps Risk Mitigation: Test Driven Infrastructure»</a><p>, про тестировании инфраструктуры в рамках процесса deploy-я. На самом деле никакой магии нет — собирается RPM-ка, раскатывается куда-то на тестовые машины, и далее автоматизированно через rsh заходим на эти машины и тестируем все что только можно, начиная от HTTP proxy и заканчивая системой сбора логов. Докладчик, весьма колоритный old school-ный админ, как я понял, не признает всяких этих puppet-ов / chef-ов / salt-ов, но зато осознает идею того, что для поддержания качества продукта, тестами должен покрываться не только лишь один код. На мой взгляд, идея верная, и это и правда то, к чему надо стремиться. Возможно не такими способами, как говорится в докладе, но тем не менее. Всем DevOps-ам — must see.
</p><div class="spoiler"><b class="spoiler_title">Видео доклада 'DevOps Risk Mitigation: Test Driven Infrastructure'</b><p class="spoiler_text"><iframe src="https://www.youtube.com/embed/L6TtXrLmdKA?feature=oembed" frameborder="0" allowfullscreen="">VIDEO</iframe></p></div>
<h2>День четвёртый (защита исходников, SOA от Disqus, архитектура абстрактного debugger-а, dh-virtualenv)</h2><p>
День начался с замечательнейшего по полезности доклада </p><a href="https://www.youtube.com/watch?v=CoxAowBDDyE">«Multiplatform binary packaging and distribution of your client apps»</a><p>. Думаю многие программисты, кто пишет коммерческие приложения, хотя бы раз в жизни задумывались над проблемой: «они могут скопировать и прочитать наш код!». То есть иными словами возникает задача — поставлять продукт в зашифрованном виде, ну или же в виде бинарников, из которых выцепить и модифицировать исходный код достаточно проблематично. К слову, Dropbox, у которого PC клиент написан на Python, решает данную проблему довольно геморройно — они кладут в инсталлятор свою собственную патченную версию интерпретатора Python, которая умеет читать зашифрованные *.pyc файлы. Решение, предлагаемое в докладе: 
</p><ul>
<li>1. <a href="http://docs.cython.org/src/reference/compilation.html">cythonize-им исходники</a> — переводим их в *.c</li>
<li>2. компиляем полученное в native extensions</li>
<li>3. собираем exe-шник при помощи PyInstaller-ра</li>
<li>4. Упаковываем в setup.exe/dmg/rpm/deb файл</li>
</ul><p>
Для больших деталей рекомендую посмотреть </p><a href="https://www.youtube.com/watch?v=CoxAowBDDyE">видео</a><p> доклада и </p><a href="http://www.slideshare.net/hithwen/multiplatform-binary-packaging-of-your-python-client-apps">слайды</a><p>. Естественно каждый из 4х описанных мною этапов в докладе разобран более подробно — приводятся образцы кода, как и что делать. Ну и конечно же стоит оговориться, что данного рода обфускация не спасает о реверсинженеринга, когда человек может заимпортить обфусцированный пакет и просто банально пробежаться по именам методов/переменных. Кстати, ещё по данной к теме рекомендую к прочтению вот </p><a href="http://blog.biicode.com/bii-internals-compiling-your-python-application-with-cython/">эту статью</a><p> (она упоминается в докладе).
</p><div class="spoiler"><b class="spoiler_title">Видео доклада 'Multiplatform binary packaging and distribution of your client apps'</b><p class="spoiler_text"><iframe src="https://www.youtube.com/embed/CoxAowBDDyE?feature=oembed" frameborder="0" allowfullscreen="">VIDEO</iframe></p></div><p>
Следующим был весьма неплохой </p><a href="https://www.youtube.com/watch?v=CXhljKhRVpI">доклад от одного из разработчиков Disqus</a><p>. В докладе говорилось про преимущества </p><a href="https://ru.wikipedia.org/wiki/%D0%A1%D0%B5%D1%80%D0%B2%D0%B8%D1%81-%D0%BE%D1%80%D0%B8%D0%B5%D0%BD%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%BD%D0%B0%D1%8F_%D0%B0%D1%80%D1%85%D0%B8%D1%82%D0%B5%D0%BA%D1%82%D1%83%D1%80%D0%B0">SOA</a><p>-архитектуры на примере сервиса Disqus. Cервис Disqus чуть более чем полностью построен на Django, точнее он разделен на кучу-кучу мелких микросервисов (REST API, worker-ы, cron-ы и т.п.), каждый из которых построен на Django. К слову, докладчик доступно объяснил почему именно Django, а не что-то другое — большое комьюнити, куча готовых решений + намного проще найти специалистов. Если смотреть на технологический стек, то у Disqus из основных компонент используется uwsgi, django, celery, postgreSQL в качестве базы и redis для кэша. Чтобы шарить общий код между своими микросервисами, я так понял, они собирают отдельные python-овские пакетики. Из плюсов SOA подхода:
</p><ul>
<li>1. независимая масштабируемость</li>
<li>2. простота deploy-я</li>
<li>3. простота работы с кодом</li>
</ul><p>
из минусов:
</p><ul>
<li>1. если меняется какой-то один API (например external API service), то приходится не забывать догонять под измененный API другие сервисы</li>
<li>2. как упоминалось чуть выше — тяжелее шарить общий код между сервисами</li>
</ul>
<div class="spoiler"><b class="spoiler_title">Видео доклада 'How Disqus is using Django as the basis of our Service Oriented Architecture'</b><p class="spoiler_text"><iframe src="https://www.youtube.com/embed/CXhljKhRVpI?feature=oembed" frameborder="0" allowfullscreen="">VIDEO</iframe></p></div>
<a href="https://www.youtube.com/watch?v=HfzdM7rsKbU">Python Debugger Uncovered</a><p> — вот это очень классный доклад от разработчика PyCharm. Советую всем backend-разработчикам посмотреть для общей эрудиции, как устроен некий абстрактный дебаггер в вакууме. Никакой высокой магии нет, все дебаггеры сделаны по одному принципу и подобию при помощи нативных средств самого языка Python. Кстати, для справки, дебаггеры PyCharm и PyDev объединяются.
</p><div class="spoiler"><b class="spoiler_title">Видео доклада 'Python Debugger Uncovered'</b><p class="spoiler_text"><iframe src="https://www.youtube.com/embed/HfzdM7rsKbU?feature=oembed" frameborder="0" allowfullscreen="">VIDEO</iframe></p></div><p>
Ещё в этот день был очень стоящий </p><a href="https://www.youtube.com/watch?v=d_jqe1O31X8">доклад про tool-у dh-virtualenv</a><p> от Spotify. Spotify в качестве основой production ОС используют Debian, и цель создания данной утилиты заключалась в том, чтобы объединить deploy проекта в виде deb-ок с инкапсулированным virtualenv-ом. Общий смысла какой — с одной стороны Debian адски стабилен, а Debian-пакеты удобны тем, что позволяют прописать все не-python-ячи зависимости (типо libxml), с другой стороны virtualenv удобен тем, что позволяет изолировать внутри себя python-ньи зависимости, и все эти зависимости будут самыми свежими пакетами, т.к. взяты с PyPI. Тулза </p><a href="https://github.com/spotify/dh-virtualenv">dh-virtualenv</a><p> позволяет объединить одно с другим, и грубо говоря, автоматизированно собирать deb-ки из текущего развернутого virtualenv-а. Ставится она кстати через обычный apt-get. Внутри проекта, помимо setup.py и requirements.txt создается директория debian, в которой описываются характеристики и зависимости deb-пакета (rules, control и т.п.), а для создания пакета нагоняется консольная команда dpkg-buildpackage -us -uc. virtualenv на конечной qa/prod машине ставить не надо, т.к. он автоматически скачивается и упаковывается утилитой при создании пакета.
</p><div class="spoiler"><b class="spoiler_title">Видео доклада 'Packaging in packaging: dh-virtualenv'</b><p class="spoiler_text"><iframe src="https://www.youtube.com/embed/d_jqe1O31X8?feature=oembed" frameborder="0" allowfullscreen="">VIDEO</iframe></p></div><p>
Lightning Talks этого дня лично мне запомнился одним очень интересным докладом про то, почему не стоит злоупотреблять getattr().</p><p>
Пример кода:
</p><pre><code class="python">import random

class A(object):
    def get_prop(self):
        return getattr(self, 'prop', None)

class B(A):
    @property
    def prop(self):
        return random.chioce(['test prop1', 'test prop2', 'test prop3'])

print(B().get_prop())
</code></pre><p>Данный код будет выводить всегда None, т.к. исключение (из-за неправильного имени метода, т.е. random.chioce) будет игнорироваться внутри getattr.

</p><h2>День пятый (особенности работы с памятью, DB API, делаем Go из Python)</h2><p>
Доклад </p><a href="https://www.youtube.com/watch?v=hf4MKeP5oxg">“Everything You Always Wanted to Know About Memory in Python But Were Afraid to Ask”</a><p> лично мне, как человеку, сильно далекому от C/C++, и привыкшему мыслить более приземленными материями, было очень интересно послушать. Какие-то вещи я уже знал, какие-то вещи лишний раз освежил в памяти. Не буду останавливаться на деталях, скажу так — особенно интересно было послушать про существующие тулы, которые имеют реальное практическое применение (</p><a href="http://mg.pov.lt/objgraph/">objgraph</a><p>, профилировщик памяти </p><a href="https://pypi.python.org/pypi/guppy/">guppy</a><p> и т.п.), и про то, что в Python можно заюзать раличные либы, реализующие низкоуровневый malloc(), и какой профит будет от этих замен. В общем, лично я рекомендую всем посмотреть </p><a href="https://www.youtube.com/watch?v=hf4MKeP5oxg">этот доклад</a><p>. Так же в этот же день проходил ещё один крутой доклад на схожую тему — </p><a href="https://www.youtube.com/watch?v=l9Le_JOwgsM">«Fun with cPython memory allocator»</a><p>. К сожалению, я на него не ходил, но судя по отзывам моих коллег — доклад весьма стоящий. Многие наверное сталкивались с проблемой, когда создаешь в Python список из большого количества строк строк, потом удаляешь его, а память не уменьшается. Вот про эту проблему рассказывается в докладе — как это, из-за чего и как с этим бороться.
</p><div class="spoiler"><b class="spoiler_title">Видео доклада 'Everything You Always Wanted to Know About Memory in Python But Were Afraid to Ask</b><p class="spoiler_text"><iframe src="https://www.youtube.com/embed/hf4MKeP5oxg?feature=oembed" frameborder="0" allowfullscreen="">VIDEO</iframe></p></div>
<div class="spoiler"><b class="spoiler_title">Видео доклада 'Fun with cPython memory allocator</b><p class="spoiler_text"><iframe src="https://www.youtube.com/embed/l9Le_JOwgsM?feature=oembed" frameborder="0" allowfullscreen="">VIDEO</iframe></p></div><p>
Далее был весьма неоднозначный доклад </p><a href="https://www.youtube.com/watch?v=LyJ3evnz2Xw">«Advanced Database Programming with Python»</a><p>. Тем, кто в своей практике мало работал с базами данных — рекомендую послушать. Узнаете такие вещи, как уровни изоляции транзакций, например, и чем они отличаются друг от друга, а так же про python-ячью специфику работы с базами данных (согласно </p><a href="http://legacy.python.org/dev/peps/pep-0249/">PEP 249</a><p> autocommit=0 де факто и commit-ы надо не забывать писать вручную) и про какие-то базовые вещи по оптимизации запросов. Доклад неоднозначный, потому что автор делает акцент на множестве весьма редких оптимизаций типо, как например генерить ID вставляемой записи в Python-е, а не полагаться на auto_increment/sequences БД. Это-то конечно хорошо, вот только опыт показывает, что наслушавшись таких докладов, некоторые программисты начинают преждевременно оптимизировать все и вся, и это в 99% случаев приводит к весьма плачевным последствиям.
</p><div class="spoiler"><b class="spoiler_title">Видео доклада 'Advanced Database Programming with Python</b><p class="spoiler_text"><iframe src="https://www.youtube.com/embed/LyJ3evnz2Xw?feature=oembed" frameborder="0" allowfullscreen="">VIDEO</iframe></p></div><p>
И последним было </p><a href="https://www.youtube.com/watch?v=snIHnStehIo">выступление от Бенуа Шесно, создателя web сервера gunicorn</a><p>. Рассматривалось 100500 существующих вариантов реализации мультизадачности в python, и новый 100501-ый вариант — библиотечка </p><a href="https://github.com/benoitc/offset">offset</a><p>, привносящая в python функционал кроутин языка Go. Во время выступления я немного покопался во внутренностях данной библиотеки — судя по всему в основе данной либы лежит боле низкоуровневая реализация кроутин основанная на библиотеке </p><a href="https://pypi.python.org/pypi/fibers/0.1.0">fibers</a><p>. Сама же </p><a href="https://github.com/benoitc/offset">offset</a><p> привносит в язык более высокоуровневые обертки. Т.е. грубо говоря, позволяет писать программы на python сродни тому, как они бы выглядели бы в Go. В своем докладе автор как раз приводит примеры схожести кода реализации некой абстрактной задачи, написанного на Go и написанного на Python, но с использованием </p><a href="https://github.com/benoitc/offset">offset</a><p>. В общем, всем тем, кому недостаточно существующего функционала тредов, tornado/twisted, asyncio, gevent и модуля multiprocessing — данная библиотека может показаться весьма интересной. Слушать же сам доклад особого смысла не имеет — лучше сразу лезть в код на github и пробовать.
</p><div class="spoiler"><b class="spoiler_title">Видео доклада 'Concurrent programming with Python and my little experiment'</b><p class="spoiler_text"><iframe src="https://www.youtube.com/embed/snIHnStehIo?feature=oembed" frameborder="0" allowfullscreen="">VIDEO</iframe></p></div><p>
Заключительные Lightning Talks в этот день мне запомнились докладом про </p><a href="https://ru.wikipedia.org/wiki/HSTS">HSTS</a><p>. Очень полезная штука надо сказать, о которой мало кто знает. Фактически это HTTP response заголовок, который указывает браузеру всегда принудительно использовать HTTPS-соединение для данного хостнейма. Т.е. в дальнейшем если пользователь вбивает в браузере </p><a href="http://some-url.com">some-url.com</a><p>, то браузер сам автоматически подставит https. Полезно и из соображений безопасности и и из соображений сокращения числа редиректов с HTTP на HTTPS, возвращаемых с сервера.

</p><h2>Беседы в кулуарах</h2><p>
На конференции было огроменное количество стендов от компаний, так или иначе связанных с Python (Google, Amazon, DjangoCMS, JetBrains, Atlassian и пр). К ним ко всем можно было подходить и общаться на разного рода интересующие вопросы. Мы довольно много общались с ребятами из Google (правда это было не на самой конференции, а на after party от Google). Из интересного — Python у них используется преимущественно во внутренних продуктах, ну разве что кроме Youtube-а. Так же они нам по секрету сказали, что разработчики Google не очень-то любят BigTable, и уже сейчас в лабораториях Google готовится к выпуску новая революционная БД (кодовое название </p><a href="http://www.cubrid.org/blog/dev-platform/spanner-globally-distributed-database-by-google/">Spanner</a><p>), позволяющая делать распределенные транзакции на кластере, и при этом обладающая всеми плюсами NoSQL. По слухам, вроде как даже Open Source (в чем, конечно, есть большие-большие сомнения).
</p><p>
Так же общались с представителями </p><a href="https://www.django-cms.org">DjangoCMS</a><p> (тут ничего интересного, банальная незатейливая CMS на Django, можно установить на свой сервер, а можно использовать SaaS решение) и c представителями Amazon. Касательно последних, задал им вопрос, затронутый на конференции highload 2012го года, по поводу того, что пропускная способность инстансов довольно разная и непропорциональна типу инстанса (см. </p><a href="http://www.slideshare.net/profyclub_ru/partly-cloudy-aws-14831865">презентацию</a><p> — 25ый слайд), но получил в ответ «ну это специфика виртуализации такая, мы не можем сказать почему, обратитесь в поддержку». Кстати, думаю многим будет интересно, ребята из Amazon раздавали анкеты с вопросами на Python-тематику. Уже сейчас не вспомню, то ли они призы разыгрывали, то ли хантили таким образом. В общем, вопросики весьма специфичные, из разряда «эти самые вопросы, которые никогда не встречаются на практике, но их любят задавать на собеседованиях в больших конторах»:

</p><strong>1.</strong><p> Which is called first when creating an object:
</p><strong>a.</strong><p> __create__
</p><strong>b.</strong><p> __new__
</p><strong>c.</strong><p> __init__
</p><strong>d.</strong><p> __del__

</p><strong>2.</strong><p> What is printed by the last statement in:
</p><pre><code class="python">def foo(x, l=[]):
    l+=2*x
    print l

foo('a')
foo('bc')
</code></pre><strong>a.</strong><p> ['a','b','c']
</p><strong>b.</strong><p> ['a','bc']
</p><strong>c.</strong><p> ['a','a','b','c','b','c']
</p><strong>d.</strong><p> ['a','a','bc','bc']

</p><strong>3.</strong><p> What does the last statement print?
</p><pre><code class="python">class A(str):
    pass

a=A('a')
d={'a':42}
d[a]=42

print type(d.keys()[0])
</code></pre><strong>a.</strong><p> str
</p><strong>b.</strong><p> A
</p><strong>c.</strong><p> dict
</p><strong>d.</strong><p> int

</p><strong>4.</strong><p> Which of the following will these 2 statements return on Python vesrion 2?
</p><pre><code class="python">5 * 10 is 50
100 * 100 is 10000
</code></pre><strong>a.</strong><p> True, True
</p><strong>b.</strong><p> True, False
</p><strong>c.</strong><p> False, True
</p><strong>d.</strong><p> False, False
</p><p>
В целом, впечатления от конференции весьма положительные. Основная ставка организаторов делалась на общения в кулуарах. На самом деле, это первая конференция на моей памяти, где доклады прямо сразу же выкладываются на YouTube. И хотя уровень большинства докладов я бы оценил как средний, тем не менее прозвучало довольно много интересных вещей, которые так или иначе можно применить в реальных проектах.

      
      </p><p class="clear"/>
    </div>

    
  </div></body></html>