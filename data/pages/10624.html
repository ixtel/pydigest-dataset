<html><body><div><div class="span8">
    
<p><em>This work is supported by <a href="http://continuum.io">Continuum Analytics</a>
and the <a href="http://www.darpa.mil/program/XDATA">XDATA Program</a>
as part of the <a href="http://blaze.pydata.org">Blaze Project</a></em></p>

<p><strong>tl;dr</strong>: We analyze JSON data on a cluster using pure Python projects.</p>

<p>Dask, a Python library for parallel computing, now works on clusters.  During
the past few months I and others have extended dask with a new distributed
memory scheduler.  This enables dask’s existing parallel algorithms to scale
across 10s to 100s of nodes, and extends a subset of PyData to distributed
computing.  Over the next few weeks I and others will write about this system.
Please note that dask+distributed is developing quickly and so the API is
likely to shift around a bit.</p>

<p>Today we start simple with the typical cluster computing problem, parsing JSON
records, filtering, and counting events using dask.bag and the new distributed
scheduler.  We’ll dive into more advanced problems in future posts.</p>

<p><em>A video version of this blogpost is available
<a href="https://www.youtube.com/watch?v=W0Q0uwmYD6o">here</a>.</em></p>

<h2 id="github-archive-data-on-s3">GitHub Archive Data on S3</h2>

<p>GitHub releases data dumps of their public event stream as gzipped compressed,
line-delimited, JSON.  This data is too large to fit comfortably into memory,
even on a sizable workstation.  We could stream it from disk but, due to the
compression and JSON encoding this takes a while and so slogs down interactive
use.  For an interactive experience with data like this we need a distributed
cluster.</p>

<h3 id="setup-and-data">Setup and Data</h3>

<p>We provision nine <code class="highlighter-rouge">m3.2xlarge</code> nodes on EC2.  These have eight cores and 30GB
of RAM each.  On this cluster we provision one scheduler and nine workers (see
<a href="http://distributed.readthedocs.org/en/latest/setup.html">setup docs</a>).  (More
on launching in later posts.)  We have five months of data, from 2015-01-01 to
2015-05-31 on the <code class="highlighter-rouge">githubarchive-data</code> bucket in S3.  This data is publicly
avaialble if you want to play with it on EC2.  You can download the full
dataset at https://www.githubarchive.org/ .</p>

<p>The first record looks like the following:</p>

<div class="highlighter-rouge"><pre class="highlight"><code> <span class="p">{</span><span class="s">'actor'</span><span class="p">:</span> <span class="p">{</span><span class="s">'avatar_url'</span><span class="p">:</span> <span class="s">'https://avatars.githubusercontent.com/u/9152315?'</span><span class="p">,</span>
   <span class="s">'gravatar_id'</span><span class="p">:</span> <span class="s">''</span><span class="p">,</span>
   <span class="s">'id'</span><span class="p">:</span> <span class="mi">9152315</span><span class="p">,</span>
   <span class="s">'login'</span><span class="p">:</span> <span class="s">'davidjhulse'</span><span class="p">,</span>
   <span class="s">'url'</span><span class="p">:</span> <span class="s">'https://api.github.com/users/davidjhulse'</span><span class="p">},</span>
  <span class="s">'created_at'</span><span class="p">:</span> <span class="s">'2015-01-01T00:00:00Z'</span><span class="p">,</span>
  <span class="s">'id'</span><span class="p">:</span> <span class="s">'2489368070'</span><span class="p">,</span>
  <span class="s">'payload'</span><span class="p">:</span> <span class="p">{</span><span class="s">'before'</span><span class="p">:</span> <span class="s">'86ffa724b4d70fce46e760f8cc080f5ec3d7d85f'</span><span class="p">,</span>
   <span class="s">'commits'</span><span class="p">:</span> <span class="p">[{</span><span class="s">'author'</span><span class="p">:</span> <span class="p">{</span><span class="s">'email'</span><span class="p">:</span> <span class="s">'david.hulse@live.com'</span><span class="p">,</span>
      <span class="s">'name'</span><span class="p">:</span> <span class="s">'davidjhulse'</span><span class="p">},</span>
     <span class="s">'distinct'</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span>
     <span class="s">'message'</span><span class="p">:</span> <span class="s">'Altered BingBot.jar</span><span class="se">\n\n</span><span class="s">Fixed issue with multiple account support'</span><span class="p">,</span>
     <span class="s">'sha'</span><span class="p">:</span> <span class="s">'a9b22a6d80c1e0bb49c1cf75a3c075b642c28f81'</span><span class="p">,</span>
     <span class="s">'url'</span><span class="p">:</span> <span class="s">'https://api.github.com/repos/davidjhulse/davesbingrewardsbot/commits/a9b22a6d80c1e0bb49c1cf75a3c075b642c28f81'</span><span class="p">}],</span>
   <span class="s">'distinct_size'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
   <span class="s">'head'</span><span class="p">:</span> <span class="s">'a9b22a6d80c1e0bb49c1cf75a3c075b642c28f81'</span><span class="p">,</span>
   <span class="s">'push_id'</span><span class="p">:</span> <span class="mi">536740396</span><span class="p">,</span>
   <span class="s">'ref'</span><span class="p">:</span> <span class="s">'refs/heads/master'</span><span class="p">,</span>
   <span class="s">'size'</span><span class="p">:</span> <span class="mi">1</span><span class="p">},</span>
  <span class="s">'public'</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span>
  <span class="s">'repo'</span><span class="p">:</span> <span class="p">{</span><span class="s">'id'</span><span class="p">:</span> <span class="mi">28635890</span><span class="p">,</span>
   <span class="s">'name'</span><span class="p">:</span> <span class="s">'davidjhulse/davesbingrewardsbot'</span><span class="p">,</span>
   <span class="s">'url'</span><span class="p">:</span> <span class="s">'https://api.github.com/repos/davidjhulse/davesbingrewardsbot'</span><span class="p">},</span>
  <span class="s">'type'</span><span class="p">:</span> <span class="s">'PushEvent'</span><span class="p">}</span>
</code></pre>
</div>

<p>So we have a large dataset on S3 and a moderate sized play cluster on EC2,
which has access to S3 data at about  100MB/s per node.  We’re ready to play.</p>

<h2 id="play">Play</h2>

<p>We start an <code class="highlighter-rouge">ipython</code> interpreter on our local laptop and connect to the
dask scheduler running on the cluster.  For the purposes of timing, the cluster
is on the East Coast while the local machine is in California on commercial
broadband internet.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">distributed</span> <span class="kn">import</span> <span class="n">Executor</span><span class="p">,</span> <span class="n">s3</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">e</span> <span class="o">=</span> <span class="n">Executor</span><span class="p">(</span><span class="s">'54.173.84.107:8786'</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">e</span>
<span class="o">&lt;</span><span class="n">Executor</span><span class="p">:</span> <span class="n">scheduler</span><span class="o">=</span><span class="mf">54.173</span><span class="o">.</span><span class="mf">84.107</span><span class="p">:</span><span class="mi">8786</span> <span class="n">workers</span><span class="o">=</span><span class="mi">72</span> <span class="n">threads</span><span class="o">=</span><span class="mi">72</span><span class="o">&gt;</span>
</code></pre>
</div>

<p>Our seventy-two worker processes come from nine workers with eight processes
each.  We chose processes rather than threads for this task because
computations will be bound by the GIL.  We will change this to threads in later
examples.</p>

<p>We start by loading a single month of data into distributed memory.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">json</span>
<span class="n">text</span> <span class="o">=</span> <span class="n">s3</span><span class="o">.</span><span class="n">read_text</span><span class="p">(</span><span class="s">'githubarchive-data'</span><span class="p">,</span> <span class="s">'2015-01'</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s">'gzip'</span><span class="p">)</span>
<span class="n">records</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="nb">map</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">)</span>
<span class="n">records</span> <span class="o">=</span> <span class="n">e</span><span class="o">.</span><span class="n">persist</span><span class="p">(</span><span class="n">records</span><span class="p">)</span>
</code></pre>
</div>

<p>The data lives in S3 in hourly files as gzipped encoded, line delimited JSON.
The <code class="highlighter-rouge">s3.read_text</code> and <code class="highlighter-rouge">text.map</code> functions produce
<a href="http://dask.pydata.org/en/latest/bag.html">dask.bag</a> objects which track our
operations in a lazily built task graph.  When we ask the executor to <code class="highlighter-rouge">persist</code>
this collection we ship those tasks off to the scheduler to run on all of the
workers in parallel.  The <code class="highlighter-rouge">persist</code> function gives us back another <code class="highlighter-rouge">dask.bag</code>
pointing to these remotely running results.  This persist function returns
immediately, and the computation happens on the cluster in the background
asynchronously.  We gain control of our interpreter immediately while the
cluster hums along.</p>

<p>The cluster takes around 40 seconds to download, decompress, and parse this
data.  If you watch the video embedded above you’ll see fancy progress-bars.</p>

<p>We ask for a single record.  This returns in around 200ms, which is fast enough
that it feels instantaneous to a human.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">records</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="p">({</span><span class="s">'actor'</span><span class="p">:</span> <span class="p">{</span><span class="s">'avatar_url'</span><span class="p">:</span> <span class="s">'https://avatars.githubusercontent.com/u/9152315?'</span><span class="p">,</span>
   <span class="s">'gravatar_id'</span><span class="p">:</span> <span class="s">''</span><span class="p">,</span>
   <span class="s">'id'</span><span class="p">:</span> <span class="mi">9152315</span><span class="p">,</span>
   <span class="s">'login'</span><span class="p">:</span> <span class="s">'davidjhulse'</span><span class="p">,</span>
   <span class="s">'url'</span><span class="p">:</span> <span class="s">'https://api.github.com/users/davidjhulse'</span><span class="p">},</span>
  <span class="s">'created_at'</span><span class="p">:</span> <span class="s">'2015-01-01T00:00:00Z'</span><span class="p">,</span>
  <span class="s">'id'</span><span class="p">:</span> <span class="s">'2489368070'</span><span class="p">,</span>
  <span class="s">'payload'</span><span class="p">:</span> <span class="p">{</span><span class="s">'before'</span><span class="p">:</span> <span class="s">'86ffa724b4d70fce46e760f8cc080f5ec3d7d85f'</span><span class="p">,</span>
   <span class="s">'commits'</span><span class="p">:</span> <span class="p">[{</span><span class="s">'author'</span><span class="p">:</span> <span class="p">{</span><span class="s">'email'</span><span class="p">:</span> <span class="s">'david.hulse@live.com'</span><span class="p">,</span>
      <span class="s">'name'</span><span class="p">:</span> <span class="s">'davidjhulse'</span><span class="p">},</span>
     <span class="s">'distinct'</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span>
     <span class="s">'message'</span><span class="p">:</span> <span class="s">'Altered BingBot.jar</span><span class="se">\n\n</span><span class="s">Fixed issue with multiple account support'</span><span class="p">,</span>
     <span class="s">'sha'</span><span class="p">:</span> <span class="s">'a9b22a6d80c1e0bb49c1cf75a3c075b642c28f81'</span><span class="p">,</span>
     <span class="s">'url'</span><span class="p">:</span> <span class="s">'https://api.github.com/repos/davidjhulse/davesbingrewardsbot/commits/a9b22a6d80c1e0bb49c1cf75a3c075b642c28f81'</span><span class="p">}],</span>
   <span class="s">'distinct_size'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
   <span class="s">'head'</span><span class="p">:</span> <span class="s">'a9b22a6d80c1e0bb49c1cf75a3c075b642c28f81'</span><span class="p">,</span>
   <span class="s">'push_id'</span><span class="p">:</span> <span class="mi">536740396</span><span class="p">,</span>
   <span class="s">'ref'</span><span class="p">:</span> <span class="s">'refs/heads/master'</span><span class="p">,</span>
   <span class="s">'size'</span><span class="p">:</span> <span class="mi">1</span><span class="p">},</span>
  <span class="s">'public'</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span>
  <span class="s">'repo'</span><span class="p">:</span> <span class="p">{</span><span class="s">'id'</span><span class="p">:</span> <span class="mi">28635890</span><span class="p">,</span>
   <span class="s">'name'</span><span class="p">:</span> <span class="s">'davidjhulse/davesbingrewardsbot'</span><span class="p">,</span>
   <span class="s">'url'</span><span class="p">:</span> <span class="s">'https://api.github.com/repos/davidjhulse/davesbingrewardsbot'</span><span class="p">},</span>
  <span class="s">'type'</span><span class="p">:</span> <span class="s">'PushEvent'</span><span class="p">},)</span>
</code></pre>
</div>

<p>This particular event is a <code class="highlighter-rouge">'PushEvent'</code>.  Let’s quickly see all the kinds of
events.  For fun, we’ll also time the interaction:</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="o">%</span><span class="n">time</span> <span class="n">records</span><span class="o">.</span><span class="n">pluck</span><span class="p">(</span><span class="s">'type'</span><span class="p">)</span><span class="o">.</span><span class="n">frequencies</span><span class="p">()</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="n">CPU</span> <span class="n">times</span><span class="p">:</span> <span class="n">user</span> <span class="mi">112</span> <span class="n">ms</span><span class="p">,</span> <span class="n">sys</span><span class="p">:</span> <span class="mi">0</span> <span class="n">ns</span><span class="p">,</span> <span class="n">total</span><span class="p">:</span> <span class="mi">112</span> <span class="n">ms</span>
<span class="n">Wall</span> <span class="n">time</span><span class="p">:</span> <span class="mf">2.41</span> <span class="n">s</span>

<span class="p">[(</span><span class="s">'ReleaseEvent'</span><span class="p">,</span> <span class="mi">44312</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'MemberEvent'</span><span class="p">,</span> <span class="mi">69757</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'IssuesEvent'</span><span class="p">,</span> <span class="mi">693363</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'PublicEvent'</span><span class="p">,</span> <span class="mi">14614</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'CreateEvent'</span><span class="p">,</span> <span class="mi">1651300</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'PullRequestReviewCommentEvent'</span><span class="p">,</span> <span class="mi">214288</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'PullRequestEvent'</span><span class="p">,</span> <span class="mi">680879</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'ForkEvent'</span><span class="p">,</span> <span class="mi">491256</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'DeleteEvent'</span><span class="p">,</span> <span class="mi">256987</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'PushEvent'</span><span class="p">,</span> <span class="mi">7028566</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'IssueCommentEvent'</span><span class="p">,</span> <span class="mi">1322509</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'GollumEvent'</span><span class="p">,</span> <span class="mi">150861</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'CommitCommentEvent'</span><span class="p">,</span> <span class="mi">96468</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'WatchEvent'</span><span class="p">,</span> <span class="mi">1321546</span><span class="p">)]</span>
</code></pre>
</div>

<p>And we compute the total count of all commits for this month.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="o">%</span><span class="n">time</span> <span class="n">records</span><span class="o">.</span><span class="n">count</span><span class="p">()</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="n">CPU</span> <span class="n">times</span><span class="p">:</span> <span class="n">user</span> <span class="mi">134</span> <span class="n">ms</span><span class="p">,</span> <span class="n">sys</span><span class="p">:</span> <span class="mi">133</span> <span class="err">µ</span><span class="n">s</span><span class="p">,</span> <span class="n">total</span><span class="p">:</span> <span class="mi">134</span> <span class="n">ms</span>
<span class="n">Wall</span> <span class="n">time</span><span class="p">:</span> <span class="mf">1.49</span> <span class="n">s</span>

<span class="mi">14036706</span>
</code></pre>
</div>

<p>We see that it takes a few seconds to walk through the data (and perform all
scheduling overhead.)  The scheduler adds about a millisecond overhead per
task, and there are about 1000 partitions/files here (the GitHub data is split
by hour and there are 730 hours in a month) so most of the cost here is
overhead.</p>

<h2 id="investigate-jupyter">Investigate Jupyter</h2>

<p>We investigate the activities of <a href="http://jupyter.org/">Project Jupyter</a>.  We
chose this project because it’s sizable and because we understand the players
involved and so can check our accuracy.  This will require us to filter our
data to a much smaller subset, then find popular repositories and members.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">jupyter</span> <span class="o">=</span> <span class="p">(</span><span class="n">records</span><span class="o">.</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">d</span><span class="p">:</span> <span class="n">d</span><span class="p">[</span><span class="s">'repo'</span><span class="p">][</span><span class="s">'name'</span><span class="p">]</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s">'jupyter/'</span><span class="p">))</span>
                      <span class="o">.</span><span class="n">repartition</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">jupyter</span> <span class="o">=</span> <span class="n">e</span><span class="o">.</span><span class="n">persist</span><span class="p">(</span><span class="n">jupyter</span><span class="p">)</span>
</code></pre>
</div>

<p>All records, regardless of event type, have a repository which has a name like
<code class="highlighter-rouge">'organization/repository'</code> in typical GitHub fashion.  We filter all records
that start with <code class="highlighter-rouge">'jupyter/'</code>.  Additionally, because this dataset is likely
much smaller, we push all of these records into just ten partitions.  This
dramatically reduces scheduling overhead.  The <code class="highlighter-rouge">persist</code> call hands this
computation off to the scheduler and then gives us back our collection that
points to that computing result.  Filtering this month for Jupyter events takes
about 7.5 seconds.  Afterwards computations on this subset feel snappy.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="o">%</span><span class="n">time</span> <span class="n">jupyter</span><span class="o">.</span><span class="n">count</span><span class="p">()</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="n">CPU</span> <span class="n">times</span><span class="p">:</span> <span class="n">user</span> <span class="mf">5.19</span> <span class="n">ms</span><span class="p">,</span> <span class="n">sys</span><span class="p">:</span> <span class="mi">97</span> <span class="err">µ</span><span class="n">s</span><span class="p">,</span> <span class="n">total</span><span class="p">:</span> <span class="mf">5.28</span> <span class="n">ms</span>
<span class="n">Wall</span> <span class="n">time</span><span class="p">:</span> <span class="mi">199</span> <span class="n">ms</span>

<span class="mi">747</span>

<span class="o">&gt;&gt;&gt;</span> <span class="o">%</span><span class="n">time</span> <span class="n">jupyter</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">CPU</span> <span class="n">times</span><span class="p">:</span> <span class="n">user</span> <span class="mf">7.01</span> <span class="n">ms</span><span class="p">,</span> <span class="n">sys</span><span class="p">:</span> <span class="mi">259</span> <span class="err">µ</span><span class="n">s</span><span class="p">,</span> <span class="n">total</span><span class="p">:</span> <span class="mf">7.27</span> <span class="n">ms</span>
<span class="n">Wall</span> <span class="n">time</span><span class="p">:</span> <span class="mi">182</span> <span class="n">ms</span>

<span class="p">({</span><span class="s">'actor'</span><span class="p">:</span> <span class="p">{</span><span class="s">'avatar_url'</span><span class="p">:</span> <span class="s">'https://avatars.githubusercontent.com/u/26679?'</span><span class="p">,</span>
   <span class="s">'gravatar_id'</span><span class="p">:</span> <span class="s">''</span><span class="p">,</span>
   <span class="s">'id'</span><span class="p">:</span> <span class="mi">26679</span><span class="p">,</span>
   <span class="s">'login'</span><span class="p">:</span> <span class="s">'marksteve'</span><span class="p">,</span>
   <span class="s">'url'</span><span class="p">:</span> <span class="s">'https://api.github.com/users/marksteve'</span><span class="p">},</span>
  <span class="s">'created_at'</span><span class="p">:</span> <span class="s">'2015-01-01T13:25:44Z'</span><span class="p">,</span>
  <span class="s">'id'</span><span class="p">:</span> <span class="s">'2489612400'</span><span class="p">,</span>
  <span class="s">'org'</span><span class="p">:</span> <span class="p">{</span><span class="s">'avatar_url'</span><span class="p">:</span> <span class="s">'https://avatars.githubusercontent.com/u/7388996?'</span><span class="p">,</span>
   <span class="s">'gravatar_id'</span><span class="p">:</span> <span class="s">''</span><span class="p">,</span>
   <span class="s">'id'</span><span class="p">:</span> <span class="mi">7388996</span><span class="p">,</span>
   <span class="s">'login'</span><span class="p">:</span> <span class="s">'jupyter'</span><span class="p">,</span>
   <span class="s">'url'</span><span class="p">:</span> <span class="s">'https://api.github.com/orgs/jupyter'</span><span class="p">},</span>
  <span class="s">'payload'</span><span class="p">:</span> <span class="p">{</span><span class="s">'action'</span><span class="p">:</span> <span class="s">'started'</span><span class="p">},</span>
  <span class="s">'public'</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span>
  <span class="s">'repo'</span><span class="p">:</span> <span class="p">{</span><span class="s">'id'</span><span class="p">:</span> <span class="mi">5303123</span><span class="p">,</span>
   <span class="s">'name'</span><span class="p">:</span> <span class="s">'jupyter/nbviewer'</span><span class="p">,</span>
   <span class="s">'url'</span><span class="p">:</span> <span class="s">'https://api.github.com/repos/jupyter/nbviewer'</span><span class="p">},</span>
  <span class="s">'type'</span><span class="p">:</span> <span class="s">'WatchEvent'</span><span class="p">},)</span>
</code></pre>
</div>

<p>So the first event of the year was by <code class="highlighter-rouge">'marksteve'</code> who decided to watch the
<code class="highlighter-rouge">'nbviewer'</code> repository on new year’s day.</p>

<p>Notice that these computations take around 200ms.  I can’t get below this from
my local machine, so we’re likely bound by communicating to such a remote
location.  A 200ms latency is not great if you’re playing a video game, but
it’s decent for interactive computing.</p>

<p>Here are all of the Jupyter repositories touched in the month of January,</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="o">%</span><span class="n">time</span> <span class="n">jupyter</span><span class="o">.</span><span class="n">pluck</span><span class="p">(</span><span class="s">'repo'</span><span class="p">)</span><span class="o">.</span><span class="n">pluck</span><span class="p">(</span><span class="s">'name'</span><span class="p">)</span><span class="o">.</span><span class="n">distinct</span><span class="p">()</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="n">CPU</span> <span class="n">times</span><span class="p">:</span> <span class="n">user</span> <span class="mf">2.84</span> <span class="n">ms</span><span class="p">,</span> <span class="n">sys</span><span class="p">:</span> <span class="mf">4.03</span> <span class="n">ms</span><span class="p">,</span> <span class="n">total</span><span class="p">:</span> <span class="mf">6.86</span> <span class="n">ms</span>
<span class="n">Wall</span> <span class="n">time</span><span class="p">:</span> <span class="mi">204</span> <span class="n">ms</span>

<span class="p">[</span><span class="s">'jupyter/dockerspawner'</span><span class="p">,</span>
 <span class="s">'jupyter/design'</span><span class="p">,</span>
 <span class="s">'jupyter/docker-demo-images'</span><span class="p">,</span>
 <span class="s">'jupyter/jupyterhub'</span><span class="p">,</span>
 <span class="s">'jupyter/configurable-http-proxy'</span><span class="p">,</span>
 <span class="s">'jupyter/nbshot'</span><span class="p">,</span>
 <span class="s">'jupyter/sudospawner'</span><span class="p">,</span>
 <span class="s">'jupyter/colaboratory'</span><span class="p">,</span>
 <span class="s">'jupyter/strata-sv-2015-tutorial'</span><span class="p">,</span>
 <span class="s">'jupyter/tmpnb-deploy'</span><span class="p">,</span>
 <span class="s">'jupyter/nature-demo'</span><span class="p">,</span>
 <span class="s">'jupyter/nbcache'</span><span class="p">,</span>
 <span class="s">'jupyter/jupyter.github.io'</span><span class="p">,</span>
 <span class="s">'jupyter/try.jupyter.org'</span><span class="p">,</span>
 <span class="s">'jupyter/jupyter-drive'</span><span class="p">,</span>
 <span class="s">'jupyter/tmpnb'</span><span class="p">,</span>
 <span class="s">'jupyter/tmpnb-redirector'</span><span class="p">,</span>
 <span class="s">'jupyter/nbgrader'</span><span class="p">,</span>
 <span class="s">'jupyter/nbindex'</span><span class="p">,</span>
 <span class="s">'jupyter/nbviewer'</span><span class="p">,</span>
 <span class="s">'jupyter/oauthenticator'</span><span class="p">]</span>
</code></pre>
</div>

<p>And the top ten most active people on GitHub.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="o">%</span><span class="n">time</span> <span class="p">(</span><span class="n">jupyter</span><span class="o">.</span><span class="n">pluck</span><span class="p">(</span><span class="s">'actor'</span><span class="p">)</span>
                  <span class="o">.</span><span class="n">pluck</span><span class="p">(</span><span class="s">'login'</span><span class="p">)</span>
                  <span class="o">.</span><span class="n">frequencies</span><span class="p">()</span>
                  <span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">kv</span><span class="p">:</span> <span class="n">kv</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
                  <span class="o">.</span><span class="n">compute</span><span class="p">())</span>
<span class="n">CPU</span> <span class="n">times</span><span class="p">:</span> <span class="n">user</span> <span class="mf">8.03</span> <span class="n">ms</span><span class="p">,</span> <span class="n">sys</span><span class="p">:</span> <span class="mi">90</span> <span class="err">µ</span><span class="n">s</span><span class="p">,</span> <span class="n">total</span><span class="p">:</span> <span class="mf">8.12</span> <span class="n">ms</span>
<span class="n">Wall</span> <span class="n">time</span><span class="p">:</span> <span class="mi">226</span> <span class="n">ms</span>

<span class="p">[(</span><span class="s">'rgbkrk'</span><span class="p">,</span> <span class="mi">156</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'minrk'</span><span class="p">,</span> <span class="mi">87</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'Carreau'</span><span class="p">,</span> <span class="mi">87</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'KesterTong'</span><span class="p">,</span> <span class="mi">74</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'jhamrick'</span><span class="p">,</span> <span class="mi">70</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'bollwyvl'</span><span class="p">,</span> <span class="mi">25</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'pkt'</span><span class="p">,</span> <span class="mi">18</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'ssanderson'</span><span class="p">,</span> <span class="mi">13</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'smashwilson'</span><span class="p">,</span> <span class="mi">13</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'ellisonbg'</span><span class="p">,</span> <span class="mi">13</span><span class="p">)]</span>
</code></pre>
</div>

<p>Nothing too surprising here if you know these folks.</p>

<h2 id="full-dataset">Full Dataset</h2>

<p>The full five months of data is too large to fit in memory, even for this
cluster.  When we represent semi-structured data like this with dynamic data
structures like lists and dictionaries there is quite a bit of memory bloat.
Some careful attention to efficient semi-structured storage here could save us
from having to switch to such a large cluster, but that will have to be
the topic of another post.</p>

<p>Instead, we operate efficiently on this dataset by flowing it through
memory, persisting only the records we care about.  The distributed dask
scheduler descends from the single-machine dask scheduler, which was quite good
at flowing through a computation and intelligently removing intermediate
results.</p>

<p>From a user API perspective, we call <code class="highlighter-rouge">persist</code> only on the <code class="highlighter-rouge">jupyter</code> dataset,
and not the full <code class="highlighter-rouge">records</code> dataset.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">full</span> <span class="o">=</span> <span class="p">(</span><span class="n">s3</span><span class="o">.</span><span class="n">read_text</span><span class="p">(</span><span class="s">'githubarchive-data'</span><span class="p">,</span> <span class="s">'2015'</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s">'gzip'</span><span class="p">)</span>
              <span class="o">.</span><span class="nb">map</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">jupyter</span> <span class="o">=</span> <span class="p">(</span><span class="n">full</span><span class="o">.</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">d</span><span class="p">:</span> <span class="n">d</span><span class="p">[</span><span class="s">'repo'</span><span class="p">][</span><span class="s">'name'</span><span class="p">]</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s">'jupyter/'</span><span class="p">))</span>
                   <span class="o">.</span><span class="n">repartition</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">jupyter</span> <span class="o">=</span> <span class="n">e</span><span class="o">.</span><span class="n">persist</span><span class="p">(</span><span class="n">jupyter</span><span class="p">)</span>
</code></pre>
</div>

<p>It takes 2m36s to download, decompress, and parse the five months of publicly
available GitHub events for all Jupyter events on nine <code class="highlighter-rouge">m3.2xlarges</code>.</p>

<p>There were seven thousand such events.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">jupyter</span><span class="o">.</span><span class="n">count</span><span class="p">()</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="mi">7065</span>
</code></pre>
</div>

<p>We find which repositories saw the most activity during that time:</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="o">%</span><span class="n">time</span> <span class="p">(</span><span class="n">jupyter</span><span class="o">.</span><span class="n">pluck</span><span class="p">(</span><span class="s">'repo'</span><span class="p">)</span>
                  <span class="o">.</span><span class="n">pluck</span><span class="p">(</span><span class="s">'name'</span><span class="p">)</span>
                  <span class="o">.</span><span class="n">frequencies</span><span class="p">()</span>
                  <span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">kv</span><span class="p">:</span> <span class="n">kv</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
                  <span class="o">.</span><span class="n">compute</span><span class="p">())</span>
<span class="n">CPU</span> <span class="n">times</span><span class="p">:</span> <span class="n">user</span> <span class="mf">6.98</span> <span class="n">ms</span><span class="p">,</span> <span class="n">sys</span><span class="p">:</span> <span class="mi">474</span> <span class="err">µ</span><span class="n">s</span><span class="p">,</span> <span class="n">total</span><span class="p">:</span> <span class="mf">7.46</span> <span class="n">ms</span>
<span class="n">Wall</span> <span class="n">time</span><span class="p">:</span> <span class="mi">219</span> <span class="n">ms</span>

<span class="p">[(</span><span class="s">'jupyter/jupyterhub'</span><span class="p">,</span> <span class="mi">1262</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'jupyter/nbgrader'</span><span class="p">,</span> <span class="mi">1235</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'jupyter/nbviewer'</span><span class="p">,</span> <span class="mi">846</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'jupyter/jupyter_notebook'</span><span class="p">,</span> <span class="mi">507</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'jupyter/jupyter-drive'</span><span class="p">,</span> <span class="mi">505</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'jupyter/notebook'</span><span class="p">,</span> <span class="mi">451</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'jupyter/docker-demo-images'</span><span class="p">,</span> <span class="mi">363</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'jupyter/tmpnb'</span><span class="p">,</span> <span class="mi">284</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'jupyter/jupyter_client'</span><span class="p">,</span> <span class="mi">162</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'jupyter/dockerspawner'</span><span class="p">,</span> <span class="mi">149</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'jupyter/colaboratory'</span><span class="p">,</span> <span class="mi">134</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'jupyter/jupyter_core'</span><span class="p">,</span> <span class="mi">127</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'jupyter/strata-sv-2015-tutorial'</span><span class="p">,</span> <span class="mi">108</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'jupyter/jupyter_nbconvert'</span><span class="p">,</span> <span class="mi">103</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'jupyter/configurable-http-proxy'</span><span class="p">,</span> <span class="mi">89</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'jupyter/hubpress.io'</span><span class="p">,</span> <span class="mi">85</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'jupyter/jupyter.github.io'</span><span class="p">,</span> <span class="mi">84</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'jupyter/tmpnb-deploy'</span><span class="p">,</span> <span class="mi">76</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'jupyter/nbconvert'</span><span class="p">,</span> <span class="mi">66</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'jupyter/jupyter_qtconsole'</span><span class="p">,</span> <span class="mi">59</span><span class="p">)]</span>
</code></pre>
</div>

<p>We see that projects like <code class="highlighter-rouge">jupyterhub</code> were quite active during that time
while, surprisingly, <code class="highlighter-rouge">nbconvert</code> saw relatively little action.</p>

<h2 id="local-data">Local Data</h2>

<p>The Jupyter data is quite small and easily fits in a single machine.  Let’s
bring the data to our local machine so that we can compare times:</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="o">%</span><span class="n">time</span> <span class="n">L</span> <span class="o">=</span> <span class="n">jupyter</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="n">CPU</span> <span class="n">times</span><span class="p">:</span> <span class="n">user</span> <span class="mf">4.74</span> <span class="n">s</span><span class="p">,</span> <span class="n">sys</span><span class="p">:</span> <span class="mf">10.9</span> <span class="n">s</span><span class="p">,</span> <span class="n">total</span><span class="p">:</span> <span class="mf">15.7</span> <span class="n">s</span>
<span class="n">Wall</span> <span class="n">time</span><span class="p">:</span> <span class="mf">30.2</span> <span class="n">s</span>
</code></pre>
</div>

<p>It takes surprisingly long to download the data, but once its here, we can
iterate far more quickly with basic Python.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">toolz.curried</span> <span class="kn">import</span> <span class="n">pluck</span><span class="p">,</span> <span class="n">frequencies</span><span class="p">,</span> <span class="n">topk</span><span class="p">,</span> <span class="n">pipe</span>
<span class="o">&gt;&gt;&gt;</span> <span class="o">%</span><span class="n">time</span> <span class="n">pipe</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">pluck</span><span class="p">(</span><span class="s">'repo'</span><span class="p">),</span> <span class="n">pluck</span><span class="p">(</span><span class="s">'name'</span><span class="p">),</span> <span class="n">frequencies</span><span class="p">,</span>
               <span class="nb">dict</span><span class="o">.</span><span class="n">items</span><span class="p">,</span> <span class="n">topk</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">kv</span><span class="p">:</span> <span class="n">kv</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="nb">list</span><span class="p">)</span>
<span class="n">CPU</span> <span class="n">times</span><span class="p">:</span> <span class="n">user</span> <span class="mf">11.8</span> <span class="n">ms</span><span class="p">,</span> <span class="n">sys</span><span class="p">:</span> <span class="mi">0</span> <span class="n">ns</span><span class="p">,</span> <span class="n">total</span><span class="p">:</span> <span class="mf">11.8</span> <span class="n">ms</span>
<span class="n">Wall</span> <span class="n">time</span><span class="p">:</span> <span class="mf">11.5</span> <span class="n">ms</span>

<span class="p">[(</span><span class="s">'jupyter/jupyterhub'</span><span class="p">,</span> <span class="mi">1262</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'jupyter/nbgrader'</span><span class="p">,</span> <span class="mi">1235</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'jupyter/nbviewer'</span><span class="p">,</span> <span class="mi">846</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'jupyter/jupyter_notebook'</span><span class="p">,</span> <span class="mi">507</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'jupyter/jupyter-drive'</span><span class="p">,</span> <span class="mi">505</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'jupyter/notebook'</span><span class="p">,</span> <span class="mi">451</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'jupyter/docker-demo-images'</span><span class="p">,</span> <span class="mi">363</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'jupyter/tmpnb'</span><span class="p">,</span> <span class="mi">284</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'jupyter/jupyter_client'</span><span class="p">,</span> <span class="mi">162</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'jupyter/dockerspawner'</span><span class="p">,</span> <span class="mi">149</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'jupyter/colaboratory'</span><span class="p">,</span> <span class="mi">134</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'jupyter/jupyter_core'</span><span class="p">,</span> <span class="mi">127</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'jupyter/strata-sv-2015-tutorial'</span><span class="p">,</span> <span class="mi">108</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'jupyter/jupyter_nbconvert'</span><span class="p">,</span> <span class="mi">103</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'jupyter/configurable-http-proxy'</span><span class="p">,</span> <span class="mi">89</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'jupyter/hubpress.io'</span><span class="p">,</span> <span class="mi">85</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'jupyter/jupyter.github.io'</span><span class="p">,</span> <span class="mi">84</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'jupyter/tmpnb-deploy'</span><span class="p">,</span> <span class="mi">76</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'jupyter/nbconvert'</span><span class="p">,</span> <span class="mi">66</span><span class="p">),</span>
 <span class="p">(</span><span class="s">'jupyter/jupyter_qtconsole'</span><span class="p">,</span> <span class="mi">59</span><span class="p">)]</span>
</code></pre>
</div>

<p>The difference here is 20x, which is a good reminder that, once you no longer
have a large problem you should probably eschew distributed systems and act
locally.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Downloading, decompressing, parsing, filtering, and counting JSON records
is the new wordcount.  It’s the first problem anyone sees.  Fortunately it’s
both easy to solve and the common case.  Woo hoo!</p>

<p>Here we saw that dask+distributed handle the common case decently well and with
a Pure Python stack.  Typically Python users rely on a JVM technology like
Hadoop/Spark/Storm to distribute their computations.  Here we have Python
distributing Python; there are some usability gains to be had here like nice
stack traces, a bit less serialization overhead, and attention to other
Pythonic style choices.</p>

<p>Over the next few posts I intend to deviate from this common case.  Most “Big
Data” technologies were designed to solve typical data munging problems found
in web companies or with simple database operations in mind.  Python users care
about these things too, but they also reach out to a wide variety of fields.
In dask+distributed development we care about the common case, but also support
less traditional workflows that are commonly found in the life, physical, and
algorithmic sciences.</p>

<p>By designing to support these more extreme cases we’ve nailed some common pain
points in current distributed systems.  Today we’ve seen low latency and remote
control; in the future we’ll see others.</p>

<h2 id="what-doesnt-work">What doesn’t work</h2>

<p>I’ll have an honest section like this at the end of each upcoming post
describing what doesn’t work, what still feels broken, or what I would have
done differently with more time.</p>

<ul>
  <li>
    <p>The imports for dask and distributed are still strange.  They’re two
separate codebases that play very nicely together.  Unfortunately the
functionality you need is sometimes in one or in the other and it’s not
immediately clear to the novice user where to go.  For example dask.bag, the
collection we’re using for <code class="highlighter-rouge">records</code>, <code class="highlighter-rouge">jupyter</code>, etc. is in <code class="highlighter-rouge">dask</code> but the
<code class="highlighter-rouge">s3</code> module is within the <code class="highlighter-rouge">distributed</code> library.  We’ll have to merge things
at some point in the near-to-moderate future.  Ditto for the API: there are
compute methods both on the dask collections (<code class="highlighter-rouge">records.compute()</code>) and on
the distributed executor (<code class="highlighter-rouge">e.compute(records)</code>) that behave slightly
differently.</p>
  </li>
  <li>
    <p>We lack an efficient distributed shuffle algorithm.  This is very important
if you want to use operations like <code class="highlighter-rouge">.groupby</code> (which you should avoid
anyway).  The user API here doesn’t even cleanly warn users that this is
missing in the distributed case which is kind of a mess. (It works fine on a
single machine.)  Efficient alternatives like <code class="highlighter-rouge">foldby</code> <em>are</em> available.</p>
  </li>
  <li>
    <p>I would have liked to run this experiment directly on the cluster to see
how low we could have gone below the 200ms barrier we ran into here.</p>
  </li>
</ul>

<h2 id="links">Links</h2>

<ul>
  <li><a href="https://dask.pydata.org/en/latest/">dask</a>, the original project</li>
  <li><a href="https://distributed.readthedocs.org/en/latest/">distributed</a>, the
distributed memory scheduler powering the cluster computing</li>
  <li><a href="http://dask.pydata.org/en/latest/bag.html">dask.bag</a>, the user API we’ve
used in this post.</li>
  <li>This post largely repeats work by <a href="https://github.com/cowlicks">Blake Griffith</a> in a
<a href="https://www.continuum.io/content/dask-distributed-and-anaconda-cluster">similar post</a>
last year with an older iteration of the dask distributed scheduler</li>
</ul>

    <hr/>
    
    <hr/>
    


  <p id="disqus_thread"/>

<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">blog comments powered by <span class="logo-disqus">Disqus</span></a>




  </div>
  
</div></body></html>