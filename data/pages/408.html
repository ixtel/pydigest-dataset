<html><body><div><div class="content html_format"><p>
      Недавно пришлось по работе написать простенький парсер на питоне, который бы скачивал с сайта изображения (по идее тот же самый парсер может качать не только изображения, но и файлы других форматов) и сохранял их на диске. Всего я нашел в интернете четыре метода. В этой статье я их решил собрать все вместе. </p>

<a name="habracut"/><p>Вот эти методы:

</p><h5>1-ый метод</h5><p>
Первый метод использует модуль urllib (или же urllib2). Пусть имеется ссылка на некое изображение img. Метод выглядит следующим образом:

</p><pre><code class="python">import urllib

resource = urllib.urlopen(img)
out = open("...\img.jpg", 'wb')
out.write(resource.read())
out.close()
</code></pre>
<p>
Здесь нужно обратить внимание, что режим записи для изображений — 'wb' (бинарный), а не просто 'w'.

</p><h5>2-ой метод</h5><p>
Второй метод использует тот же самый urllib. В дальнейшем будет показано, что этот метод чуть медленнее первого (отрицательный оттенок фактора скорости парсинга неоднозначен), но достоин внимания из-за своей краткости:

</p><pre><code class="python">import urllib
urllib.urlretrieve(img, "...\img.jpg")
</code></pre>
<p>
Притом стоит заметить, что функция urlretrieve в библиотеке urllib2 по неизвестным мне причинам (может кто подскажет по каким) отсутствует. 

</p><h5>3-ий метод</h5><p>
Третий метод использует модуль requests. Метод имеет одинаковый порядок скорости выгрузки картинок с первыми двумя методами:

</p><pre><code class="python">import requests

p = requests.get(img)
out = open("...\img.jpg", "wb")
out.write(p.content)
out.close()
</code></pre><p>
При этом при работе с веб в питоне рекомендуется использовать именно requests вместо семейств urllib и httplib из-за его краткости и удобства обращения с ним.

</p><h5>4-ый метод</h5><p>
Четвертый метод по скорости кардинально отличается от предыдущих методов (на целый порядок). Основан на использовании модуля httplib2. Выглядит следующим образом:

</p><pre><code class="python">import httplib2

h = httplib2.Http('.cache')
response, content = h.request(img)
out = open('...\img.jpg', 'wb')
out.write(content)
out.close()
</code></pre>
<p>
Здесь явно используется кэширование. Без кэширования (h = httplib2.Http()) метод работает в 6-9 раза медленнее предыдущих аналогов.
</p><p>
Тестирование скорости проводилось на примере скачивания картинок с расширением *.jpg c сайта новостной ленты </p><a href="http://lenta.ru/">lenta.ru</a><p>. Выбор картинок, подпадающих под этот критерий и измерение времени выполнения программы производились следующим образом:

</p><pre><code class="python">import re, time, urllib2

url = "http://lenta.ru/"
content = urllib2.urlopen(url).read()
imgUrls = re.findall('img .*?src="(.*?)"', сontent)

start = time.time()
for img in imgUrls:
    if img.endswith(".jpg"):
        """реализация метода по загрузке изображения из url"""

print time.time()-start
</code></pre>
<p>
Постоянно меняющиеся картинки на сайте не повлияли на чистоту измерений, поскольку методы отрабатывали друг за другом. Полученные результаты таковы:

</p><table>
<caption>Таблица сравнения скоростей методов</caption>
<tr>
<th>Метод 1, с</th>
<th>Метод 2, с</th>
<th>Метод 3, с</th>
<th>Метод 4, с (без кэширования, с)</th>
</tr>
<tr>
<td>0.823</td>
<td>0.908</td>
<td>0.874</td>
<td>0.089 (7.625)</td>
</tr>
</table><p>
Данные представлены как результат усреднения результатов семи измерений.</p><p>
Просьба к тем, кто имел дело с библиотекой Grab (и с другими), написать в комментариях аналогичный метод по скачиванию изображений с помощью этой и других библиотек.

      
      </p><p class="clear"/>
    </div>

    
  </div></body></html>