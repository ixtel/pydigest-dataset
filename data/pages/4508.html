<html><body><div><article class="markdown-body entry-content" itemprop="text"><h1><a id="user-content-keras-deep-learning-library-for-theano-and-tensorflow" class="anchor" href="#keras-deep-learning-library-for-theano-and-tensorflow" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Keras: Deep Learning library for Theano and TensorFlow</h1>

<p><a href="https://camo.githubusercontent.com/ad2e4678f172bd0aff5db3aa39d559837f7b5016/68747470733a2f2f6170692e7472617669732d63692e6f72672f6663686f6c6c65742f6b657261732e737667" target="_blank"><img src="https://camo.githubusercontent.com/ad2e4678f172bd0aff5db3aa39d559837f7b5016/68747470733a2f2f6170692e7472617669732d63692e6f72672f6663686f6c6c65742f6b657261732e737667" alt="Build status" data-canonical-src="https://api.travis-ci.org/fchollet/keras.svg"/></a></p>

<h2><a id="user-content-you-have-just-found-keras" class="anchor" href="#you-have-just-found-keras" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>You have just found Keras.</h2>

<p>Keras is a minimalist, highly modular neural networks library, written in Python and capable of running on top of either <a href="https://github.com/tensorflow/tensorflow">TensorFlow</a> or <a href="https://github.com/Theano/Theano">Theano</a>. It was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research.</p>

<p>Use Keras if you need a deep learning library that:</p>

<ul>
<li>allows for easy and fast prototyping (through total modularity, minimalism, and extensibility).</li>
<li>supports both convolutional networks and recurrent networks, as well as combinations of the two.</li>
<li>supports arbitrary connectivity schemes (including multi-input and multi-output training).</li>
<li>runs seamlessly on CPU and GPU.</li>
</ul>

<p>Read the documentation at <a href="http://keras.io">Keras.io</a>.</p>

<p>Keras is compatible with: <strong>Python 2.7-3.5</strong>.</p>

<hr/>

<h2><a id="user-content-guiding-principles" class="anchor" href="#guiding-principles" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Guiding principles</h2>

<ul>
<li><p><strong>Modularity.</strong> A model is understood as a sequence or a graph of standalone, fully-configurable modules that can be plugged together with as little restrictions as possible. In particular, neural layers, cost functions, optimizers, initialization schemes, activation functions, regularization schemes are all standalone modules that you can combine to create new models.</p></li>
<li><p><strong>Minimalism.</strong> Each module should be kept short and simple. Every piece of code should be transparent upon first reading. No black magic: it hurts iteration speed and ability to innovate.</p></li>
<li><p><strong>Easy extensibility.</strong> New modules are dead simple to add (as new classes and functions), and existing modules provide ample examples. To be able to easily create new modules allows for total expressiveness, making Keras suitable for advanced research.</p></li>
<li><p><strong>Work with Python</strong>. No separate models configuration files in a declarative format. Models are described in Python code, which is compact, easier to debug, and allows for ease of extensibility.</p></li>
</ul>

<hr/>

<h2><a id="user-content-getting-started-30-seconds-to-keras" class="anchor" href="#getting-started-30-seconds-to-keras" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Getting started: 30 seconds to Keras</h2>

<p>The core data structure of Keras is a <strong>model</strong>, a way to organize layers. There are two types of models: <a href="http://keras.io/models/#sequential"><code>Sequential</code></a> and <a href="http://keras.io/models/#graph"><code>Graph</code></a>.</p>

<p>Here's the <code>Sequential</code> model (a linear pile of layers):</p>

<div class="highlight highlight-source-python"><pre><span class="pl-k">from</span> keras.models <span class="pl-k">import</span> Sequential

model <span class="pl-k">=</span> Sequential()</pre></div>

<p>Stacking layers is as easy as <code>.add()</code>:</p>

<div class="highlight highlight-source-python"><pre><span class="pl-k">from</span> keras.layers.core <span class="pl-k">import</span> Dense, Activation

model.add(Dense(<span class="pl-v">output_dim</span><span class="pl-k">=</span><span class="pl-c1">64</span>, <span class="pl-v">input_dim</span><span class="pl-k">=</span><span class="pl-c1">100</span>, <span class="pl-v">init</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>glorot_uniform<span class="pl-pds">"</span></span>))
model.add(Activation(<span class="pl-s"><span class="pl-pds">"</span>relu<span class="pl-pds">"</span></span>))
model.add(Dense(<span class="pl-v">output_dim</span><span class="pl-k">=</span><span class="pl-c1">10</span>, <span class="pl-v">init</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>glorot_uniform<span class="pl-pds">"</span></span>))
model.add(Activation(<span class="pl-s"><span class="pl-pds">"</span>softmax<span class="pl-pds">"</span></span>))</pre></div>

<p>Once your model looks good, configure its learning process with <code>.compile()</code>:</p>

<div class="highlight highlight-source-python"><pre>model.compile(<span class="pl-v">loss</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">'</span>categorical_crossentropy<span class="pl-pds">'</span></span>, <span class="pl-v">optimizer</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">'</span>sgd<span class="pl-pds">'</span></span>)</pre></div>

<p>If you need to, you can further configure your optimizer. A core principle of Keras is to make things reasonably simple, while allowing the user to be fully in control when they need to (the ultimate control being the easy extensibility of the source code).</p>

<div class="highlight highlight-source-python"><pre><span class="pl-k">from</span> keras.optimizers <span class="pl-k">import</span> <span class="pl-c1">SGD</span>
model.compile(<span class="pl-v">loss</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">'</span>categorical_crossentropy<span class="pl-pds">'</span></span>, <span class="pl-v">optimizer</span><span class="pl-k">=</span>SGD(<span class="pl-v">lr</span><span class="pl-k">=</span><span class="pl-c1">0.01</span>, <span class="pl-v">momentum</span><span class="pl-k">=</span><span class="pl-c1">0.9</span>, <span class="pl-v">nesterov</span><span class="pl-k">=</span><span class="pl-c1">True</span>))</pre></div>

<p>You can now iterate on your training data in batches:</p>

<div class="highlight highlight-source-python"><pre>model.fit(<span class="pl-c1">X_train</span>, <span class="pl-c1">Y_train</span>, <span class="pl-v">nb_epoch</span><span class="pl-k">=</span><span class="pl-c1">5</span>, <span class="pl-v">batch_size</span><span class="pl-k">=</span><span class="pl-c1">32</span>)</pre></div>

<p>Alternatively, you can feed batches to your model manually:</p>

<div class="highlight highlight-source-python"><pre>model.train_on_batch(<span class="pl-c1">X_batch</span>, <span class="pl-c1">Y_batch</span>)</pre></div>

<p>Evaluate your performance in one line:</p>

<div class="highlight highlight-source-python"><pre>objective_score <span class="pl-k">=</span> model.evaluate(<span class="pl-c1">X_test</span>, <span class="pl-c1">Y_test</span>, <span class="pl-v">batch_size</span><span class="pl-k">=</span><span class="pl-c1">32</span>)</pre></div>

<p>Or generate predictions on new data:</p>

<div class="highlight highlight-source-python"><pre>classes <span class="pl-k">=</span> model.predict_classes(<span class="pl-c1">X_test</span>, <span class="pl-v">batch_size</span><span class="pl-k">=</span><span class="pl-c1">32</span>)
proba <span class="pl-k">=</span> model.predict_proba(<span class="pl-c1">X_test</span>, <span class="pl-v">batch_size</span><span class="pl-k">=</span><span class="pl-c1">32</span>)</pre></div>

<p>Building a network of LSTMs, a deep CNN, a Neural Turing Machine, a word2vec embedder or any other model is just as fast. The ideas behind deep learning are simple, so why should their implementation be painful?</p>

<p>Have a look at these <a href="http://keras.io/examples/">starter examples</a>.</p>

<p>In the <a href="https://github.com/fchollet/keras/tree/master/examples">examples folder</a> of the repo, you will find more advanced models: question-answering with memory networks, text generation with stacked LSTMs, neural turing machines, etc.</p>

<hr/>

<h2><a id="user-content-installation" class="anchor" href="#installation" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Installation</h2>

<p>Keras uses the following dependencies:</p>

<ul>
<li>numpy, scipy</li>
<li>pyyaml</li>
<li>HDF5 and h5py (optional, required if you use model saving/loading functions)</li>
<li>Optional but recommended if you use CNNs: cuDNN.</li>
</ul>

<p><em>When using the Theano backend:</em></p>



<p><strong>Note</strong>: You should use the latest version of Theano, not the PyPI version. Install it with:</p>

<pre><code>sudo pip install git+git://github.com/Theano/Theano.git
</code></pre>

<p><em>When using the TensorFlow backend:</em></p>



<p>To install Keras, <code>cd</code> to the Keras folder and run the install command:</p>

<pre><code>sudo python setup.py install
</code></pre>

<p>You can also install Keras from PyPI:</p>

<pre><code>sudo pip install keras
</code></pre>

<hr/>

<h2><a id="user-content-switching-from-theano-to-tensorflow" class="anchor" href="#switching-from-theano-to-tensorflow" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Switching from Theano to TensorFlow</h2>

<p>By default, Keras will use Theano as its tensor manipulation library. <a href="http://keras.io/backend/">Follow these instructions</a> to configure the Keras backend.</p>

<hr/>

<h2><a id="user-content-support" class="anchor" href="#support" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Support</h2>

<p>You can ask questions and join the development discussion on the <a href="https://groups.google.com/forum/#!forum/keras-users">Keras Google group</a>.</p>

<p>You can also post bug reports and feature requests in <a href="https://github.com/fchollet/keras/issues">Github issues</a>. Make sure to read <a href="https://github.com/fchollet/keras/blob/master/CONTRIBUTING.md">our guidelines</a> first.</p>

<hr/>

<h2><a id="user-content-why-this-name-keras" class="anchor" href="#why-this-name-keras" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Why this name, Keras?</h2>

<p>Keras (κέρας) means <em>horn</em> in Greek. It is a reference to a literary image from ancient Greek and Latin literature, first found in the <em>Odyssey</em>, where dream spirits (<em>Oneiroi</em>, singular <em>Oneiros</em>) are divided between those who deceive men with false visions, who arrive to Earth through a gate of ivory, and those who announce a future that will come to pass, who arrive through a gate of horn. It's a play on the words κέρας (horn) / κραίνω (fulfill), and ἐλέφας (ivory) / ἐλεφαίρομαι (deceive).</p>

<p>Keras was initially developed as part of the research effort of project ONEIROS (Open-ended Neuro-Electronic Intelligent Robot Operating System).</p>

<blockquote>
<p><em>"Oneiroi are beyond our unravelling --who can be sure what tale they tell? Not all that men look for comes to pass. Two gates there are that give passage to fleeting Oneiroi; one is made of horn, one of ivory. The Oneiroi that pass through sawn ivory are deceitful, bearing a message that will not be fulfilled; those that come out through polished horn have truth behind them, to be accomplished for men who see them."</em> Homer, Odyssey 19. 562 ff (Shewring translation).</p>
</blockquote>

<hr/>
</article>
  </div></body></html>