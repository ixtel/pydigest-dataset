<html><body><div><div class="blogbody ">
            
                
                    
<p><span class="dropcaps">N</span>at­ur­al Lan­guage Pro­cessing is a field that cov­ers com­puter un­der­stand­ing and ma­nip­u­la­tion of hu­man lan­guage, and it’s ripe with pos­sib­il­it­ies for news­gath­er­ing. You usu­ally hear about it in the con­text of ana­lyz­ing large pools of le­gis­la­tion or oth­er doc­u­ment sets, at­tempt­ing to dis­cov­er pat­terns or root out cor­rup­tion. I de­cided to take it in­to the kit­chen for my latest pro­ject: The Times <a href="http://recipes.latimes.com/">Cali­for­nia Cook­book</a> re­cipe data­base.</p>

<p>The first phase of the pro­ject, the hol­i­day edi­tion, launched with more than 600 hol­i­day-themed re­cipes from The Times Test Kit­chen. It’s a large num­ber, but there’s much more to come next year – we have close to an­oth­er 5,000 re­cipes staged and nearly ready to go.</p>
<p>With only four months between the concept stage of the site and launch, the Data Desk had a tight time frame and lim­ited re­sources to com­plete two par­al­lel tasks: build the web­site and pre­pare the re­cipes for pub­lic­a­tion. The biggest chal­lenge was pre­par­ing the re­cipes, which were stored in The Times lib­rary archive as, es­sen­tially, un­struc­tured plain text. Pars­ing thou­sands of re­cords by hand was un­man­age­able, so we needed a pro­gram­mat­ic solu­tion to get us most of the way there.</p>
<p>We had a pile of a couple thou­sand re­cords – news stor­ies, columns and more – and each re­cord con­tained one or more re­cipes. We needed to do the fol­low­ing:</p>
<ol>
<li>Sep­ar­ate the re­cipes from the rest of the story, while keep­ing the story in­tact for dis­play along­side the re­cipe later.</li>
<li>De­term­ine how many re­cipes there were – more than one in many cases, and counts up to a dozen wer­en’t par­tic­u­larly un­usu­al.</li>
<li>For each re­cipe, find the name, in­gredi­ents, steps, prep time, servings, nu­tri­tion and more.</li>
<li>Load these in­to a data­base, pre­serving the re­la­tion­ships between the re­cipes that ran to­geth­er in the news­pa­per.</li>
</ol>
<h2 id="where-to-start">Where to start?</h2>
<p>The well-worn path here at the Data Desk would be to write a pars­er that looks for com­mon pat­terns in format­ting and punc­tu­ation. You can break up the text line by line, then look for one or more reg­u­lar ex­pres­sion matches on each line. It might go something like this:</p>
<div class="codehilite"><pre><span class="kn">import</span> <span class="nn">re</span>

<span class="c"># Define our patterns for a step and ingredient</span>
<span class="c"># A step could have a number in front</span>
<span class="c"># followed by a period like "1." or an "*"</span>
<span class="n">step_pattern</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="s">r'^(?:[0-9]{1,2}\.\s|\*)'</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">S</span><span class="p">)</span>
<span class="c"># An ingredient could have a fraction in front like "1/2" or  "1 1/4"</span>
<span class="n">ingredient_pattern</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="s">r'^(?:[0-9]{1,3}\s|[0-9,/]{1,4}\s|[0-9]\s[0-9][/][0-9])'</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">S</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">tag</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Attempt to classify a line of text as a "step" or "ingredient"</span>
<span class="sd">    based on the formatting or leading text.</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="n">step_pattern</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
        <span class="k">return</span> <span class="s">'step'</span>

    <span class="k">if</span> <span class="n">ingredient_pattern</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
        <span class="k">return</span> <span class="s">'ingredient'</span>

    <span class="k">return</span> <span class="bp">None</span>

<span class="c"># Test it out</span>
<span class="n">tag</span><span class="p">(</span><span class="s">'3 eggs'</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="s">'ingredient'</span>

<span class="n">tag</span><span class="p">(</span><span class="s">'1. Heat the oven to 375 degrees.'</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="s">'step'</span>
</pre></div>
<p>Then you can make an at­tempt to tag each line of the story with a re­cipe field – de­scrip­tion, name, in­gredi­ent, step, nu­tri­tion, etc. – and write an­oth­er script to as­semble those parts in­to re­cipes that can be loaded in­to a data­base. </p>
<p>After look­ing at a few re­cords it was im­me­di­ately evid­ent we wouldn’t be able to use pure reg­u­lar ex­pres­sions to parse them. We had de­cided to try to grab all of the re­cipes The Times had pub­lished from the year 2000 to present, and there were enorm­ous dif­fer­ences in the format­ting and struc­ture over the years. We needed nat­ur­al lan­guage pro­cessing and ma­chine learn­ing to parse it.</p>
<h2 id="enter-nltk">Enter <span class="caps">NLTK</span></h2>
<img src="/media/img/archive-example.jpg"/>
<p>Nat­ur­al lan­guage pro­cessing is a big field, and you can do a lot with it – the vast ma­jor­ity of which I will not cov­er here. Py­thon, my pro­gram­ming lan­guage of choice, has an ex­cel­lent lib­rary for nat­ur­al lan­guage pro­cessing and ma­chine learn­ing called Nat­ur­al Lan­guage Toolkit, or <a href="http://nltk.org/"><span class="caps">NLTK</span></a>, which I primar­ily used for this pro­cess. At left is an ex­ample of what the raw re­cipes looked like com­ing out of our lib­rary archive.</p>
<p>One of the more com­mon uses of <span class="caps">NLTK</span> is tag­ging text. You could, for ex­ample, have it tag a news story with top­ics or ana­lyze an email to see if it’s spam. The very ba­sic ap­proach is to <a href="http://nlp.stanford.edu/IR-book/html/htmledition/tokenization-1.html">token­ize</a> the text in­to words, then pass off those words in­to a clas­si­fi­er that you’ve trained with a set of already-tagged ex­amples. The clas­si­fi­er then re­turns the best fit­ting tag for the text. </p>
<p>For re­cipes, we already have well-defined fields we need to ex­tract. There will be in­gredi­ents, steps, nu­tri­tion, servings, prep time and pos­sibly a couple more. We just need to train a clas­si­fi­er to tell the dif­fer­ence by passing it some ex­amples we’ve done manu­ally. After a bit of re­search and test­ing, I chose to go with a <a href="http://en.wikipedia.org/wiki/Maximum_entropy_classifier">Max­im­um En­tropy clas­si­fi­er</a> be­cause it seemed to fit the pro­ject best and was very ac­cur­ate.</p>
<p>A ba­sic ap­proach might look something like this:</p>
<div class="codehilite"><pre><span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">from</span> <span class="nn">nltk.classify</span> <span class="kn">import</span> <span class="n">MaxentClassifier</span>

<span class="c"># Set up our training material in a nice dictionary.</span>
<span class="n">training</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'ingredients'</span><span class="p">:</span> <span class="p">[</span>
        <span class="s">'Pastry for 9-inch tart pan'</span><span class="p">,</span>
        <span class="s">'Apple cider vinegar'</span><span class="p">,</span>
        <span class="s">'3 eggs'</span><span class="p">,</span>
        <span class="s">'1/4 cup sugar'</span><span class="p">,</span>
    <span class="p">],</span>
    <span class="s">'steps'</span><span class="p">:</span> <span class="p">[</span>
        <span class="s">'Sift the powdered sugar and cocoa powder together.'</span><span class="p">,</span>
        <span class="s">'Coarsely crush the peppercorns using a mortar and pestle.'</span><span class="p">,</span>
        <span class="s">'While the vegetables are cooking, scrub the pig ears clean and cut away any knobby bits of cartilage so they will lie flat.'</span><span class="p">,</span>
        <span class="s">'Heat the oven to 375 degrees.'</span><span class="p">,</span>
    <span class="p">]</span>
<span class="p">}</span>

<span class="c"># Set up a list that will contain all of our tagged examples,</span>
<span class="c"># which we will pass into the classifier at the end.</span>
<span class="n">training_set</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">training</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">val</span><span class="p">:</span>
        <span class="c"># Set up a list we can use for all of our features,</span>
        <span class="c"># which are just individual words in this case.</span>
        <span class="n">feats</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c"># Before we can tokenize words, we need to break the</span>
        <span class="c"># text out into sentences.</span>
        <span class="n">sentences</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">sent_tokenize</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">:</span>
            <span class="n">feats</span> <span class="o">=</span> <span class="n">feats</span> <span class="o">+</span> <span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>

        <span class="c"># For this example, it's a good idea to normalize for case.</span>
        <span class="c"># You may or may not need to do this.</span>
        <span class="n">feats</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">feats</span><span class="p">]</span>
        <span class="c"># Each feature needs a value. A typical use for a case like this</span>
        <span class="c"># is to use True or 1, though you can use almost any value for</span>
        <span class="c"># a more complicated application or analysis.</span>
        <span class="n">feats</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">([(</span><span class="n">i</span><span class="p">,</span> <span class="bp">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">feats</span><span class="p">])</span>
        <span class="c"># <span class="caps">NLTK</span> expects you to feed a classifier a list of tuples</span>
        <span class="c"># where each tuple is (features, tag).</span>
        <span class="n">training_set</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">feats</span><span class="p">,</span> <span class="n">key</span><span class="p">))</span>

<span class="c"># Train up our classifier</span>
<span class="n">classifier</span> <span class="o">=</span> <span class="n">MaxentClassifier</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">training_set</span><span class="p">)</span>

<span class="c"># Test it out!</span>
<span class="c"># You need to feed the classifier your data in the same format you used</span>
<span class="c"># to train it, in this case individual lowercase words.</span>
<span class="n">classifier</span><span class="o">.</span><span class="n">classify</span><span class="p">({</span><span class="s">'apple'</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'cider'</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'vinegar'</span><span class="p">:</span> <span class="bp">True</span><span class="p">})</span>
<span class="o">&gt;&gt;&gt;</span> <span class="s">'ingredients'</span>

<span class="c"># Save it to disk, if you want, because these can take a long time to train.</span>
<span class="n">outfile</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s">'my_pickle.pickle'</span><span class="p">,</span> <span class="s">'wb'</span><span class="p">)</span>
<span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span> <span class="n">outfile</span><span class="p">)</span>
<span class="n">outfile</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
<p>The built-in Max­im­um En­tropy clas­si­fi­er can take an ex­ceed­ingly long time to train, but <span class="caps">NLTK</span> can in­ter­face with sev­er­al ex­tern­al ma­chine-learn­ing ap­plic­a­tions to make that pro­cess much quick­er. I was able to in­stall <a href="http://www.umiacs.umd.edu/~hal/megam/">MegaM</a> on my Mac, with some modi­fic­a­tions, and used it with <span class="caps">NLTK</span> to great ef­fect.</p>
<h2 id="deeper-analysis">Deep­er ana­lys­is</h2>
<p>But that’s just a be­gin­ning, and what is typ­ic­ally de­scribed as a “bag of words” ap­proach. To put it simply, the clas­si­fi­er learns how to tag your text based on the fre­quency of some of the words. It doesn’t ac­count for the or­der of the words, or com­mon phrases or any­thing else. Us­ing this meth­od I was able to tag fields with slightly more than 90% ac­cur­acy, which is pretty good. But we can do bet­ter.</p>
<p>If you think about how a re­cipe is writ­ten, there are more dif­fer­ences between the fields than the in­di­vidu­al words like “but­ter” or “fry.” There might be com­mon phrases like “heat the oven” or “at room tem­per­at­ure.”</p>
<p>There also might be dif­fer­ences in the gram­mar. For ex­ample, how can you cor­rectly tag “Mini ricotta latkes with sour cherry sauce” as a re­cipe title and not an in­gredi­ent? In­gredi­ents might have a reas­on­ably pre­dict­able mix of ad­ject­ives, nouns and prop­er nouns while steps might have more verbs and de­term­iners. A title would rarely have a pro­noun but could in­clude pre­pos­i­tions fairly of­ten.</p>
<p><span class="caps">NLTK</span> comes with a few meth­ods to make this type of ana­lys­is much easi­er. It has a great part-of-speech tag­ger, for in­stance, as well as func­tions for pulling bi-grams and tri-grams (two and three word phrases) out of blocks of text. You can eas­ily write a func­tion that token­izes text in­to sen­tences, then words, then tri-grams and parts of speech. Feed all of that in­to your clas­si­fi­er and you can tag text much more ac­cur­ately.</p>
<p>It could look something like this:</p>
<div class="codehilite"><pre><span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">from</span> <span class="nn">nltk.tag.simplify</span> <span class="kn">import</span> <span class="n">simplify_wsj_tag</span>

<span class="k">def</span> <span class="nf">get_features</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">words</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c"># Same steps to start as before</span>
    <span class="n">sentences</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">sent_tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">:</span>
        <span class="n">words</span> <span class="o">=</span> <span class="n">words</span> <span class="o">+</span> <span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>

    <span class="c"># part of speech tag each of the words</span>
    <span class="n">pos</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">pos_tag</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>
    <span class="c"># Sometimes it's helpful to simplify the tags <span class="caps">NLTK</span> returns by default.</span>
    <span class="c"># I saw an increase in accuracy if I did this, but you may not</span>
    <span class="c"># depending on the application.</span>
    <span class="n">pos</span> <span class="o">=</span> <span class="p">[</span><span class="n">simplify_wsj_tag</span><span class="p">(</span><span class="n">tag</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">tag</span> <span class="ow">in</span> <span class="n">pos</span><span class="p">]</span>
    <span class="c"># Then, convert the words to lowercase like before</span>
    <span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">words</span><span class="p">]</span>
    <span class="c"># Grab the trigrams</span>
    <span class="n">trigrams</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">trigrams</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>
    <span class="c"># We need to concatinate the trigrams into a single string to process</span>
    <span class="n">trigrams</span> <span class="o">=</span> <span class="p">[</span><span class="s">"</span><span class="si">%s</span><span class="s">/</span><span class="si">%s</span><span class="s">/</span><span class="si">%s</span><span class="s">"</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">i</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">i</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">trigrams</span><span class="p">]</span>
    <span class="c"># Get our final dict rolling</span>
    <span class="n">features</span> <span class="o">=</span> <span class="n">words</span> <span class="o">+</span> <span class="n">pos</span> <span class="o">+</span> <span class="n">trigrams</span>
    <span class="c"># get our feature dict rolling</span>
    <span class="n">features</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">([(</span><span class="n">i</span><span class="p">,</span> <span class="bp">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">features</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">features</span>

<span class="c"># Try it out</span>
<span class="n">text</span> <span class="o">=</span> <span class="s">"Transfer the pan to a wire rack to cool for 15 minutes."</span>
<span class="n">get_features</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="p">{</span><span class="s">'<span class="caps">DET</span>'</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'transfer/the/pan'</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'for/15/minutes'</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'rack/to/cool'</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'wire'</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'wire/rack/to'</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'for'</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'to'</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'transfer'</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'to/a/wire'</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'.'</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'<span class="caps">TO</span>'</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'<span class="caps">NUM</span>'</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'<span class="caps">NP</span>'</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'pan'</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'a/wire/rack'</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'the/pan/to'</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'N'</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'P'</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'pan/to/a'</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'15/minutes/.'</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'cool'</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'a'</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'15'</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'to/cool/for'</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'cool/for/15'</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'the'</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'minutes'</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'rack'</span><span class="p">:</span> <span class="bp">True</span><span class="p">}</span>
</pre></div>
<h2 id="wrapping-it-up">Wrap­ping it up</h2>
<p>Us­ing a com­bin­a­tion of these meth­ods I was able to pull re­cipes out of news stor­ies very suc­cess­fully. To get the clas­si­fi­er work­ing really well you need to train it on a large, ran­dom sample of your data.</p>
<p>I parsed about 10 or 20 re­cords by hand to get star­ted, then cre­ated a small Django app to ran­domly load a re­cord and at­tempt to parse it. I cor­rec­ted the tags that were wrong, saved the cor­rect ver­sion to a data­base, and peri­od­ic­ally re­trained the clas­si­fi­er us­ing the new samples. I ended up with a couple hun­dred parsed re­cords, and the clas­si­fi­er (which has some built-in meth­ods for test­ing) was about 98% ac­cur­ate.</p>
<p>I wrote a pars­ing script that in­cor­por­ated some reg­u­lar ex­pres­sions and a bit of if/else lo­gic to try to tag as much as I could from format­ting, then used <span class="caps">NLTK</span> to tag the rest. After the tag­ging, the story still had to be as­sembled in­to one or more dis­crete re­cipes and loaded in­to a data­base so that hu­mans could re­view them.</p>
<p>That pro­cess was re­l­at­ively straight­for­ward, but I did have to build a cus­tom ad­min for a small group of people to com­pare the ori­gin­al re­cord and parsed out­put side by side. In the end every re­cord had to be re­viewed by hand, and many of them needed one or more small tweaks. Only about one in 20 had struc­tur­al prob­lems. A big thanks to Maloy Moore, Tenny Tatus­i­an and the Food sec­tion staff for comb­ing through all of the re­cords by hand. Com­puters can really only do so much.</p>
<p>If you want to learn more I highly re­com­mend the book <a href="http://nltk.org/book/">Nat­ur­al Lan­guage Pro­cessing with Py­thon</a>, which I read be­fore em­bark­ing on this pro­ject.</p>

                
            
        </div>

        </div></body></html>