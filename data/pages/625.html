<html><body><div><div class="pf-content"><p>Code profiling is an attempt to find bottlenecks in your code. Profiling is supposed to find what parts of your code take the longest. Once you know that, then you can look at those pieces of your code and try to find ways to optimize it. Python comes with three profilers built in: <strong>cProfile</strong>, <strong>profile </strong>and <strong>hotshot</strong>. According to the Python documentation, <strong>hotshot</strong> “no longer maintained and may be dropped in a future version of Python”. The <strong>profile</strong> module is a pure Python module, but adds a lot of overhead to profiled programs. Thus we will be focusing on <strong>cProfile</strong>, which has an interface that mimics the profile module.<span id="more-1336"/></p>
<hr/>
<h3>Profiling Your Code with cProfile</h3>
<p>
</p><p>Profiling code with cProfile is really quite easy. All you need to do is import the module and call its <strong>run</strong> function. Let’s look at a simple example:</p>
<pre class="python"><span>&gt;&gt;&gt;</span> <span>import</span> hashlib
<span>&gt;&gt;&gt;</span> <span>import</span> cProfile
<span>&gt;&gt;&gt;</span> cProfile.<span>run</span><span>(</span><span>"hashlib.md5('abcdefghijkl').digest()"</span><span>)</span>
         <span>4</span> function calls <span>in</span> <span>0.000</span> CPU seconds
 
   Ordered by: standard name
 
   ncalls  tottime  percall  cumtime  percall filename:lineno<span>(</span>function<span>)</span>
        <span>1</span>    <span>0.000</span>    <span>0.000</span>    <span>0.000</span>    <span>0.000</span> <span>&lt;</span>string<span>&gt;</span>:<span>1</span><span>(</span><span>&lt;</span>module<span>&gt;</span><span>)</span>
        <span>1</span>    <span>0.000</span>    <span>0.000</span>    <span>0.000</span>    <span>0.000</span> <span>{</span>_hashlib.<span>openssl_md5</span><span>}</span>
        <span>1</span>    <span>0.000</span>    <span>0.000</span>    <span>0.000</span>    <span>0.000</span> <span>{</span>method <span>'digest'</span> of <span>'_hashlib.HASH'</span> objects<span>}</span>
        <span>1</span>    <span>0.000</span>    <span>0.000</span>    <span>0.000</span>    <span>0.000</span> <span>{</span>method <span>'disable'</span> of <span>'_lsprof.Profiler'</span> objects<span>}</span></pre>
<p>Here we import the <strong>hashlib</strong> module and use cProfile to profile the creation of an MD5 hash. The first line shows that there were 4 function calls. The next line tells us how the results are ordered. According to the documentation, <em>standard name</em> refers to the far right column. There are a number of columns here.</p>
<ul>
<li><strong>ncalls</strong> is the number of calls made. </li>
<li><strong>tottime</strong> is a total of the time spent in the given function. </li>
<li><strong>percall </strong>refers to the quotient of tottime divided by ncalls</li>
<li><strong>cumtime</strong> is the cumulative time spent in this and all subfunctions. It’s even accurate for recursive functions!</li>
<li>The second <strong>percall column</strong> is the quotient of cumtime divided by primitive calls</li>
<li><strong>filename:lineno(function)</strong> provides the respective data of each function</li>
</ul>
<p>A primitive call is one that was not induced via recursion.</p>
<p>This isn’t a very interesting example as there are no obvious bottlenecks. Let’s create a piece of code with some built in bottlenecks and see if the profiler detects them.</p>
<pre class="python"><span>import</span> <span>time</span>
 
<span>#----------------------------------------------------------------------</span>
<span>def</span> fast<span>(</span><span>)</span>:
    <span>""</span><span>""</span><span>""</span>
    <span>print</span><span>(</span><span>"I run fast!"</span><span>)</span>
 
<span>#----------------------------------------------------------------------</span>
<span>def</span> slow<span>(</span><span>)</span>:
    <span>""</span><span>""</span><span>""</span>
    <span>time</span>.<span>sleep</span><span>(</span><span>3</span><span>)</span>
    <span>print</span><span>(</span><span>"I run slow!"</span><span>)</span>
 
<span>#----------------------------------------------------------------------</span>
<span>def</span> medium<span>(</span><span>)</span>:
    <span>""</span><span>""</span><span>""</span>
    <span>time</span>.<span>sleep</span><span>(</span><span>0.5</span><span>)</span>
    <span>print</span><span>(</span><span>"I run a little slowly..."</span><span>)</span>
 
<span>#----------------------------------------------------------------------</span>
<span>def</span> main<span>(</span><span>)</span>:
    <span>""</span><span>""</span><span>""</span>
    fast<span>(</span><span>)</span>
    slow<span>(</span><span>)</span>
    medium<span>(</span><span>)</span>
 
<span>if</span> __name__ == <span>'__main__'</span>:
    main<span>(</span><span>)</span></pre>
<p>In this example, we create four functions. The first three run at different rates. The <strong>fast</strong> function will run at normal speed; the <strong>medium</strong> function will take approximately half a second to run and the <strong>slow</strong> function will take around 3 seconds to run. The <strong>main</strong> function calls the other three. Now let’s run cProfile against this silly little program:</p>
<pre class="python"><span>&gt;&gt;&gt;</span> <span>import</span> cProfile
<span>&gt;&gt;&gt;</span> <span>import</span> ptest
<span>&gt;&gt;&gt;</span> cProfile.<span>run</span><span>(</span><span>'ptest.main()'</span><span>)</span>
I run fast<span>!</span>
I run slow<span>!</span>
I run a little slowly...
         <span>8</span> function calls <span>in</span> <span>3.500</span> seconds
 
   Ordered by: standard name
 
   ncalls  tottime  percall  cumtime  percall filename:lineno<span>(</span>function<span>)</span>
        <span>1</span>    <span>0.000</span>    <span>0.000</span>    <span>3.500</span>    <span>3.500</span> <span>&lt;</span>string<span>&gt;</span>:<span>1</span><span>(</span><span>&lt;</span>module<span>&gt;</span><span>)</span>
        <span>1</span>    <span>0.000</span>    <span>0.000</span>    <span>0.500</span>    <span>0.500</span> ptest.<span>py</span>:<span>15</span><span>(</span>medium<span>)</span>
        <span>1</span>    <span>0.000</span>    <span>0.000</span>    <span>3.500</span>    <span>3.500</span> ptest.<span>py</span>:<span>21</span><span>(</span>main<span>)</span>
        <span>1</span>    <span>0.000</span>    <span>0.000</span>    <span>0.000</span>    <span>0.000</span> ptest.<span>py</span>:<span>4</span><span>(</span>fast<span>)</span>
        <span>1</span>    <span>0.000</span>    <span>0.000</span>    <span>3.000</span>    <span>3.000</span> ptest.<span>py</span>:<span>9</span><span>(</span>slow<span>)</span>
        <span>1</span>    <span>0.000</span>    <span>0.000</span>    <span>0.000</span>    <span>0.000</span> <span>{</span>method <span>'disable'</span> of <span>'_lsprof.Profiler'</span> objects<span>}</span>
        <span>2</span>    <span>3.499</span>    <span>1.750</span>    <span>3.499</span>    <span>1.750</span> <span>{</span><span>time</span>.<span>sleep</span><span>}</span></pre>
<p>This time around we see the program took 3.5 seconds to run. If you examine the results, you will see that cProfile has identified the <strong>slow</strong> function as taking 3 seconds to run. That’s the biggest bottleneck after the <strong>main</strong> function. Normally when you find a bottleneck like this, you would try to find a faster way to execute your code or perhaps decide that the runtime was acceptable. In this example, we know that the best way to speed up the function is to remove the <strong>time.sleep</strong> call or at least reduce the sleep length.</p>
<p>You can also call cProfile on the command line rather than using it in the interpreter. Here’s one way to do it:</p>
<pre class="python">python -m cProfile ptest.<span>py</span></pre>
<p>This will run cProfile against your script in much the same way as we did before. But what if you want to save the profiler’s output? Well, that’s easy with cProfile! All you need to do is pass it the <strong>-o</strong> command followed by the name (or path) of the output file. Here’s an example:</p>
<pre class="python">python -m cProfile -o output.<span>txt</span> ptest.<span>py</span></pre>
<p>Unfortunately, the file it outputs isn’t exactly human-readable. If you want to read the file, then you’ll need to use Python’s <strong>pstats</strong> module. You can use pstats to format the output in various ways. Here’s some code that shows how to get some output that’s similar to what we’ve seen so far:</p>
<pre class="python"><span>&gt;&gt;&gt;</span> <span>import</span> <span>pstats</span>
<span>&gt;&gt;&gt;</span> p = <span>pstats</span>.<span>Stats</span><span>(</span><span>"output.txt"</span><span>)</span>
<span>&gt;&gt;&gt;</span> p.<span>strip_dirs</span><span>(</span><span>)</span>.<span>sort_stats</span><span>(</span><span>-1</span><span>)</span>.<span>print_stats</span><span>(</span><span>)</span>
Thu Mar <span>20</span> <span>18</span>:<span>32</span>:<span>16</span> <span>2014</span>    output.<span>txt</span>
 
         <span>8</span> function calls <span>in</span> <span>3.501</span> seconds
 
   Ordered by: standard name
 
   ncalls  tottime  percall  cumtime  percall filename:lineno<span>(</span>function<span>)</span>
        <span>1</span>    <span>0.000</span>    <span>0.000</span>    <span>3.501</span>    <span>3.501</span> ptest.<span>py</span>:<span>1</span><span>(</span><span>&lt;</span>module<span>&gt;</span><span>)</span>
        <span>1</span>    <span>0.001</span>    <span>0.001</span>    <span>0.500</span>    <span>0.500</span> ptest.<span>py</span>:<span>15</span><span>(</span>medium<span>)</span>
        <span>1</span>    <span>0.000</span>    <span>0.000</span>    <span>3.501</span>    <span>3.501</span> ptest.<span>py</span>:<span>21</span><span>(</span>main<span>)</span>
        <span>1</span>    <span>0.001</span>    <span>0.001</span>    <span>0.001</span>    <span>0.001</span> ptest.<span>py</span>:<span>4</span><span>(</span>fast<span>)</span>
        <span>1</span>    <span>0.001</span>    <span>0.001</span>    <span>3.000</span>    <span>3.000</span> ptest.<span>py</span>:<span>9</span><span>(</span>slow<span>)</span>
        <span>1</span>    <span>0.000</span>    <span>0.000</span>    <span>0.000</span>    <span>0.000</span> <span>{</span>method <span>'disable'</span> of <span>'_lsprof.Profiler'</span> objects<span>}</span>
        <span>2</span>    <span>3.499</span>    <span>1.750</span>    <span>3.499</span>    <span>1.750</span> <span>{</span><span>time</span>.<span>sleep</span><span>}</span>
 
 
<span>&lt;</span>pstats.<span>Stats</span> instance at 0x017C9030<span>&gt;</span></pre>
<p>The <strong>strip_dirs</strong> call will strip out all the paths to the modules from the output while the <strong>sort_stats</strong> call does the sorting that we’re used to seeing. There are a bunch of really interesting examples in the cProfile documentation showing different ways to extract information using the pstats module. </p>
<hr/>
<h3>Wrapping Up</h3>
<p>
</p><p>At this point you should be able to use the cProfile module to help you diagnose why your code is so slow. You might also want to take a look at Python’s <strong>timeit</strong> module. It allows you to time small pieces of your code if you don’t want to deal with the complexities involved with profiling. There are also several other 3rd party modules that are good for profiling such as the <a href="https://pythonhosted.org/line_profiler/" target="_blank">line_profiler</a> and the <a href="https://github.com/fabianp/memory_profiler" target="_blank">memory_profiler</a> projects.</p>
<hr/>
<h3>Related Reading</h3>
<p>
</p>
</div>	</div></body></html>