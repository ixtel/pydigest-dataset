<html><body><div><article class="col-md-10 col-md-offset-1">
            


<p>Time based data can be a pain to work with--Is it a date or a datetime? Are my dates in the right format? Luckily, Python and pandas provide some super helpful utilities for making this easier. In this post, we'll be using pandas and ggplot to analyze time series data.</p>
<h3>Data set</h3>
<p>For these examples, we'll be using the <code><a href="http://www.ers.usda.gov/data-products/livestock-meat-domestic-data.aspx#.UnQf35RgZBA" title="Livestock &amp; Meat Domestic Data" target="_blank">meat</a></code> data set which has been made available to us from the U.S. Dept. of Agriculture. It contains metrics on livestock, dairy, and poultry outlook and production.</p>
<p>You can find the data set in either the <code><a href="https://github.com/yhat/ggplot" title="yhat / ggplot - ggplot for python on github" target="_blank">ggplot</a></code> package or the <code><a href="https://github.com/yhat/pandasql" title="yhat / pandasql - sql for pandas dataframes on github" target="_blank">pandasql</a></code> package, both of which are installed via pip.</p>
<p><code>$ pip install -U ggplot</code></p>
<p><code>$ pip install -U pandasql</code></p>
<pre><code>import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from ggplot import *

meat = meat.dropna(thresh=800, axis=1) # drop columns that have fewer than 800 observations
ts = meat.set_index(['date'])
</code></pre>
<p>Heading our file:</p>
<pre><code>ts.head(10)
</code></pre>
<table border="1" class="dataframe">
  <thead>
    <tr id="tr_309d_0">
      <th/>
      <th>beef</th>
      <th>veal</th>
      <th>pork</th>
      <th>lamb_and_mutton</th>
    </tr>
    <tr>
      <th>date</th>
      <th/>
      <th/>
      <th/>
      <th/>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1944-01-01</th>
      <td> 751</td>
      <td>  85</td>
      <td> 1280</td>
      <td>  89</td>
    </tr>
    <tr>
      <th>1944-02-01</th>
      <td> 713</td>
      <td>  77</td>
      <td> 1169</td>
      <td>  72</td>
    </tr>
    <tr>
      <th>1944-03-01</th>
      <td> 741</td>
      <td>  90</td>
      <td> 1128</td>
      <td>  75</td>
    </tr>
    <tr>
      <th>1944-04-01</th>
      <td> 650</td>
      <td>  89</td>
      <td>  978</td>
      <td>  66</td>
    </tr>
    <tr>
      <th>1944-05-01</th>
      <td> 681</td>
      <td> 106</td>
      <td> 1029</td>
      <td>  78</td>
    </tr>
    <tr>
      <th>1944-06-01</th>
      <td> 658</td>
      <td> 125</td>
      <td>  962</td>
      <td>  79</td>
    </tr>
    <tr>
      <th>1944-07-01</th>
      <td> 662</td>
      <td> 142</td>
      <td>  796</td>
      <td>  82</td>
    </tr>
    <tr>
      <th>1944-08-01</th>
      <td> 787</td>
      <td> 175</td>
      <td>  748</td>
      <td>  87</td>
    </tr>
    <tr>
      <th>1944-09-01</th>
      <td> 774</td>
      <td> 182</td>
      <td>  678</td>
      <td>  91</td>
    </tr>
    <tr>
      <th>1944-10-01</th>
      <td> 834</td>
      <td> 215</td>
      <td>  777</td>
      <td> 100</td>
    </tr>
  </tbody>
</table>

<h3>Working-with-dates-and-times-with-pandas"&gt;Working with dates and times with pandas</h3>
<p><code>pandas</code> has some excellent out of the box functionality for aggregating date and time based data.</p>
<pre><code>ts.groupby(ts.index.year).sum().head(10)
</code></pre>
<table border="1" class="dataframe">
  <thead>
    <tr id="tr_309d_1">
      <th/>
      <th>beef</th>
      <th>veal</th>
      <th>pork</th>
      <th>lamb_and_mutton</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1944</th>
      <td>  8801</td>
      <td> 1629</td>
      <td> 11502</td>
      <td> 1001</td>
    </tr>
    <tr>
      <th>1945</th>
      <td>  9936</td>
      <td> 1552</td>
      <td>  8843</td>
      <td> 1030</td>
    </tr>
    <tr>
      <th>1946</th>
      <td>  9010</td>
      <td> 1329</td>
      <td>  9220</td>
      <td>  946</td>
    </tr>
    <tr>
      <th>1947</th>
      <td> 10096</td>
      <td> 1493</td>
      <td>  8811</td>
      <td>  779</td>
    </tr>
    <tr>
      <th>1948</th>
      <td>  8766</td>
      <td> 1323</td>
      <td>  8486</td>
      <td>  728</td>
    </tr>
    <tr>
      <th>1949</th>
      <td>  9142</td>
      <td> 1240</td>
      <td>  8875</td>
      <td>  587</td>
    </tr>
    <tr>
      <th>1950</th>
      <td>  9248</td>
      <td> 1137</td>
      <td>  9397</td>
      <td>  581</td>
    </tr>
    <tr>
      <th>1951</th>
      <td>  8549</td>
      <td>  972</td>
      <td> 10190</td>
      <td>  508</td>
    </tr>
    <tr>
      <th>1952</th>
      <td>  9337</td>
      <td> 1080</td>
      <td> 10321</td>
      <td>  635</td>
    </tr>
    <tr>
      <th>1953</th>
      <td> 12055</td>
      <td> 1451</td>
      <td>  8971</td>
      <td>  715</td>
    </tr>
  </tbody>
</table>

<p>Since we indexed our data on a datetime column (<code>date</code>), we can group by the year and take the sum over the columns pretty easily.</p>
<p>But what if we're keen to look at the sums over the decades?</p>
<h3>Grouping by decade</h3>
<p>If you're only interested in one or more specific decades, you can accomplish that using the date and time slicing functionality baked-in to <code>pandas</code>. Here we selected a slice of the data corresponding to the 1940s.</p>
<pre><code>the1940s = ts.groupby(ts.index.year).sum().ix['1940-01-01':'1949-12-31']
the1940s
</code></pre>
<table border="1" class="dataframe">
  <thead>
    <tr id="tr_309d_2">
      <th/>
      <th>beef</th>
      <th>veal</th>
      <th>pork</th>
      <th>lamb_and_mutton</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1944</th>
      <td>  8801</td>
      <td> 1629</td>
      <td> 11502</td>
      <td> 1001</td>
    </tr>
    <tr>
      <th>1945</th>
      <td>  9936</td>
      <td> 1552</td>
      <td>  8843</td>
      <td> 1030</td>
    </tr>
    <tr>
      <th>1946</th>
      <td>  9010</td>
      <td> 1329</td>
      <td>  9220</td>
      <td>  946</td>
    </tr>
    <tr>
      <th>1947</th>
      <td> 10096</td>
      <td> 1493</td>
      <td>  8811</td>
      <td>  779</td>
    </tr>
    <tr>
      <th>1948</th>
      <td>  8766</td>
      <td> 1323</td>
      <td>  8486</td>
      <td>  728</td>
    </tr>
    <tr>
      <th>1949</th>
      <td>  9142</td>
      <td> 1240</td>
      <td>  8875</td>
      <td>  587</td>
    </tr>
  </tbody>
</table>

<p>Then you could just sum the column or columns you're interested in to get the total for the decade you're looking at.</p>
<p>But what if you need to look at <i>all the decades</i>?</p>
<p>One quick way is to use Python's unambiguous <a href="http://stackoverflow.com/a/1282954/359786" title="Python integer division yields float" target="_blank">floor division operator</a>, <code>//</code> .</p>
<pre><code>def floor_decade(date_value):
    "Takes a date. Returns the decade."
    return (date_value.year // 10) * 10

pd.to_datetime('2013-10-09')
</code></pre>
<p>Result:</p>
<pre><code>Timestamp(&amp;apos;2013-10-09 00:00:00&amp;apos;, tz=None)
</code></pre>
<p>Running our function:</p>
<pre><code>floor_decade(_)
</code></pre>
<p>We get:</p>
<pre><code>2010
</code></pre>
<p>Voil√†!
Now we can just apply the <code>floor_decade</code> over the dates like so:</p>
<pre><code>ts.groupby(floor_decade).sum()
</code></pre>
<table border="1" class="dataframe">
  <thead>
    <tr id="tr_309d_3">
      <th/>
      <th>beef</th>
      <th>veal</th>
      <th>pork</th>
      <th>lamb_and_mutton</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1940</th>
      <td>  55751.0</td>
      <td>  8566.0</td>
      <td>  55737.0</td>
      <td> 5071.0</td>
    </tr>
    <tr>
      <th>1950</th>
      <td> 119161.0</td>
      <td> 12693.0</td>
      <td>  98450.0</td>
      <td> 6724.0</td>
    </tr>
    <tr>
      <th>1960</th>
      <td> 177754.0</td>
      <td>  8577.0</td>
      <td> 116587.0</td>
      <td> 6873.0</td>
    </tr>
    <tr>
      <th>1970</th>
      <td> 228947.0</td>
      <td>  5713.0</td>
      <td> 132539.0</td>
      <td> 4256.0</td>
    </tr>
    <tr>
      <th>1980</th>
      <td> 230100.0</td>
      <td>  4278.0</td>
      <td> 150528.0</td>
      <td> 3394.0</td>
    </tr>
    <tr>
      <th>1990</th>
      <td> 243579.0</td>
      <td>  2938.0</td>
      <td> 173519.0</td>
      <td> 2986.0</td>
    </tr>
    <tr>
      <th>2000</th>
      <td> 260540.7</td>
      <td>  1685.3</td>
      <td> 208211.3</td>
      <td> 1964.7</td>
    </tr>
    <tr>
      <th>2010</th>
      <td>  76391.5</td>
      <td>   371.9</td>
      <td>  66491.2</td>
      <td>  455.6</td>
    </tr>
  </tbody>
</table>

<pre><code>the1940s.sum().reset_index(name='meat sums in the 1940s')
</code></pre>
<table border="1" class="dataframe">
  <thead>
    <tr id="tr_309d_4">
      <th/>
      <th>index</th>
      <th>meat sums in the 1940s</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>            beef</td>
      <td> 55751</td>
    </tr>
    <tr>
      <th>1</th>
      <td>            veal</td>
      <td>  8566</td>
    </tr>
    <tr>
      <th>2</th>
      <td>            pork</td>
      <td> 55737</td>
    </tr>
    <tr>
      <th>3</th>
      <td> lamb_and_mutton</td>
      <td>  5071</td>
    </tr>
  </tbody>
</table>

<p>And just to sanity check, we see that the numbers tie out the same no matter which of these approaches you take.</p>
<pre><code>by_decade = ts.groupby(floor_decade).sum()

by_decade.index.name = 'year'

by_decade = by_decade.reset_index()

ggplot(by_decade, aes('year', weight='beef')) + \
    geom_bar() + \
    scale_y_continuous(labels='comma') + \
    ggtitle('Head of Cattle Slaughtered by Decade')
</code></pre>
<p><img alt="" src="../static/img/cattle_by_decade.png"/></p>
<p>Things are starting to make sense. Now how might we better inspect the trends we're seeing over time? Well one way we could do it is by using the same bar chart as before, but stacking the values for each type of livestock.</p>
<pre><code>by_decade_long = pd.melt(by_decade, id_vars="year")

ggplot(aes(x='year', weight='value', colour='variable'), data=by_decade_long) + \
geom_bar() + \
ggtitle("Meat Production by Decade")
</code></pre>
<p><img alt="" src="../static/img/meat_bar.png"/></p>
<p>For all you <code>ggplot2</code> fans wondering why we didn't do a stacked bar chart--don't worry! It's coming in a release in the not so distant future.</p>
<h3>Trends over time</h3>
<p>For our last plot we're going to jump back a little bit. Instead of looking at the data in aggregate, we're going to take another approach to making sense of our time series data. We're going to bring the original <code>meat</code> dataset back into the mix so we can take a look at all of our livestock varieties.</p>
<pre><code>from ggplot import meat
meat_lng = pd.melt(meat, id_vars=['date'])
ggplot(aes(x='date', y='value', colour='variable'), data=meat_lng) + geom_line()
</code></pre>
<p><img alt="" src="../static/img/meat_crowded_line.png"/></p>
<p>Ok so this plot looks a bit cluttered. We've got way too much zigging and zagging. Sure the colors are nice, but it's a bit overwhelming.
Instead of getting rid of our data, we're going to apply a smoothing function so that we'll see the <strong>trend</strong> instead of the <strong>noise</strong>.</p>
<pre><code>ggplot(aes(x='date', y='value', colour='variable'), data=meat_lng) + \
    stat_smooth(span=0.10) + \
    ggtitle("Smoothed Livestock Production")
</code></pre>
<p><img alt="" src="../static/img/meat_smoothed_line.png"/></p>
<p>Ahh, much better. This plot I can actually make sense of. You can see that chicken production has been growing quickly since the late 1950's, and that sometime in late 1970s/early 1980s it overtook pork production, and a few years later it overtook beef production.</p>
<p>We're still working out some of the kinks in <code>stat_smooth</code>, but you can see that it's already an incredibly useful function. If you're interested in helping build <code>ggplot</code> for Python, drop us a note at <a href="info@yhathq.com">info@yhathq.com</a>! We'd love to hear from you.</p>

        </article>
    </div></body></html>