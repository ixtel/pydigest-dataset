<html><body><div><div class="section">
              <h1>Flintrock 0.3.0</h1>

              


<p>A command-line tool for launching Apache Spark clusters.</p>








<div>
<img src="https://raw.githubusercontent.com/nchammas/flintrock/master/flintrock-logo.png"/>
<p>Flintrock logo</p>
</div>
<p><a href="https://github.com/nchammas/flintrock/blob/master/LICENSE" rel="nofollow"><img src="https://img.shields.io/badge/license-Apache%202.0-blue.svg"/>
</a> <a href="https://travis-ci.org/nchammas/flintrock" rel="nofollow"><img src="https://img.shields.io/travis/nchammas/flintrock.svg"/>
</a> <a href="https://gitter.im/nchammas/flintrock" rel="nofollow"><img src="https://img.shields.io/gitter/room/nchammas/flintrock.svg"/>
</a></p>
<p>Flintrock is a command-line tool for launching <a href="http://spark.apache.org/" rel="nofollow">Apache
Spark</a> clusters.</p>
<p><strong>Flintrock is currently undergoing heavy development. Until we make a
1.0 release, you probably should not use Flintrock unless you are ready
to keep up with frequent changes to how it works.</strong> Python hackers or
heavy spark-ec2 users who are looking to experiment with something new
are welcome to try Flintrock out and potentially even
<a href="https://github.com/nchammas/flintrock/blob/master/CONTRIBUTING.md" rel="nofollow">contribute</a>.</p>
<div id="usage">
<h2>Usage</h2>
<p>Here’s a quick way to launch a cluster on EC2, assuming you already have
an <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/get-set-up-for-amazon-ec2.html" rel="nofollow">AWS account set
up</a>.</p>
<pre>flintrock launch test-cluster <span class="se">\
</span>    --num-slaves <span class="m">1</span> <span class="se">\
</span>    --spark-version 1.6.0 <span class="se">\
</span>    --ec2-key-name key_name <span class="se">\
</span>    --ec2-identity-file /path/to/key.pem <span class="se">\
</span>    --ec2-ami ami-60b6c60a <span class="se">\
</span>    --ec2-user ec2-user
</pre>
<p>If you <a href="#configurable-cli-defaults" rel="nofollow">persist these options to a file</a>,
you’ll be able to do the same thing simply by typing:</p>
<pre>flintrock launch test-cluster
</pre>
<p>Once you’re done using a cluster, don’t forget to destroy it with:</p>
<pre>flintrock destroy test-cluster
</pre>
<p>Other things you can do with Flintrock include:</p>
<pre>flintrock login test-cluster
flintrock describe test-cluster
flintrock run-command test-cluster <span class="s1">'sudo yum install -y package'</span>
flintrock copy-file test-cluster /local/path /remote/path
</pre>
<p>To see what else Flintrock can do, or to see detailed help for a
specific command, try:</p>
<pre>flintrock --help
flintrock &lt;subcommand&gt; --help
</pre>
<p>That’s not all. Flintrock has a few more <a href="#features" rel="nofollow">features</a> that
you may find interesting.</p>
</div>
<div id="installation">
<h2>Installation</h2>
<p>Before using Flintrock, take a quick look at the
<a href="https://github.com/nchammas/flintrock/blob/master/COPYRIGHT" rel="nofollow">copyright</a>
notice and
<a href="https://github.com/nchammas/flintrock/blob/master/LICENSE" rel="nofollow">license</a>
and make sure you’re OK with their terms.</p>
<p><strong>Flintrock requires Python 3.4 or newer</strong>, unless you are using one of
our <strong>standalone packages</strong>. Flintrock has been thoroughly tested only
on OS X, but it should run on all POSIX systems. We have plans to <a href="https://github.com/nchammas/flintrock/issues/46" rel="nofollow">add
Windows support</a> in
the future, too.</p>
<div id="release-version">
<h3>Release version</h3>
<p>To get the latest release of Flintrock, simply run
<a href="https://pip.pypa.io/en/stable/" rel="nofollow">pip</a>:</p>
<pre>pip3 install flintrock
</pre>
<p>This will install Flintrock and place it on your path. You should be
good to go now!</p>
<p>You’ll probably want to get started with the following two commands:</p>
<pre>flintrock --help
flintrock configure
</pre>
</div>
<div id="standalone-version-python-not-required">
<h3>Standalone version (Python not required!)</h3>
<p>If you don’t have a recent enough version of Python, or if you don’t
have Python installed at all, you can still use Flintrock. We publish
standalone packages of Flintrock on GitHub with our
<a href="https://github.com/nchammas/flintrock/releases" rel="nofollow">releases</a>.</p>
<p>Find the standalone package for your OS under our <a href="https://github.com/nchammas/flintrock/releases/latest" rel="nofollow">latest
release</a>,
unzip it to a location of your choice, and run the <tt>flintrock</tt>
executable inside.</p>
<p>For example:</p>
<pre>curl --location --remote-name <span class="s2">"https://github.com/nchammas/flintrock/releases/download/v0.3.0/flintrock-0.3.0-OSX-x86_64.zip"</span>
unzip -q -d flintrock <span class="s2">"flintrock-0.3.0-OSX-x86_64.zip"</span>
<span class="nb">cd</span> flintrock/

<span class="c1"># You're good to go!
</span>./flintrock --help
</pre>
<p>You’ll probably want to add the location of the Flintrock executable to
your <tt>PATH</tt> so that you can invoke it from any directory.</p>
</div>
<div id="development-version">
<h3>Development version</h3>
<p>If you like living on the edge, install the development version of
Flintrock:</p>
<pre>pip3 install git+https://github.com/nchammas/flintrock
</pre>
<p>If you want to
<a href="https://github.com/nchammas/flintrock/blob/master/CONTRIBUTING.md" rel="nofollow">contribute</a>,
follow the instructions in our contributing guide on <a href="https://github.com/nchammas/flintrock/blob/master/CONTRIBUTING.md#contributing-code" rel="nofollow">how to install
Flintrock</a>.</p>
</div>
</div>
<div id="use-cases">
<h2>Use Cases</h2>
<div id="experimentation">
<h3>Experimentation</h3>
<p>If you want to play around with Spark, develop a prototype application,
run a one-off job, or otherwise just experiment, Flintrock is the
fastest way to get you a working Spark cluster.</p>
</div>
<div id="performance-testing">
<h3>Performance testing</h3>
<p>Flintrock exposes many options of its underlying providers (e.g.
EBS-optimized volumes on EC2) which makes it easy to create a cluster
with predictable performance for <a href="https://github.com/databricks/spark-perf" rel="nofollow">Spark performance
testing</a>.</p>
</div>
<div id="automated-pipelines">
<h3>Automated pipelines</h3>
<p>Most people will use Flintrock interactively from the command line, but
Flintrock is also designed to be used as part of an automated pipeline.
Flintrock’s exit codes are carefully chosen; it offers options to
disable interactive prompts; and when appropriate it prints output in
YAML, which is both human- and machine-friendly.</p>
</div>
</div>
<div id="anti-use-cases">
<h2>Anti-Use Cases</h2>
<p>There are some things that Flintrock specifically <em>does not</em> support.</p>
<div id="managing-permanent-infrastructure">
<h3>Managing permanent infrastructure</h3>
<p>Flintrock is not for managing long-lived clusters, or any infrastructure
that serves as a permanent part of some environment.</p>
<p>For starters, Flintrock provides no guarantee that clusters launched
with one version of Flintrock can be managed by another version of
Flintrock, and no considerations are made for any long-term use cases.</p>
<p>If you are looking for ways to manage permanent infrastructure, look at
tools like <a href="https://www.terraform.io/" rel="nofollow">Terraform</a>,
<a href="http://www.ansible.com/" rel="nofollow">Ansible</a>,
<a href="http://saltstack.com/" rel="nofollow">SaltStack</a>, or <a href="http://www.ubuntu.com/cloud/tools/juju" rel="nofollow">Ubuntu
Juju</a>. You might also find a
service like <a href="https://databricks.com/product/databricks" rel="nofollow">Databricks</a>
useful if you’re looking for someone else to host and manage Spark for
you. Amazon also offers <a href="https://aws.amazon.com/elasticmapreduce/details/spark/" rel="nofollow">Spark on
EMR</a>.</p>
</div>

<div id="launching-out-of-date-services">
<h3>Launching out-of-date services</h3>
<p>Flintrock will always take advantage of new features of Spark and
related services to make the process of launching a cluster faster,
simpler, and easier to maintain. If that means dropping support for
launching older versions of a service, then we will generally make that
tradeoff.</p>
</div>
</div>
<div id="features">
<h2>Features</h2>
<div id="polished-cli">
<h3>Polished CLI</h3>
<p>Flintrock has a clean command-line interface.</p>
<pre>flintrock --help
flintrock describe
flintrock destroy --help
flintrock launch test-cluster --num-slaves 10
</pre>
</div>
<div id="configurable-cli-defaults">
<h3>Configurable CLI Defaults</h3>
<p>Flintrock lets you persist your desired configuration to a YAML file so
that you don’t have to keep typing out the same options over and over at
the command line.</p>
<p>To setup and edit the default config file, call <tt>flintrock configure</tt>.
You can also point Flintrock to a non-default config file by using the
<tt><span class="pre">--config</span></tt> option.</p>
<div id="sample-config-yaml">
<h4>Sample <tt>config.yaml</tt></h4>
<pre><span class="l-Scalar-Plain">provider</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">ec2</span>

<span class="l-Scalar-Plain">services</span><span class="p-Indicator">:</span>
  <span class="l-Scalar-Plain">spark</span><span class="p-Indicator">:</span>
    <span class="l-Scalar-Plain">version</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">1.6.0</span>

<span class="l-Scalar-Plain">launch</span><span class="p-Indicator">:</span>
  <span class="l-Scalar-Plain">num-slaves</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">1</span>

<span class="l-Scalar-Plain">ec2</span><span class="p-Indicator">:</span>
  <span class="l-Scalar-Plain">key-name</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">key_name</span>
  <span class="l-Scalar-Plain">identity-file</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">/path/to/.ssh/key.pem</span>
  <span class="l-Scalar-Plain">instance-type</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">m3.medium</span>
  <span class="l-Scalar-Plain">region</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">us-east-1</span>
  <span class="l-Scalar-Plain">ami</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">ami-60b6c60a</span>
  <span class="l-Scalar-Plain">user</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">ec2-user</span>
</pre>
<p>With a config file like that, you can now launch a cluster with just
this:</p>
<pre>flintrock launch test-cluster
</pre>
<p>And if you want, you can even override individual options in your config
file at the command line:</p>
<pre>flintrock launch test-cluster <span class="se">\
</span>    --num-slaves <span class="m">10</span> <span class="se">\
</span>    --ec2-instance-type r3.xlarge
</pre>
</div>
</div>
<div id="fast-launches">
<h3>Fast Launches</h3>
<p>Flintrock is really fast. This is how quickly it can launch fully
operational clusters on EC2 compared to
<a href="https://spark.apache.org/docs/latest/ec2-scripts.html" rel="nofollow">spark-ec2</a>.</p>
<div id="setup">
<h4>Setup</h4>
<ul>
<li>Provider: EC2</li>
<li>Instance type: <tt>m3.large</tt></li>
<li>AMI:
</li>
<li>Launch time: Best of 6 tries</li>
</ul>
</div>
<div id="results">
<h4>Results</h4>
<table>
<colgroup>
<col/>
<col/>
<col/>
</colgroup>
<thead>
<tr><th>Cluster Size</th>
<th>Flintrock Launch Time</th>
<th>spark-ec2 Launch Time</th>
</tr>
</thead>
<tbody>
<tr><td>1 slave</td>
<td>2m 06s</td>
<td>8m 44s</td>
</tr>
<tr><td>50 slaves</td>
<td>2m 30s</td>
<td>37m 30s</td>
</tr>
<tr><td>100 slaves</td>
<td>2m 42s</td>
<td>1h 06m 05s</td>
</tr>
</tbody>
</table>
<p>The spark-ec2 launch times are sourced from
<a href="https://issues.apache.org/jira/browse/SPARK-5189" rel="nofollow">SPARK-5189</a>.</p>
<p>Note that AWS performance is highly variable, so you will not get these
results consistently. They show the best case scenario for each tool,
and not the typical case. For Flintrock, the typical launch time will be
a minute or two longer.</p>
</div>
</div>
<div id="advanced-storage-setup">
<h3>Advanced Storage Setup</h3>
<p>Flintrock automatically configures any available <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html" rel="nofollow">ephemeral
storage</a>
on the cluster and makes it available to installed services like HDFS
and Spark. This storage is fast and is perfect for use as a temporary
store by those services.</p>
</div>
<div id="tests">
<h3>Tests</h3>
<p>Flintrock comes with a set of automated, end-to-end
<a href="https://github.com/nchammas/flintrock/tree/master/tests" rel="nofollow">tests</a>.
These tests help us develop Flintrock with confidence and guarantee a
certain level of quality.</p>
</div>
<div id="low-level-provider-options">
<h3>Low-level Provider Options</h3>
<p>Flintrock exposes low-level provider options (e.g. <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/terminating-instances.html#Using_ChangingInstanceInitiatedShutdownBehavior" rel="nofollow">instance-initiated
shutdown
behavior</a>)
so you can control the details of how your cluster is setup if you want.</p>
</div>
<div id="no-custom-machine-image-dependencies">
<h3>No Custom Machine Image Dependencies</h3>
<p>Flintrock is built and tested against vanilla Amazon Linux and CentOS.
You can easily launch Flintrock clusters using your own custom machine
images built from either of those distributions.</p>
</div>
</div>
<div id="anti-features">
<h2>Anti-Features</h2>
<h2 id="support-for-out-of-date-versions-of-python-ec2-apis-etc"><span class="section-subtitle">Support for out-of-date versions of Python, EC2 APIs, etc.</span></h2>
<p>Supporting multiple versions of anything is tough. There’s more surface
area to cover for testing, and over the long term the maintenance burden
of supporting something non-current with bug fixes and workarounds
really adds up.</p>
<p>There are projects that support stuff across a wide cut of language or
API versions. For example, Spark supports Java 7 and 8, and Python 2.6+
and 3+. The people behind these projects are gods. They take on an
immense maintenance burden for the benefit and convenience of their
users.</p>
<p>We here at project Flintrock are much more modest in our abilities. We
are best able to serve the project over the long term when we limit
ourselves to supporting a small but widely applicable set of
configurations.</p>
</div>
<div id="motivation">
<h2>Motivation</h2>
<p><em>Note: The explanation here is provided from the perspective of
Flintrock’s original author, Nicholas Chammas.</em></p>
<p>I got started with Spark by using
<a href="http://spark.apache.org/docs/latest/ec2-scripts.html" rel="nofollow">spark-ec2</a>.
It’s one of the biggest reasons I found Spark so accessible. I didn’t
need to spend time upfront working through some setup guide before I
could work on a “real” problem. Instead, with a simple spark-ec2 command
I was able to launch a large, working cluster and get straight to
business.</p>
<p>As I became a heavy user of spark-ec2, several limitations stood out and
became an increasing pain. They provided me with the motivation for this
project.</p>
<p>Among those limitations are:</p>
<ul>
<li><strong>Slow launches</strong>: spark-ec2 cluster launch times increase linearly
with the number of slaves being created. For example, it takes
spark-ec2 <strong>`over an
hour &lt;https://issues.apache.org/jira/browse/SPARK-5189&gt;`__</strong> to
launch a cluster with 100 slaves.
(<a href="https://issues.apache.org/jira/browse/SPARK-4325" rel="nofollow">SPARK-4325</a>,
<a href="https://issues.apache.org/jira/browse/SPARK-5189" rel="nofollow">SPARK-5189</a>)</li>
<li><strong>No support for configuration files</strong>: spark-ec2 does not support
reading options from a config file, so users are always forced to
type them in at the command line.
(<a href="https://issues.apache.org/jira/browse/SPARK-925" rel="nofollow">SPARK-925</a>)</li>
<li><strong>Un-resizable clusters</strong>: Adding or removing slaves from an existing
spark-ec2 cluster is not possible.
(<a href="https://issues.apache.org/jira/browse/SPARK-2008" rel="nofollow">SPARK-2008</a>)</li>
<li><strong>Custom machine images</strong>: spark-ec2 uses custom machine images, and
since the process of updating those machine images is not automated,
they have not been updated in years.
(<a href="https://issues.apache.org/jira/browse/SPARK-3821" rel="nofollow">SPARK-3821</a>)</li>
<li><strong>Unexposed EC2 options</strong>: spark-ec2 does not expose all the EC2
options one would want to use as part of automated performance
testing of Spark.
(<a href="https://issues.apache.org/jira/browse/SPARK-6220" rel="nofollow">SPARK-6220</a>)</li>
<li><strong>Poor support for programmatic use cases</strong>: spark-ec2 was not built
with programmatic use in mind, so many flows are difficult or
impossible to automate.
(<a href="https://issues.apache.org/jira/browse/SPARK-5627" rel="nofollow">SPARK-5627</a>,
<a href="https://issues.apache.org/jira/browse/SPARK-5629" rel="nofollow">SPARK-5629</a>)</li>
<li><strong>No standalone distribution</strong>: spark-ec2 comes bundled with Spark
and has no independent releases or distribution. Instead of being a
nimble tool that can progress independently and be installed
separately, it is tied to Spark’s release cycle and distributed with
Spark, which clocks in at a few hundred megabytes.</li>
</ul>
<p>Flintrock addresses, or will address, all of these shortcomings.</p>
</div>



<a name="downloads"> </a>


<ul class="nodot">
  <li><strong>Downloads (All Versions):</strong></li>
  <li>
    <span>0</span> downloads in the last day
  </li>
  <li>
    <span>170</span> downloads in the last week
  </li>
  <li>
    <span>1040</span> downloads in the last month
  </li>
</ul>









            </div>


          </div></body></html>