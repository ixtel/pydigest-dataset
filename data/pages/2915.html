<html><body><div><div class="entry-content">
                
                <p>Here you can see a <a href="https://vimeo.com/117667330">video of how to scrape 260 keywords on Bing in very short time</a>. Sorry for the bad english and the stuttering. It is my first video :D</p>
<h2>Introduction</h2>
<p>In the following article we will show the awesome speed of <a href="https://github.com/NikolaiT/GoogleScraper">GoogleScraper</a> by trying to scrape 260 keywords in a second and outputting the data in JSON format.</p>
<h2>The preparation</h2>
<p>First we need our 260 keywords. For this, I opened the wikipedia page with a list of best selling books in the overall history of humanity. You can see the list yourself <a href="http://en.wikipedia.org/wiki/List_of_best-selling_books">here</a>.</p>
<p>Then I extracted the books with a small jQuery script that I wrote in a <a href="http://scrapeulous.com/googlescraper-market-analysis.html">previous arcticle</a> (Notice to myself: <strong>Very good</strong>, you actually reused a small snippet of code and saved 10 minutes) and prepended <strong>buy </strong> to every book title. The list then looks something like this:</p>
<div class="highlight"><pre>buy A Tale of Two Cities
buy The Lord of the Rings
buy The Little Prince
buy Harry Potter and the Philosopher's Stone
buy And Then There Were None
buy Dream of the Red Chamber
buy The Hobbit
buy She: A History of Adventure
buy The Lion, the Witch and the Wardrobe
buy The Da Vinci Code
buy Think and Grow Rich
buy Harry Potter and the Half-Blood Prince
buy The Catcher in the Rye
buy The Alchemist
buy Harry Potter and the Chamber of Secrets
buy Harry Potter and the Prisoner of Azkaban
buy Harry Potter and the Goblet of Fire
buy Harry Potter and the Order of the Phoenix
buy Harry Potter and the Deathly Hallows
buy One Hundred Years of Solitude

(... many more books ...)
</pre></div>


<p>Then you need to save the keywords somewhere, I saved my list in the file <em>/tmp/books.txt</em>.</p>
<h2>Installing GoogleScraper</h2>
<p>Because I explained this step already quite a few times, I will skip it and just mention that I have a rather good description of how to install it on the <a href="https://github.com/NikolaiT/GoogleScraper#installation">Github Page</a>. If you are on a linux system, it probably works out of the box if you fire this command in your shell:</p>
<div class="highlight"><pre>pip install GoogleScraper
</pre></div>


<p>But note that GoogleScraper is writen in Python 3.4. So use the 3 version of pip.</p>
<h2>The scraping</h2>
<p>Now lets to the fun thing. Switch to the directory where you saved your file with the 260 keywords and enter the following command in a shell:</p>
<div class="highlight"><pre>GoogleScraper --version
0.1.20
</pre></div>


<p>The version should be at least <strong>0.1.20</strong>. If you have the correct vesion, then we can begin the asynchronous scrape. Note that we will scrape the search engine <em>Bing</em>. In the second example we try the same with <em>Google</em>. </p>
<div class="highlight"><pre>GoogleScraper -m http-async --keyword-file books.txt -s bing -o bing_results.json --verbosity 2
</pre></div>


<p><strong>BAAAM!!!</strong>.
In my case, because my internet is really shitty, I had to wait 10 seconds. But after just 10 seconds and using only one IP address, this is what GoogleScraper spitted out: <a href="http://scrapeulous.com/txt/bing_results.json">bing_results.json output file</a>. 1.5 Megabyte of json data. 260*10=2600 unique links. And a ton of metadata to analyze. Gathered just within very small time (Note that if you have a better internet connection as mine, which is probably the case, you have the results in one second).</p>
<p>Now we try the same with Google. </p>
<div class="highlight"><pre>nikolai@nikolai:~/Projects/private/GoogleScraper<span class="nv">$ </span>GoogleScraper -m http-async --keyword-file /tmp/books.txt -s google -o google_results.json --verbosity 3
2015-01-24 14:27:37,986 - GoogleScraper - INFO - Continuing last scrape.
2015-01-24 14:27:37,989 - GoogleScraper - INFO - <span class="m">0</span> cache files found in .scrapecache/
2015-01-24 14:27:37,989 - GoogleScraper - INFO - 0/257 objects have been <span class="nb">read </span>from the cache. <span class="m">257</span> remain to get scraped.
2015-01-24 14:27:37,990 - GoogleScraper - INFO - Going to scrape <span class="m">257</span> keywords with <span class="m">1</span> proxies by using <span class="m">1</span> threads.
2015-01-24 14:27:40,234 - GoogleScraper - INFO - <span class="o">[</span>+<span class="o">]</span> localhost requested keyword <span class="s1">'buy Jonathan Livingston Seagull'</span> on google. Response status: 503
2015-01-24 14:27:40,234 - GoogleScraper - INFO - <span class="o">[</span>i<span class="o">]</span> URL: https://www.google.com/search?num<span class="o">=</span>50<span class="p">&amp;</span><span class="nv">start</span><span class="o">=</span>1<span class="p">&amp;</span><span class="nv">q</span><span class="o">=</span>buy+Jonathan+Livingston+Seagull HEADERS: <span class="o">{</span><span class="s1">'Accept'</span>: <span class="s1">'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'</span>, <span class="s1">'Accept-Encoding'</span>: <span class="s1">'gzip, deflate'</span>, <span class="s1">'Accept-Language'</span>: <span class="s1">'en-US,en;q=0.5'</span>, <span class="s1">'Connection'</span>: <span class="s1">'keep-alive'</span><span class="o">}</span>
2015-01-24 14:27:40,246 - GoogleScraper - INFO - <span class="o">[</span>+<span class="o">]</span> localhost requested keyword <span class="s1">'buy Harry Potter and the Goblet of Fire'</span> on google. Response status: 503
2015-01-24 14:27:40,247 - GoogleScraper - INFO - <span class="o">[</span>i<span class="o">]</span> URL: https://www.google.com/search?num<span class="o">=</span>50<span class="p">&amp;</span><span class="nv">start</span><span class="o">=</span>1<span class="p">&amp;</span><span class="nv">q</span><span class="o">=</span>buy+Harry+Potter+and+the+Goblet+of+Fire HEADERS: <span class="o">{</span><span class="s1">'Accept'</span>: <span class="s1">'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'</span>, <span class="s1">'Accept-Encoding'</span>: <span class="s1">'gzip, deflate'</span>, <span class="s1">'Accept-Language'</span>: <span class="s1">'en-US,en;q=0.5'</span>, <span class="s1">'Connection'</span>: <span class="s1">'keep-alive'</span><span class="o">}</span>
2015-01-24 14:27:40,257 - GoogleScraper - INFO - <span class="o">[</span>+<span class="o">]</span> localhost requested keyword <span class="s1">'buy Calico Cat Holmes series'</span> on google. Response status: 503
2015-01-24 14:27:40,258 - GoogleScraper - INFO - <span class="o">[</span>i<span class="o">]</span> URL: https://www.google.com/search?num<span class="o">=</span>50<span class="p">&amp;</span><span class="nv">start</span><span class="o">=</span>1<span class="p">&amp;</span><span class="nv">q</span><span class="o">=</span>buy+Calico+Cat+Holmes+series HEADERS: <span class="o">{</span><span class="s1">'Accept'</span>: <span class="s1">'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'</span>, <span class="s1">'Accept-Encoding'</span>: <span class="s1">'gzip, deflate'</span>, <span class="s1">'Accept-Language'</span>: <span class="s1">'en-US,en;q=0.5'</span>, <span class="s1">'Connection'</span>: <span class="s1">'keep-alive'</span><span class="o">}</span>
2015-01-24 14:27:40,268 - GoogleScraper - INFO - <span class="o">[</span>+<span class="o">]</span> localhost requested keyword <span class="s1">'buy Star Wars'</span> on google. Response status: 503
2015-01-24 14:27:40,268 - GoogleScraper - INFO - <span class="o">[</span>i<span class="o">]</span> URL: https://www.google.com/search?num<span class="o">=</span>50<span class="p">&amp;</span><span class="nv">start</span><span class="o">=</span>1<span class="p">&amp;</span><span class="nv">q</span><span class="o">=</span>buy+Star+Wars HEADERS: <span class="o">{</span><span class="s1">'Accept'</span>: <span class="s1">'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'</span>, <span class="s1">'Accept-Encoding'</span>: <span class="s1">'gzip, deflate'</span>, <span class="s1">'Accept-Language'</span>: <span class="s1">'en-US,en;q=0.5'</span>, <span class="s1">'Connection'</span>: <span class="s1">'keep-alive'</span><span class="o">}</span>
</pre></div>


<p>But we see that we always get the <strong>Response status: 503</strong>. So Google blocks us immediately.</p>
<h2>Conclusion</h2>
<p>This is a <strong>serious bug in Bing</strong>, because we can scrape as much data in a very very short time, without getting banned. Just think about this: With a good connection, you can easily process 5000 keywords in a second. This is a hell of a lot. Google on the other hand blocks us very fast and we run into an 503 server error (solving an stupid catpcha).</p>
<p>Now what you want to do with it is up to you. But stay responsible and <strong>give credits to where it belongs :D</strong></p>
            </div>
            
        </div></body></html>