<html><body><div><article>
          <h1/>

          <p>When writing a web application or REST backend I occasionally run into a<br/>
common problem: sometimes I need to do things that will take a while: sending a<br/>
push notification to mobile apps, generating emails or doing an expensive<br/>
calculation. Doing this immediately would result in very long response times,<br/>
which is not acceptable. That means I need a way to offload those to something<br/>
else. This is where task queues come in: they allow you to submit a task for<br/>
out-of-band processing. There are multiple tools that do this, but all of them<br/>
suffer from one or more design flaws that makek them harder to use in non-trivial<br/>
systems. This document tries to address a few requirements and looks at how<br/>
existing frameworks try to address them.</p>

<p>The examples use Pyramid, but the problems are generic and apply to all<br/>
frameworks.</p>

<h2 id="global-configuration">Global configuration</h2>

<p>A common fallacy is requiring the configuration to be defined globally before<br/>
you can define a task. Here is an example from<br/>
<a href="http://www.celeryproject.org/">Celery</a>:</p>

<pre><code class="language-python">from celery import Celery

app = Celery('tasks', broker='amqp://guest@localhost//')

@app.task
def add(x, y):
    return x + y

add.delay(4, 4)
</code></pre>

<p>or the <a href="http://python-rq.org/">rq</a> version (note that this style is optional with rq)</p>

<pre><code class="language-python">from rq.decorators import job

@job('low', connection=my_redis_conn, timeout=5)
def add(x, y):
    return x + y
</code></pre>

<p>This pattern makes it almost impossible to make your application configurable:<br/>
it requires your connection details to be set on a global before you can import<br/>
any code that defines a task, which will quickly lead to complex import depenedencies<br/>
and can be impossible with some frameworks. A better approach is be to decouple<br/>
configuration from the task definition. For example (from rq again):</p>

<pre><code>def add(x, y):
    return x + y

redis_conn = Redis()
q = Queue(connection=redis_conn)  # no args implies the default queue
job = q.enqueue(add, 4, 4)
</code></pre>

<h2 id="transparency">Transparency</h2>

<p>When you write an expensive function that you want to delay, you also want<br/>
to be able to call it immediately in some situations, for example when you<br/>
call it from another function that is itself delayed. Building on our example<br/>
we might want to call <code>add</code> directly from a new <code>add_and_multiply</code> function.</p>

<pre><code class="language-python">def add(x, y):
    reeturn x + y


def add_and_multiple(x, y):
    return (add(x, y), x ** y))  # Do not delay this call to add
</code></pre>

<p>There should also not be any requirements on function naming. Celery has<br/>
a problem here: it does not allow you to define two tasks with the same<br/>
name in different modules. If you do this:</p>

<pre><code class="language-python"># view1.py
@task()
def send_mail():
    pass

# view2.py
@task()
def send_mail()
    pass
</code></pre>

<p>If you call <code>view2.send_mail</code> Celery will happily run ``view1.send_mail`<br/>
instead without telling you.</p>

<h2 id="task-context">Task context</h2>

<p>Tasks commonly expect to run within a configured environment, similar to how<br/>
tests often require a fixture: a working database connection, a transaction<br/>
manager, application configuration available, etc. There are three types<br/>
of context to distinguish:</p>

<ul>
  <li>Global state you can load once, for example application configuration.</li>
  <li>Per-process state that has to be initialised for every new process. Things<br/>
like database connections fall in this category. For an application using<br/>
Pyramid you would call<br/>
<a href="http://docs.pylonsproject.org/projects/pyramid/en/latest/api/paster.html#pyramid.paster.bootstrap">pyramid.paster.bootstrap</a><br/>
to set this up.</li>
  <li>Per-task state. Common examples of this are running each task in a separate<br/>
transaction and managing thread-local variables.</li>
</ul>

<p>For task context you may need more control to be able to cleanly handle<br/>
exceptions or job teardown. As an example to run a task in a transaction you<br/>
may want to use something like this:</p>

<pre><code class="language-python">import transaction

def transaction_state(func):
    with transaction.manager as tx:
        result = func()
	tx.commit()
	return result

worker.add_task_state_handler(transaction_state)
</code></pre>

<p>A concept like <a href="http://docs.pylonsproject.org/projects/pyramid/en/latest/narr/hooks.html#registering-tweens">Pyramidâ€™s<br/>
tweens</a><br/>
may be useful here.</p>

<p>Celery seems to be the only framework which tries to address this with its<br/>
<a href="http://docs.celeryproject.org/en/latest/userguide/signals.html">signals</a><br/>
mechanism.</p>

<h2 id="parameter-handling">Parameter handling</h2>

<p>When calling an expensive function that must be run out-of-process I do not<br/>
want to have to worry about what parameters I can safely pass to it. For<br/>
example if I am using <a href="http://sqlalchemy.org">SQLAlchemy</a> I want to be able to<br/>
just pass an ORM instance to a function. The system should automatically detect<br/>
that so it can flush any state out to the SQL server or abort if the object is<br/>
dirty, and before running my function in a worker process merge the instances<br/>
into the current session. This is some pseudo-code for a Pyramid view to register<br/>
new users:</p>

<pre><code class="language-python">def send_welcome_mail(user):
    """Generate and send a welcome email to a new user.
    """


@view_config('register', renderer='welcome.pt')
def register_user(request):
    user = User(email=request.params['email'])
    DBSession.add(user)
    request.registry['task-queue'].submit(send_welcome_mail, user)
    return {'user': user}
</code></pre>

<p>This is also useful to allow passing requests. A standard request has many things<br/>
such as open file handles and a copy of the request body that you can now safely<br/>
transfer to a task queue, but you do want to transfer any data over that is needed<br/>
to generate URLs with the right scheme, hostname and port. To make this transparent<br/>
that requires stripping a request down before queueing the task, and recreating<br/>
it before running the task.</p>

<pre><code class="language-python">def send_push_message(request, device_token):
    site_url = request.route_url('news')
    message = Message([device_token],
        alert='Our website has been updated. Please visit %s' % site_url)
    apn_server.submit(message)


@view_config('publish', renderer='publish.pt')
def publish_page(request):
    ....
    request.registry['task-queue'].submit(send_push_message, user.token)
    return {}
</code></pre>

<p><a href="https://www.maltheborch.com">Malthe Borch</a> pointed out using a <code>__reduce__</code><br/>
method can help here. He uses <a href="https://gist.github.com/malthe/b03cad86c4f9c4382045">this<br/>
snippet</a> to handle<br/>
pickling of SQLAlchemy instances. None of the existing frameworks try to address this.</p>

<h2 id="transaction-integration">Transaction integration</h2>

<p>When writing a function to register new users I submit a task for later processing<br/>
to generate a welcome email for the new user. But what if I hit a critical error<br/>
after submitting that task that causes the new user not be created in my database?<br/>
In that situations the task needs to be aborted before it has a chance to run. This<br/>
requires integration of the task queue with the transaction manager.</p>

<p>The example below has a critical error which causes the transaction to be aborted.<br/>
In that case the transaction will be aborted and the user will be shown an error,<br/>
so it would be very confusing if the welcome email was still send.</p>

<pre><code class="language-python">@view_config('register', renderer='welcome.pt')
def register_user(request):
    user = User(email=request.params['email'])
    DBSession.add(user)
    request.registry['task-queue'].submit(send_welcome_mail, user)
    return {'user': usr}  # Code error: usr is undefined
</code></pre>

<p>Sometimes you may need to return a task id to the user so he can come back later<br/>
to fetch a result. This requires two-phase commit support from the task queue so<br/>
it can allocate a task id before submitting the task.</p>

<pre><code class="language-python">@view_config('rest-call', renderer='json')
def rest_call(request):
    # Schedule an expensive function
    task = request.registry['task-queue'].submit(expensive_function)
    # Tell client to check the task status in 10 seconds.
    request.response.status_int = 202
    request.headers['Location'[ = request.route_url('task-status', task_id=task.id)
    return {'task': task.id, 'delay': 10}
</code></pre>

<p>None of the existing frameworks try to address this.</p>




        </article>
        </div></body></html>