<html><body><div><article id="post-84" class="post post-84 type-post status-publish format-standard hentry category-technology tag-code tag-crawler tag-python">
		

	
		
		
		<p class="date-author">
			
			Posted on August 12, 2015
						by <a class="author-link" href="http://blog.webhose.io/author/gevaran/" rel="author">
				Ran Geva			</a>
			
		</p>
		
		
		
		
		






		<p>If you need a simple web crawler that will scour the web for a while to download random site’s content – this code is for you.</p>
<p>Usage:</p>
<pre><code>$ python tinyDirtyIffyGoodEnoughWebCrawler.py http://cnn.com</code></pre>
<p>Where http://cnn.com is your seed site. It could be any site that contains content and links to other sites.</p>
<p>My colleagues described this piece of code I wrote as “Dirty”, “Iffy”, “Bad”, “Not very good”. I say, it gets the job done and downloads thousands of pages from multiple pages in a matter of hours. No setup is required, no external imports, just run the following python code with a seed site and sit back (or go do something else because it could take a few hours, or days depending on how much data you need).</p>
<p><span>tinyDirtyIffyGoodEnoughWebCrawler.py</span></p>
<pre><code>import sys, thread, Queue, re, urllib, urlparse, time, os, sys
dupcheck = set()  
q = Queue.Queue(100) 
q.put(sys.argv[1]) 
def queueURLs(html, origLink): 
    for url in re.findall('''&lt;a[^&gt;]+href=["'](.[^"']+)["']''', html, re.I): 
        link = url.split("#", 1)[0] if url.startswith("http") else '{uri.scheme}://{uri.netloc}'.format(uri=urlparse.urlparse(origLink)) + url.split("#", 1)[0] 
        if link in dupcheck:
            continue
        dupcheck.add(link)
        if len(dupcheck) &gt; 99999: 
            dupcheck.clear()
        q.put(link) 
def getHTML(link): 
    try:
        html = urllib.urlopen(link).read() 
        open(str(time.time()) + ".html", "w").write("" % link  + "n" + html) 
        queueURLs(html, link) 
    except (KeyboardInterrupt, SystemExit): 
        raise
    except Exception:
        pass
while True:
    thread.start_new_thread( getHTML, (q.get(),)) 
    time.sleep(0.5)
</code></pre>
<p>Features:</p>
<ul>
<li>Multi-threaded – for fastness</li>
<li>Duplication elimination (kinda) – for link uniqueness</li>
<li>Saves both source and its link – for the purpose it was built</li>
<li>FREE</li>
</ul>
<p>Enjoy,</p>
<p>Ran</p>
<span class="et_bloom_bottom_trigger"/>	
	</article>
	
	
	
	
            
      
      
      
      
      
       </div></body></html>