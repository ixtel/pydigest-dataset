<html><body><div><div class="section" id="type-definition-syntax">
   
   <p>
    The syntax leverages
    <a class="reference external" href="/dev/peps/pep-3107">
     PEP 3107
    </a>
    -style annotations with a number of
extensions described in sections below.  In its basic form, type
hinting is used by filling function annotation slots with classes:
   </p>
   <pre class="literal-block">
def greeting(name: str) -&gt; str:
    return 'Hello ' + name
</pre>
   <p>
    This states that the expected type of the
    <tt class="docutils literal">
     name
    </tt>
    argument is
    <tt class="docutils literal">
     str
    </tt>
    .  Analogically, the expected return type is
    <tt class="docutils literal">
     str
    </tt>
    .
   </p>
   <p>
    Expressions whose type is a subtype of a specific argument type are
also accepted for that argument.
   </p>
   <div class="section" id="acceptable-type-hints">
    
    <p>
     Type hints may be built-in classes (including those defined in
standard library or third-party extension modules), abstract base
classes, types available in the
     <tt class="docutils literal">
      types
     </tt>
     module, and user-defined
classes (including those defined in the standard library or
third-party modules).
    </p>
    <p>
     While annotations are normally the best format for type hints,
there are times when it is more appropriate to represent them
by a special comment, or in a separately distributed stub
file.  (See below for examples.)
    </p>
    <p>
     Annotations must be valid expressions that evaluate without raising
exceptions at the time the function is defined (but see below for
forward references).
    </p>
    <p>
     Annotations should be kept simple or static analysis tools may not be
able to interpret the values. For example, dynamically computed types
are unlikely to be understood.  (This is an
intentionally somewhat vague requirement, specific inclusions and
exclusions may be added to future versions of this PEP as warranted by
the discussion.)
    </p>
    <p>
     In addition to the above, the following special constructs defined
below may be used:
     <tt class="docutils literal">
      None
     </tt>
     ,
     <tt class="docutils literal">
      Any
     </tt>
     ,
     <tt class="docutils literal">
      Union
     </tt>
     ,
     <tt class="docutils literal">
      Tuple
     </tt>
     ,
     <tt class="docutils literal">
      Callable
     </tt>
     , all ABCs and stand-ins for concrete classes exported
from
     <tt class="docutils literal">
      typing
     </tt>
     (e.g.
     <tt class="docutils literal">
      Sequence
     </tt>
     and
     <tt class="docutils literal">
      Dict
     </tt>
     ), type variables, and
type aliases.
    </p>
    <p>
     All newly introduced names used to support features described in
following sections (such as
     <tt class="docutils literal">
      Any
     </tt>
     and
     <tt class="docutils literal">
      Union
     </tt>
     ) are available in
the
     <tt class="docutils literal">
      typing
     </tt>
     module.
    </p>
   </div>
   <div class="section" id="using-none">
    
    <p>
     When used in a type hint, the expression
     <tt class="docutils literal">
      None
     </tt>
     is considered
equivalent to
     <tt class="docutils literal">
      type(None)
     </tt>
     .
    </p>
   </div>
   <div class="section" id="type-aliases">
    
    <p>
     Type aliases are defined by simple variable assignments:
    </p>
    <pre class="literal-block">
Url = str

def retry(url: Url, retry_count: int) -&gt; None: ...
</pre>
    <p>
     Note that we recommend capitalizing alias names, since they represent
user-defined types, which (like user-defined classes) are typically
spelled that way.
    </p>
    <p>
     Type aliases may be as complex as type hints in annotations --
anything that is acceptable as a type hint is acceptable in a type
alias:
    </p>
    <pre class="literal-block">
from typing import TypeVar, Iterable, Tuple

T = TypeVar('T', int, float, complex)
Vector = Iterable[Tuple[T, T]]

def inproduct(v: Vector) -&gt; T:
    return sum(x*y for x, y in v)
</pre>
    <p>
     This is equivalent to:
    </p>
    <pre class="literal-block">
from typing import TypeVar, Iterable, Tuple

T = TypeVar('T', int, float, complex)

def inproduct(v: Iterable[Tuple[T, T]]) -&gt; T:
    return sum(x*y for x, y in v)
</pre>
   </div>
   <div class="section" id="callable">
    
    <p>
     Frameworks expecting callback functions of specific signatures might be
type hinted using
     <tt class="docutils literal">
      <span class="pre">
       Callable[[Arg1Type,
      </span>
      Arg2Type], ReturnType]
     </tt>
     .
Examples:
    </p>
    <pre class="literal-block">
from typing import Callable

def feeder(get_next_item: Callable[[], str]) -&gt; None:
    # Body

def async_query(on_success: Callable[[int], None],
                on_error: Callable[[int, Exception], None]) -&gt; None:
    # Body
</pre>
    <p>
     It is possible to declare the return type of a callable without
specifying the call signature by substituting a literal ellipsis
(three dots) for the list of arguments:
    </p>
    <pre class="literal-block">
def partial(func: Callable[..., str], *args) -&gt; Callable[..., str]:
    # Body
</pre>
    <p>
     Note that there are no square brackets around the ellipsis.  The
arguments of the callback are completely unconstrained in this case
(and keyword arguments are acceptable).
    </p>
    <p>
     Since using callbacks with keyword arguments is not perceived as a
common use case, there is currently no support for specifying keyword
arguments with
     <tt class="docutils literal">
      Callable
     </tt>
     .  Similarly, there is no support for
specifying callback signatures with a variable number of argument of a
specific type.
    </p>
    <p>
     Because
     <tt class="docutils literal">
      typing.Callable
     </tt>
     does double-duty as a replacement for
     <tt class="docutils literal">
      collections.abc.Callable
     </tt>
     ,
     <tt class="docutils literal">
      isinstance(x, typing.Callable)
     </tt>
     is
implemented by deferring to
     <tt class="docutils literal">
      `isinstance(x, collections.abc.Callable)
     </tt>
     .
However,
     <tt class="docutils literal">
      isinstance(x,
      <span class="pre">
       typing.Callable[...])
      </span>
     </tt>
     is not supported.
    </p>
   </div>
   <div class="section" id="generics">
    
    <p>
     Since type information about objects kept in containers cannot be
statically inferred in a generic way, abstract base classes have been
extended to support subscription to denote expected types for container
elements.  Example:
    </p>
    <pre class="literal-block">
from typing import Mapping, Set

def notify_by_email(employees: Set[Employee], overrides: Mapping[str, str]) -&gt; None: ...
</pre>
    <p>
     Generics can be parametrized by using a new factory available in
     <tt class="docutils literal">
      typing
     </tt>
     called
     <tt class="docutils literal">
      TypeVar
     </tt>
     .  Example:
    </p>
    <pre class="literal-block">
from typing import Sequence, TypeVar

T = TypeVar('T')      # Declare type variable

def first(l: Sequence[T]) -&gt; T:   # Generic function
    return l[0]
</pre>
    <p>
     In this case the contract is that the returned value is consistent with
the elements held by the collection.
    </p>
    <p>
     A
     <tt class="docutils literal">
      TypeVar()
     </tt>
     expression must always directly be assigned to a
variable (it should not be used as part of a larger expression).  The
argument to
     <tt class="docutils literal">
      TypeVar()
     </tt>
     must be a string equal to the variable name
to which it is assigned.  Type variables must not be redefined.
    </p>
    <p>
     <tt class="docutils literal">
      TypeVar
     </tt>
     supports constraining parametric types to a fixed set of
possible types.  For example, we can define a type variable that ranges
over just
     <tt class="docutils literal">
      str
     </tt>
     and
     <tt class="docutils literal">
      bytes
     </tt>
     .  By default, a type variable ranges
over all possible types.  Example of constraining a type variable:
    </p>
    <pre class="literal-block">
from typing import TypeVar

AnyStr = TypeVar('AnyStr', str, bytes)

def concat(x: AnyStr, y: AnyStr) -&gt; AnyStr:
    return x + y
</pre>
    <p>
     The function
     <tt class="docutils literal">
      concat
     </tt>
     can be called with either two
     <tt class="docutils literal">
      str
     </tt>
     arguments
or two
     <tt class="docutils literal">
      bytes
     </tt>
     arguments, but not with a mix of
     <tt class="docutils literal">
      str
     </tt>
     and
     <tt class="docutils literal">
      bytes
     </tt>
     arguments.
    </p>
    <p>
     There should be at least two constraints, if any; specifying a single
constraint is disallowed.
    </p>
    <p>
     Subtypes of types constrained by a type variable should be treated
as their respective explicitly listed base types in the context of the
type variable.  Consider this example:
    </p>
    <pre class="literal-block">
class MyStr(str): ...

x = concat(MyStr('apple'), MyStr('pie'))
</pre>
    <p>
     The call is valid but the type variable
     <tt class="docutils literal">
      AnyStr
     </tt>
     will be set to
     <tt class="docutils literal">
      str
     </tt>
     and not
     <tt class="docutils literal">
      MyStr
     </tt>
     . In effect, the inferred type of the return
value assigned to
     <tt class="docutils literal">
      x
     </tt>
     will also be
     <tt class="docutils literal">
      str
     </tt>
     .
    </p>
    <p>
     Additionally,
     <tt class="docutils literal">
      Any
     </tt>
     is a valid value for every type variable.
Consider the following:
    </p>
    <pre class="literal-block">
def count_truthy(elements: List[Any]) -&gt; int:
    return sum(1 for elem in elements if element)
</pre>
    <p>
     This is equivalent to omitting the generic notation and just saying
     <tt class="docutils literal">
      elements: List
     </tt>
     .
    </p>
   </div>
   <div class="section" id="user-defined-generic-types">
    
    <p>
     You can include a
     <tt class="docutils literal">
      Generic
     </tt>
     base class to define a user-defined class
as generic.  Example:
    </p>
    <pre class="literal-block">
from typing import TypeVar, Generic

T = TypeVar('T')

class LoggedVar(Generic[T]):
    def __init__(self, value: T, name: str, logger: Logger) -&gt; None:
        self.name = name
        self.logger = logger
        self.value = value

    def set(self, new: T) -&gt; None:
        self.log('Set ' + repr(self.value))
        self.value = new

    def get(self) -&gt; T:
        self.log('Get ' + repr(self.value))
        return self.value

    def log(self, message: str) -&gt; None:
        self.logger.info('{}: {}'.format(self.name message))
</pre>
    <p>
     <tt class="docutils literal">
      Generic[T]
     </tt>
     as a base class defines that the class
     <tt class="docutils literal">
      LoggedVar
     </tt>
     takes a single type parameter
     <tt class="docutils literal">
      T
     </tt>
     . This also makes
     <tt class="docutils literal">
      T
     </tt>
     valid as
a type within the class body.
    </p>
    <p>
     The
     <tt class="docutils literal">
      Generic
     </tt>
     base class uses a metaclass that defines
     <tt class="docutils literal">
      __getitem__
     </tt>
     so that
     <tt class="docutils literal">
      LoggedVar[t]
     </tt>
     is valid as a type:
    </p>
    <pre class="literal-block">
from typing import Iterable

def zero_all_vars(vars: Iterable[LoggedVar[int]]) -&gt; None:
    for var in vars:
        var.set(0)
</pre>
    <p>
     A generic type can have any number of type variables, and type variables
may be constrained. This is valid:
    </p>
    <pre class="literal-block">
from typing import TypeVar, Generic
...

T = TypeVar('T')
S = TypeVar('S')

class Pair(Generic[T, S]):
    ...
</pre>
    <p>
     Each type variable argument to
     <tt class="docutils literal">
      Generic
     </tt>
     must be distinct. This is
thus invalid:
    </p>
    <pre class="literal-block">
from typing import TypeVar, Generic
...

T = TypeVar('T')

class Pair(Generic[T, T]):   # INVALID
    ...
</pre>
    <p>
     You can use multiple inheritance with
     <tt class="docutils literal">
      Generic
     </tt>
     :
    </p>
    <pre class="literal-block">
from typing import TypeVar, Generic, Sized

T = TypeVar('T')

class LinkedList(Sized, Generic[T]):
    ...
</pre>
    <p>
     Subclassing a generic class without specifying type parameters assumes
     <tt class="docutils literal">
      Any
     </tt>
     for each position.  In the following example,
     <tt class="docutils literal">
      MyIterable
     </tt>
     is not generic but implicitly inherits from
     <tt class="docutils literal">
      Iterable[Any]
     </tt>
     :
    </p>
    <pre class="literal-block">
from typing import Iterable

class MyIterable(Iterable):  # Same as Iterable[Any]
    ...
</pre>
    <p>
     Generic metaclasses are not supported.
    </p>
   </div>
   <div class="section" id="instantiating-generic-classes-and-type-erasure">
    
    <p>
     Generic types like
     <tt class="docutils literal">
      List
     </tt>
     or
     <tt class="docutils literal">
      Sequence
     </tt>
     cannot be instantiated.
However, user-defined classes derived from them can be instantiated.
Suppose we write a
     <tt class="docutils literal">
      Node
     </tt>
     class inheriting from
     <tt class="docutils literal">
      Generic[T]
     </tt>
     :
    </p>
    <pre class="literal-block">
from typing import TypeVar, Generic

T = TypeVar('T')

class Node(Generic[T]):
    ...
</pre>
    <p>
     Now there are two ways we can instantiate this class; the type
inferred by a type checker may be different depending on the form we
use.  The first way is to give the value of the type parameter
explicitly -- this overrides whatever type inference the type
checker would otherwise perform:
    </p>
    <pre class="literal-block">
x = Node[T]()  # The type inferred for x is Node[T].

y = Node[int]()  # The type inferred for y is Node[int].
</pre>
    <p>
     If no explicit types are given, the type checker is given some
freedom. Consider this code:
    </p>
    <pre class="literal-block">
x = Node()
</pre>
    <p>
     The inferred type could be
     <tt class="docutils literal">
      Node[Any]
     </tt>
     , as there isn't enough
context to infer a more precise type.  Alternatively, a type checker
may reject the line and require an explicit annotation, like this:
    </p>
    <pre class="literal-block">
x = Node()  # type: Node[int]  # Inferred type is Node[int].
</pre>
    <p>
     A type checker with more powerful type inference could look at how
     <tt class="docutils literal">
      x
     </tt>
     is used elsewhere in the file and try to infer a more precise
type such as
     <tt class="docutils literal">
      Node[int]
     </tt>
     even without an explicit type annotation.
However, it is probably impossible to make such type inference work
well in all cases, since Python programs can be very dynamic.
    </p>
    <p>
     This PEP doesn't specify the details of how type inference should
work.  We allow different tools to experiment with various approaches.
We may give more explicit rules in future revisions.
    </p>
    <p>
     At runtime the type is not preserved, and the class of
     <tt class="docutils literal">
      x
     </tt>
     is just
     <tt class="docutils literal">
      Node
     </tt>
     in all cases.  This behavior is called "type erasure"; it is
common practice in languages with generics (e.g. Java, TypeScript).
    </p>
   </div>
   <div class="section" id="arbitrary-generic-types-as-base-classes">
    
    <p>
     <tt class="docutils literal">
      Generic[T]
     </tt>
     is only valid as a base class -- it's not a proper type.
However, user-defined generic types such as
     <tt class="docutils literal">
      LinkedList[T]
     </tt>
     from the
above example and built-in generic types and ABCs such as
     <tt class="docutils literal">
      List[T]
     </tt>
     and
     <tt class="docutils literal">
      Iterable[T]
     </tt>
     are valid both as types and as base classes. For
example, we can define a subclass of
     <tt class="docutils literal">
      Dict
     </tt>
     that specializes type
arguments:
    </p>
    <pre class="literal-block">
from typing import Dict, List, Optional

class Node:
    ...

class SymbolTable(Dict[str, List[Node]]):
    def push(self, name: str, node: Node) -&gt; None:
        self.setdefault(name, []).append(node)

    def pop(self, name: str) -&gt; Node:
        return self[name].pop()

    def lookup(self, name: str) -&gt; Optional[Node]:
        nodes = self.get(name)
        if nodes:
            return nodes[-1]
        return None
</pre>
    <p>
     <tt class="docutils literal">
      SymbolTable
     </tt>
     is a subclass of
     <tt class="docutils literal">
      dict
     </tt>
     and a subtype of
     <tt class="docutils literal">
      Dict[str,
List[Node]]
     </tt>
     .
    </p>
    <p>
     If a generic base class has a type variable as a type argument, this
makes the defined class generic. For example, we can define a generic
     <tt class="docutils literal">
      LinkedList
     </tt>
     class that is iterable and a container:
    </p>
    <pre class="literal-block">
from typing import TypeVar, Iterable, Container

T = TypeVar('T')

class LinkedList(Iterable[T], Container[T]):
    ...
</pre>
    <p>
     Now
     <tt class="docutils literal">
      LinkedList[int]
     </tt>
     is a valid type. Note that we can use
     <tt class="docutils literal">
      T
     </tt>
     multiple times in the base class list, as long as we don't use the
same type variable
     <tt class="docutils literal">
      T
     </tt>
     multiple times within
     <tt class="docutils literal">
      <span class="pre">
       Generic[...]
      </span>
     </tt>
     .
    </p>
    <p>
     Also consider the following example:
    </p>
    <pre class="literal-block">
from typing import TypeVar, Mapping

T = TypeVar('T')

class MyDict(Mapping[str, T]):
    ...
</pre>
    <p>
     In this case MyDict has a single parameter, T.
    </p>
   </div>
   <div class="section" id="abstract-generic-types">
    
    <p>
     The metaclass used by
     <tt class="docutils literal">
      Generic
     </tt>
     is a subclass of
     <tt class="docutils literal">
      abc.ABCMeta
     </tt>
     .
A generic class can be an ABC by including abstract methods
or properties, and generic classes can also have ABCs as base
classes without a metaclass conflict.
    </p>
   </div>
   <div class="section" id="type-variables-with-an-upper-bound">
    
    <p>
     A type variable may specify an upper bound using
     <tt class="docutils literal">
      <span class="pre">
       bound=&lt;type&gt;
      </span>
     </tt>
     .
This means that an actual type substituted (explicitly or implictly)
for the type variable must be a subclass of the boundary type.  A
common example is the definition of a Comparable type that works well
enough to catch the most common errors:
    </p>
    <pre class="literal-block">
from typing import TypeVar

class Comparable(metaclass=ABCMeta):
    @abstractmethod
    def __lt__(self, other: Any) -&gt; bool: ...
    ... # __gt__ etc. as well

CT = TypeVar('CT', bound=Comparable)

def min(x: CT, y: CT) -&gt; CT:
    if x &lt; y:
        return x
    else:
        return y

min(1, 2) # ok, return type int
min('x', 'y') # ok, return type str
</pre>
    <p>
     (Note that this is not ideal -- for example
     <tt class="docutils literal">
      <span class="pre">
       min('x',
      </span>
      1)
     </tt>
     is invalid
at runtime but a type checker would simply infer the return type
     <tt class="docutils literal">
      Comparable
     </tt>
     .  Unfortunately, addressing this would require
introducing a much more powerful and also much more complicated
concept, F-bounded polymorphism.  We may revisit this in the future.)
    </p>
    <p>
     An upper bound cannot be combined with type constraints (as in used
     <tt class="docutils literal">
      AnyStr
     </tt>
     , see the example earlier); type constraints cause the
inferred type to be _exactly_ one of the constraint types, while an
upper bound just requires that the actual type is a subclass of the
boundary type.
    </p>
   </div>
   <div class="section" id="covariance-and-contravariance">
    
    <p>
     Consider a class
     <tt class="docutils literal">
      Employee
     </tt>
     with a subclass
     <tt class="docutils literal">
      Manager
     </tt>
     .  Now
suppose we have a function with an argument annotated with
     <tt class="docutils literal">
      List[Employee]
     </tt>
     .  Should we be allowed to call this function with a
variable of type
     <tt class="docutils literal">
      List[Manager]
     </tt>
     as its argument?  Many people would
answer "yes, of course" without even considering the consequences.
But unless we know more about the function, a type checker should
reject such a call: the function might append an
     <tt class="docutils literal">
      Employee
     </tt>
     instance
to the list, which would violate the variable's type in the caller.
    </p>
    <p>
     It turns out such an argument acts _contravariantly_, whereas the
intuitive answer (which is correct in case the function doesn't mutate
its argument!) requires the argument to act _covariantly_.  A longer
introduction to these concepts can be found on Wikipedia
     <a class="citation-reference" href="#wiki-variance" id="id3">
      [wiki-variance]
     </a>
     ; here we just show how to control a type checker's
behavior.
    </p>
    <p>
     By default type variables are considered _invariant_, which means that
arguments for arguments annotated with types like
     <tt class="docutils literal">
      List[Employee]
     </tt>
     must exactly match the type annotation -- no subclasses or
superclasses of the type parameter (in this example
     <tt class="docutils literal">
      Employee
     </tt>
     ) are
allowed.
    </p>
    <p>
     To facilitate the declaration of container types where covariant type
checking is acceptable, a type variable can be declared using
     <tt class="docutils literal">
      covariant=True
     </tt>
     .  For the (rare) case where contravariant behavior
is desirable, pass
     <tt class="docutils literal">
      contravariant=True
     </tt>
     .  At most one of these may
be passed.
    </p>
    <p>
     A typical example involves defining an immutable (or read-only)
container class:
    </p>
    <pre class="literal-block">
from typing import TypeVar, Generic, Iterable, Iterator

T = TypeVar('T', covariant=True)

class ImmutableList(Generic[T]):
    def __init__(self, items: Iterable[T]) -&gt; None: ...
    def __iter__(self) -&gt; Iterator[T]: ...
    ...

class Employee: ...

class Manager(Employee): ...

def dump_employees(emps: ImmutableList[Employee]) -&gt; None:
    for emp in emps:
        ...

mgrs = ImmutableList([Manager()])  # type: ImmutableList[Manager]
dump_employees(mgrs)  # OK
</pre>
    <p>
     The read-only collection classes in
     <tt class="docutils literal">
      typing
     </tt>
     are all defined using a
covariant type variable (e.g.
     <tt class="docutils literal">
      Mapping
     </tt>
     and
     <tt class="docutils literal">
      Sequence
     </tt>
     ).  The
mutable collection classes (e.g.
     <tt class="docutils literal">
      MutableMapping
     </tt>
     and
     <tt class="docutils literal">
      MutableSequence
     </tt>
     ) are defined using regular invariant type
variables.  The one example of a contravariant type variable is the
     <tt class="docutils literal">
      Generator
     </tt>
     type, which is contravariant in the
     <tt class="docutils literal">
      send()
     </tt>
     argument
type (see below).
    </p>
    <p>
     Note: variance affects type parameters for generic types -- it does
not affect regular parameters.  For example, the following example is
fine:
    </p>
    <pre class="literal-block">
from typing import TypeVar

class Employee: ...

class Manager(Employee): ...

E = TypeVar('E', bound=Employee)  # Invariant

def dump_employee(e: E) -&gt; None: ...

dump_employee(Manager())  # OK
</pre>
   </div>
   <div class="section" id="the-numeric-tower">
    
    <p>
     <a class="reference external" href="/dev/peps/pep-3141">
      PEP 3141
     </a>
     defines Python's numeric tower, and the stdlib module
     <tt class="docutils literal">
      numbers
     </tt>
     implements the corresponding ABCs (
     <tt class="docutils literal">
      Number
     </tt>
     ,
     <tt class="docutils literal">
      Complex
     </tt>
     ,
     <tt class="docutils literal">
      Real
     </tt>
     ,
     <tt class="docutils literal">
      Rational
     </tt>
     and
     <tt class="docutils literal">
      Integral
     </tt>
     ).  There are some
issues with these ABCs, but the built-in concrete numeric classes
     <tt class="docutils literal">
      complex
     </tt>
     ,
     <tt class="docutils literal">
      float
     </tt>
     and
     <tt class="docutils literal">
      int
     </tt>
     are ubiquitous (especially the
latter two :-).
    </p>
    <p>
     Rather than requiring that users write
     <tt class="docutils literal">
      import numbers
     </tt>
     and then use
     <tt class="docutils literal">
      numbers.Float
     </tt>
     etc., this PEP proposes a straightforward shortcut
that is almost as effective: when an argument is annotated as having
type
     <tt class="docutils literal">
      float
     </tt>
     , an argument of type
     <tt class="docutils literal">
      int
     </tt>
     is acceptable; similar,
for an argument annotated as having type
     <tt class="docutils literal">
      complex
     </tt>
     , arguments of
type
     <tt class="docutils literal">
      float
     </tt>
     or
     <tt class="docutils literal">
      int
     </tt>
     are acceptable.  This does not handle
classes implementing the corresponding ABCs or the
     <tt class="docutils literal">
      fractions.Fraction
     </tt>
     class, but we believe those use cases are
exceedingly rare.
    </p>
   </div>
   <div class="section" id="the-bytes-types">
    
    <p>
     There are three different builtin classes used for arrays of bytes
(not counting the classes available in the
     <tt class="docutils literal">
      array
     </tt>
     module):
     <tt class="docutils literal">
      bytes
     </tt>
     ,
     <tt class="docutils literal">
      bytearray
     </tt>
     and
     <tt class="docutils literal">
      memoryview
     </tt>
     .  Of these,
     <tt class="docutils literal">
      bytes
     </tt>
     and
     <tt class="docutils literal">
      bytearray
     </tt>
     have many behaviors in common (though not all --
     <tt class="docutils literal">
      bytearray
     </tt>
     is mutable).
    </p>
    <p>
     While there is an ABC
     <tt class="docutils literal">
      ByteString
     </tt>
     defined in
     <tt class="docutils literal">
      collections.abc
     </tt>
     and a corresponding type in
     <tt class="docutils literal">
      typing
     </tt>
     , functions accepting bytes (of
some form) are so common that it would be cumbersome to have to write
     <tt class="docutils literal">
      typing.ByteString
     </tt>
     everywhere.  So, as a shortcut similar to that
for the builtin numeric classes, when an argument is annotated as
having type
     <tt class="docutils literal">
      bytes
     </tt>
     , arguments of type
     <tt class="docutils literal">
      bytearray
     </tt>
     or
     <tt class="docutils literal">
      memoryview
     </tt>
     are acceptable.  (Again, there are situations where
this isn't sound, but we believe those are exceedingly rare in
practice.)
    </p>
   </div>
   <div class="section" id="forward-references">
    
    <p>
     When a type hint contains names that have not been defined yet, that
definition may be expressed as a string literal, to be resolved later.
    </p>
    <p>
     A situation where this occurs commonly is the definition of a
container class, where the class being defined occurs in the signature
of some of the methods.  For example, the following code (the start of
a simple binary tree implementation) does not work:
    </p>
    <pre class="literal-block">
class Tree:
    def __init__(self, left: Tree, right: Tree):
        self.left = left
        self.right = right
</pre>
    <p>
     To address this, we write:
    </p>
    <pre class="literal-block">
class Tree:
    def __init__(self, left: 'Tree', right: 'Tree'):
        self.left = left
        self.right = right
</pre>
    <p>
     The string literal should contain a valid Python expression (i.e.,
     <tt class="docutils literal">
      compile(lit, '', 'eval')
     </tt>
     should be a valid code object) and it
should evaluate without errors once the module has been fully loaded.
The local and global namespace in which it is evaluated should be the
same namespaces in which default arguments to the same function would
be evaluated.
    </p>
    <p>
     Moreover, the expression should be parseable as a valid type hint, i.e.,
it is constrained by the rules from the section
     <a class="reference internal" href="#acceptable-type-hints">
      Acceptable type hints
     </a>
     above.
    </p>
    <p>
     It is allowable to use string literals as
     <em>
      part
     </em>
     of a type hint, for
example:
    </p>
    <pre class="literal-block">
class Tree:
    ...
    def leaves(self) -&gt; List['Tree']:
        ...
</pre>
    <p>
     A common use for forward references is when e.g. Django models are
needed in the signatures.  Typically, each model is in a separate
file, and has methods that arguments whose type involves other models.
Because of the way circular imports work in Python, it is often not
possible to import all the needed models directly:
    </p>
    <pre class="literal-block">
# File models/a.py
from models.b import B
class A(Model):
    def foo(self, b: B): ...

# File models/b.py
from models.a import A
class B(Model):
    def bar(self, a: A): ...

# File main.py
from models.a import A
from models.b import B
</pre>
    <p>
     Assuming main is imported first, this will fail with an ImportError at
the line
     <tt class="docutils literal">
      from models.a import A
     </tt>
     in models/b.py, which is being
imported from models/a.py before a has defined class A.  The solution
is to switch to module-only imports and reference the models by their
_module_._class_ name:
    </p>
    <pre class="literal-block">
# File models/a.py
from models import b
class A(Model):
    def foo(self, b: 'b.B'): ...

# File models/b.py
from models import a
class B(Model):
    def bar(self, a: 'a.A'): ...

# File main.py
from models.a import A
from models.b import B
</pre>
   </div>
   <div class="section" id="union-types">
    
    <p>
     Since accepting a small, limited set of expected types for a single
argument is common, there is a new special factory called
     <tt class="docutils literal">
      Union
     </tt>
     .
Example:
    </p>
    <pre class="literal-block">
from typing import Union

def handle_employees(e: Union[Employee, Sequence[Employee]]) -&gt; None:
    if isinstance(e, Employee):
        e = [e]
    ...
</pre>
    <p>
     A type factored by
     <tt class="docutils literal">
      Union[T1, T2,
      <span class="pre">
       ...]
      </span>
     </tt>
     responds
     <tt class="docutils literal">
      True
     </tt>
     to
     <tt class="docutils literal">
      issubclass
     </tt>
     checks for
     <tt class="docutils literal">
      T1
     </tt>
     and any of its subtypes,
     <tt class="docutils literal">
      T2
     </tt>
     and
any of its subtypes, and so on.
    </p>
    <p>
     One common case of union types are
     <em>
      optional
     </em>
     types.  By default,
     <tt class="docutils literal">
      None
     </tt>
     is an invalid value for any type, unless a default value of
     <tt class="docutils literal">
      None
     </tt>
     has been provided in the function definition.  Examples:
    </p>
    <pre class="literal-block">
def handle_employee(e: Union[Employee, None]) -&gt; None: ...
</pre>
    <p>
     As a shorthand for
     <tt class="docutils literal">
      Union[T1, None]
     </tt>
     you can write
     <tt class="docutils literal">
      Optional[T1]
     </tt>
     ;
for example, the above is equivalent to:
    </p>
    <pre class="literal-block">
from typing import Optional

def handle_employee(e: Optional[Employee]) -&gt; None: ...
</pre>
    <p>
     An optional type is also automatically assumed when the default value is
     <tt class="docutils literal">
      None
     </tt>
     , for example:
    </p>
    <pre class="literal-block">
def handle_employee(e: Employee = None): ...
</pre>
    <p>
     This is equivalent to:
    </p>
    <pre class="literal-block">
def handle_employee(e: Optional[Employee] = None) -&gt; None: ...
</pre>
   </div>
   <div class="section" id="the-any-type">
    
    <p>
     A special kind of type is
     <tt class="docutils literal">
      Any
     </tt>
     .  Every type is a subtype of
     <tt class="docutils literal">
      Any
     </tt>
     .  This is also true for the builtin type
     <tt class="docutils literal">
      object
     </tt>
     .
However, to the static type checker these are completely different.
    </p>
    <p>
     When the type of a value is
     <tt class="docutils literal">
      object
     </tt>
     , the type checker will reject
almost all operations on it, and assigning it to a variable (or using
it as a return value) of a more specialized type is a type error.  On
the other hand, when a value has type
     <tt class="docutils literal">
      Any
     </tt>
     , the type checker will
allow all operations on it, and a value of type
     <tt class="docutils literal">
      Any
     </tt>
     can be assigned
to a variable (or used as a return value) of a more constrained type.
    </p>
   </div>
   <div class="section" id="version-and-platform-checking">
    
    <p>
     Type checkers are expected to understand simple version and platform
checks, e.g.:
    </p>
    <pre class="literal-block">
import sys

if sys.version_info[0] &gt;= 3:
    # Python 3 specific definitions
else:
    # Python 2 specific definitions

if sys.platform == 'win32':
    # Windows specific definitions
else:
    # Posix specific definitions
</pre>
    <p>
     Don't expect a checker to understand obfuscations like
     <tt class="docutils literal">
      <span class="pre">
       "".join(reversed(sys.platform))
      </span>
      == "xunil"
     </tt>
     .
    </p>
   </div>
   <div class="section" id="default-argument-values">
    
    <p>
     In stubs it may be useful to declare an argument as having a default
without specifying the actual default value.  For example:
    </p>
    <pre class="literal-block">
def foo(x: AnyStr, y: AnyStr = ...) -&gt; AnyStr: ...
</pre>
    <p>
     What should the default value look like?  Any of the options
     <tt class="docutils literal">
      ""
     </tt>
     ,
     <tt class="docutils literal">
      b""
     </tt>
     or
     <tt class="docutils literal">
      None
     </tt>
     fails to satisfy the type constraint (actually,
     <tt class="docutils literal">
      None
     </tt>
     will
     <em>
      modify
     </em>
     the type to become
     <tt class="docutils literal">
      Optional[AnyStr]
     </tt>
     ).
    </p>
    <p>
     In such cases the default value may be specified as a literal
ellipsis, i.e. the above example is literally what you would write.
    </p>
   </div>
  </div>
  <div class="section" id="stub-files">
   
   <p>
    Stub files are files containing type hints that are only for use by
the type checker, not at runtime.  There are several use cases for
stub files:
   </p>
   <ul class="simple">
    <li>
     Extension modules
    </li>
    <li>
     Third-party modules whose authors have not yet added type hints
    </li>
    <li>
     Standard library modules for which type hints have not yet been
written
    </li>
    <li>
     Modules that must be compatible with Python 2 and 3
    </li>
    <li>
     Modules that use annotations for other purposes
    </li>
   </ul>
   <p>
    Stub files have the same syntax as regular Python modules.  There is one
feature of the
    <tt class="docutils literal">
     typing
    </tt>
    module that may only be used in stub files:
the
    <tt class="docutils literal">
     @overload
    </tt>
    decorator described below.
   </p>
   <p>
    The type checker should only check function signatures in stub files;
It is recommended that function bodies in stub files just be a single
ellipsis (
    <tt class="docutils literal">
     ...
    </tt>
    ).
   </p>
   <p>
    The type checker should have a configurable search path for stub files.
If a stub file is found the type checker should not read the
corresponding "real" module.
   </p>
   <p>
    While stub files are syntactically valid Python modules, they use the
    <tt class="docutils literal">
     .pyi
    </tt>
    extension to make it possible to maintain stub files in the
same directory as the corresponding real module.  This also reinforces
the notion that no runtime behavior should be expected of stub files.
   </p>
   <p>
    Additional notes on stub files:
   </p>
   <ul class="simple">
    <li>
     Modules and variables imported into the stub are not considered
exported from the stub unless the import uses the
     <tt class="docutils literal">
      import ... as
...
     </tt>
     form or the equivalent
     <tt class="docutils literal">
      from ... import ... as ...
     </tt>
     form.
    </li>
    <li>
     However, as an exception to the previous bullet, all objects
imported into a stub using
     <tt class="docutils literal">
      from ... import *
     </tt>
     are considered
exported.  (This makes it easier to re-export all objects from a
given module that may vary by Python version.)
    </li>
   </ul>
   <div class="section" id="function-overloading">
    
    <p>
     The
     <tt class="docutils literal">
      @overload
     </tt>
     decorator allows describing functions that support
multiple different combinations of argument types.  This pattern is
used frequently in builtin modules and types.  For example, the
     <tt class="docutils literal">
      __getitem__()
     </tt>
     method of the
     <tt class="docutils literal">
      bytes
     </tt>
     type can be described as
follows:
    </p>
    <pre class="literal-block">
from typing import overload

class bytes:
    ...
    @overload
    def __getitem__(self, i: int) -&gt; int: ...
    @overload
    def __getitem__(self, s: slice) -&gt; bytes: ...
</pre>
    <p>
     This description is more precise than would be possible using unions
(which cannot express the relationship between the argument and return
types):
    </p>
    <pre class="literal-block">
from typing import Union

class bytes:
    ...
    def __getitem__(self, a: Union[int, slice]) -&gt; Union[int, bytes]: ...
</pre>
    <p>
     Another example where
     <tt class="docutils literal">
      @overload
     </tt>
     comes in handy is the type of the
builtin
     <tt class="docutils literal">
      map()
     </tt>
     function, which takes a different number of
arguments depending on the type of the callable:
    </p>
    <pre class="literal-block">
from typing import Callable, Iterable, Iterator, Tuple, TypeVar, overload

T1 = TypeVar('T1')
T2 = TypeVar('T2)
S = TypeVar('S')

@overload
def map(func: Callable[[T1], S], iter1: Iterable[T1]) -&gt; Iterator[S]: ...
@overload
def map(func: Callable[[T1, T2], S],
        iter1: Iterable[T1], iter2: Iterable[T2]) -&gt; Iterator[S]: ...
# ... and we could add more items to support more than two iterables
</pre>
    <p>
     Note that we could also easily add items to support
     <tt class="docutils literal">
      map(None,
      <span class="pre">
       ...)
      </span>
     </tt>
     :
    </p>
    <pre class="literal-block">
@overload
def map(func: None, iter1: Iterable[T1]) -&gt; Iterable[T1]: ...
@overload
def map(func: None,
        iter1: Iterable[T1],
        iter2: Iterable[T2]) -&gt; Iterable[Tuple[T1, T2]]: ...
</pre>
    <p>
     The
     <tt class="docutils literal">
      @overload
     </tt>
     decorator may only be used in stub files.  While it
would be possible to provide a multiple dispatch implementation using
this syntax, its implementation would require using
     <tt class="docutils literal">
      sys._getframe()
     </tt>
     , which is frowned upon.  Also, designing and
implementing an efficient multiple dispatch mechanism is hard, which
is why previous attempts were abandoned in favor of
     <tt class="docutils literal">
      functools.singledispatch()
     </tt>
     .  (See
     <a class="reference external" href="/dev/peps/pep-0443">
      PEP 443
     </a>
     , especially its section
"Alternative approaches".)  In the future we may come up with a
satisfactory multiple dispatch design, but we don't want such a design
to be constrained by the overloading syntax defined for type hints in
stub files.  In the meantime, using the
     <tt class="docutils literal">
      @overload
     </tt>
     decorator or
calling
     <tt class="docutils literal">
      overload()
     </tt>
     directly raises
     <tt class="docutils literal">
      RuntimeError
     </tt>
     .
    </p>
    <p>
     A constrained
     <tt class="docutils literal">
      TypeVar
     </tt>
     type can often be used instead of using the
     <tt class="docutils literal">
      @overload
     </tt>
     decorator.  For example, the definitions of
     <tt class="docutils literal">
      concat1
     </tt>
     and
     <tt class="docutils literal">
      concat2
     </tt>
     in this stub file are equivalent:
    </p>
    <pre class="literal-block">
from typing import TypeVar

AnyStr = TypeVar('AnyStr', str, bytes)

def concat1(x: AnyStr, y: AnyStr) -&gt; AnyStr: ...

@overload
def concat2(x: str, y: str) -&gt; str: ...
@overload
def concat2(x: bytes, y: bytes) -&gt; bytes: ...
</pre>
    <p>
     Some functions, such as
     <tt class="docutils literal">
      map
     </tt>
     or
     <tt class="docutils literal">
      bytes.__getitem__
     </tt>
     above, can't
be represented precisely using type variables.  However, unlike
     <tt class="docutils literal">
      @overload
     </tt>
     , type variables can also be used outside stub files.  We
recommend that
     <tt class="docutils literal">
      @overload
     </tt>
     is only used in cases where a type
variable is not sufficient, due to its special stub-only status.
    </p>
    <p>
     Another important difference between type variables such as
     <tt class="docutils literal">
      AnyStr
     </tt>
     and using
     <tt class="docutils literal">
      @overload
     </tt>
     is that the prior can also be used to define
constraints for generic class type parameters.  For example, the type
parameter of the generic class
     <tt class="docutils literal">
      typing.IO
     </tt>
     is constrained (only
     <tt class="docutils literal">
      IO[str]
     </tt>
     ,
     <tt class="docutils literal">
      IO[bytes]
     </tt>
     and
     <tt class="docutils literal">
      IO[Any]
     </tt>
     are valid):
    </p>
    <pre class="literal-block">
class IO(Generic[AnyStr]): ...
</pre>
   </div>
   <div class="section" id="storing-and-distributing-stub-files">
    
    <p>
     The easiest form of stub file storage and distribution is to put them
alongside Python modules in the same directory.  This makes them easy to
find by both programmers and the tools.  However, since package
maintainers are free not to add type hinting to their packages,
third-party stubs installable by
     <tt class="docutils literal">
      pip
     </tt>
     from PyPI are also supported.
In this case we have to consider three issues: naming, versioning,
installation path.
    </p>
    <p>
     This PEP does not provide a recommendation on a naming scheme that
should be used for third-party stub file packages.  Discoverability will
hopefully be based on package popularity, like with Django packages for
example.
    </p>
    <p>
     Third-party stubs have to be versioned using the lowest version of the
source package that is compatible.  Example: FooPackage has versions
1.0, 1.1, 1.2, 1.3, 2.0, 2.1, 2.2.  There are API changes in versions
1.1, 2.0 and 2.2.  The stub file package maintainer is free to release
stubs for all versions but at least 1.0, 1.1, 2.0 and 2.2 are needed
to enable the end user type check all versions.  This is because the
user knows that the closest
     <em>
      lower or equal
     </em>
     version of stubs is
compatible.  In the provided example, for FooPackage 1.3 the user would
choose stubs version 1.1.
    </p>
    <p>
     Note that if the user decides to use the "latest" available source
package, using the "latest" stub files should generally also work if
they're updated often.
    </p>
    <p>
     Third-party stub packages can use any location for stub storage.  Type
checkers should search for them using PYTHONPATH.  A default fallback
directory that is always checked is
     <tt class="docutils literal">
      shared/typehints/python3.5/
     </tt>
     (or
3.6, etc.).  Since there can only be one package installed for a given
Python version per environment, no additional versioning is performed
under that directory (just like bare directory installs by
     <tt class="docutils literal">
      pip
     </tt>
     in
site-packages).  Stub file package authors might use the following
snippet in
     <tt class="docutils literal">
      setup.py
     </tt>
     :
    </p>
    <pre class="literal-block">
...
data_files=[
    (
        'shared/typehints/python{}.{}'.format(*sys.version_info[:2]),
        pathlib.Path(SRC_PATH).glob('**/*.pyi'),
    ),
],
...
</pre>
   </div>
   <div class="section" id="the-typeshed-repo">
    
    <p>
     There is a shared repository where useful stubs are being collected
     <a class="citation-reference" href="#typeshed" id="id4">
      [typeshed]
     </a>
     .  Note that stubs for a given package will not be included
here without the explicit consent of the package owner.  Further
policies regarding the stubs collected here will be decided at a later
time, after discussion on python-dev, and reported in the typeshed
repo's README.
    </p>
   </div>
  </div>
  <div class="section" id="rejected-alternatives">
   
   <p>
    During discussion of earlier drafts of this PEP, various objections
were raised and alternatives were proposed.  We discuss some of these
here and explain why we reject them.
   </p>
   <p>
    Several main objections were raised.
   </p>
   <div class="section" id="which-brackets-for-generic-type-parameters">
    
    <p>
     Most people are familiar with the use of angular brackets
(e.g.
     <tt class="docutils literal">
      List&lt;int&gt;
     </tt>
     ) in languages like C++, Java, C# and Swift to
express the parametrization of generic types.  The problem with these
is that they are really hard to parse, especially for a simple-minded
parser like Python.  In most languages the ambiguities are usually
dealt with by only allowing angular brackets in specific syntactic
positions, where general expressions aren't allowed.  (And also by
using very powerful parsing techniques that can backtrack over an
arbitrary section of code.)
    </p>
    <p>
     But in Python, we'd like type expressions to be (syntactically) the
same as other expressions, so that we can use e.g. variable assignment
to create type aliases.  Consider this simple type expression:
    </p>
    <pre class="literal-block">
List&lt;int&gt;
</pre>
    <p>
     From the Python parser's perspective, the expression begins with the
same four tokens (NAME, LESS, NAME, GREATER) as a chained comparison:
    </p>
    <pre class="literal-block">
a &lt; b &gt; c  # I.e., (a &lt; b) and (b &gt; c)
</pre>
    <p>
     We can even make up an example that could be parsed both ways:
    </p>
    <pre class="literal-block">
a &lt; b &gt; [ c ]
</pre>
    <p>
     Assuming we had angular brackets in the language, this could be
interpreted as either of the following two:
    </p>
    <pre class="literal-block">
(a&lt;b&gt;)[c]      # I.e., (a&lt;b&gt;).__getitem__(c)
a &lt; b &gt; ([c])  # I.e., (a &lt; b) and (b &gt; [c])
</pre>
    <p>
     It would surely be possible to come up with a rule to disambiguate
such cases, but to most users the rules would feel arbitrary and
complex.  It would also require us to dramatically change the CPython
parser (and every other parser for Python).  It should be noted that
Python's current parser is intentionally "dumb" -- a simple grammar is
easier for users to reason about.
    </p>
    <p>
     For all these reasons, square brackets (e.g.
     <tt class="docutils literal">
      List[int]
     </tt>
     ) are (and
have long been) the preferred syntax for generic type parameters.
They can be implemented by defining the
     <tt class="docutils literal">
      __getitem__()
     </tt>
     method on
the metaclass, and no new syntax is required at all.  This option
works in all recent versions of Python (starting with Python 2.2).
Python is not alone in this syntactic choice -- generic classes in
Scala also use square brackets.
    </p>
   </div>
   <div class="section" id="what-about-existing-uses-of-annotations">
    
    <p>
     One line of argument points out that
     <a class="reference external" href="/dev/peps/pep-3107">
      PEP 3107
     </a>
     explicitly supports
the use of arbitrary expressions in function annotations.  The new
proposal is then considered incompatible with the specification of
     <a class="reference external" href="/dev/peps/pep-3107">
      PEP
3107
     </a>
     .
    </p>
    <p>
     Our response to this is that, first of all, the current proposal does
not introduce any direct incompatibilities, so programs using
annotations in Python 3.4 will still work correctly and without
prejudice in Python 3.5.
    </p>
    <p>
     We do hope that type hints will eventually become the sole use for
annotations, but this will require additional discussion and a
deprecation period after the initial roll-out of the typing module
with Python 3.5.  The current PEP will have provisional status (see
     <a class="reference external" href="/dev/peps/pep-0411">
      PEP 411
     </a>
     ) until Python 3.6 is released.  The fastest conceivable scheme
would introduce silent deprecation of non-type-hint annotations in
3.6, full deprecation in 3.7, and declare type hints as the only
allowed use of annotations in Python 3.8.  This should give authors of
packages that use annotations plenty of time to devise another
approach, even if type hints become an overnight success.
    </p>
    <p>
     Another possible outcome would be that type hints will eventually
become the default meaning for annotations, but that there will always
remain an option to disable them.  For this purpose the current
proposal defines a decorator
     <tt class="docutils literal">
      @no_type_check
     </tt>
     which disables the
default interpretation of annotations as type hints in a given class
or function.  It also defines a meta-decorator
     <tt class="docutils literal">
      @no_type_check_decorator
     </tt>
     which can be used to decorate a decorator
(!), causing annotations in any function or class decorated with the
latter to be ignored by the type checker.
    </p>
    <p>
     There are also
     <tt class="docutils literal">
      # type: ignore
     </tt>
     comments, and static checkers should
support configuration options to disable type checking in selected
packages.
    </p>
    <p>
     Despite all these options, proposals have been circulated to allow
type hints and other forms of annotations to coexist for individual
arguments.  One proposal suggests that if an annotation for a given
argument is a dictionary literal, each key represents a different form
of annotation, and the key
     <tt class="docutils literal">
      'type'
     </tt>
     would be use for type hints.
The problem with this idea and its variants is that the notation
becomes very "noisy" and hard to read.  Also, in most cases where
existing libraries use annotations, there would be little need to
combine them with type hints.  So the simpler approach of selectively
disabling type hints appears sufficient.
    </p>
   </div>
   <div class="section" id="the-problem-of-forward-declarations">
    
    <p>
     The current proposal is admittedly sub-optimal when type hints must
contain forward references.  Python requires all names to be defined
by the time they are used.  Apart from circular imports this is rarely
a problem: "use" here means "look up at runtime", and with most
"forward" references there is no problem in ensuring that a name is
defined before the function using it is called.
    </p>
    <p>
     The problem with type hints is that annotations (per
     <a class="reference external" href="/dev/peps/pep-3107">
      PEP 3107
     </a>
     , and
similar to default values) are evaluated at the time a function is
defined, and thus any names used in an annotation must be already
defined when the function is being defined.  A common scenario is a
class definition whose methods need to reference the class itself in
their annotations.  (More general, it can also occur with mutually
recursive classes.)  This is natural for container types, for
example:
    </p>
    <pre class="literal-block">
class Node:
    """Binary tree node."""

    def __init__(self, left: Node, right: Node):
        self.left = left
        self.right = right
</pre>
    <p>
     As written this will not work, because of the peculiarity in Python
that class names become defined once the entire body of the class has
been executed.  Our solution, which isn't particularly elegant, but
gets the job done, is to allow using string literals in annotations.
Most of the time you won't have to use this though -- most
     <em>
      uses
     </em>
     of
type hints are expected to reference builtin types or types defined in
other modules.
    </p>
    <p>
     A counterproposal would change the semantics of type hints so they
aren't evaluated at runtime at all (after all, type checking happens
off-line, so why would type hints need to be evaluated at runtime at
all).  This of course would run afoul of backwards compatibility,
since the Python interpreter doesn't actually know whether a
particular annotation is meant to be a type hint or something else.
    </p>
    <p>
     A compromise is possible where a
     <tt class="docutils literal">
      __future__
     </tt>
     import could enable
turning
     <em>
      all
     </em>
     annotations in a given module into string literals, as
follows:
    </p>
    <pre class="literal-block">
from __future__ import annotations

class ImSet:
    def add(self, a: ImSet) -&gt; List[ImSet]: ...

assert ImSet.add.__annotations__ == {'a': 'ImSet', 'return': 'List[ImSet]'}
</pre>
    <p>
     Such a
     <tt class="docutils literal">
      __future__
     </tt>
     import statement may be proposed in a separate
PEP.
    </p>
   </div>
   <div class="section" id="the-double-colon">
    
    <p>
     A few creative souls have tried to invent solutions for this problem.
For example, it was proposed to use a double colon (
     <tt class="docutils literal">
      ::
     </tt>
     ) for type
hints, solving two problems at once: disambiguating between type hints
and other annotations, and changing the semantics to preclude runtime
evaluation.  There are several things wrong with this idea, however.
    </p>
    <ul class="simple">
     <li>
      It's ugly.  The single colon in Python has many uses, and all of
them look familiar because they resemble the use of the colon in
English text.  This is a general rule of thumb by which Python
abides for most forms of punctuation; the exceptions are typically
well known from other programming languages.  But this use of
      <tt class="docutils literal">
       ::
      </tt>
      is unheard of in English, and in other languages (e.g. C++) it is
used as a scoping operator, which is a very different beast.  In
contrast, the single colon for type hints reads naturally -- and no
wonder, since it was carefully designed for this purpose (the idea
long predates
      <a class="reference external" href="/dev/peps/pep-3107">
       PEP 3107
      </a>
      <a class="citation-reference" href="#gvr-artima" id="id5">
       [gvr-artima]
      </a>
      ).  It is also used in the same
fashion in other languages from Pascal to Swift.
     </li>
     <li>
      What would you do for return type annotations?
     </li>
     <li>
      It's actually a feature that type hints are evaluated at runtime.
      <ul>
       <li>
        Making type hints available at runtime allows runtime type
checkers to be built on top of type hints.
       </li>
       <li>
        It catches mistakes even when the type checker is not run.  Since
it is a separate program, users may choose not to run it (or even
install it), but might still want to use type hints as a concise
form of documentation.  Broken type hints are no use even for
documentation.
       </li>
      </ul>
     </li>
     <li>
      Because it's new syntax, using the double colon for type hints would
limit them to code that works with Python 3.5 only.  By using
existing syntax, the current proposal can easily work for older
versions of Python 3.  (And in fact mypy supports Python 3.2 and
newer.)
     </li>
     <li>
      If type hints become successful we may well decide to add new syntax
in the future to declare the type for variables, for example
      <tt class="docutils literal">
       var age: int = 42
      </tt>
      .  If we were to use a double colon for
argument type hints, for consistency we'd have to use the same
convention for future syntax, perpetuating the ugliness.
     </li>
    </ul>
   </div>
   <div class="section" id="other-forms-of-new-syntax">
    
    <p>
     A few other forms of alternative syntax have been proposed, e.g. the
introduction of a
     <tt class="docutils literal">
      where
     </tt>
     keyword
     <a class="citation-reference" href="#roberge" id="id6">
      [roberge]
     </a>
     , and Cobra-inspired
     <tt class="docutils literal">
      requires
     </tt>
     clauses.  But these all share a problem with the double
colon: they won't work for earlier versions of Python 3.  The same
would apply to a new
     <tt class="docutils literal">
      __future__
     </tt>
     import.
    </p>
   </div>
   <div class="section" id="other-backwards-compatible-conventions">
    
    <p>
     The ideas put forward include:
    </p>
    <ul class="simple">
     <li>
      A decorator, e.g.
      <tt class="docutils literal">
       @typehints(name=str, returns=str)
      </tt>
      .  This could
work, but it's pretty verbose (an extra line, and the argument names
must be repeated), and a far cry in elegance from the
      <a class="reference external" href="/dev/peps/pep-3107">
       PEP 3107
      </a>
      notation.
     </li>
     <li>
      Stub files.  We do want stub files, but they are primarily useful
for adding type hints to existing code that doesn't lend itself to
adding type hints, e.g. 3rd party packages, code that needs to
support both Python 2 and Python 3, and especially extension
modules.  For most situations, having the annotations in line with
the function definitions makes them much more useful.
     </li>
     <li>
      Docstrings.  There is an existing convention for docstrings, based
on the Sphinx notation (
      <tt class="docutils literal">
       :type arg1: description
      </tt>
      ).  This is
pretty verbose (an extra line per parameter), and not very elegant.
We could also make up something new, but the annotation syntax is
hard to beat (because it was designed for this very purpose).
     </li>
    </ul>
    <p>
     It's also been proposed to simply wait another release.  But what
problem would that solve?  It would just be procrastination.
    </p>
   </div>
  </div>
  </div></body></html>