<html><body><div><article class="js-autolink "><h1>Deploying Python Applications with Gunicorn</h1>
<p class="last-updated"><span class="icon-clock"/>Last updated 12 January 2016</p>

<p>Web applications that process incoming HTTP requests concurrently make much more efficient use of dyno resources than web applications that only process one request at a time. Because of this, we recommend using web servers that support concurrent request processing whenever developing and running production services.</p>

<p>The Django and Flask web frameworks feature convenient built-in web servers, but these blocking servers only process a single request at a time. If you deploy with one of these servers on Heroku, your dyno resources will be underutilized and your application will feel unresponsive.</p>

<p><a href="http://gunicorn.org">Gunicorn</a>  is a pure-Python HTTP server for  WSGI  applications. It allows you to run any Python application concurrently by running multiple Python processes within a single dyno. It provides a perfect balance of performance, flexibility, and configuration simplicity.</p>

<p>This guide will walk you through deploying a new Python application to Heroku using the Gunicorn web server. For basic setup and knowledge about Heroku, see <a href="https://devcenter.heroku.com/articles/getting-started-with-python">Getting Started with Python</a>.</p>

<div class="warning">
<p>As always, test configuration changes in a staging environment before you deploy to your production application.</p>
</div>

<h2 id="adding-gunicorn-to-your-application">Adding Gunicorn to your application</h2>

<p>First, install Gunicorn with <code>pip</code>:</p>




<p>Then, update your <code>requirements.txt</code> file with <code>pip freeze</code>:</p>

<div class="CodeRay">
  <div class="code"><pre><span class="prompt">$</span><span class="function"> pip freeze &gt; requirements.txt
</span></pre></div>
</div>


<p>Or, you can manually add it to your <code>requirements.txt</code> file.</p>

<p>Next, revise your application’s <code>Procfile</code> to use Gunicorn. Here’s an example <code>Procfile</code> for the Flask application we created in <a href="https://devcenter.heroku.com/articles/getting-started-with-python">Getting Started with Python on Heroku</a>.</p>

<h4 id="adding-gunicorn-to-your-application-procfile">Procfile</h4>

<div class="CodeRay">
  <div class="code"><pre>web: gunicorn gettingstarted.wsgi --log-file -
</pre></div>
</div>


<h2 id="basic-configuration">Basic configuration</h2>

<p>Gunicorn forks multiple system processes within each dyno to allow a Python app to support multiple concurrent requests without requiring them to be thread-safe. In Gunicorn terminology, these are referred to as worker processes (not to be confused with Heroku worker processes, which run in their own dynos).</p>

<p>Each forked system process consumes additional memory. This limits how many processes you can run in a single dyno. With a typical Django application memory footprint, you can expect to run 2–4 Gunicorn worker processes on a <code>free</code>, <code>hobby</code> or <code>standard-1x</code> dyno. Your application may allow for a variation of this, depending on your application’s specific memory requirements.</p>

<p>We recommend setting a configuration variable for this setting. Gunicorn automatically honors the <code>WEB_CONCURRENCY</code> environment variable, if set.</p>

<div class="CodeRay">
  <div class="code"><pre><span class="prompt">$</span><span class="function"> heroku config:set WEB_CONCURRENCY=3
</span></pre></div>
</div>


<p>The <code>WEB_CONCURRENCY</code> environment variable is automatically set by Heroku, based on the processes' Dyno size. This feature is intended to be a sane starting point for your application. We recommend knowing the memory requirements of your processes and setting this configuration variable accordingly.</p>

<h4 id="basic-configuration-procfile">Procfile</h4>




<p>The Heroku Labs <a href="https://devcenter.heroku.com/articles/log-runtime-metrics">log-runtime-metrics</a> feature adds support for enabling visibility into load and memory usage for running dynos. Once enabled, your can monitor application memory usage with the <code>heroku logs</code> command.</p>

<h2 id="advanced-configuration">Advanced configuration</h2>

<h3 id="app-preloading">App preloading</h3>

<p>If you are constrained for memory or experiencing slow app boot time, you might want to consider enabling the <code>preload</code> option. This loads the application code before the worker processes are forked.</p>

<div class="CodeRay">
  <div class="code"><pre>web: gunicorn hello:app --preload
</pre></div>
</div>


<p>See the <a href="http://docs.gunicorn.org/en/latest/settings.html#preload-app">Gunicorn Docs on Preloading</a> for more information.</p>

<h3 id="worker-timeouts">Worker timeouts</h3>

<p>By default, Gunicorn gracefully restarts a worker if hasn’t completed any work within the last 30 seconds. If you expect your application to respond quickly to constant incoming flow of requests, try experimenting with a lower timeout configuration.</p>

<div class="CodeRay">
  <div class="code"><pre><span class="prompt">$</span><span class="function"> gunicorn hello:app --timeout 10
</span></pre></div>
</div>


<p>See the <a href="http://docs.gunicorn.org/en/latest/settings.html#timeout">Gunicorn Docs on Worker Timeouts</a> for more information.</p>

<h3 id="max-request-recycling">Max request recycling</h3>

<p>If your application suffers from memory leaks, you can configure Gunicorn to gracefully restart a worker after it has processed a given number of requests. This can be a convenient way to help limit the effects of the memory leak.</p>

<div class="CodeRay">
  <div class="code"><pre><span class="prompt">$</span><span class="function"> gunicorn hello:app --max-requests 1200
</span></pre></div>
</div>


<p>See the <a href="http://docs.gunicorn.org/en/latest/settings.html#max-requests">Gunicorn Docs on Max Requests</a> for more information.</p>

<h3 id="asynchronous-workers">Asynchronous workers</h3>

<p>If your application is mostly I/O bound, you may want to try experimenting with asynchronous worker types, like <code>gevent</code> or <code>eventlet</code>. These allow Gunicorn to create tens of thousands of “greenlets” to handle incoming HTTP traffic instead of heavy system threads. This can tremendously increase the concurrency and throughput of your application.</p>

<p>However, many application dependencies aren’t compatible with Gevent, so you will have to experiment on your own to see if this configuration will suit your needs. Luckily, with Gunicorn, this is only single-line change:</p>

<div class="CodeRay">
  <div class="code"><pre>web: gunicorn hello:app --worker-class gevent
</pre></div>
</div>


<p>See the <a href="http://docs.gunicorn.org/en/latest/settings.html#worker-class">Gunicorn Docs on Worker Classes</a> for more information.</p>

<h2 id="further-reading">Further reading</h2>


</article></div></body></html>