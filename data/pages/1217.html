<html><body><div><div><p>We do a <strong>lot</strong> of A/B testing at Mobify, and that means a lot of analysis of
the results. We collect and store data from many websites and need to be able to
run analyses multiple times as we improve and modify our techniques.</p>
<p>Much of this work is done in Python, using <a href="http://www.sqlalchemy.org/">SQLAlchemy</a> for
database access and <a href="http://pandas.pydata.org/pandas-docs/stable/index.html">Pandas</a>
for analysis. This post is about how we took an initial script that used a simple approach
to reading data and reduced the peak memory requirements.</p>


<p>Pandas is a powerful tool, but it has one weakness: all the data being analyzed
(in DataFrames) is held in memory. We have some <strong>very</strong> large data sets, and so
it's important to try to use the smallest amount of memory we can, to
minimize the number of big, expensive EC2 instances that we need to spin up.</p>
<p>The figures in this post are taken from a real data analysis run
spanning eleven days of traffic on one medium-size website. In practice, we
often need to cover a month or more or very high-traffic sites, so the values
are correspondingly higher: peak memory requirements of many tens of Gb.</p>
<h3>The Original Code</h3>
<p>Here's the key fragment of the data reading code as it was first written, with
comments added:</p>
<div class="codehilite"><pre><span class="n">engine</span> <span class="o">=</span> <span class="n">create_engine</span><span class="p">(</span><span class="n">ENGINE_STRING</span><span class="p">)</span>
<span class="c"># Connect to the PostgreSQL database</span>
<span class="k">with</span> <span class="n">engine</span><span class="o">.</span><span class="n">connect</span><span class="p">()</span> <span class="k">as</span> <span class="n">connection</span><span class="p">:</span>
    <span class="c"># Execute the query against the database</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">connection</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
    <span class="c"># Fetch all the results of the query</span>
    <span class="n">fetchall</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">fetchall</span><span class="p">()</span>
    <span class="c"># Build a DataFrame with the results</span>
    <span class="n">dataframe</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">fetchall</span><span class="p">)</span>
</pre></div>


<p>To see how much memory is being used at each step, I added some diagnostic code.
I'm using <a href="https://pypi.python.org/pypi/Pympler">Pympler</a> to look at the Python
heap and track what objects exist on it, and
<a href="https://github.com/giampaolo/psutil"><code>psutil</code></a> to get the VM size of the
process. The VM size is <em>the total amount of virtual memory used including all
code, data and shared libraries plus pages that have been swapped out</em> (from the
<em>top</em> manpage). Don't confuse VM size with <em>the actual amount of memory that the
process is using for data</em>. Measuring <strong>that</strong> is a complex task, and a full
discussion of Python memory usage is worth an entire series of blogposts.
However, a working summary is:</p>
<ul>
<li>
<p>There is a <em>Python heap</em> which holds Python objects. The <code>muppy</code> module from
  <code>pympler</code> can scan the Python heap and return object counts and sizes.</p>
</li>
<li>
<p>There is a <em>C heap</em> which holds non-Python objects. We can't easily check what
  objects on the C heap, but we can see when it increases in size by looking at
  the process VM size.</p>
</li>
<li>
<p>The VM size of the process includes the C heap, which also includes the Python heap.</p>
</li>
<li>
<p>The VM size grows when the process uses more memory.</p>
</li>
</ul>
<p>Here's the diagnostic code:</p>
<div class="codehilite"><pre><span class="kn">from</span> <span class="nn">pympler</span> <span class="kn">import</span> <span class="n">summary</span><span class="p">,</span> <span class="n">muppy</span>
<span class="kn">import</span> <span class="nn">psutil</span>

<span class="k">def</span> <span class="nf">get_virtual_memory_usage_kb</span><span class="p">():</span>
    <span class="sd">"""</span>
<span class="sd">    The process's current virtual memory size in Kb, as a float.</span>

<span class="sd">    """</span>
    <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">psutil</span><span class="o">.</span><span class="n">Process</span><span class="p">()</span><span class="o">.</span><span class="n">memory_info_ex</span><span class="p">()</span><span class="o">.</span><span class="n">vms</span><span class="p">)</span> <span class="o">/</span> <span class="mf">1024.0</span>

<span class="k">def</span> <span class="nf">memory_usage</span><span class="p">(</span><span class="n">where</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Print out a basic summary of memory usage.</span>

<span class="sd">    """</span>
    <span class="n">mem_summary</span> <span class="o">=</span> <span class="n">summary</span><span class="o">.</span><span class="n">summarize</span><span class="p">(</span><span class="n">muppy</span><span class="o">.</span><span class="n">get_objects</span><span class="p">())</span>
    <span class="k">print</span> <span class="s">"Memory summary:"</span><span class="p">,</span> <span class="n">where</span>
    <span class="n">summary</span><span class="o">.</span><span class="n">print_</span><span class="p">(</span><span class="n">mem_summary</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">print</span> <span class="s">"VM: </span><span class="si">%.2f</span><span class="s">Mb"</span> <span class="o">%</span> <span class="p">(</span><span class="n">get_virtual_memory_usage_kb</span><span class="p">()</span> <span class="o">/</span> <span class="mf">1024.0</span><span class="p">)</span>
</pre></div>


<p>When it's called, <code>memory_usage</code> will print out (using <code>summary</code>) the top two
types of objects that are taking up space in the Python heap, together with
their counts and total sizes. It'll also print out the total VM size in Mb.</p>
<p>Next, I added calls to <code>memory_usage</code> at various steps in the code:</p>
<div class="codehilite"><pre><span class="n">engine</span> <span class="o">=</span> <span class="n">create_engine</span><span class="p">(</span><span class="n">ENGINE_STRING</span><span class="p">)</span>
<span class="k">with</span> <span class="n">engine</span><span class="o">.</span><span class="n">connect</span><span class="p">()</span> <span class="k">as</span> <span class="n">connection</span><span class="p">:</span>
    <span class="n">memory_usage</span><span class="p">(</span><span class="s">"1 - before executing query"</span><span class="p">)</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">connection</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
    <span class="n">memory_usage</span><span class="p">(</span><span class="s">"2 - after query, before fetchall"</span><span class="p">)</span>
    <span class="n">fetched</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">fetchall</span><span class="p">()</span>
    <span class="n">memory_usage</span><span class="p">(</span><span class="s">"3 - after fetchall, before creating DataFrame"</span><span class="p">)</span>
    <span class="n">dataframe</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">fetched</span><span class="p">)</span>
    <span class="n">memory_usage</span><span class="p">(</span><span class="s">"4 - after creating DataFrame"</span><span class="p">)</span>
</pre></div>


<p>Running the code gives this output:</p>
<div class="codehilite"><pre>Memory summary: 1 - before executing query
  types |   # objects |   total size
    str |       37310 |      7.06 MB
   dict |        5066 |      6.39 MB
VM: 444.86Mb
Memory summary: 2 - after query, before fetchall
  types |   # objects |   total size
    str |       37351 |      7.07 MB
   dict |        5084 |      6.40 MB
VM: 831.24Mb
Memory summary: 3 - after fetchall, before creating DataFrame
                                      types |   # objects |   total size
  &lt;class 'sqlalchemy.engine.result.RowProxy |      554378 |     42.30 MB
                                        str |       37351 |      7.07 MB
                                       dict |        5084 |      6.39 MB
VM: 1782.64Mb
Memory summary: 4 - after creating DataFrame
                                      types |   # objects |   total size
  &lt;class 'sqlalchemy.engine.result.RowProxy |      554378 |     42.30 MB
                                        str |       37351 |      7.07 MB
                                       dict |        5087 |      6.40 MB
VM: 1876.64Mb
</pre></div>


<p>Let's look at each step in more detail.</p>
<ol>
<li>
<p>Before executing the query, the memory footprint is the 'base level' of the
   process. The initial VM size of 444.86Mb includes all the code, shared
   libraries and so on, and we don't need to worry about reducing it. What we're
   interested in is how much this figure grows as each step is executed.</p>
</li>
<li>
<p>After the query is executed, the VM size has increased by 386.38Mb. This is
   because by default, SQLAlchemy (via the <code>psycopg2</code> library it uses to talk to
   PostgreSQL) executes the query, fetches all the results in memory and buffers
   them in memory. We know that this buffering is on the C heap, because the VM
   size has increased, but there's no significant change in the top Python
   objects.</p>
</li>
<li>
<p>The call to <code>fetchall</code> copies the buffered query results from the C heap into
   <code>fetched</code>, a Python list. We don't know if SQLAlchemy/psycopg2 discards the
   buffered results once that's done, but we can see that the VM size has
   increased by an additional 951.4Mb. We can also see that the Python heap is
   holding 554,378 <code>sqlalchemy.engine.result.RowProxy</code> objects - these are the
   query results, one object per row.</p>
</li>
<li>
<p>The DataFrame is created, and this pushes up memory by another 94Mb.</p>
</li>
</ol>
<p>Overall, peak memory use is 1431.78Mb (the final VM size of 1876.64 minus the
initial size of 444.86Mb). It's this peak use that matters to us, for an
important reason: <strong>when a process releases memory (for example, when a big
Python structure goes out of scope and is garbage-collected), that doesn't
reduce the amount of virtual memory used</strong>.</p>
<p>That applies at step 4: If you look at the code, you'll see that <code>fetched</code> is
still in scope after the call to <code>DataFrame()</code>, so it's still taking up memory.
However, even if we deleted it at that point, we wouldn't get that virtual
memory back.</p>
<p>If you need to understand exactly how memory works in Python, <a href="http://revista.python.org.ar/2/en/html/memory-fragmentation.html">start here</a>,
or Google for "heap fragmentation" and be prepared to spend a lot of time
reading. Alternatively, just keep this rule in mind: <em>it's far, far better to
avoid allocating memory in the first place, rather than allocate it and then
free it.</em></p>
<h3>First Pass</h3>
<p>There's a very simple first step we can take: eliminate the buffering of the
query results. SQLAlchemy supports <a href="http://docs.sqlalchemy.org/en/rel_0_9/core/connections.html?highlight=stream_results#sqlalchemy.engine.Connection.execution_options"><em>streaming</em> of the results</a>
from some databases (including PostgreSQL) so that the result rows are not
buffered, but fetched as they're needed. Since the data needs to travel over the
network from the database whether it's streamed or not, this doesn't add a huge
overhead, but we'll see that it reduces memory requirements.</p>
<p>To do this, we replace the <code>connection.execute</code> line with:</p>
<div class="codehilite"><pre><span class="n">results</span> <span class="o">=</span> <span class="p">(</span><span class="n">connection</span>
           <span class="o">.</span><span class="n">execution_options</span><span class="p">(</span><span class="n">stream_results</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>  <span class="c"># Added this line</span>
           <span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="n">query</span><span class="p">))</span>
</pre></div>


<p>Now we can run the code again and see what the effect is:</p>
<div class="codehilite"><pre>Memory summary: 1 - before executing query
  types |   # objects |   total size
    str |       37310 |      7.06 MB
   dict |        5066 |      6.39 MB
VM: 444.87Mb
Memory summary: 2 - after query, before fetchall
  types |   # objects |   total size
    str |       37354 |      7.07 MB
   dict |        5087 |      6.40 MB
VM: 455.76Mb
Memory summary: 3 - after fetchall, before creating DataFrame
                                      types |   # objects |   total size
  &lt;class 'sqlalchemy.engine.result.RowProxy |      554378 |     42.30 MB
                                        str |       37333 |      7.07 MB
                                       dict |        5086 |      6.40 MB
VM: 1760.65Mb
Memory summary: 4 - after creating DataFrame
                                      types |   # objects |   total size
  &lt;class 'sqlalchemy.engine.result.RowProxy |      554378 |     42.30 MB
                                        str |       37333 |      7.07 MB
                                       dict |        5089 |      6.40 MB
VM: 1760.65Mb
</pre></div>


<p>Look at the results at step 2 - where previously memory increased by 386.38Mb,
now we've only used an additional 11Mb. We can see the
<code>sqlalchemy.engine.result.RowProxy</code> objects on the Python heap after steps 3 and
4, as they're returned from <code>fetchall</code>, so we're still paying the cost of
holding them all in memory.</p>
<p>We've reduced peak usage a little to 1315.78Mb: 91% of the original value.</p>
<h3>Second Pass</h3>
<p>There isn't really any need to fetch all the data before building the DataFrame.
Pandas accepts a range of different types as the data source in the
<code>DataFrame()</code> constructor, including any iterable or iterator. The result of the
SQLAlchemy <code>execute</code> call is a <code>ResultProxy</code>, which can be used as an iterator,
so we can avoid fetching the data and pass the results directly to <code>DataFrame()</code>.
This eliminates step 3, and the code now looks like this:</p>
<div class="codehilite"><pre><span class="n">memory_usage</span><span class="p">(</span><span class="s">"1 - before executing query"</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="p">(</span><span class="n">connection</span>
           <span class="o">.</span><span class="n">execution_options</span><span class="p">(</span><span class="n">stream_results</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
           <span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="n">query</span><span class="p">))</span>
<span class="n">memory_usage</span><span class="p">(</span><span class="s">"2 - after query, before creating DataFrame"</span><span class="p">)</span>
<span class="n">dataframe</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">results</span><span class="p">))</span>  <span class="c"># Pass results as an iterator</span>
<span class="n">dataframe</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
<span class="n">memory_usage</span><span class="p">(</span><span class="s">"4 - after creating DataFrame"</span><span class="p">)</span>
</pre></div>


<p>We need to call wrap <code>results</code> in an <code>iter()</code> so that <code>pandas</code> recognises it as
an iterator and extracts the rows to build the DataFrame. We're effectively
streaming straight to <code>pandas.DataFrame()</code>. We set the columns afterwards, from
the columns information in <code>results</code>.</p>
<p>This gives:</p>
<div class="codehilite"><pre>Memory summary: 1 - before executing query
  types |   # objects |   total size
    str |       37310 |      7.06 MB
   dict |        5066 |      6.39 MB
VM: 445.24Mb
Memory summary: 2 - after query, before creating DataFrame
  types |   # objects |   total size
    str |       37354 |      7.07 MB
   dict |        5087 |      6.40 MB
VM: 456.36Mb
Memory summary: 4 - after creating DataFrame
  types |   # objects |   total size
    str |       37333 |      7.07 MB
   dict |        5089 |      6.40 MB
VM: 1483.34Mb
</pre></div>


<p>Look at the Python heap after step 4: there are no <code>sqlalchemy.engine.result.RowProxy</code>
objects. That's because they were each consumed by <code>DataFrame()</code> and then
discarded, as the results were streamed.</p>
<p>We're down to a peak VM increase of 1038.1Mb, 72.5% of the first pass. But that's
still a fairly large amount of memory used for only eleven days of data. We can
tell that most of it is on the C heap, since the largest Python heap occupier is
7Mb of strings. That tells us that Pandas is doing most of its data allocation
on the C heap.</p>
<h3>Third Pass</h3>
<p>In order to explain why this third pass saves memory, I need to take a small
detour into the world of Python string handling.</p>
<p>Python creates new string objects when new strings are created. That's
reasonable, but we need to remember that two strings may have the same <em>value</em>,
but be different <em>objects</em>:</p>
<div class="codehilite"><pre><span class="n">Python</span> <span class="mf">2.7</span><span class="o">.</span><span class="mi">3</span> <span class="p">(</span><span class="n">default</span><span class="p">,</span> <span class="n">Feb</span> <span class="mi">27</span> <span class="mi">2014</span><span class="p">,</span> <span class="mi">19</span><span class="p">:</span><span class="mi">58</span><span class="p">:</span><span class="mi">35</span><span class="p">)</span>
<span class="p">[</span><span class="n">GCC</span> <span class="mf">4.6</span><span class="o">.</span><span class="mi">3</span><span class="p">]</span> <span class="n">on</span> <span class="n">linux2</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="s">'/vagrant'</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c"># We'll create two identical strings</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">s1</span> <span class="o">=</span> <span class="s">'It was the best of times, it was the worst of times. It was Hammer Time.'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">s2</span> <span class="o">=</span> <span class="s">'It was the best of times, it was the worst of times. It was Hammer Time.'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c"># Let's check that these strings are equal</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">s1</span> <span class="o">==</span> <span class="n">s2</span>
<span class="bp">True</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c"># Let's check if they are the same string object</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">s1</span> <span class="ow">is</span> <span class="n">s2</span>
<span class="bp">False</span>
</pre></div>


<p>Strings <code>s1</code> and <code>s2</code> have the same value but are different objects, and each
has a separate copy of its string data. This is the usual behaviour when strings
are created. However, Python can automatically <a href="https://docs.python.org/2/library/functions.html?highlight=intern#intern"><em>intern</em></a>
short strings - re-using existing string objects rather than allocating new ones:</p>
<div class="codehilite"><pre><span class="o">&gt;&gt;&gt;</span> <span class="c"># Try this with some short strings</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">s1</span> <span class="o">=</span> <span class="s">'abc'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">s2</span> <span class="o">=</span> <span class="s">'abc'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">s1</span> <span class="o">==</span> <span class="n">s2</span>
<span class="bp">True</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">s1</span> <span class="ow">is</span> <span class="n">s2</span>
<span class="bp">True</span>
</pre></div>


<p>Interning was originally intended to avoid string duplication for internal
strings like method and class names. In Python 2.7, according to the docs,
<em>...the names used in Python programs are automatically interned, and the
dictionaries used to hold module, class or instance attributes have interned
keys</em>. Python automatically interned <code>s1</code> and <code>s2</code> because they have short
values, but we can request that Python intern any string by using <code>intern()</code>:</p>
<div class="codehilite"><pre><span class="o">&gt;&gt;&gt;</span> <span class="n">s1</span> <span class="o">=</span> <span class="nb">intern</span><span class="p">(</span><span class="s">'It was the third of September, that day I''ll always remember'</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">s2</span> <span class="o">=</span> <span class="nb">intern</span><span class="p">(</span><span class="s">'It was the third of September, that day I''ll always remember'</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">s1</span> <span class="o">==</span> <span class="n">s2</span>
<span class="bp">True</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">s1</span> <span class="ow">is</span> <span class="n">s2</span>
<span class="bp">True</span>
</pre></div>


<p>But why is any of this a memory issue? In our processing example, the rows of
result data being returned by SQLAlchemy contain many repeated string <em>values</em>
(such as URLs and user agents), but each one is a different string <em>object</em>
(technically they're Unicode objects, but we can think of them as strings).
When these are passed to Pandas, it stores a copy of the data for each string on
the C heap, and we end up with many copies of the same string value taking up
memory. What we want is that we have a single shared string object for any one
value. For example, if we have many rows that all refer to a URL "http://www.mobify.com/blog",
then we want there to be one string with that value, and all the rows to refer
to it.</p>
<p>This is sometimes called string "folding". Folding does just what we want:
combines strings so that instead of code holding references to multiple string
objects that have the same value, all the references for any given value are to
the <strong>same</strong> string object. Remember that Python strings are <em>immutable</em>, so
it's completely safe to have many different parts of the code holding references
to the same string object: there's no way for the object's value to be changed.</p>
<p>The <code>fold_string</code> function below does the work. Since <code>intern</code> won't accept
<code>unicode</code> objects, and SQLAlchemy will usually return any CHAR-based type as
<code>unicode</code>, <code>fold_string</code> attempts to coerce a unicode object to a string object
with the same value, and calls <code>intern</code> on the result. If the unicode literal
can't be coerced, then it's stored in a separate map which does the same job as
<code>intern</code>.</p>
<div class="codehilite"><pre><span class="k">class</span> <span class="nc">StringFolder</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Class that will fold strings. See 'fold_string'.</span>
<span class="sd">    This object may be safely deleted or go out of scope when</span>
<span class="sd">    strings have been folded.</span>
<span class="sd">    """</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">unicode_map</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">def</span> <span class="nf">fold_string</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">s</span><span class="p">):</span>
        <span class="sd">"""</span>
<span class="sd">        Given a string (or unicode) parameter s, return a string object</span>
<span class="sd">        that has the same value as s (and may be s). For all objects</span>
<span class="sd">        with a given value, the same object will be returned. For unicode</span>
<span class="sd">        objects that can be coerced to a string with the same value, a</span>
<span class="sd">        string object will be returned.</span>
<span class="sd">        If s is not a string or unicode object, it is returned unchanged.</span>
<span class="sd">        :param s: a string or unicode object.</span>
<span class="sd">        :return: a string or unicode object.</span>
<span class="sd">        """</span>
        <span class="c"># If s is not a string or unicode object, return it unchanged</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="nb">basestring</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">s</span>

        <span class="c"># If s is already a string, then str() has no effect.</span>
        <span class="c"># If s is Unicode, try and encode as a string and use intern.</span>
        <span class="c"># If s is Unicode and can't be encoded as a string, this try</span>
        <span class="c"># will raise a UnicodeEncodeError.</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">intern</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>
        <span class="k">except</span> <span class="ne">UnicodeEncodeError</span><span class="p">:</span>
            <span class="c"># Fall through and handle s as Unicode</span>
            <span class="k">pass</span>

        <span class="c"># Look up the unicode value in the map and return</span>
        <span class="c"># the object from the map. If there is no matching entry,</span>
        <span class="c"># store this unicode object in the map and return it.</span>
        <span class="n">t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">unicode_map</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">t</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="c"># Put s in the map</span>
            <span class="n">t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">unicode_map</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="n">s</span>
        <span class="k">return</span> <span class="n">t</span>
</pre></div>


<p>Finally, we use <code>fold_string</code> within a generator function that will take each
row of the data, fold all the strings and yield tuples that Pandas can use to
build the DataFrame, one tuple for each row. Generators are very useful for
processing rows of data from SQLAlchemy, since a generator is itself an
iterator, and can be used anywhere that you might want to iterate over the data.</p>
<div class="codehilite"><pre><span class="k">def</span> <span class="nf">string_folding_wrapper</span><span class="p">(</span><span class="n">results</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    This generator yields rows from the results as tuples,</span>
<span class="sd">    with all string values folded.</span>
<span class="sd">    """</span>
    <span class="c"># Get the list of keys so that we build tuples with all</span>
    <span class="c"># the values in key order.</span>
    <span class="n">keys</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
     <span class="n">folder</span> <span class="o">=</span> <span class="n">StringFolder</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
        <span class="k">yield</span> <span class="nb">tuple</span><span class="p">(</span>
            <span class="n">folder</span><span class="o">.</span><span class="n">fold_string</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="n">key</span><span class="p">])</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">keys</span>
        <span class="p">)</span>
</pre></div>


<p>The query code changes just one line, to:</p>
<div class="codehilite"><pre><span class="n">dataframe</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">string_folding_wrapper</span><span class="p">(</span><span class="n">results</span><span class="p">))</span>
</pre></div>


<p>Running this gives:</p>
<div class="codehilite"><pre>Memory summary: 1 - before executing query
  types |   # objects |   total size
    str |       37314 |      7.06 MB
   dict |        5066 |      6.39 MB
VM: 444.84Mb
Memory summary: 2 - after query, before creating DataFrame
  types |   # objects |   total size
    str |       37358 |      7.07 MB
   dict |        5087 |      6.40 MB
VM: 456.61Mb
Memory summary: 4 - after creating DataFrame
  types |   # objects |   total size
    str |       37337 |      7.07 MB
   dict |        5089 |      6.40 MB
VM: 901.54Mb
</pre></div>


<p>Now we're down to a peak of just 456.7Mb - a fraction under 32% of the original peak. We've saved 1419.94Mb!</p>
<h3>Conclusion</h3>
<p>These techniques let us change from 60Gb instances to instances with 30Gb or
even less, saving us at least 50% in EC2 costs. As we expand to collect and
analyze more data, those savings will also increase.</p>
<p>You can use the same techniques in your own code, but here are some key points
to take away:</p>
<ol>
<li>
<p>Don't allocate memory if you can sensibly avoid it. Here the key word is
   <em>sensibly</em>: as Donald Knuth said, <em>premature optimization is the root of all
   evil</em>. In this case, though, we want to avoid peak memory scaling wildly with
   data volume, and the optimization directly affects our processing costs, so
   it's well worth doing.</p>
</li>
<li>
<p>If you can process the results of database queries iteratively (and very
   often you can), stream the results, assuming you're using a library that
   supports it. SQLAlchemy will do that for PostgreSQL with the <code>stream_results</code>
   execution option, and <a href="https://github.com/farcepest/MySQLdb1">MySQLdb</a> supports
   it using <code>SSCursor</code> (server-side cursors).</p>
</li>
<li>
<p>If you're iterating over data that contains many repeated strings <strong>that are
   kept in memory</strong>, consider using a wrapping generator to fold them.</p>
</li>
</ol></div>
        </div></body></html>