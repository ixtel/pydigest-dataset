<html><body><div><div id="article_text">
    <a class="reference external image-reference" href="http://i.imgur.com/nfX9lqm.jpg"><img alt="Popular Airline Passenger Routes" src="http://i.imgur.com/nfX9lqml.jpg"/></a>
<p>This map represents some of the most popular commercial airline routes. Each route is coloured and given a line width to represent how many people in the latest year reported flew between two given airports.</p>
<div class="section" id="the-data-collection-process">
<h2>The Data Collection Process</h2>
<p>When I started the data collection process for this map I knew not every airport page on Wikipedia reported how many passengers flew to and from the destinations they connect with. But I suspected I could fill in the blanks if the other destinations reported what passenger counts they were seeing.</p>
<p>Neither of Moscow's two big airports, <a class="reference external" href="https://en.wikipedia.org/wiki/Sheremetyevo_International_Airport">Sheremetyevo</a> and <a class="reference external" href="https://en.wikipedia.org/wiki/Domodedovo_International_Airport">Domodedovo</a>, report how many passengers travel to and from their top destinations on their Wikipedia pages. But Bangkok's <a class="reference external" href="https://en.wikipedia.org/wiki/Suvarnabhumi_Airport">Suvarnabhumi Airport</a> Wikipedia page reports that 266,889 and 316,055 passengers flew to and from Sheremetyevo and Domodedovo respectively in 2013. Novosibirsk's <a class="reference external" href="https://en.wikipedia.org/wiki/Tolmachevo_Airport">Tolmachevo</a> did report 215,408 passengers coming and going in 2013 from Bangkok's Suvarnabhumi which lines up closely with 212,715 reported on Suvarnabhumi's Wikipedia page.</p>
<p>Prague Airport and Charles de Gaulle Airport reported 637,566 and 790,922 passengers respectively flying between their airports and Sheremetyevo. But others, like Kiev's <a class="reference external" href="https://en.wikipedia.org/wiki/Boryspil_International_Airport">Boryspil</a> grouped passenger counts by major city by combining the numbers for Domodedovo and Sheremetyevo.</p>
<p>The routes for Sheremetyevo &amp; Sharm el-Sheikh, Sheremetyevo &amp; Krasnodar, Sheremetyevo &amp; Kaliningrad had no reported passenger numbers at all. A large part of passenger traffic in China, India, Brazil and South Africa isn't broken down by destination/arrival airport.</p>
<p>Of the 28,731 wikipedia articles I found with a title that has 'Airport' in it I extracted 5,958 airport entities and 343^ of those airports had passenger counts broken down by destinations they connect with. Most of the said pages had at least the top 10 connecting airports with corresponding passenger counts for the year, many had the top 20 and a few stars (mostly in Western Europe and South East Asia) had over 50.</p>
<p>^ This number is probably higher but 343 was all my parser could sort out.</p>
</div>
<div class="section" id="setting-up-an-environment">
<h2>Setting up an Environment</h2>
<p>I installed a few tools on my Ubuntu 14.04 machine to collect the data and render it out.</p>
<div class="highlight"><pre><span class="nv">$ </span>sudo apt-get update
<span class="nv">$ </span>sudo apt-get install python-mpltoolkits.basemap <span class="se">\</span>
                       pandoc <span class="se">\</span>
                       libxml2-dev <span class="se">\</span>
                       libxslt1-dev <span class="se">\</span>
                       redis-server
<span class="nv">$ </span>sudo pip install docopt
</pre></div>
<p>I almost exclusively work in a virtual environment, and in the collection phase of this project I did but the BaseMap package used by Matplotlib wasn't playing nice when I tried to install it via pip so I chose to go with the Ubuntu distribution.</p>
<p>I moved the map rendering tasks out to <cite>plot.py</cite>. For all the work I did in <cite>app.py</cite> I had a virtual environment setup with 11 packages:</p>
<div class="highlight"><pre><span class="nv">$ </span>virtualenv passengers
<span class="nv">$ </span><span class="nb">source </span>passengers/bin/activate
<span class="nv">$ </span>pip install -r requirements.txt
</pre></div>
<p>When switching from the collection process to the rendering process you can exit the virtual environment with the following:</p>

</div>
<div class="section" id="download-a-copy-of-wikipedia">
<h2>Download a copy of Wikipedia</h2>
<p>If I can avoid making tens of thousands of network requests, even via a queue, to a remote server then I'll do my best to do so. For this task I decided to download ~11GB of Wikipedia's English-language articles. There is a single file you can download or you can do it in chunks:</p>
<div class="highlight"><pre><span class="nv">$ </span>wget -c https://dumps.wikimedia.org/enwiki/20150702/enwiki-20150702-pages-articles1.xml-p000000010p000010000.bz2
<span class="nv">$ </span>wget -c https://dumps.wikimedia.org/enwiki/20150702/enwiki-20150702-pages-articles2.xml-p000010002p000025001.bz2
<span class="nv">$ </span>wget -c https://dumps.wikimedia.org/enwiki/20150702/enwiki-20150702-pages-articles3.xml-p000025001p000055000.bz2
<span class="nv">$ </span>wget -c https://dumps.wikimedia.org/enwiki/20150702/enwiki-20150702-pages-articles4.xml-p000055002p000104998.bz2
<span class="nv">$ </span>wget -c https://dumps.wikimedia.org/enwiki/20150702/enwiki-20150702-pages-articles5.xml-p000105002p000184999.bz2
<span class="nv">$ </span>wget -c https://dumps.wikimedia.org/enwiki/20150702/enwiki-20150702-pages-articles6.xml-p000185003p000305000.bz2
<span class="nv">$ </span>wget -c https://dumps.wikimedia.org/enwiki/20150702/enwiki-20150702-pages-articles7.xml-p000305002p000465001.bz2
<span class="nv">$ </span>wget -c https://dumps.wikimedia.org/enwiki/20150702/enwiki-20150702-pages-articles8.xml-p000465001p000665001.bz2
<span class="nv">$ </span>wget -c https://dumps.wikimedia.org/enwiki/20150702/enwiki-20150702-pages-articles9.xml-p000665001p000925001.bz2
<span class="nv">$ </span>wget -c https://dumps.wikimedia.org/enwiki/20150702/enwiki-20150702-pages-articles10.xml-p000925001p001325001.bz2
<span class="nv">$ </span>wget -c https://dumps.wikimedia.org/enwiki/20150702/enwiki-20150702-pages-articles11.xml-p001325001p001825001.bz2
<span class="nv">$ </span>wget -c https://dumps.wikimedia.org/enwiki/20150702/enwiki-20150702-pages-articles12.xml-p001825001p002425000.bz2
<span class="nv">$ </span>wget -c https://dumps.wikimedia.org/enwiki/20150702/enwiki-20150702-pages-articles13.xml-p002425002p003125001.bz2
<span class="nv">$ </span>wget -c https://dumps.wikimedia.org/enwiki/20150702/enwiki-20150702-pages-articles14.xml-p003125001p003925001.bz2
<span class="nv">$ </span>wget -c https://dumps.wikimedia.org/enwiki/20150702/enwiki-20150702-pages-articles15.xml-p003925001p004824998.bz2
<span class="nv">$ </span>wget -c https://dumps.wikimedia.org/enwiki/20150702/enwiki-20150702-pages-articles16.xml-p004825005p006025001.bz2
<span class="nv">$ </span>wget -c https://dumps.wikimedia.org/enwiki/20150702/enwiki-20150702-pages-articles17.xml-p006025001p007524997.bz2
<span class="nv">$ </span>wget -c https://dumps.wikimedia.org/enwiki/20150702/enwiki-20150702-pages-articles18.xml-p007525004p009225000.bz2
<span class="nv">$ </span>wget -c https://dumps.wikimedia.org/enwiki/20150702/enwiki-20150702-pages-articles19.xml-p009225002p011124997.bz2
<span class="nv">$ </span>wget -c https://dumps.wikimedia.org/enwiki/20150702/enwiki-20150702-pages-articles20.xml-p011125004p013324998.bz2
<span class="nv">$ </span>wget -c https://dumps.wikimedia.org/enwiki/20150702/enwiki-20150702-pages-articles21.xml-p013325003p015724999.bz2
<span class="nv">$ </span>wget -c https://dumps.wikimedia.org/enwiki/20150702/enwiki-20150702-pages-articles22.xml-p015725013p018225000.bz2
<span class="nv">$ </span>wget -c https://dumps.wikimedia.org/enwiki/20150702/enwiki-20150702-pages-articles23.xml-p018225004p020925000.bz2
<span class="nv">$ </span>wget -c https://dumps.wikimedia.org/enwiki/20150702/enwiki-20150702-pages-articles24.xml-p020925002p023725001.bz2
<span class="nv">$ </span>wget -c https://dumps.wikimedia.org/enwiki/20150702/enwiki-20150702-pages-articles25.xml-p023725001p026624997.bz2
<span class="nv">$ </span>wget -c https://dumps.wikimedia.org/enwiki/20150702/enwiki-20150702-pages-articles26.xml-p026625004p029624976.bz2
<span class="nv">$ </span>wget -c https://dumps.wikimedia.org/enwiki/20150702/enwiki-20150702-pages-articles27.xml-p029625017p047137381.bz2
</pre></div>
</div>
<div class="section" id="make-the-data-smaller">
<h2>Make the Data Smaller</h2>
<p>As a single step I wanted to extract all the article titles and bodies from the XML files where 'Airport' appeared in the title. This process took over an hour on my machine and the result was that I didn't need to repeat this step if and when future steps failed.</p>
<div class="highlight"><pre><span class="nv">$ </span>python app.py get_wikipedia_content title_article_extract.json
</pre></div>
<p>This process turned ~11GB of compressed articles into a 68MB uncompressed JSON file. I was happy to see Python's standard library did almost everything I needed to achieve this:</p>
<div class="highlight"><pre><span class="kn">import</span> <span class="nn">bz2</span>
<span class="kn">import</span> <span class="nn">codecs</span>
<span class="kn">from</span> <span class="nn">glob</span> <span class="kn">import</span> <span class="n">glob</span>

<span class="kn">from</span> <span class="nn">lxml</span> <span class="kn">import</span> <span class="n">etree</span>


<span class="k">def</span> <span class="nf">get_parser</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
    <span class="n">ns_token</span>        <span class="o">=</span> <span class="s">'{http://www.mediawiki.org/xml/export-0.10/}ns'</span>
    <span class="n">title_token</span>     <span class="o">=</span> <span class="s">'{http://www.mediawiki.org/xml/export-0.10/}title'</span>
    <span class="n">revision_token</span>  <span class="o">=</span> <span class="s">'{http://www.mediawiki.org/xml/export-0.10/}revision'</span>
    <span class="n">text_token</span>      <span class="o">=</span> <span class="s">'{http://www.mediawiki.org/xml/export-0.10/}text'</span>

    <span class="k">with</span> <span class="n">bz2</span><span class="o">.</span><span class="n">BZ2File</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s">'r+b'</span><span class="p">)</span> <span class="k">as</span> <span class="n">bz2_file</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">event</span><span class="p">,</span> <span class="n">element</span> <span class="ow">in</span> <span class="n">etree</span><span class="o">.</span><span class="n">iterparse</span><span class="p">(</span><span class="n">bz2_file</span><span class="p">,</span> <span class="n">events</span><span class="o">=</span><span class="p">(</span><span class="s">'end'</span><span class="p">,)):</span>
            <span class="k">if</span> <span class="n">element</span><span class="o">.</span><span class="n">tag</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s">'page'</span><span class="p">):</span>
                <span class="n">namespace_tag</span> <span class="o">=</span> <span class="n">element</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="n">ns_token</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">namespace_tag</span><span class="o">.</span><span class="n">text</span> <span class="o">==</span> <span class="s">'0'</span><span class="p">:</span>
                    <span class="n">title_tag</span> <span class="o">=</span> <span class="n">element</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="n">title_token</span><span class="p">)</span>
                    <span class="n">text_tag</span> <span class="o">=</span> <span class="n">element</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="n">revision_token</span><span class="p">)</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="n">text_token</span><span class="p">)</span>
                    <span class="k">yield</span> <span class="n">title_tag</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="n">text_tag</span><span class="o">.</span><span class="n">text</span>

                <span class="n">element</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">pluck_wikipedia_titles_text</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="s">'enwiki-*-pages-articles*.xml-*.bz2'</span><span class="p">,</span>
                               <span class="n">out_file</span><span class="o">=</span><span class="s">'title_article_extract.json'</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">codecs</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">out_file</span><span class="p">,</span> <span class="s">'a+b'</span><span class="p">,</span> <span class="s">'utf8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">out_file</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">bz2_filename</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">glob</span><span class="p">(</span><span class="n">pattern</span><span class="p">),</span>
                                   <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">a</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span>
                                        <span class="n">a</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">'articles'</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">'.'</span><span class="p">)[</span><span class="mi">0</span><span class="p">]),</span>
                                   <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
            <span class="k">print</span> <span class="n">bz2_filename</span>
            <span class="n">parser</span> <span class="o">=</span> <span class="n">get_parser</span><span class="p">(</span><span class="n">bz2_filename</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">title</span><span class="p">,</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">parser</span><span class="p">:</span>
                <span class="k">if</span> <span class="s">'airport'</span> <span class="ow">in</span> <span class="n">title</span><span class="o">.</span><span class="n">lower</span><span class="p">():</span>
                    <span class="n">out_file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">([</span><span class="n">title</span><span class="p">,</span> <span class="n">text</span><span class="p">],</span>
                                              <span class="n">ensure_ascii</span><span class="o">=</span><span class="bp">False</span><span class="p">))</span>
                    <span class="n">out_file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>
</pre></div>
<p>The files are processes in descending order as the largest files came last and I wanted to know about any memory and recursion issues early on.</p>
</div>
<div class="section" id="converting-wikipedia-s-markdown-into-html">
<h2>Converting Wikipedia's Markdown into HTML</h2>
<p>When I first started exploring the idea of making this map I downloaded the HTML of a few airport pages from Wikipedia and used BeautifulSoup to parse the airport characteristics and passenger counts out. The process was easy to write and worked well on the few examples I presented it with. But the article data I've downloaded from Wikipedia is in their own Markdown flavour and needs to be converted into HTML.</p>
<p>I experimented with creole and pandoc for doing the conversion. Both had mixed results. Not all airport pages are written in the same fashion so even though the data is there it can be structured very differently on two different pages. Infoboxes and tables did not render into HTML properly at all. In some cases every cell in a table would show up as it's own row.</p>
<p>In order to keep this task in the time box I assigned to it I decided to try three ways of extracting the data I wanted: try creole, if I couldn't parse out the data I needed I then tried pandoc. If pandoc didn't work out I manually connected out to Wikipedia's site and scraped the HTML from them. I didn't want to hammer Wikipedia's servers with requests so I limited the calls to 3 every 10 seconds and cached the results in Redis.</p>
<div class="highlight"><pre><span class="kn">import</span> <span class="nn">ratelim</span>
<span class="kn">import</span> <span class="nn">redis</span>
<span class="kn">import</span> <span class="nn">requests</span>


<span class="nd">@ratelim.greedy</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span> <span class="c"># 3 calls / 10 seconds</span>
<span class="k">def</span> <span class="nf">get_wikipedia_page_from_internet</span><span class="p">(</span><span class="n">url_suffix</span><span class="p">):</span>
    <span class="n">url</span> <span class="o">=</span> <span class="s">'https://en.wikipedia.org</span><span class="si">%s</span><span class="s">'</span> <span class="o">%</span> <span class="n">url_suffix</span>
    <span class="n">resp</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">resp</span><span class="o">.</span><span class="n">status_code</span> <span class="o">==</span> <span class="mi">200</span><span class="p">,</span> <span class="p">(</span><span class="n">resp</span><span class="p">,</span> <span class="n">url</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">resp</span><span class="o">.</span><span class="n">content</span>


<span class="k">def</span> <span class="nf">get_wikipedia_page</span><span class="p">(</span><span class="n">url_suffix</span><span class="p">):</span>
    <span class="n">redis_con</span> <span class="o">=</span> <span class="n">redis</span><span class="o">.</span><span class="n">StrictRedis</span><span class="p">()</span>
    <span class="n">redis_key</span> <span class="o">=</span> <span class="s">'wikipedia_</span><span class="si">%s</span><span class="s">'</span> <span class="o">%</span> <span class="n">sha1</span><span class="p">(</span><span class="n">url_suffix</span><span class="p">)</span><span class="o">.</span><span class="n">hexdigest</span><span class="p">()[:</span><span class="mi">6</span><span class="p">]</span>
    <span class="n">resp</span> <span class="o">=</span> <span class="n">redis_con</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">redis_key</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">resp</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">resp</span>

    <span class="n">html</span> <span class="o">=</span> <span class="n">get_wikipedia_page_from_internet</span><span class="p">(</span><span class="n">url_suffix</span><span class="p">)</span>
    <span class="n">redis_con</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">redis_key</span><span class="p">,</span> <span class="n">html</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">html</span>
</pre></div>
<p>If there was a connection issue or one of the page links given was to a page that didn't exist the script would just carry on to the next page:</p>
<div class="highlight"><pre><span class="k">try</span><span class="p">:</span>
    <span class="n">html</span> <span class="o">=</span> <span class="n">get_wikipedia_page</span><span class="p">(</span><span class="n">url_key</span><span class="p">)</span>
<span class="k">except</span> <span class="p">(</span><span class="ne">AssertionError</span><span class="p">,</span> <span class="n">requests</span><span class="o">.</span><span class="n">exceptions</span><span class="o">.</span><span class="n">ConnectionError</span><span class="p">):</span>
    <span class="k">pass</span> <span class="c"># Some pages link to 404s, just move on...</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">html</span><span class="p">,</span> <span class="s">"html5lib"</span><span class="p">)</span>
</pre></div>
<p>I found some of the HTML would render so poorly that it would cause BeautifulSoup to hit recursion depth limits set in CPython. When this happened I just moved on to the next page knowing that I could handle some missing data and good is not the enemy of perfect.</p>
<div class="highlight"><pre><span class="k">try</span><span class="p">:</span>
    <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">html</span><span class="p">,</span> <span class="s">"html5lib"</span><span class="p">)</span>
    <span class="n">passenger_numbers</span> <span class="o">=</span> <span class="n">pluck_passenger_numbers</span><span class="p">(</span><span class="n">soup</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">RuntimeError</span> <span class="k">as</span> <span class="n">exc</span><span class="p">:</span>
    <span class="k">if</span> <span class="s">'maximum recursion depth exceeded'</span> <span class="ow">in</span> <span class="n">exc</span><span class="o">.</span><span class="n">message</span><span class="p">:</span>
        <span class="n">passenger_numbers</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">exc</span>
</pre></div>
<p>The command to pluck out the airport properties and connections details is as follows:</p>
<div class="highlight"><pre><span class="nv">$ </span>python app.py pluck_airport_meta_data <span class="se">\</span>
                title_article_extract.json <span class="se">\</span>
                stats.json
</pre></div>
</div>
<div class="section" id="picking-a-design-for-the-map">
<h2>Picking a Design for the Map</h2>
<p>I didn't want this data to render as a <a class="reference external" href="http://www.economist.com/blogs/graphicdetail/2012/05/daily-chart-8">bar chart</a> but plotting lines on a map of the Earth which is coloured in bright blue and green would just leave me with an image that felt noisy.</p>
<p>Luckily, I came across a <a class="reference external" href="http://spatial.ly/2013/05/great-world-flight-paths-map/">blog post</a> by James Cheshire, a lecturer at the UCL Department of Geography, where he critiques maps put together by Michael Markieta. Michael had plotted flight routes from four airports in London to destinations they connected to around the world. The map of Earth used was the <a class="reference external" href="http://visibleearth.nasa.gov/view.php?id=79765">Night lights</a> map put together by NASA.</p>
<p>I had struggled to find a colour scheme that separated the routes visually and the pink to red scheme he used seem to work well. I found a scheme similar at <a class="reference external" href="http://colorbrewer2.org/">Color Brewer 2.0</a>. In addition to the colour, I varied the transparency and line width based on how many passengers had used a route in a given year.</p>
<div class="highlight"><pre><span class="n">display_params</span> <span class="o">=</span> <span class="p">(</span>
    <span class="c"># color   alpha  width threshold</span>
    <span class="p">(</span><span class="s">'#e5cccf'</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
    <span class="p">(</span><span class="s">'#f7c4b1'</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mi">250000</span><span class="p">),</span>
    <span class="p">(</span><span class="s">'#ed8d75'</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mi">500000</span><span class="p">),</span>
    <span class="p">(</span><span class="s">'#ef684b'</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mi">1000000</span><span class="p">),</span>
    <span class="p">(</span><span class="s">'#e93a27'</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mi">2000000</span><span class="p">),</span>
<span class="p">)</span>

<span class="k">for</span> <span class="n">iata_pair</span><span class="p">,</span> <span class="n">passenger_count</span> <span class="ow">in</span> <span class="n">pairs</span><span class="o">.</span><span class="n">iteritems</span><span class="p">():</span>
    <span class="n">colour</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">linewidth</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">display_params</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">_colour</span><span class="p">,</span> <span class="n">_alpha</span><span class="p">,</span> <span class="n">_linewidth</span><span class="p">,</span> <span class="n">_threshold</span> <span class="ow">in</span> <span class="n">display_params</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">_threshold</span> <span class="o">&gt;</span> <span class="n">passenger_count</span><span class="p">:</span>
            <span class="k">break</span>

        <span class="n">colour</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">linewidth</span> <span class="o">=</span> <span class="n">_colour</span><span class="p">,</span> <span class="n">_alpha</span><span class="p">,</span> <span class="n">_linewidth</span>
</pre></div>
</div>
<div class="section" id="rendering-the-map">
<h2>Rendering the Map</h2>
<p>Using the Basemap package to render the map was reasonably straight forward. The only issue I ran up against was routes crossing the Pacific Ocean would stop at the edge of the image, draw a straight line across to the other side of the image and then continue on to their destination. It's a documented problem in the documentation for the <a class="reference external" href="http://matplotlib.org/basemap/api/basemap_api.html#mpl_toolkits.basemap.Basemap.drawgreatcircle">drawgreatcircle</a> method.</p>
<p>Phil Elson, a core developer on matplotlib, came up with a <a class="reference external" href="http://stackoverflow.com/questions/13888566/python-basemap-drawgreatcircle-function">solution</a> that fixed this issue.</p>
<div class="highlight"><pre><span class="n">line</span><span class="p">,</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">drawgreatcircle</span><span class="p">(</span><span class="n">long1</span><span class="p">,</span> <span class="n">lat1</span><span class="p">,</span> <span class="n">long2</span><span class="p">,</span> <span class="n">lat2</span><span class="p">,</span>
                                  <span class="n">linewidth</span><span class="o">=</span><span class="n">linewidth</span><span class="p">,</span>
                                  <span class="n">color</span><span class="o">=</span><span class="n">colour</span><span class="p">,</span>
                                  <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span>
                                  <span class="n">solid_capstyle</span><span class="o">=</span><span class="s">'round'</span><span class="p">)</span>

<span class="n">p</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">get_path</span><span class="p">()</span>

<span class="c"># Find the index which crosses the dateline (the delta is large)</span>
<span class="n">cut_point</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">vertices</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]))</span> <span class="o">&gt;</span> <span class="mi">200</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

<span class="k">if</span> <span class="n">cut_point</span><span class="p">:</span>
    <span class="n">cut_point</span> <span class="o">=</span> <span class="n">cut_point</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c"># Create new vertices with a nan in between and set</span>
    <span class="c"># those as the path's vertices</span>
    <span class="n">new_verts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">p</span><span class="o">.</span><span class="n">vertices</span><span class="p">[:</span><span class="n">cut_point</span><span class="p">,</span> <span class="p">:],</span>
                                <span class="p">[[</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">]],</span>
                                <span class="n">p</span><span class="o">.</span><span class="n">vertices</span><span class="p">[</span><span class="n">cut_point</span><span class="o">+</span><span class="mi">1</span><span class="p">:,</span> <span class="p">:]])</span>
    <span class="n">p</span><span class="o">.</span><span class="n">codes</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="n">p</span><span class="o">.</span><span class="n">vertices</span> <span class="o">=</span> <span class="n">new_verts</span>
</pre></div>
<p>The commands to render a PNG and an SVG map are as follows:</p>
<div class="highlight"><pre><span class="c"># Exit the virtual environment in order to use the system-wide</span>
<span class="c"># Basemap package:</span>
<span class="nv">$ </span>deactivate

<span class="nv">$ </span>python plot.py render stats.json out.png
<span class="nv">$ </span>python plot.py render stats.json out.svg
</pre></div>
</div>
<div class="section" id="see-what-you-can-do-with-the-data">
<h2>See what you can do with the data</h2>
<p>I've made the airport IATA code pairs and passenger volumes available as a <a class="reference external" href="https://gist.github.com/marklit/d26182b41f3333ef3caa">CSV</a>.</p>
<p>The routes plotted on the night lights image from from NASA are available as an <a class="reference external" href="https://gist.github.com/marklit/18041a2876ee75b6f524">SVG file</a>. This should allow someone with good Illustrator skills to further stylise the map.</p>
<p>The Python code used to pull the data together and plot it on the map is available on <a class="reference external" href="https://github.com/marklit/airline-passenger-counts">GitHub</a>.</p>
<p>A PNG-formatted, 4,096 x 1,821px version of the image is available on <a class="reference external" href="http://i.imgur.com/nfX9lqm.jpg">imgur</a>.</p>
</div>

  </div>

   <div id="support_text"><p>
    Thank you for taking the time to read this post. If you're considering using </p><a href="https://www.digitalocean.com/?refcode=074ce6598105">Digital Ocean</a><p>, the hosting provider this blog is hosted on, please consider using </p><a href="https://www.digitalocean.com/?refcode=074ce6598105">this link to sign up</a><p>.
  </p></div>


  
</div></body></html>