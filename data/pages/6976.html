<html><body><div><article class="markdown-body entry-content" itemprop="text"><h1><a id="user-content-question-answering-corpus" class="anchor" href="#question-answering-corpus" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Question Answering Corpus</h1>

<p>This repository contains a script to generate question/answer pairs using
CNN and Daily Mail articles downloaded from the Wayback Machine.</p>

<p>For a detailed description of this corpus please read:
<a href="http://arxiv.org/abs/1506.03340">Teaching Machines to Read and Comprehend</a>, Hermann et al., NIPS 2015.
Please cite the paper if you use this corpus in your work.</p>

<h3><a id="user-content-bibtex" class="anchor" href="#bibtex" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Bibtex</h3>

<pre><code>@inproceedings{nips15_hermann,
author = {Karl Moritz Hermann and Tom\'a\v{s} Ko\v{c}isk\'y and Edward Grefenstette and Lasse Espeholt and Will Kay and Mustafa Suleyman and Phil Blunsom},
title = {Teaching Machines to Read and Comprehend},
url = {http://arxiv.org/abs/1506.03340},
booktitle = "Advances in Neural Information Processing Systems (NIPS)",
year = "2015",
}
</code></pre>

<h2><a id="user-content-download-processed-version" class="anchor" href="#download-processed-version" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Download Processed Version</h2>

<p>In case the script does not work you can also download the processed data sets from [<a href="http://cs.nyu.edu/%7Ekcho/DMQA/">http://cs.nyu.edu/~kcho/DMQA/</a>]. This should help in situations where the underlying data is not accessible (Wayback Machine partially down).</p>

<h2><a id="user-content-running-the-script" class="anchor" href="#running-the-script" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Running the Script</h2>

<h3><a id="user-content-prerequisites" class="anchor" href="#prerequisites" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Prerequisites</h3>

<p>Python 2.7, <code>wget</code>, <code>libxml2</code>, <code>libxslt</code> and <code>virtualenv</code>. <code>libxml2</code> must be
version 2.9.1.</p>

<pre><code>sudo pip install virtualenv
</code></pre>

<h3><a id="user-content-download-script" class="anchor" href="#download-script" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Download Script</h3>

<pre><code>mkdir rc-data
cd rc-data
wget https://github.com/deepmind/rc-data/raw/master/generate_questions.py
</code></pre>

<h3><a id="user-content-download-and-extract-metadata" class="anchor" href="#download-and-extract-metadata" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Download and Extract Metadata</h3>

<pre><code>wget https://storage.googleapis.com/deepmind-data/20150824/data.tar.gz -O - | tar -xz --strip-components=1
</code></pre>

<p>The news article metadata is ~1 GB.</p>

<h3><a id="user-content-enter-virtual-environment-and-install-packages" class="anchor" href="#enter-virtual-environment-and-install-packages" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Enter Virtual Environment and Install Packages</h3>

<pre><code>virtualenv venv
source venv/bin/activate
wget https://github.com/deepmind/rc-data/raw/master/requirements.txt
pip install -r requirements.txt
</code></pre>

<p>You may need to install <code>libxml2</code> development packages to install <code>lxml</code>:</p>

<pre><code>sudo apt-get install libxml2-dev libxslt-dev
</code></pre>

<h3><a id="user-content-download-urls" class="anchor" href="#download-urls" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Download URLs</h3>

<pre><code>python generate_questions.py --corpus=[cnn/dailymail] --mode=download
</code></pre>

<p>This will download news articles from the Wayback Machine. Some URLs may be
unavailable. The script can be run again and will cache
URLs that already have been downloaded. Generation of questions can run
without all URLs downloaded successfully.</p>

<h3><a id="user-content-generate-questions" class="anchor" href="#generate-questions" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Generate Questions</h3>

<pre><code>python generate_questions.py --corpus=[cnn/dailymail] --mode=generate
</code></pre>

<p>Note, this will generate ~1,000,000 small files for the Daily Mail so an SSD is
preferred.</p>

<p>Questions are stored in [cnn/dailymail]/questions/ in the following format:</p>

<pre><code>[URL]

[Context]

[Question]

[Answer]

[Entity mapping]
</code></pre>

<h3><a id="user-content-deactivate-virtual-environment" class="anchor" href="#deactivate-virtual-environment" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Deactivate Virtual Environment</h3>

<pre><code>deactivate
</code></pre>

<h3><a id="user-content-verifying-test-sets" class="anchor" href="#verifying-test-sets" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Verifying Test Sets</h3>

<pre><code>wget https://github.com/deepmind/rc-data/raw/master/expected_[cnn/dailymail]_test.txt
comm -3 &lt;(cat expected_[cnn/dailymail]_test.txt) &lt;(ls [cnn/dailymail]/questions/test/)
</code></pre>

<p>The filenames of the questions in the first column are missing generated questions. No output means everything is downloaded and generated correctly.</p>
</article>
  </div></body></html>