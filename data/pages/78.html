<html><body><div><div class="content html_format"><p>
      Некоторое время назад я рассказывал о «</p><a href="http://moscowdjango.ru/meetup/13/profiling-django/">Профилировании и отладке Django</a><p>». После выступления я получил много вопросов (как лично, так и по email), с парой новых знакомых мы даже выбрались в бар, чтобы обсудить важные проблемы программирования за кружечкой отменного эля, со многими людьми я продолжаю общаться до сих пор.
</p><p>
Поскольку выступление вызвало живой интерес, а беседы с коллегами позволили мне переосмыслить некоторые моменты презентации и исправить достадные ляпы, я решил оформить доклад и свои мысли в виде статьи. Это позволит ознакомиться с темой гораздо большему кругу заинтересованных лиц, к тому же Хабр предоставляет из себя идеальную площадку для комментирования предложенного материала и общения с интересными собеседниками.
</p><a name="habracut"/><p>
Материала много, статья получилась огромная, поэтому я решил разбить её на несколько частей:
</p>

<h2>Введение</h2><p>
В первую очередь необходимо разобраться с определениями. </p><a href="http://ru.wikipedia.org/wiki/Профилирование_(информатика)">Читаем</a><p> в Википедии:

</p><em>Профилирование — сбор характеристик работы программы с целью их дальнейшей оптимизации.</em>
<p>
Итак, для профилирования нам нужна работающая программа, причём работающая не совсем так, как нам хотелось бы: либо работающая слишком медленно, либо потребляющая слишком много ресурсов.
</p><p>
Какие же характеристики работы программы можно собирать?
</p><ul>
<li>время выполнения отдельных строк кода (инструкций)</li>
<li>количество вызовов и время выполнения отдельных функций</li>
<li>дерево вызовов функций</li>
<li>«<a href="http://ru.wikipedia.org/wiki/Хот-спот_(программирование)">hot spots</a>» (участки кода, на которые приходится существенная доля исполненных инструкций)</li>
<li>загрузку CPU и потребление памяти</li>
<li>обращение к другим ресурсам компьютера (например, к файловым дескрипторам)</li>
<li>и т.д. и т.п.</li>
</ul><p>
Конечно, не всегда есть смысл изучать проект подробно под микроскопом, разбирая каждую инструкцию и изучая всё досканально, но знать что, как и где мы можем посмотреть, полезно и нужно.
</p><p>
Давайте определимся с понятием «оптимизация». Википедия </p><a href="http://ru.wikipedia.org/wiki/Оптимизация_(информатика)">подсказывает</a><p> нам, что:

</p><em>Оптимизация — это модификация системы для улучшения её эффективности.</em>
<p>
Понятие «эффективность» — очень расплывчатое, и напрямую зависит от поставленной цели, например, в одних случаях программа должна работать максимально быстно, в других можно пренебречь скоростью и гораздо важнее сэкономить оперативную память или другие ресурсы (такие, как диск). Как справедливо </p><a href="http://ru.wikipedia.org/wiki/Серебряной_пули_нет">сказал</a><p> Фредерик Брукс, «серебрянной пули не существует».
</p><p>
Очевидно, что оптимизацией программы можно заниматься бесконечно: в любом достаточно сложном проекта всегда найдётся узкое место, которое можно улучшить, поэтому важно уметь останавливаться вовремя. В большинстве случаев (исключения крайне редки и относятся, скорее, к </p><a href="http://habrahabr.ru/post/27055/">фольклору</a><p>, чем к реальной жизни) нет смысла тратить, скажем, три дня рабочего времени ради 5% выигрыша по скорости.
</p><p>
С другой стороны, как любил повторять Дональд Кнут: «Преждевременная оптимизация — это корень всех бед».

</p><i>Какая статья про оптимизацию обходится без этой цитаты? Многие полагают, что её автор — Дональд Кнут, но сам Дональд утверждает, что впервые её произнёс Энтони Хоар. Энтони же отпирается и предлагает считать высказывание «всеобщим достоянием».</i>
<p>
Важно чётко понимать, что именно нас не устраивает в работе программы и каких целей мы хотим достичь, но это не значит, что профилированием и последующей оптимизацией нужно заниматься тогда, когда всё начинает тормозить. Хороший программист всегда знает, как себя чувствует написанная им программа и прогнозирует её работоспособность в критических ситуациях (таких, как хабраэффект).
</p><p>
Хочу заметить ещё один немаловажный момент: часто оптимизация сопровождается значительным ухудшением читаемости кода. По возможности, старайтесь избегать этого, а в случае, если всё-таки пришлось написать менее читаемый код в критичных местах, не поленитесь и оставьте комментарий с подробным описанием его работы. Ваши коллеги скажут вам спасибо, да и вы сами посчитаете себя удивительно проницательным, когда вернётесь к этим строкам через некоторое время.
</p><p>
Я не буду больше затрагивать вопрос оптимизации, поскольку, как я сказал выше, всё очень сильно зависит от поставленной задачи и каждый случай нужно разбирать отдельно. Сосредоточимся на обнаружении проблемных участков программы.

</p><h2>Подходы к профилированию</h2><p>
Существует, по крайней мере, три подхода к профилированию:
</p><ul>
<li>метод пристального взгляда</li>
<li>ручное профилирование</li>
<li>с использованием инструментов</li>
</ul><p>
С </p><strong>методом пристального взгляда</strong><p> (и родственным ему «</p><strong>методом тыка</strong><p>») всё понятно. Просто садимся перед текстовым редактором, открываем код и думаем, где может быть проблема, пробуем починить, смотрим на результат, откатываемся. И только в редких случаях (</p><i>либо при высочайшей квалификации разработчика</i><p>) метод оказывается действенным.
</p><p>
Достоинства и недостатки этого метода:</p><p>
+ не требует особых знаний и умений</p><p>
– сложно оценить трудозатраты и результат

</p><strong>Ручное профилирование</strong><p> удобно использовать, когда есть обоснованное предположение об узких местах и требуется подтвердить или опровергнуть гипотезу. Либо если нам, в отличие от первого метода, нужно получить численные показатели результатов нашей оптимизации (например, функция выполнялась за 946 милисекунд, стала отрабатывать за 73 милисекунды, ускорили код в 13 раз).
</p><p>
Суть этого метода в следующем: перед выполнением спорного участка программы сохраняем в переменную текущее системное время (с точностью до микросекунд), а после заново получаем текущее время и вычитаем из него значение сохранённой переменной. Получаем (с достаточной для нас погрешностью) время выполнения анализируемого кода. Для достоверного результата повторяем N раз и берём среднее значение.
</p><p>
Достоинства и недостатки этого метода:</p><p>
+ очень простое применение</p><p>
+ ограниченно подходит для продакшена</p><p>
– вставка «чужеродного» кода в проект</p><p>
– использование возможно не всегда</p><p>
– никакой информации о программе, кроме времени выполнения анализируемого участка</p><p>
– анализ результатов может быть затруднительным
</p><p>
Профилирование </p><strong>с помощью инструментов</strong><p> помогает, когда мы (по тем или иным причинам) не знаем, отчего программа работает не так, как следует, либо когда нам лень использовать ручное профилирование и анализировать его результаты. Подробнее об инструментах в следующем разделе.
</p><p>
Должен заметить, что независимо от выбранного подхода, главным инструментом разработчика остаётся его мозг. Ни одна программа (</p><i>пока(?)</i><p>) не скажет:
</p><em>Эй, да у тебя в строке 619 файла <i>project/app.py</i> ерунда написана! Вынеси-ка вызов той функции из цикла и будет тебе счастье. И ещё, если ты используешь кэширование, и перепишешь функцию <i>calculate</i> на Си, тогда быстродействие увеличится в среднем в 18 раз!</em>

<h2>Какие бывают инструменты</h2><p>
Инструменты бывают двух видов (на самом деле вариантов классификации и терминологии гораздо больше, но мы ограничимся двумя):
</p><ul>
<li>статистический (statistical) профайлер</li>
<li>событийный (deterministic, event-based) профайлер</li>
</ul>
<i>К сожалению, я так и не смог придумать красивого названия на русском языке для «детерминистического» профайлера, поэтому я буду использовать слово «событийный». Буду благодарен, если кто-нибудь поправит меня в комментариях.</i>
<p>
Большинство разработчиков знакомы только с событийными профайлерами, и большой неожиданностью для них оказывается тот факт, что статистический профайлер появился первым: в начале семидесятых годов прошлого столетия программисты компьютеров </p><a href="http://ru.wikipedia.org/wiki/IBM_System/360">IBM/360</a><p> и </p><a href="http://ru.wikipedia.org/wiki/IBM_System/370">IBM/370</a><p> ставили прерывание по таймеру, которое записывало текущее значение </p><a href="http://en.wikipedia.org/wiki/Program_status_word">Program status word</a><p> (PSW). Дальнейший анализ сохранённых данных позволял определить проблемные участки программы.
</p><p>
Первый событийный профайлер появился в конце тех же семидесятых годов, это была утилита ОС Unix </p><strong>prof</strong><p>, которая показывала время выполнения всех функций программы. Спустя несколько лет (1982 год) появилась утилита </p><strong>gprof</strong><p>, которая научилась отображать граф вызовов функций.

</p><h3>Статистический профайлер</h3><p>
Принцип работы статистического профайлера прост: через заданные (достаточно маленькие) промежутки времени берётся указатель на текущую выполняемую инструкцию и сохраняет эту информацию («семплы») для последующего изучения. Выглядит это так:
</p><img src="https://habrastorage.org/getpro/habr/post_images/8a9/6cb/bc3/8a96cbbc3a23582f4ec1f465d9b01cbc.png"/><p>
видно, функция </p><strong>bar()</strong><p>выполнялась почти в два с половиной раза дольше, чем функции </p><strong>foo()</strong><p>, </p><strong>baz()</strong><p> и какая-то безымянная инструкция.
</p><p>
Один из недостатков статистического профайлера заключается в том, что для получения адекватной статистики работы программы нужно провести как можно большее (в идеале — бесконечное) количество измерений с как можно меньшим интервалом. Иначе некоторые вызовы вообще могут быть не проанализированы:
</p><img src="https://habrastorage.org/getpro/habr/post_images/d4e/a00/2b9/d4ea002b9d96438ec259b11d856f88cc.png"/><p>
например, из рисунка видно, что безымянная функция не попала в выборку.
</p><p>
Так же сложно оценить реальное время работы анализируемых функций. Рассмотрим ситуацию, когда функция </p><strong>foo()</strong><p> выполняется достаточно быстро, но вызывается очень часто:
</p><img src="https://habrastorage.org/getpro/habr/post_images/c2e/9ee/be5/c2e9eebe5dedcdecc8ff8b3f9157e676.png"/><p>
и ситуацию, когда функция </p><strong>foo()</strong><p> выполняется очень долго, но вызывается лишь один раз:
</p><img src="https://habrastorage.org/getpro/habr/post_images/7a3/6b6/889/7a36b68898ff129c22ece3baad08c299.png"/><p>
результат работы статистического профайлера будет одинаковым в обоих случаях.
</p><p>
Тем не менее, с поиском самых «тяжёлых» и «горячих» мест программы статистический профайлер справляется великолепно, а его минимальное влияние на анализируемую программу (и, как следствие, пригодность к использованию в продакшене) перечёркивает все минусы. К тому же Python позволяет получить полный stacktrace для кода при семплировании и его анализ позволяет получать более полную и подробную картину.
</p><p>
Достоинства и недостатки статистического профайлера:</p><p>
+ можно пускать в продакшен (влияние на анализируемую программу минимально)</p><p>
– получаем далеко не всю информация о коде (фактически только «hot spots»)</p><p>
– возможно некорректное интерпретирование результата</p><p>
– требуется длительное время для сбора адекватной статистики</p><p>
– мало инструментов для анализа

</p><h3>Событийный профайлер</h3><p>
Событийный профайлер отслеживает все вызовы функций, возвраты, исключения и замеряет интервалы между этими событиями. Измеренное время (вместе с информацией о соответствующих участках кода и количестве вызовов) сохраняется для дальнейшего анализа.
</p><img src="https://habrastorage.org/getpro/habr/post_images/fd3/9ee/478/fd39ee4789da3cfc81e2cedf859e78de.png"/>
<p>
Самый важный недостаток таких профайлеров прямо следует из принципа их работы: поскольку мы вмешиваемся в анализируемую программу </p><strong>на каждом шагу</strong><p>, процесс её выполнения может (и будет) сильно отличаться от «обычных» условий работы (прям как в квантовой механике). Так, например, в некоторых случаях возможно замедление работы программы в два и более раз. Конечно, в продакшен выпускать такое можно только в случае отчаяния и полной безысходности.
</p><p>
И тем не менее плюсы перевешивают минусы, иначе не было бы такого огромного разнообразия различных инструментов. Просмотр результатов в удобном интерфейсе с возможностью анализа времени выполнения и количества вызовов каждой строки программы многого стоят, граф вызовов помогает обнаружить недостатки в используемых алгоритмах.
</p><p>
Достоинства и недостатки событийных профайлеров:</p><p>
+ не требуется изменения кода</p><p>
+ получаем всю информаци о работе программы</p><p>
+ огромное количество инструментов</p><p>
– в некоторых случаях профайлер меняет поведение программы</p><p>
– очень медленно</p><p>
– практически непригодно для продакшена
</p><p>
В </p><a href="http://habrahabr.ru/company/mailru/blog/201778/">следующей статье</a><p> мы на практике разберём ручное профилирование и статистические профайлеры. Оставайтесь на связи =)

      
      </p><p class="clear"/>
    </div>

    
  </div></body></html>