<html><body><div><article class="markdown-body entry-content" itemprop="text"><h3><a id="user-content-all-the-time-the-sun--is-wheeling-out-of-a-dark-bright-ground" class="anchor" href="#all-the-time-the-sun--is-wheeling-out-of-a-dark-bright-ground" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>"All the time the sun / Is wheeling out of a dark bright ground."</h3>

<p><a href="https://s3.amazonaws.com/rossgoodwin/neuralsnap/145215747053_img1.jpg"><img src="https://camo.githubusercontent.com/d3ab2b39174f384c93fb8c126dfa7aa2f0208ccb/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f726f7373676f6f6477696e2f6e657572616c736e61702f3134353231353734373035335f696d67312e6a7067" data-canonical-src="https://s3.amazonaws.com/rossgoodwin/neuralsnap/145215747053_img1.jpg"/></a></p><p>A close up of a red and white striped umbrella and the streets are still still and the sun is still a little and the sun is still and the sun is still and the sun is still and the sun is gone.</p><p>The sun is singing and the sun is still and the sun is looking for the sun.</p><p>The sun is still there and the sun is still and the sun is down and the sun is still and the sun is gone.</p><p>The sun is still there and the sun is gone.</p><p>The sun is still and the sun is still there.</p><p>The sun is dead.</p><p>The sun is still, and the sun is shining in the wind.</p>

<p>A close up of a red and white striped umbrella, and the post office was a fire of stone in the middle of the bar. The streetcar remains of the police. The bar was a little strange and sharp as the man who had the strength to stay away from the problem. The little girl was a big fish with a green shoe which had hardly a shot and the party of the storm was being considered a strange story.</p>

<p>A close up of a red and white striped umbrella, and the mountains are lighted and still there is no definition in the morning of a little of morning to the first thing that makes the moon sink under the space that will be gone from the stars.</p><p>I want to see it like this has been so awkward and unwanted. I shall see it all out of the sea of the past. Only the sound of the trees are coming up like a bone to be put on a strange ship.</p>

<p>A close up of a red and white striped umbrella, and the living and the dark and the red with the sleep of a hand, and the wind remains the sun and the high leaves.</p><p>The sun is beautiful, and there is no desire to feel the mind off the sea.</p><p>In the middle of the place, the moon is opened with the human form.</p><p>The world is all the streets are all there.</p><p>The land of the broken light of life is a procession</p><p>Of many million men in lonely arms</p><p>On the page of the barn. All the time the sun</p><p>Is wheeling out of a dark bright ground.</p>

<p><em>(Painting by Mark Rothko, poetry generated by NeuralSnap)</em></p>

<h1><a id="user-content-neuralsnap" class="anchor" href="#neuralsnap" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>NeuralSnap</h1>

<p>A new year, a new word camera: NeuralSnap uses artificial neural networks to generate poetry from images.</p>

<p>By <a href="http://rossgoodwin.com">Ross Goodwin</a>, 2016</p>

<h2><a id="user-content-more-output-samples" class="anchor" href="#more-output-samples" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>More Output Samples</h2>



<h2><a id="user-content-intent" class="anchor" href="#intent" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Intent</h2>

<p>This project, in many ways a follow-up on <a href="https://word.camera">word.camera</a>, was created on the shoulders of two spectacular open source contributions by <a href="https://github.com/karpathy">Andrej Karpathy</a>: <a href="https://github.com/karpathy/neuraltalk">NeuralTalk2</a> and <a href="https://github.com/karpathy/char-rnn">Char-RNN</a>, both of which run in <a href="http://torch.ch/">Torch</a>. The code I've provided in this repository is a modest Python wrapper for a few of Karpathy's scripts, and a means to experiment with a few models that I've trained on <a href="http://www.nvidia.com/object/tesla-k80.html">Nvidia K80 GPUs</a> using the High Performance Computing facilities at NYU.</p>

<p>In my research, I am developing tools that I hope will serve to augment human creativity. These are the first neural network models to emerge from my explorations, and I've decided to make them available to others:</p>

<pre><code>$ wget https://s3.amazonaws.com/rossgoodwin/models/2016-01-12_char-rnn_model_01_rg.t7
$ wget https://s3.amazonaws.com/rossgoodwin/models/2016-01-12_char-rnn_model_02_rg.t7
$ wget https://s3.amazonaws.com/rossgoodwin/models/2016-01-12_neuraltalk2_model_01_rg.t7
</code></pre>

<p>NOTE: These models are licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. That means if you use them you must attribute me (Ross Goodwin), you cannot use these models for commercial purposes, and any derivative work you produce must be licensed under the same terms.</p>

<p><a href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" src="https://camo.githubusercontent.com/6887feb0136db5156c4f4146e3dd2681d06d9c75/68747470733a2f2f692e6372656174697665636f6d6d6f6e732e6f72672f6c2f62792d6e632d73612f342e302f38387833312e706e67" data-canonical-src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png"/></a><br/>NeuralSnap Models by <a href="http://rossgoodwin.com">Ross Goodwin</a> are licensed under a <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.<br/>Based on a work at <a href="https://github.com/rossgoodwin/neuralsnap"/><a href="https://github.com/rossgoodwin/neuralsnap">https://github.com/rossgoodwin/neuralsnap</a>.</p>

<h2><a id="user-content-how-it-works" class="anchor" href="#how-it-works" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>How It Works</h2>

<p><a href="https://github.com/karpathy/neuraltalk">NeuralTalk2</a> uses <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional</a> and <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">recurrent</a> neural networks to caption images. I trained my own model on the <a href="http://mscoco.org/">MSCOCO dataset</a>, using the general guidelines Karpathy outlines in his documentation, but made adjustments to increase verbosity.</p>

<p>I then trained a recurrent neural network using <a href="https://github.com/karpathy/char-rnn">Char-RNN</a> on about 40MB of (mostly) 20th-century poetry from a variety of writers (and a variety of cultures) around the world.</p>

<p>In the output examples above, the red text is the image caption, and the poetry-trained net generated the rest of the text. The stanzas iterate through different RNN "temperature" values, an input that controls the riskiness of the model's predictions. Lower temperature results will be more repetitive and strictly grammatical, while higher temperature results contain more variety but may also contain more errors.</p>

<h2><a id="user-content-how-to-run-it" class="anchor" href="#how-to-run-it" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>How To Run It</h2>

<p>I have tested this software on Ubuntu 14.04 and 15.10. You can try other OS options at your own risk -- in theory, it should run on anything that can run Torch and Python, although I've heard that <a href="https://github.com/SaMnCo/docker-neuraltalk2">NeuralTalk2 does not play nice with the Raspberry Pi</a>.</p>

<p>You'll need to clone the <a href="https://github.com/karpathy/neuraltalk">NeuralTalk2</a> and <a href="https://github.com/karpathy/char-rnn">Char-RNN</a> repos into the main folder, then follow Karpathy's README instructions to install the dependencies for NeuralTalk2 -- you don't need to worry about any of the GPU or training stuff, unless you want to use your own models. (The models I've provided are calibrated to run on CPUs.) Thankfully, the dependencies of Char-RNN are a subset of those required for NeuralTalk2.</p>

<h2><a id="user-content-usage" class="anchor" href="#usage" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Usage</h2>

<pre><code>$ python neuralsnap.py &lt;output_title&gt; &lt;ntalk_model_filepath&gt; &lt;rnn_model_filepath&gt; &lt;image_folder_filepath&gt;
</code></pre>

<p>e.g.</p>

<pre><code>$ python neuralsnap.py testing123 /path/to/neuraltalk2/model/2016-01-12_neuraltalk2_model_01_rg.t7 /path/to/char-rnn/model/2016-01-12_char-rnn_model_02_rg.t7 /path/to/image/folder
</code></pre>

<h2><a id="user-content-software-license-information" class="anchor" href="#software-license-information" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Software License Information</h2>

<p>As noted above, my trained models are available under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. However, I have licensed the code in this repository under GPLv3.</p>

<pre><code>NeuralSnap image-to-text poetry generator
Copyright (C) 2016  Ross Goodwin

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;.

You may contact Ross Goodwin via email at ross.goodwin@gmail.com or
address physical correspondence to:

Ross Goodwin c/o ITP
721 Broadway, 4th Floor
New York, NY 10003
</code></pre>
</article>
  </div></body></html>