<html><body><div><div class="content html_format">
      <img src="https://habrastorage.org/getpro/habr/post_images/92d/b64/dea/92db64deaa585651fb5060baa37dce0f.png"/>
<p>
Вещь, которая привлекла меня изучать компьютерную науку была компилятором. Я думал, что это все магия, как они могут читать даже мой плохо написанный код и компилировать его. Когда я прошел курс компиляторов, я стал находить этот процесс очень простым и понятным.

</p><p>
В этом цикле статей я попытаюсь захватить часть этой простоты путем написания простого интерпретатора для обычного императивного языка </p><b>IMP</b><p> (IMperative Language). Интерпретатор будет написан на Питоне, потому что это простой и широко известный язык. Также, питон-код похож на псевдокод, и даже если вы не знаете его [питон], у вас получится понять код. Парсинг будет выполнен с помощью простого набора комбинаторов, написанных с нуля (подробнее расскажу в следующей части). Никаких дополнительных библиотек не будет использовано, кроме </p><i>sys</i><p> (для I/O), </p><i>re</i><p> (регулярные выражения в лексере) и </p><i>unittest</i><p> (для проверки работоспособности нашей поделки).
</p><a name="habracut"/>
<h5>Сущность языка IMP</h5><p>
Прежде всего, давайте обсудим, для чего мы будем писать интерпретатор. IMP есть нереально простой язык со следующими конструкциями:

</p><i>Присвоения (все переменные являются глобальные и принимают только integer):</i>

<pre><code class="python">x := 1</code></pre>

<i>Условия:</i>

<pre><code class="python">if x = 1 then 
  y := 2 
else 
  y := 3
end
</code></pre>

<i>Цикл while:</i>

<pre><code class="python">while x &lt; 10 do 
  x := x + 1
end
</code></pre>

<i>Составные операторы (разделенные <b>;</b>):</i>

<pre><code class="python">x := 1; 
y := 2
</code></pre>
<p>
Это всего-лишь игрушечный язык. Но вы можете расширить его до уровня полезности как у Python или Lua. Я лишь хотел сохранить его настолько простым, насколько смогу.

</p><i>А вот тут пример программы, которая вычисляет факториал:</i>

<pre><code class="python">n := 5;
p := 1;
while n &gt; 0 do
  p := p * n;
  n := n - 1
end
</code></pre>
<p>
Язык IMP не умеет читать входные данные (input), т.е. в начале программы нужно создать все нужные переменные и присвоить им значения. Также, язык не умеет выводить что-либо: интерпретатор выведет результат в конце.

</p><h5>Структура интерпретатора</h5><p>
Ядро интерпретатора является ничем иным, как промежуточным представлением (intermediate representation, IR). Оно будет представлять наши IMP-программы в памяти. Так как IMP простой как 3 рубля, IR будет напрямую соответствовать синтаксису языка; мы создадим по классу для каждой единицы синтаксиса. Конечно, в более сложном языке вы хотели бы использовать еще и семантическую представление, которое намного легче для анализа или исполнения.
</p><p>
Всего три стадии интерпретации:
</p><ul>
<li>Разобрать символы исходного кода на токены.</li>
<li>Собрать все токены в абстрактное синтаксическое дерево (abstract syntax tree, AST). AST и есть наша IR.</li>
<li>Исполнить AST и вывести результат в конце.</li>
</ul>
<p>
Процессом разделения символов на токены называется лексинг (lexing), а занимается этим лексер (lexer). Токены являют собой короткие, удобоваримые строки, содержащие самые основные части программы, такие как числа, идентификаторы, ключевые слова и операторы. Лексер будет пропускать пробелы и комментарии, так как они игнорируются интерпретатором.
</p><p>
Процесс сборки токенов в AST называется парсингом. Парсер извлекает структуру нашей программы в форму, которую мы можем исполнить.
</p><img src="http://habrastorage.org/storage3/1ee/b66/213/1eeb66213f95fdbe1d27a530c6aaf465.png" align="right"/>
<p>
Эта статься будет сосредоточена исключительно на лексере. Сначала мы напишем общую лекс-библиотеку а затем уже лексер для IMP. Следующие части будут сфокусированы на парсере и исполнителе.

</p><h5>Лексер</h5><p>
По правде говоря, лексические операции очень просты и основываются на регулярных выражениях. Если вы с ними не знакомы, то можете прочитать </p><a href="http://docs.python.org/2/library/re.html">официальную документацию</a><p>.
</p><p>
Входными данными для лексера будет простой поток символов. Для простоты мы прочитаем инпут в память. А вот выходящими данными будет список токенов. Каждый токен включает в себя значение и метку (тег, для идентификации вида токена). Парсер будет использовать это для построения дерева (AST).
</p><p>
Итак, давайте сделаем обычнейший лексер, который будет брать список регэкспов и разбирать на теги код. Для каждого выражения он будет проверять, соответствует ли инпут текущей позиции. Если совпадение найдено, то соответствующий текст извлекается в токен, наряду с тегом регулярного выражения. Если регулярное выражение ни к чему не подходит, то текст отбрасывается. Это позволяет нам избавиться от таких вещей как комментарии и пробелы. Если вообще ничего не совпало, то мы рапортуем об ошибке и скрипт становится героем. Этот процесс повторяется, пока мы не разберем весь поток кода.

</p><i>Вот код из библиотеки лексера:</i>

<pre><code class="python">import sys
import re

def lex(characters, token_exprs):
	pos = 0
	tokens = []
	while pos &lt; len(characters):
		match = None
		for token_expr in token_exprs:
			pattern, tag = token_expr
			regex = re.compile(pattern)
			match = regex.match(characters, pos)
			if match:
				text = match.group(0)
				if tag:
					token = (text, tag)
					tokens.append(token)
				break
		if not match:
			sys.stderr.write('Illegal character: %s\n' % characters[pos])
			sys.exit(1)
		else:
			pos = match.end(0)
	return tokens
</code></pre>
<p>
Отметим, что порядок передачи в регулярные выражения является значительным. Функция lex будет перебирать все выражения и примет только первое найденное совпадение. Это значит, что при использовании этой функции, первым делом нам следует передавать специфичные выражения (соответствующие операторам и ключевым словам), а затем уже обычные выражения (идентификаторы и числа).

</p><h5>Лексер IMP</h5><p>
С учетом кода выше, создание лексера для нашего языка становится очень простым. Для начала определим серию тегов для токенов. Для языка нужно всего лишь 3 тега. </p><b>RESERVED</b><p> для зарезервированных слов или операторов, </p><b>INT</b><p> для чисел, </p><b>ID</b><p> для идентификаторов.

</p><pre><code class="python">import lexer

RESERVED = 'RESERVED'
INT      = 'INT'
ID       = 'ID'
</code></pre>
<p>
Теперь мы определим выражения для токенов, которые будут использованы в лексере. Первые два выражения соответствуют пробелам и комментариям. Так как у них нету тегов, лексер их пропустит.

</p><pre><code class="python">token_exprs = [
    (r'[ \n\t]+',              None),
    (r'#[^\n]*',               None),
</code></pre>
<p>
После этого следуют все наши операторы и зарезервированные слова.

</p><pre><code class="python">    (r'\:=',                   RESERVED),
    (r'\(',                    RESERVED),
    (r'\)',                    RESERVED),
    (r';',                     RESERVED),
    (r'\+',                    RESERVED),
    (r'-',                     RESERVED),
    (r'\*',                    RESERVED),
    (r'/',                     RESERVED),
    (r'&lt;=', RESERVED),
    (r'&lt;', RESERVED),
    (r'&gt;=', RESERVED),
    (r'&gt;', RESERVED),
    (r'=',                     RESERVED),
    (r'!=',                    RESERVED),
    (r'and',                   RESERVED),
    (r'or',                    RESERVED),
    (r'not',                   RESERVED),
    (r'if',                    RESERVED),
    (r'then',                  RESERVED),
    (r'else',                  RESERVED),
    (r'while',                 RESERVED),
    (r'do',                    RESERVED),
    (r'end',                   RESERVED),
</code></pre>
<p>
Наконец, нам нужны выражения для чисел и идентификаторов. Обратите внимание, что регулярным выражениям для идентификаторов будут соответствовать все зарезервированные слова выше, поэтому очень важно, чтобы эти две строчки шли последними.

</p><pre><code class="python">    (r'[0-9]+',                INT),
    (r'[A-Za-z][A-Za-z0-9_]*', ID),
]
</code></pre>
<p>
Когда наши регэкспы определены, мы можем создать обертку над функцией </p><b>lex:</b>

<pre><code class="python">def imp_lex(characters):
    return lexer.lex(characters, token_exprs)
</code></pre>
<p>
Если вы дочитали до этих слов, то вам, скорее всего, будет интересно как работает наше чудо. Вот код для теста:

</p><pre><code class="python">import sys
from imp_lexer import *

if __name__ == '__main__':
    filename = sys.argv[1]
    file = open(filename)
    characters = file.read()
    file.close()
    tokens = imp_lex(characters)
    for token in tokens:
        print token
</code></pre>

<pre><code class="python">$ python imp.py hello.imp</code></pre>
<p>
Скачать полный исходный код: </p><a href="http://www.jayconrod.com/code/imp-interpreter.tar.gz">imp-interpreter.tar.gz</a><p>
Автор оригинальной статьи — </p><a href="http://www.jayconrod.com/posts/37/a-simple-interpreter-from-scratch-in-python-part-1">Jay Conrod</a><p>.

</p><b>UPD:</b><p> Спасибо пользователю </p><a href="https://habrahabr.ru/users/zelark/" class="user_link">zeLark</a><p> за исправление бага, связанного с порядком определения шаблонов.
      </p><p class="clear"/>
    </div>

    
  </div></body></html>