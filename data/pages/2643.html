<html><body><div><body id="readabilityBody">

<p>Entire website open-sourced at: <a href="https://github.com/grokit/website_grokit_ca/">https://github.com/grokit/website_grokit_ca/</a>. Feel free to make pull requests if you find mistakes!</p>

<h1>The Knapsack Problem</h1>
<p>You have a knapsack of size W and a set 'S' of n items of value v and weight w: S = {s1, s2, ..., sn} = {(v1, w1), (v2, w2), ..., (vn, wn)} with \(W, vi, wi \in \mathbb{N}\). v1 = value(s1), w1 = weight(s1).</p>
<p>Find the combinations of items SOL in set S that yield the highest combined value whilst having a total weight w &lt;= W. That is, find SOL such that: \(SOL \subseteq S, \sum_{i} weight(SOL_{i}) &lt;= W, \sum_{i} value(SOL_{i})\) is maximal.</p>
<p>Note: since all weights are non-negative integers, this is the <em>unbounded knapsack problem</em>.</p>
<h2>Brute Force</h2>
<p>The simplest way to approach this problem is to just iterate all the possible \(|\mathcal{P}(S)| = 2^n\) items combinations (each item can be either in the bag or not in the bag), discard the combinations that do not satisfy the weight constraint and output the item combination that has the maximum value. This is a pretty straightforward implementation:</p>
<p><strong>[Inserted file: knapsack_bruteforce.py.]</strong></p>
<pre><code>import knapsack

def recurse(i, S, currWeight, currValue):
    """
    i = current position in S.
    S: [(v0, w0), ..., (vn, wn)]
    """

    if currWeight &lt; 0:
        return -1

    if i == len(S):
        return currValue

    # Pick item at S[i]
    s1 = recurse(i+1, S, currWeight - S[i][1], currValue + S[i][0])

    # Do no pick item.
    s2 = recurse(i+1, S, currWeight, currValue)

    return max(s1, s2)

maxWeight, S = knapsack.readProblemSTDIn()
s = recurse(0, S, maxWeight, 0)
print(s)
</code></pre>
<p>However, for values n ~&gt; 40, this becomes <a href="http://www.grokit.ca/cnt/ComputationallyFeasible/">computationally unfeasible</a>. Computers generally work in gigahertz, which means that there is a clock cycle every 1e-9 second. \(2^{30}\) ~= 1e9, which means that if every iteration of your algorithm takes ~100 clock cycles, then the program will complete in ~100 seconds. For n = 50, it will complete in over a thousand days <code>(100*(2**50) / (1e9*(60*60*24)))</code>. Too slow.</p>
<h2>Greedy?</h2>
<p>It worth considering if there is a simple greedy heuristic that could solve this problem.</p>
<p>Let's first prove by contradiction that you cannot just pick the item with maximum value. Given a set of items SOL = {(19, 1), (19, 1) (20, 20)} and W = 20. Then we would pick item (20, 20) and have a full backpack \((\sum w_i = 20)\) for value of 20. If we had picked {(19, 1), (19, 1)}, we would have W = 2 and v = 38, which is better. Therefore the <code>pick the maximum value item</code> heuristic does not work.</p>
<p>A little less naive solution would be to first pick the items in order of greatest density (value/weight) to lowest density. However, by contradiction again, consider the following problem: SOL = {(6, 6), (4, 5), (4, 5)}; W = 10. The density of s1 = 1, density of s2 and s3 are 0.8. The maximum density heuristic would pick s1 for value = 6, while the optimal solution is SOL' = {(4, 5), (4, 5)} for weight of 10 and value of 8.</p>
<p>So greedy seems like it is not the way to go. We did not prove that, but if you find a greedy approach that works, tell me and you and I will be very rich!</p>
<h3>Note that Greedy Would Work if We Could Cut the Items Into Fractions</h3>
<p>We stated the problem as a 0-1 Knapsack problem, that is, the items are either in the bag or not. If it were possible to cut the items into fractions, then a greedy approach would work since we could simply fill the bag with decreasingly highest density items without having to worry about taking space that could be filled with a more optimal fractional item (by definition).</p>
<h2>Dynamic Programming (DP) Solution</h2>
<p>The problem with the exorbitant cost of exploring the whole \(O(2^n)\) solution space. So, can we do better? When looking for DP solutions, it is worth considering if you can solve the problem by iteratively adding or removing items in the set <em>in order</em>. You can look at this from from two vintage points: start with empty problem and build-up or start with hypothetical best solution, then decompose into smaller cases. I like to imagine DP problems as a snake that can be grabbed either by the head or the tail. In this case, we will start with an hypothetical optimal solution set SOL, then try to simplify the problem by iteratively plucking away the last item sn (grab by the head!). This leads to two possibilities for every iteration:</p>
<ol>
<li>
<p>sn was not a member of SOL, therefore can consider the simpler, equivalent problem of S - {sn} with weight unchanged. This is correct since if there exist a solution SOL' which is better than SOL given that SOL' can pick sn and SOL cannot, then SOL' is a better solution than SOL in S, which is incorrect by definition.</p>
</li>
<li>
<p>The other possibility is that sn is a member of SOL, in which case S - {sn} with weight -= wn is a subproblem with optimal solution SOL - {sn}. We can prove this is correct by contradiction: if SOL - {sn} is not an optimal solution with weight = weight' = weight - wn using set S - {sn}, then there exist a solution \(SOL' \subseteq  S - S\{sn\}\) which has higher value than SOL - {sn}. This implies that there exist a better solution than SOL: SOL* = SOL' + {sn} which satisfies the weight constraint -- this is incorrect by definition.</p>
</li>
</ol>
<p><a href="@@meta: explanation below could be improved. @@@finish"/></p>
<p>If you remove the first item, you can solve that sub-problem in \(O(2^{n-1})\) time (do not forget to remove the weight of the item discarded to the problem). If you do this recursively, you end-up with a solution to a set of smaller problems which can be <em>combined</em> into the solution to the complete problem.</p>
<p>Since you can remove n items from S, and that each time you remove an item you change the total weight of the solution, there can be at maximum n<em>W sub-problems to solve, yielding a DP cost of O(n</em>W).</p>
<h2>Code: Dynamic Programming Solution (Tree Approach)</h2>
<p><strong>[Inserted file: knapsack.py.]</strong></p>
<pre><code>"""
Knapsack problem.

Solution for problem as stated in https://class.coursera.org/algo2-2012-001/quiz/attempt?quiz_id=85.

# TODO

- Code exhaustive solution.
- Use the 2D array method and compare performance.
- Use branch and bound and compare performance.
"""

def readProblemSTDIn():
    """
    Format of input file:
    maxWeight n
    v0 w0
    v1 w1
    ...
    vn wn
    """

    maxWeight, n = [int(x) for x in input().strip().split(' ')]

    I = []
    for i in range(n):
        X = [(int(x), int(y)) for x, y in [input().strip().split(' ')]][0]
        I.append(X)

    return (maxWeight, I)

def recurse(i, S, currWeight, memo):
    """
    i = current position in S.
    S: [(v0, w0), ..., (vn, wn)]
    """

    if memo.get((i, currWeight)) is not None:
        return memo[(i, currWeight)]

    if i == len(S):
        return 0

    if currWeight - S[i][1] &gt;= 0:
        choicePickItem = recurse(i + 1, S, currWeight - S[i][1], memo)
        choicePickItem += S[i][0]
    else:
        choicePickItem = -int(1e20)

    choiceNotPickItem = recurse(i + 1, S, currWeight, memo)

    if choiceNotPickItem &gt;= choicePickItem:
        sol = choiceNotPickItem
    else:
        sol = choicePickItem

    memo[(i, currWeight)] = sol

    return sol


if __name__ == '__main__':
    maxWeight, S = readProblemSTDIn()
    s = recurse(0, S, maxWeight, {})
    print(s)
</code></pre>
<p><strong>[Inserted file: knapsack_tiny.in.]</strong></p>
<pre><code>750 15
135 70
139 73
149 77
150 80
156 82
163 87
173 90
184 94
192 98
201 106
210 110
214 113
221 115
229 118
240 1
</code></pre>
<p><strong>[Inserted file: solutions.txt.]</strong></p>
<pre><code>Tiny:  1686 
Small: 2493893
Large: 2595819
</code></pre>
<p>The small and large files can be found <a href="https://github.com/grokit/website_grokit_ca/tree/master/articles/web/KnapsackProblem">on GitHub</a>.</p>
<h3>Limitations of DP Approach</h3>
<p>Why does it work only for integer weights?</p>
<p>If you have floating point values for the weight, then the amount of memory you need to hold is not bounded by n*W. Let's say all n items have different floating point weights, it is possible that you never land on the same weight value for a given i.</p>
<p>Note that the values could be non-integral since we are just maximizing the value. What would happen if the values would be allowed to be negative?</p>
<h2>Other Approaches</h2>
<ul>
<li>Can also use the standard table approach where you build a 2D array for of i / w.</li>
</ul>
<h2>References</h2>
<h4>Page Metadata</h4><p id="metainfo">date: ['2015-01-03']<br/>category: ['auto']<br/>tags: ['viewA', 'csiq_combinatorics', 'csiq_elementary', 'csiq_average', 'dynamic programming']<br/></p>

<h2>Comments</h2>



<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by </a>













</body>
</div></body></html>