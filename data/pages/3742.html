<html><body><div><div class="content html_format">
      <img align="left" src="https://habrastorage.org/files/5d5/583/b08/5d5583b088a14c7eb219fbe1e2072d4a.png"/><p> Привет, хабр!
</p><p>
После публикации </p><a href="http://habrahabr.ru/users/akrot/topics/">нескольких статей</a><p> по </p><b>Big Data</b><p> и </p><b>Машинному обучению</b><p>, ко мне пришло немало писем от читателей с вопросами. За последние несколько месяцев мне удалось помочь многим людям сделать быстрый старт, некоторые из них — уже решают прикладные задачи и делают успехи. А кто-то уже устроился на работу и занимается решением реальных задач. Моя цель — чтобы вокруг меня были умные люди, с которыми в том числе и я смогу работать в дальнейшем. Поэтому я хочу помочь тем, кто действительно хочет научиться решать настоящие задачи на практике. В сети присутствует большое количество мануалов о том, как стать ученым по данным (</p><b>Data Scientist</b><p>). В свое время я прошел все, что там есть. </p><b>Однако, на практике порой нужны совсем другие знания.</b><p> О том, какие именно навыки нужны — я расскажу в сегодняшней статье и постараюсь ответить на все Ваши вопросы.
</p><a name="habracut"/><p>
Если загуглить </p><b>«How to become a Data Scientist»</b><p>, можно наткнуться на множество картинок вроде </p><a href="http://i1.wp.com/blog.datacamp.com/wp-content/uploads/2014/08/How-to-become-a-data-scientist.jpg">этой</a><p> или </p><a href="https://markcarrigan.files.wordpress.com/2014/09/datasci.png">этой</a><p>. В целом, все, что там написано — действительно так. Но, изучив все это, не гарантируется, что вас ждет успех в решении реальных задач на практике. В целом, можно пойти путем, изложенным на изображениях выше — а именно, учиться самостоятельно, после чего пойти и решать реальные задачи. Можно поступить иначе — пойти получить специальное образование. В свое время мне довелось пройти и тот и другой путь — и курсы </p><a href="https://www.coursera.org/">Coursera</a><p>, и </p><a href="http://shad.yandex.ru/">Школу Анализа Данных</a><p> и множество других курсов в ВУЗе, в том числе по компьютерному зрению, анализу веб-графов, Large Scale Machine Learning и др. Мне повезло учиться у лучших преподавателей — и пройти лучшие курсы, какие только есть. Но только после того, как я начал применять полученные знания на практике, пришло понимание, что в курсах зачастую не уделяется должное внимание практическим проблемам, либо они не усваиваются до тех пор, пока сам на них не наткнешься. Поэтому, я постараюсь изложить набор минимальных навыков, которых будет достаточно для того, чтобы как можно скорее начать решать задачи на практике.

</p><h3>Станьте отличным математиком</h3><p>
Да, это наверное самое важное — математическое мышление, которое надо развивать в себе постоянно с младших лет. Для тех, кто, возможно это упустил, стоит начать с курсов по Дискретной математике — это полезно вообще для всех людей, которые работают в IT. На этом основаны все доказательства и рассуждения в дальнейших курсах. Рекомендую пройти </p><a href="http://habrahabr.ru/post/252077/">курс</a><p> Александра Борисовича Дайняка, который когда-то я слушал очно. Этого должно быть достаточно. </p><b>Здесь важно набрать навыки работы с дискретными обьектами.</b>
<p>
После того, как вы научитесь оперировать дискретными обьектами, рекомендуется познакомиться с построением эффективных алгоритмов — для этого достаточно пройти небольшой курс по алгоритмам, вроде </p><a href="http://shad.yandex.ru/lectures/algorithms.xml">курса ШАДа</a><p> или прочитав обзор известных алгоритмов на </p><a href="http://e-maxx.ru/">e-maxx.ru</a><p> — довольно популярный сайт среди участников ACM. </p><b>Здесь достаточно понимать, как реализовавывать алгоритмы эффективно, а также знать типичные структуры данных и случаи, когда их использовать.</b>
<p>
После того, как ваш мозг научился оперировать с дисретными обьектами, а также развилось алгоритмическое мышление вам необходимо научиться мыслить в терминах теории вероятности. Для этого я рекомендую (заодно освежив знания в области дискретной математики) пройти </p><a href="http://shad.yandex.ru/lectures/probability.xml">курс</a><p> моего научного руководителя </p><a href="http://www.gazeta.ru/science/2012/02/08_a_3992561.shtml">Андрея Михайловича Райгородского</a><p>, который умеет обьянять сложные вещи «на пальцах». </p><b>Здесь важно научиться оперировать в терминах теории вероятности и знать основные понятия математической статистики.</b>
<p>
В целом, этого хоть и мало, но на практике достаточно для того, чтобы иметь дело с дискретными обьектами и оперировать вероятностными величинами. Еще неплохо иметь представление о линейной алгебре, но, как правило, в курсах машинного обучения есть введения в необходимые разделы. Добавив к этому хорошие навыки программирования, можно стать неплохим разработчиком. 

</p><h3>Научитесь писать код</h3><p>
Для того, чтобы стать хорошим разработчиком, конечно необходимо знать языки программирования и иметь опыт написания хорошего промышленного кода. Для ученого по данным достаточно знания, как правило, скриптовых языков, такие вещи, как шаблоны или классы, обработка исключений, как правило — не нужны, поэтому в них углубляться не стоит. Вместо этого неплохо знать хотя бы один скриптовый язык, ориентированный на научные и статистические вычисления. Наиболее популярные из них — это </p><b>Python</b><p> и </p><b>R</b><p>. Существует достаточно много хороший онлайн курсов по обоим языкам. Например, вот </p><a href="http://www.codecademy.com/tracks/python">этот</a><p> по Python или вот </p><a href="https://www.datacamp.com/">этот</a><p> по R — в них даются базовые знания, достаточные для специалиста по данным. </p><b>Здесь в первую очередь важно научиться работать с манипулированием данными — это 80% работы ученого по данным.</b>

<h3>Пройдите основные курсы по машинному обучению</h3><p>
После того, как вы обрели хорошую математическую культуру и получили навыки программирования — самое время начать изучать машинное обучение. Я настоятельно рекомендую начать с курса </p><a href="https://www.coursera.org/course/ml">Andrew Ng</a><p> — т.к. этот курс остается до сих пор наилучшим введением в предмет. Конечно, в курсе проспускаются важные распространенные алгоритмы, вроде деревьев — но на практике, теоретических знаний, полученных в этом курсе вам будет достаточно для решения большинства задач. После этого настоятельно рекомендуется начать как можно скорее решать задачи на </p><a href="http://www.kaggle.com/">Kaggle</a><p> — а именно, начать с задач из раздела </p><b>Knowledge</b><p> — в них есть хорошие Tutorials, в которых разбираются задачи — именно они нацелены на быстрый старт для новичков. Уже после этого можно подробнее познакомиться с оставшимися разделами машинного обучения и пройти полностью </p><a href="http://shad.yandex.ru/lectures/machine_learning.xml">курс К.В.Воронцова по машинному обучению</a><p>. </p><b>Здесь важно получить целостное представление о задачах, которые могут возникать на практике, методах их решения и научиться реализовывать свои идеи на практике.</b><p> Важно также добавить, что большинство алгоритмов машинного обучения уже реализовано в библиотеках, таких как </p><a href="http://scikit-learn.org/stable/">scikit-learn</a><p> для Python. Введение в Scikit-Learn я публиковал </p><a href="http://habrahabr.ru/post/247751/">ранее</a><p>.

</p><h3>Практикуйтесь в построении алгоритмов</h3><p>
Участвуйте как можно больше в соревнованиях по машинному обучению — решайте как простые классические задачи, так и задачи в неклассической постановке, когда, например, </p><a href="http://www.kaggle.com/c/axa-driver-telematics-analysis">нет обучающей выборки</a><p>. </p><b>Это необходимо для того, чтобы вы набрались различных методик и трюков, которые используются в задачах и помогают значительно увеличить качество полученных алгоритмов</b><p>. О некоторых практически важных трюках я рассказывал ранее </p><a href="http://habrahabr.ru/post/248129/">здесь</a><p> и </p><a href="http://habrahabr.ru/post/249759/">здесь</a><p>.
</p><p>
После этого, вы уже, как правило готовы к построению хороших алгоритмов и к участию в денежных соревнованиях Kaggle, однако, пока ваши возможности ограничиваются работой с небольшими данными, которые помещаются в оперативной памяти вашей машины. Для того, чтобы иметь возможность работать с большими данными необходимо познакомиться с моделью вычислений Map-Reduce и инструментами, применяемыми для работы с большими данными

</p><h3>Познакомьтесь с большими данными</h3><p>
После того, как вы научились строить хорошие модели — необходимо научиться работать с большими данными. В первую очередь нужно познакомиться с методами хранения больших данных, а именно с файловой системой </p><b>HDFS</b><p>, которая входит в стек </p><b>Hadoop</b><p>, а также с моделью вычислений </p><b>Map-Reduce</b><p>. После этого необходимо познакомиться с остальными компонентами из стека Hadoop — а именно, как устроена </p><b>YARN</b><p>, как работает планировщик </p><b>Oozie</b><p>, как устроена </p><b>NoSQL</b><p> базы данных, такие как </p><b>Cassandra</b><p> и </p><b>HBase</b><p>. Как данные импортируются в кластер с помощью </p><b>Apache Flume</b><p> и </p><b>Apache Sqoop</b><p>. В сети пока еще мало курсов по этим разделам, наиболее полным справочником остается книга </p><a href="http://shop.oreilly.com/product/0636920021773.do">Hadoop: The Definitive Guide</a><p>. </p><b>Здесь важно понять особенности взаимодействия всех компонент Hadoop, а также способы хранения и вычислений на больших данных.</b>

<h3>Познакомьтесь с современными инструментами</h3><p>
После изучения стека технологий Hadoop, вам необходимо познакомиться с фреймворками, которые используются парадигму Map-Reduce и с прочими инструментами, которые использутся для вычислений на больших данных. Часть из этих инструментов я описывал уже ранее. А именно — познакомьтесь с набирающем в последнее время популярность </p><b>Apache Spark</b><p>, который мы уже рассматривали </p><a href="http://habrahabr.ru/post/250811/">здесь</a><p>, </p><a href="http://habrahabr.ru/post/251471/">здесь</a><p> и </p><a href="http://habrahabr.ru/post/252157/">здесь</a><p>. Помимо этого рекомендуется познакомиться с альтернативными инструментами, работать с которыми вы можете даже не имея кластера — это инструмент, позволяющий строить линейные модели (обучая их в онлайн-режиме, не помещая обучающую выборку в оперативную память) </p><b>Vowpal Wabbit</b><p>, обзор которого мы делали </p><a href="http://habrahabr.ru/post/248779/">ранее</a><p>. Также, важно изучить простые инструменты из стека Hadoop — </p><b>Hive</b><p> и </p><b>Pig</b><p>, которые используются для несложных операций с данными в кластере. </p><b>Здесь важно научиться реализовывать необходимые вам алгоритмы машинного обучения, как вы это делали ранее с помощью Python. Отличием является то, что теперь вы работаете с большими данными с помощью другой модели вычислений.</b>

<h3>Изучите Real-Time инструменты обработки больших данных и вопросы архитектуры</h3><p>
Зачастую хочется строить системы, которые принимают решения в реальном времени. В отличие от работы с накопленными данными, здесь существует своя терминология и модель вычислений. Рекомендуется познакомиться с инструментами </p><b>Apache Storm</b><p>, который исходит из предположения, что единица обрабатываемой информации — это транзакция, и </p><b>Apache Spark Streaming</b><p> — в котором заложена идея о том, чтобы производить обработку данных мелкими кусками (</p><b>batch</b><p>'ами). После этого у любого читателя возникнет вопрос — как выглядит архитектура кластера, в которой часть поступающих данных обрабатывается в режиме онлайн, а часть — накапливается для последующей обработки, как эти две компоненты взаимодействуют между собой и какие инструменты используются в каждом на каждом этапе хранения и обработки данных. Для этого я рекомендую познакомиться с так называемой </p><b>лямбда-архитектурой</b><p>, которая достаточно подробно описана на </p><a href="http://lambda-architecture.net/">этом</a><p> ресурсе. </p><b>Здесь важно понимать, что на каждом этапе происходит данными, как они преобразуются, как они хранятся и как над ними происходят вычисления</b><p>.
</p><p>
Итак, мы рассмотрели далеко не все знания и навыки, которые требуются для того, чтобы понимать, как на практике работать с Big Data. Но часто в реальных задачах на практике возникает множество трудностей, с которыми приходится работать. Например, элементарно может отсутствовать обучающая выборка или часть данных может быть известна с некоторой точностью. Когда же дело касается реально огромных массивов данных — то тут зачастую начинаются в том числе и технические трудности и важно знать не только методы машинного обучения, но и их эффективную реализацию. Более того, </p><a href="http://habrahabr.ru/post/250811/">еще только появляются и развиваются инструменты</a><p>, которые позволяют обрабатывать данные в оперативной памяти и часто нужно очень постараться, чтобы правильно их закэшировать, либо известная проблема мелких файлов того же </p><b>Apache Spark</b><p> — со всем этим приходится иметь дело на практике!

</p><h3>Напишите мне Ваши вопросы</h3><p>
Повторюсь, что публикуя статьи на хабре, я преследую цель подготовки людей для работы в Big Data, для того, чтобы в последствии с ними работать. За последние несколько месяцев мне удалось помочь многим людям сделать быстрый старт. Поэтому, я очень хочу с Вами познакомиться и ответить на текущие вопросы, помочь начать решать задачи или помочь с решением уже существующих. Дальше я буду наблюдать за вашим прогрессом (если Вы не против) и помогать, если это будет необходимо. Лучших людей я выберу и буду персонально готовить на протяжении ближайших нескольких месяцев, после чего, возможно, у меня к ним будут интересные предложения!
</p><p>
Не знаю, сколько писем придет на почту, сразу лишь скажу — что отвечать буду поздно вечером, либо ночью, т.к. днем я работаю). Постараюсь ответить на столько писем, насколько смогу. 
</p><p>
Помимо цели обучения людей, я также хочу показать, что методы обработки </p><b>«Big Data»</b><p>, про которые так любят рассказывать маркетологи, не являются «волшебной палочкой», с помощью которой можно творить чудеса. Я постараюсь показать, какие задачи сейчас решаются хорошо, какие возможно решить при желании, а какие — пока еще решать тяжело. После Ваших вопросов я напишу большой пост, в котором опубликую развернутые ответы. Давайте вместе развивать </p><b>Data Science</b><p>, потому что настоящих специалистов сейчас очень не хватает, а </p><a href="http://habrahabr.ru/company/npl/blog/252589/">дорогих курсов хоть отбавляй</a><p>.
</p><p>
Поэтому, все те, кто хотел бы научиться решать задачи, независимо от Вашего уровня подготовки — напишите мне на почту (</p><b>al.krot.kav@gmail.com</b><p>) письмо с темой </p><b>Big Data</b><p>, указав:

</p><ul>
<li><b>Информацию о себе:</b> как вас зовут, чем занимаетесь, где работаете/учитесь</li>
<li><b>Ваш опыт:</b> что пытались учить сами, что получилось/не получилось</li>
<li><b>Цели, которых хотите достичь:</b> самый важный пункт — без этого письмо читать не буду)</li>
<li><b>Ваш непосредственный вопрос, если таковой уже есть</b></li>
</ul>
<p>
Буду ждать Ваших писем!

      
      </p><p class="clear"/>
    </div>

    
  </div></body></html>