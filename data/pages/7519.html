<html><body><div><div class="section-inner layoutSingleColumn"><p name="8d51" id="8d51" class="graf--p graf-after--figure">Hello! Lately, I’ve been striking off some tasks from my long pending TODO list. First, I finished off with <a href="https://github.com/vipul-sharma20/summrizer" data-href="https://github.com/vipul-sharma20/summrizer" class="markup--anchor markup--p-anchor" rel="nofollow">Summrizer</a> and now this, which has been in my list since quite a long time!</p><p name="2c7f" id="2c7f" class="graf--p graf-after--p">After implementing a simple <a href="http://github.com/vipul-sharma20/gesture-opencv" data-href="http://github.com/vipul-sharma20/gesture-opencv" class="markup--anchor markup--p-anchor" rel="nofollow">hand gesture recognizer </a>using Python + OpenCV, I always wanted to do something more exciting and fascinating, like simulating different keyboard events based on the gesture to achieve small tasks like opening files, folders, applications etc. But what’s the fun in doing such boring tasks.</p><p name="4790" id="4790" class="graf--p graf-after--p">Therefore, I thought of playing the old school game of <a href="https://en.wikipedia.org/wiki/Pac-Man" data-href="https://en.wikipedia.org/wiki/Pac-Man" class="markup--anchor markup--p-anchor" rel="nofollow">Pacman</a> using gestures! No keyboard; only gestures in front of a webcam :D</p><p name="b07e" id="b07e" class="graf--p graf-after--p">For all the impatient folks, TL;DR here is the link to the</p><p name="8b22" id="8b22" class="graf--p graf-after--p">code: <a href="https://github.com/vipul-sharma20/gesture-pacman" data-href="https://github.com/vipul-sharma20/gesture-pacman" class="markup--anchor markup--p-anchor" rel="nofollow">https://github.com/vipul-sharma20/gesture-pacman</a></p><p name="9178" id="9178" class="graf--p graf-after--p">blog: <a href="http://vipulsharma20.blogspot.in/" data-href="http://vipulsharma20.blogspot.in/" class="markup--anchor markup--p-anchor" rel="nofollow">http://vipulsharma20.blogspot.in</a></p><h3 name="28a8" id="28a8" class="graf--h3 graf-after--p">Implementation of gesture mechanism</h3><p name="6fa2" id="6fa2" class="graf--p graf-after--h3">In layman’s terms:</p><ul class="postList"><li name="1d52" id="1d52" class="graf--li graf-after--p">Capture image frame containing any recognizable object</li><li name="8ab9" id="8ab9" class="graf--li graf-after--li">Detect the object</li><li name="1ff3" id="1ff3" class="graf--li graf-after--li">Check if/where the object moves</li><li name="b64c" id="b64c" class="graf--li graf-after--li">Assign tasks (keyboard key press) as per different types of movement</li></ul><p name="8135" id="8135" class="graf--p graf-after--li">The above algorithm seems to be quite easy to implement and yes, it’s very easy :D Please read further for more detailed explanation of each step.</p><h3 name="6223" id="6223" class="graf--h3 graf-after--p">1. Capture Frame</h3><p name="c5ac" id="c5ac" class="graf--p graf-after--h3">Capturing an image frame is the easiest task. We want to sense the gestures therefore, we’ll have to continue taking frames forever to record the change in the location of the object or hand or anything recognizable which we can track and use as a mode to input the gestures.</p><p name="5a26" id="5a26" class="graf--p graf-after--p">Here is a test frame which I will be using to demonstrate all the processes involved:</p><figure name="4006" id="4006" class="graf--figure graf-after--p"/><p name="39c4" id="39c4" class="graf--p graf-after--figure">You may notice that here I am holding a #9b465d colored (some people call it “pink”) square paper. We can use this to input gestures by moving it in different directions in front of the webcam and then execute appropriate tasks based on its motion.</p><h3 name="1c1d" id="1c1d" class="graf--h3 graf-after--p">2. Detecting Object</h3><h4 name="c035" id="c035" class="graf--h4 graf-after--h3">Thresholding</h4><p name="17bc" id="17bc" class="graf--p graf-after--h4">In very basic terms, thresholding is like a Low Pass Filter by allowing only particular color ranges to be highlighted as white while the other colors are suppressed by showing them as black.</p><p name="ff1d" id="ff1d" class="graf--p graf-after--p">Before thresholding, the captured image is flipped (<em class="markup--em markup--p-em">I’ve already flipped the above image</em>) and converted from BGR to HSV.</p><figure name="6a93" id="6a93" class="graf--figure graf-after--p"><figcaption class="imageCaption"><em class="markup--em markup--figure-em">BGR to HSV transformed image</em></figcaption></figure><p name="ab2a" id="ab2a" class="graf--p graf-after--figure">Initially, I thought of thresholding using Otsu’s Binarization method. In this method, OpenCV automatically calculates/approximates the threshold value of a bimodal image from its image histogram. But for optimal results, we may need a clear background in front of the webcam which is not possible in general. Also, what’s the fun in that ;) So, I went with the traditional method of global thresholding by providing a range of min and max HSV values as a threshold range for the color pink. In this way, we will not be affected by the background unless it has something of the same color as the object in our hand.</p><p name="0510" id="0510" class="graf--p graf-after--p">Notice the difference in thresholding using Otsu’s method and global method:</p><figure name="1d15" id="1d15" class="graf--figure graf-after--p"><figcaption class="imageCaption"><em class="markup--em markup--figure-em">Thresholding using Otsu’s Binarization method</em></figcaption></figure><p name="8cd5" id="8cd5" class="graf--p graf-after--figure">You can notice here that there is a lot of white whereas we want only our object to be highlighted. We can obviously decide an ROI before thresholding, but that would be more of a restriction in the available region for moving the object.</p><p name="36e8" id="36e8" class="graf--p graf-after--p">Therefore, a global thresholding is more desirable.</p><figure name="674b" id="674b" class="graf--figure graf-after--p"><figcaption class="imageCaption"><em class="markup--em markup--figure-em">Global Thresholding method</em></figcaption></figure><p name="6e27" id="6e27" class="graf--p graf-after--figure">For better results, we can also try thresholding after performing Gaussian Blurring on the original image. We blur the image for smoothing and to reduce noise and details from the image. We are not interested in the details of the image but in the shape/size of the object to track. In my implementation, I’ve NOT used this step as it is a little slow in terms of realtime processing but you might like to see the effect of blurring in thresholding</p><figure name="1e77" id="1e77" class="graf--figure graf-after--p"><figcaption class="imageCaption"><em class="markup--em markup--figure-em">Original image after Gaussian Blur</em></figcaption></figure><figure name="6459" id="6459" class="graf--figure graf-after--figure"><figcaption class="imageCaption"><em class="markup--em markup--figure-em">Applying Global Thresholding on blurred frame</em></figcaption></figure><p name="29b6" id="29b6" class="graf--p graf-after--figure">Here, we can see that thresholding after blurring has lesser noise and more discrete white regions than the one thresholded without blurring. Unfortunately, we’ll have to compromise this optimal performance as it is a little slow. But, we can get the desired results after some tweaks even without implementing this step. Just read further :D</p><h4 name="c631" id="c631" class="graf--h4 graf-after--p">Contour Detection and Bounding Rectangle</h4><p name="28dd" id="28dd" class="graf--p graf-after--h4">Once the image is thresholded, we need to create a bounding rectangle so that we always have the exact coordinates of the object in our hand in real-time. To achieve this, we will first need to extract all the contours from the thresholded image and then selecting the contour which has the max area. This max area contour will be the object around which, we will create a bounding rectangle. More precisely, we can track the coordinates of the moving object in real-time by tracking the centroid of the bounding rectangle.</p><figure name="851e" id="851e" class="graf--figure graf-after--p"><figcaption class="imageCaption"><em class="markup--em markup--figure-em">Creating bounding rectangles around all the contours detected from the thresholded image</em></figcaption></figure><p name="9616" id="9616" class="graf--p graf-after--figure">The good thing is, we have a bounding rectangle around the object we want to track and the bad thing is clearly visible. We can correct this by creating the bounding rectangle only around the contour which has the maximum area. If we notice the thresholded image again, we can see that the largest white colored area is of the pink colored square and that’s what we want to track. Therefore, by creating a rectangle around the largest area we get the desired result.</p><figure name="f430" id="f430" class="graf--figure graf-after--p"/><p name="a830" id="a830" class="graf--p graf-after--figure">The red mark inside the rectangle is the centroid of the bounding rectangle.</p><h3 name="f1b2" id="f1b2" class="graf--h3 graf-after--p">3. Check if/where object moves</h3><p name="a5ee" id="a5ee" class="graf--p graf-after--h3">For this, we can define our own quadrants on a frame and locate the position of the centroid of the bounding rectangle in those quadrants. Based on the quadrant in which the point lies, we can trigger an appropriate keyboard event.</p><figure name="2d44" id="2d44" class="graf--figure graf-after--p"/><p name="48db" id="48db" class="graf--p graf-after--figure">Here, I’ve created 4 rectangular divisions for triggering 4 different movements: up, down, left, right. Looking closely we can see that the centroid lies in the upper division hence, we can simulate an “Up” key press event and similarly we can trigger left, down, right key press events based on the location of the centroid among the quadrants.</p><p name="1230" id="1230" class="graf--p graf-after--p">For simulating keyboard key press events, I’ve used <a href="https://github.com/asweigart/pyautogui" data-href="https://github.com/asweigart/pyautogui" class="markup--anchor markup--p-anchor" rel="nofollow"><em class="markup--em markup--p-em">pyautogui</em></a> library.</p><p name="c4e9" id="c4e9" class="graf--p graf-after--p">Here is the link to the code : <a href="https://github.com/vipul-sharma20/gesture-pacman" data-href="https://github.com/vipul-sharma20/gesture-pacman" class="markup--anchor markup--p-anchor" rel="nofollow">https://github.com/vipul-sharma20/gesture-pacman</a></p><p name="d27e" id="d27e" class="graf--p graf-after--p">The big question: <strong class="markup--strong markup--p-strong">Where is Pacman ??</strong></p><p name="f505" id="f505" class="graf--p graf-after--p">Now that we have created the script to input gestures and trigger keyboard events, we can now try it by playing Pacman :D</p><p name="47b8" id="47b8" class="graf--p graf-after--p">Below is the video of me playing Pacman with gestures. This is not exactly the same old classic Pacman which had the <a href="https://en.wikipedia.org/wiki/Pac-Man#Split-screen" data-href="https://en.wikipedia.org/wiki/Pac-Man#Split-screen" class="markup--anchor markup--p-anchor" rel="nofollow">kill screen</a> bug, but it’s good enough to demonstrate the working :)</p><figure name="4c6d" id="4c6d" class="graf--figure graf--iframe graf-after--p"><p class="iframeContainer"/></figure><figure name="84f5" id="84f5" class="graf--figure graf-after--figure"><figcaption class="imageCaption"><em class="markup--em markup--figure-em">In case you were wondering how the header image was captured…</em></figcaption></figure><p name="cf5c" id="cf5c" class="graf--p graf-after--figure">Github Profile: <a href="http://github.com/vipul-sharma20" data-href="http://github.com/vipul-sharma20" class="markup--anchor markup--p-anchor" rel="nofollow">http://github.com/vipul-sharma20</a></p><p name="9d45" id="9d45" class="graf--p graf-after--p graf--last">Blog: <a href="http://vipulsharma20.blogspot.in/" data-href="http://vipulsharma20.blogspot.in/" class="markup--anchor markup--p-anchor" rel="nofollow">http://vipulsharma20.blogspot.in</a></p></div></div></body></html>