<html><body><div><div class="content html_format"><p>
      Добрый день, коллеги.</p>
<p>
Сегодня я расскажу о не совсем простой концепции быстрого (до часа после нескольких тренировок) развёртывания проекта для работы команды, состоящей как минимум из отдельных фронтенд и бэкенд разработчиков.
</p><p>
Исходные данные у нас такие: начинается разработка проекта, в которой планируется «тонкий бэкенд». Т.е. бэк у нас состоит из закешированных страниц (рендерятся любым шаблонизатором), объёмных моделей с сопутствующей логикой (ORM) и REST API, выполняющего роль контроллера. Фактически, View в такой системе редуцировано и вынесено в JS, благо есть разные реакты, ангуляры и прочие вещи, которые позволяют фронтендщикам считать себя «белыми людьми».
</p><a name="habracut"/><p>
Среда разработки у нас выглядит так: Ubuntu LTS (14.04), PyCharm, Python любой версии (мы возьмём 2.7 для запуска виртуальной среды, на которой будет стоять аналогичная версия). Django (1.8)
</p><p>
Решаем мы следующие проблемы:
</p><ol>
<li>Необходимо полностью эмулировать пространство Production, а ещё лучше — поставлять код участникам процесса разработки вместе со средой.</li>
<li>Необходимо отделить среду выполнения нашего проекта от среды операционной системы. Нам нафиг не нужны проблемы с версиями пайтона, настройками node.js или развёртыванием БД. Пусть наша настольная система будет чистой и светлой.</li>
<li>Необходимо автоматизировать развёртывание проекта, над которым будет трудиться ещё и гуру JS, и, возможно, крутой верстальщик. Да так, чтобы проект можно было поднять и у тестировщика, и у менеджера с начальными знаниями в технической области.</li>
<li>Необходимо без особых проблем отделить dev версию от production. Даунтайм должен быть минимальным. Никто не будет ждать, пока ведущий программист исправит все переменные в settings и пофиксит прочие проблемы.</li>
<li>Нужно сделать так, чтобы участники разработки не решали проблемы друг-друга. JS разработчик не должен вникать в тонкости запуска Celery, слияния JS файлов и т.д. Верстальщика не должно интересовать что компилирует его Sass код и т.д. Это относится к автоматизации развёртывания, но важно подчеркнуть, что эти проблемы могут создать неудобство и потребуется тратить время на написание подробной инструкции по развёртыванию, если оно будет происходить в ручном режиме.</li>
</ol>

<h2>Установка Docker</h2><p>
Для нашего приложения мы будем использовать </p><a href="https://www.docker.com/">Docker</a><p>. Об этом инструменте на Хабре сказано много. Сразу оговорюсь, что мы пока не планируем усложнять Production сервер. Нам важно построить среду разработки с заделом на последующее применение концепции CI. Но, в рамках текущей статьи будем работать только с docker-compose и не затронем методы быстрого деплоймента. Благо, у Docker таковых имеется в избытке.
</p><p>
Docker может с переменным успехом устанавливаться на Mac и Windows машины. Но мы рассмотрим его установку на Ubuntu 14.04. Есть </p><a href="http://docs.docker.com/engine/installation/ubuntulinux/">инструкция</a><p> по установке Docker на этой системе, но она может вызвать проблемы. От части, можно списать их на нотик из этой инструкции:

</p><blockquote>Note: Ubuntu Utopic 14.10 exists in Docker’s apt repository but it is no longer officially supported.</blockquote>
<p>
Поэтому, не выпендриваемся и ставим так, как рекомендует </p><a href="http://docs.docker.com/linux/step_one/">другая инструкция</a><p>:

</p><pre><code class="bash">$ sudo apt-get update
$ sudo apt-get install wget
wget -qO- https://get.docker.com/ | sh
</code></pre>
<p>
И проверяем установку командой:

</p><pre><code class="bash">$ docker run hello-world
</code></pre>
<p>
Теперь создадим виртуальную среду для запуска Docker:
</p><pre><code class="bash">$ mkdir ~/venvs
$ virtualenv ~/venvs/docker
$ source ~/venvs/docker/bin/activate
(docker) $ pip install docker-compose
(docker) $ docker-compose -v
</code></pre>

<h2>Создаём проект</h2><p>
Откроем PyCharm и создадим проект для работы.

</p><img src="https://habrastorage.org/files/4a8/d9d/247/4a8d9d2470bf4901a8a09518e04ef48a.png" alt="Минимальный состав проекта"/>
<p>
Проект создаём для любого интерпретатора. Пусть это будет pure python проект. На схеме выше вы видите минимальный состав проекта. За запуск сервера у нас будет отвечать supervisord. Файлы .gitignore и .dockerignore позволят указать те файлы, которые не будут закоммичены в репозиторий проекта или не будут смонтированы в docker контейнеры. Контейнерами будет управлять файл docker-compose.yml, поскольку он прост как палка и эффективен как автомат Калашникова. Для основного проекта мы дополнительно создадим Dockerfile, чтобы установить отсутствующие библиотеки.
</p><p>
Папка dockerfiles имеет подпапку pgdata — в ней у нас будет храниться БД от PostgreSQL на случай, если мы захотим перенести данные из одного места в другое. В dockerfiles/sshdconf поместим настройки для SSH сервера. Для прямого соединения он нам не понадобится, но для настройки окружения в PyCharm — ещё как. Ключ id_rsa.pub позволит PyCharm соединяться с контейнером без плясок вокруг пароля. Всё что вам нужно — это создать связку SSH ключей и скопировать (или перенести) публичный ключ в директорию dockerfiles.
</p><p>
Директория src — корень нашего проекта. Сейчас наша задача — развернуть контейнеры.

</p><h2>Создаём контейнеры</h2><p>
Файл docker-compose.yml будет у нас выглядеть так:

</p><pre><code>postgresql:
  image: postgres:9.3
  env_file: .env
  volumes:
    - ./dockerfiles/pgdata:/var/lib/postgresql/data/pgdata
  ports:
    - "5433:5432"

project:
  build: ./
  env_file: .env
  working_dir: /opt/project
  command: bash -c "sleep 3 &amp;&amp; /etc/init.d/ssh start &amp;&amp; supervisord -n"
  volumes:
    - ./src:/opt/project
    - ./dockerfiles/sshdconf/sshd_config:/etc/ssh/sshd_config
    - ./dockerfiles/id_rsa.pub:/root/.ssh/authorized_keys
    - /home/USERNAME/.pycharm_helpers/:/root/.pycharm_helpers/
    - ./supervisord.conf:/etc/supervisord.conf
    - ./djangod.conf:/etc/djangod.conf
  links:
    - postgresql
  ports:
    - "2225:22"
    - "8005:8000"
</code></pre>
<p>
Обратите внимание на первый контейнер — postgresql. Ему мы однозначно передаём .env для формирования первичных данных. Директива ports отвечает за проброс портов. Первая цифра перед двоеточием — номер порта, по которому будет доступна эта база в нашей убунте. Вторая цифра — это номер порта, который пробрасывается с контейнера. Дефолтный PostgreSQL порт
</p><p>
Второй контейнер будем собирать из Dockerfile. Поэтому, здесь стоит build. Команда запуска идёт с небольшой задержкой — на случай, если нам нужно будет время для запуска БД и других инструментов внутри контейнеров. Здесь же видим все подключаемые директории и файлы. При пробросе портов имеем порт 2225 — для SSH и 8005 — для сервера. В sshd_config нам нужно настроить под себя вот эти директивы:
</p><p>
PermitRootLogin without-password</p><p>
StrictModes no
</p><p>
RSAAuthentication yes</p><p>
PubkeyAuthentication yes</p><p>
AuthorizedKeysFile %h/.ssh/authorized_keys
</p><p>
Помните, что всё это добро будет работать только у команды разработчиков. На продакшн мы это не выложим. Хотя, в принципе, ssh сервер будет доступен только локально.
</p><p>
/home/USERNAME/.pycharm_helpers/:/root/.pycharm_helpers/ — Эта команда на монтирование позволит нам запускать тесты и дебаг прямо из PyCharm. Не забудьте прописать тут свой USERNAME

</p><b>В supervisord.conf пропишем следующее:</b>
<p>
[unix_http_server]</p><p>
file=/opt/project/daemons/supervisor.sock; path to your socket file
</p><p>
[supervisord]</p><p>
logfile=/opt/project/logs/supervisord.log; supervisord log file</p><p>
logfile_maxbytes=50MB; maximum size of logfile before rotation</p><p>
logfile_backups=10; number of backed up logfiles</p><p>
loglevel=info; info, debug, warn, trace</p><p>
pidfile=/opt/project/daemons/supervisord.pid; pidfile location</p><p>
nodaemon=false; run supervisord as a daemon</p><p>
minfds=1024; number of startup file descriptors</p><p>
minprocs=200; number of process descriptors</p><p>
user=root; default user</p><p>
childlogdir=/opt/project/logs/; where child log files will live
</p><p>
[rpcinterface:supervisor]</p><p>
supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface
</p><p>
[supervisorctl]</p><p>
serverurl=unix:///opt/project/daemons/supervisor.sock; use unix:// schem for a unix sockets.
</p><p>
[include]
</p><p>
# Uncomment this line for celeryd for Python</p><p>
files=djangod.conf

</p><b>В djangod.conf:</b>
<p>
[program:django_project]</p><p>
command=python /opt/project/manage.py runserver 0.0.0.0:8000</p><p>
directory=/opt/project/</p><p>
stopasgroup=true</p><p>
stdout_logfile=/opt/project/logs/django.log</p><p>
stderr_logfile=/opt/project/logs/django_err.log
</p><p>
Тот кто внимательно читает конфиги, должен обратить внимание на то, что мы объявили две не созданные ещё папки. Так что создадим в src директории logs и daemons. В .gitignore добавим соответственно /src/logs/* и /src/daemons/*
</p><p>
Обратите внимание на то, что в django, обычно, stdout_logfile не пишется. Все логи осыпаются в stderr_logfile. Настройка была взята из какой-то готовой инструкции, а удалять строчку не слишком хочется, ведь stdout_logfile — довольно стандартная директива.

</p><b>Теперь не забудем про наш .env файл:</b>
<p>
POSTGRES_USER=habrdockerarticle</p><p>
POSTGRES_DB=habrdockerarticle</p><p>
POSTGRES_PASSWORD=qwerty</p><p>
POSTGRES_HOST=postgresql</p><p>
POSTGRES_PORT=5432</p><p>
PGDATA=/var/lib/postgresql/data/pgdata</p><p>
C_FORCE_ROOT=true
</p><p>
Его можно добавить или не добавлять в .gitignore — значения не имеет.
</p><p>
В конце заполним Dockerfile
</p><p>
FROM python:2.7
</p><p>
RUN apt-get update &amp;&amp; apt-get install -y openssh-server \</p><p>
 &amp;&amp; apt-get purge -y --auto-remove -o APT::AutoRemove::RecommendsImportant=false -o APT::AutoRemove::SuggestsImportant=false $buildDeps
</p><p>
COPY ./src/requirements.txt ./requirements.txt
</p><p>
RUN pip install -r requirements.txt

</p><a href="https://github.com/docker-library/python/blob/5909006206b117a7e9d1a329abdde6031e7342c5/2.7/Dockerfile">Docker Hub</a><p> не скрывает от нас того, что наш контейнер будет обслуживаться Debian Jessie. В Dockerfile мы запланировали установку ssh сервера, чистку ненужных нам списков пакетов и установку requirements. Кстати, файл зависимостей у нас ещё не создан. Надо исправить этот недочёт и создать requirements.txt в папке src:
</p><p>
Django==1.8</p><p>
psycopg2</p><p>
supervisor

</p><h2>Первый запуск</h2><p>
Проект готов к первому запуску! Запускать будем поочерёдно. Сперва выполним:

</p><pre><code class="bash">(docker) $ docker-compose run --rm --service-ports postgresql
</code></pre>
<p>
Эта операция скачает нам образ, необходимый для запуска postgresql сервера. Сервер запустится, пользователь и база, указанные в .env создадутся автоматически. Команда заблокирует нам ввод данных, но пока не будем её останавливать. Убедимся в наличии базы и ролей входа, подключившись через pgadmin

</p><img src="https://habrastorage.org/files/8be/4ec/843/8be4ec843b1642908f8abd34a4e0657f.png" alt="Настройки PgAdmin"/>
<p>
Как мы видим, всё уже создано для работы:

</p><img src="https://habrastorage.org/files/e89/61d/eca/e8961deca2db441ebc64dc6e16266f83.png" alt="База и роль входа созданы"/>
<p>
Теперь комбинацией клавиш ctrl+C в консоли остановим процесс. Нам надо собрать образ проекта. Так что выполним:

</p><pre><code class="bash">(docker) $ docker-compose build project
</code></pre>
<p>
Эта команда соберёт нам проект, а также, выполнит все команды из Dockerfile. Т.е. у нас будет установлен ssh сервер, а также, установлены зависимости из requirements.txt. Теперь у нас возникает вопрос создания Django проекта. Создать его можно нескольким способами. Самый пуленепробиваемый — это поставить в нашу docker virtualenv на убунте нужную версию Django:

</p><pre><code class="bash">(docker) $ pip install django==1.8
(docker) $ cd ./src
(docker) $ django-admin startproject projectname
(docker) $ cd ../
</code></pre>
<p>
Django из venv можно удалить или оставить для других проектов. Всё что нам осталось — это перенести внутренности проекта в корень папки src.
</p><p>
Теперь нам следует проверить наш проект и настроить соединение с БД. Сперва поменяем настройки в settings.py:

</p><pre><code class="python">DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.postgresql_psycopg2',
        'NAME': os.getenv('POSTGRES_DB'),
        'USER': os.getenv('POSTGRES_USER'),
        'PASSWORD': os.getenv('POSTGRES_PASSWORD'),
        'HOST': os.getenv('POSTGRES_HOST'),
        'PORT': int(os.getenv('POSTGRES_PORT'))
    }
}
</code></pre>
<p>
Потом запустим контейнеры проекта:

</p><pre><code class="bash">(docker) $ docker-compose up -d
</code></pre>
<p>
И убедимся в положительном результате:

</p><img src="https://habrastorage.org/files/1f0/ad8/dd3/1f0ad8dd3534418c882fcb0fcd9fab11.png" alt="Запущенный проект"/>
<p>
Для остановки проекта и удаления временных файлов можно использовать:

</p><pre><code class="bash">(docker) $ docker-compose stop &amp;&amp; docker-compose rm -f
</code></pre>
<p>
Если у нас меняется что-то в requirements.txt, используем следующую команду для быстрого пересбора

</p><pre><code class="bash">(docker) $ docker-compose stop &amp;&amp; docker-compose rm -f &amp;&amp; docker-compose build --no-cache project &amp;&amp; docker-compose up -d
</code></pre>
<p>
Давайте, проверим какая структура проекта у нас получилась:

</p><img src="https://habrastorage.org/files/0d0/283/72d/0d028372d7954f7fb38aa097c36781c5.png" alt="Структура проекта"/>
<p>
Папка root в моём коде содержит готовые helpers PyCharm'а.

</p><h2>Подключаем контейнер для JS программиста</h2>
<p>
Теперь можно сделать то, ради чего мы всё это и затевали — подключить Gulp для управления статикой. Файл docker-compose.yml теперь будет выглядеть так:

</p><pre><code>...
    
gulp:
  build: ./src/gulp
  command: bash -c "sleep 3 &amp;&amp; gulp"
  volumes:
    - ./src/gulp:/app
    - ./src/static/scripts:/app/build

project:
  ...
  links:
    - postgresql
    - gulp
  ...
</code></pre>
<p>
Я добавил новый контейнер и указал его в зависимостях к project.
</p><p>
Теперь мне нужно создать папку gulp в src для исходников и static/scripts для скомпилированных файлов. В папке src/gulp создадим файл package.json со следующим содержимым:

</p><pre><code>{
  "name": "front",
  "version": "3.9.0",
  "description": "",
  "main": "gulpfile.js",
  "scripts": {
    "test": "echo \"Error: no test specified\" &amp;&amp; exit 1"
  },
  "author": "",
  "license": "BSD-2-Clause",
  "devDependencies": {
    "gulp": "~3.9.0",
    "gulp-uglify": "~1.4.2",
    "gulp-concat": "~2.6.0",
    "gulp-livereload": "~3.8.1",
    "gulp-jade": "~1.1.0",
    "gulp-imagemin": "~2.3.0",
    "tiny-lr": "0.2.1"
  }
}
</code></pre>
<p>
Создадим gulpfile.js. в папке src/gulp. Я использовал свой старый файл для образца:

</p><pre><code class="javascript">/**
 * Created by werevolff on 18.10.15.
 */

var gulp = require('gulp'),
    uglify = require('gulp-uglify'),
    concat = require('gulp-concat'),
    refresh = require('gulp-livereload'),
    lr = require('tiny-lr'),
    server = lr();


/**
 * Mainpage
 */
gulp.task('mainpage', function () {
    gulp.src(['./front/jquery/*.js', './front/bootstrap/*.js', './front/angularjs/angular.min.js',
        './front/angularjs/i18n/angular-locale_ru-ru.js', './front/project/**/*.js'])
        .pipe(uglify())
        .pipe(concat('mainpage.js'))
        .pipe(gulp.dest('./build'))
        .pipe(refresh(server));
});


/**
 * Rebuild JS files
 */

gulp.task('lr-server', function () {
    server.listen(35729, function (err) {
        if (err) return console.log(err);
    });
});

/**
 * Gulp Tasks
 */
gulp.task('default', ['mainpage', 'lr-server'], function () {
    gulp.watch('./front/**/*.js', ['mainpage']);
});
</code></pre>
<p>
Как мы видим из конфига, нам следует залить в папку src/gulp/front некоторые популярные библиотеки и создать папку src/gulp/front/project для написанных JS программистом скриптов. Также, не забываем о создании Dockerfile в src/gulp
</p><p>
FROM neo9polska/nodejs-bower-gulp
</p><p>
COPY package.json ./package.json</p><p>
COPY node_modules ./node_modules
</p><p>
RUN npm install --verbose
</p><p>
Теперь довольно важный вопрос — node_modules. Без этой папки контейнер с Gulp будет откровенно лажать. Здесь у нас два варианта получения этой папки:

</p><ol>
<li>Собрать проект на локальной машине и перенести из него папку с модулями</li>
<li>Убрать из Dockerfile всё что ниже директивы FROM, выполнить docker-compose run --rm gulp npm install --verbose, а потом поменять права на директорию с node_modules и вернуть то, что было ниже FROM обратно.</li>
</ol>
<p>
Однако, менять права не обязательно. Просто разработчики будут вынуждены постоянно выполнять команду на пересборку gulp. Впрочем, весь код, описанный в статье, я выложу на Github и можно взять node_modules оттуда. Проблема эта связана с docker-compose. Но победить её легко.
</p><p>
Итак, в результате запуска контейнеров

</p><pre><code class="bash">(docker) $ docker-compose up -d
</code></pre>
<p>
Мы должны получить вот такой скомпилированный файл:

</p><img src="https://habrastorage.org/files/146/506/e33/146506e33667419ebc16890b4a91d230.png" alt="Результат работы контейнера с Gulp"/><p>.
</p><p>
Готово! Проект можно залить в git и начинать работать с ним.
</p><p>
Полная команда перезапуска с пересборкой выглядит так:

</p><pre><code class="bash">(docker) $ docker-compose stop &amp;&amp; docker-compose rm -f &amp;&amp; docker-compose build --no-cache gulp &amp;&amp; docker-compose build --no-cache project &amp;&amp; docker-compose up -d
</code></pre>
<p>
Для запуска проекта у нового участника процесса достаточно выполнить:

</p><pre><code class="bash">(docker) $ docker-compose build --no-cache gulp &amp;&amp; docker-compose build --no-cache project &amp;&amp; docker-compose up -d
</code></pre>
<p>
Для просмотра основного журнала контейнера с запущенным приложением:

</p><pre><code class="bash">(docker) $ docker-compose logs CONTAINER NAME
</code></pre>
<p>
Логи Django из project пишутся в папку src/logs.
</p><p>
Исходный код проекта вы можете посмотреть в </p><a href="https://github.com/werevolff/habr-docker-article">моём GitHub</a><p>.
</p><p>
P.S. Ещё один важный аспект — настройка интерпретатора python в PyCharm. Для этой настройки достаточно добавить remote interpreter:

</p><img src="https://habrastorage.org/files/909/72f/80c/90972f80c9e946079241a82b69c65fd9.png" alt="Настройка среды выполнения в PyCharm"/>
<p>
И обратите внимание на то, что PyCharm имеет плагин для интеграции с Docker. Мы же используем SSH соединение, поскольку не затрагивали вопрос развёртывания проекта на docker-machine.

      
      </p><p class="clear"/>
    </div>

    
  </div></body></html>