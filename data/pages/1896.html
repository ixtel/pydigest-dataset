<html><body><div><div class="post-body entry-content">
<p>Вообще, пресечь мат (ненормативную лексику) в данных, поступающих от пользователя и никак не модерируемых — задача сложная и вряд ли решаемая. Пользователь для достижения цели (написания мата) может использовать как богатые возможности русского языка для словообразования, так и различные уловки: вставка каких-то символов между буквами, замена букв на похожие. Даже описать весь спектр возможностей — колоссальный труд. И, надо сказать, такие попытки предпринимались. Но я решил обойтись "малой кровью". Понятно, что бороться с матом сложно. Но можно помочь в модерации.</p><a name="more"/>

<p>Представьте, что модератору какой-либо информации приходится просматривать десятки тысяч знаков в день на предмет выявления мата. Невольно можно пропустить что-то. Но можно в тексте, например, автоматически подсветить необходимые фрагменты и жизнь уже станет чуточку проще. Конечно, это не избавляет от ошибок, потому что любой алгоритм в силу вышеуказанных причин обречен на провал, но вероятность ошибки всё же меньше.</p>

<p>Для решения поставленной цели — помочь модераторам — посмотрел на способы решения. В общем случае их 2: регулярные выражения и сопоставление со словарем. Решил создать моуль, объединяющий оба этих способа.</p>

<p>Способ сопоставления со словарем — самый интересный. Он основан на морфологическом анализе слов, приведении этих слов к нормальной форме и сопоставлении нормальных форм слов. Для морфологического анализа и нормализации я использовал шикарную утилиту <a href="https://pypi.python.org/pypi/pymorphy2">Pymorphy2</a>. Составил базу данных уже нормализованных слов. Этот способ очень неплохо работает. Из плюсов можно отметить "обучаемость". То есть если вы нашли какое-то неучтенное слово — просто добавьте его в словарь. Минусы этого способа: более низкая производительность по сравнению с анализом на основе регулярных выражений и невозможность учесть трюки пользователей, о которых упоминалось ранее.</p>

<p>Способ на основе анализа регулярными выражениями тоже можно использовать. Но для "обучения" придется дописывать паттерны.</p>

<p>Как использовать модуль, в общем-то, выбирать заинтересовавшимся этим модулем пользователям. Использовать его с фреймверком Django можно так. Устанавливаем пакет:</p>

<pre>
<code class="language-bash">$ pip install djantimat</code></pre>

<p>Добавляем в INSTALLED_APPS приложение djantimat и делаем миграцию:</p>

<pre>
<code class="language-bash">manage.py migrate djantimat</code></pre>

<p>Для подгрузки заготовленного словаря надо сделать syncdb или подгрузить фикстуру:</p>

<pre>
<code class="language-bash">manage.py loaddata djantimat/fixtures/initial_data.json</code></pre>

<p>Если вы вне фреймверка Django, то вам придется самим разобрать базу из файла djantimat/fixtures/initial_data.json и подменить свойство PymorphyProc.words списком слов.</p>

<p>Использование:</p>

<pre>
<code class="language-python">from djantimat.helpers import PymorphyProc, RegexpProc

# Способ со словарем

# Есть ли матерные слова в тексте:
slang_detected = PymorphyProc.test(u'Здесь текст с матерками')

# Замена матерных слов в тексте шаблоном:
without_slang = PymorphyProc.replace(u'Здесь текст с матерками', repl='[xxx]')

# Оборачивание матерных слов в тексте например тегом:
highlighted_slang = PymorphyProc.wrap(u'Здесь текст с матерками', wrap=('&lt;pre&gt;', '&lt;/pre&gt;',))

# Способ с регулярками

# Есть ли матерные слова в тексте:
slang_detected = RegexpProc.test(u'Здесь текст с матерками')

# Замена матерных слов в тексте шаблоном:
without_slang = RegexpProc.replace(u'Здесь текст с матерками', repl='[xxx]')

# Оборачивание матерных слов в тексте например тегом:
highlighted_slang = RegexpProc.wrap(u'Здесь текст с матерками', wrap=('&lt;pre&gt;', '&lt;/pre&gt;',))</code></pre>

<p>Буду рад любым предложениям по усовершенствованию.</p>

<p><a href="https://pypi.python.org/pypi/djantimat/">Пакет на PyPI</a>.</p>

<p><a href="https://github.com/PixxxeL/djantimat">Исходники на github</a>.</p>
<p/>
</div>
</div></body></html>