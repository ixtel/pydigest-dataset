<html><body><div><div class="blog-entry" id="e20160116T070304"><p>When calling functions that are expensive, and expected to return the same
    results for the same input, lots of people like using an @memoize
    decorator.  It uses a cache to quickly return the same results if they have
    been produced before.  Here's a simplified one, adapted from
    <a href="https://wiki.python.org/moin/PythonDecoratorLibrary#Memoize">a
    collection of @memoize implementations</a>:</p><blockquote class="code"><code><span class="k">def</span> <span class="nf">memoize</span><span class="p">(</span><span class="n">func</span><span class="p">):</span><br/>    <span class="n">cache</span> <span class="o">=</span> <span class="p">{}</span><br/><br/>    <span class="k">def</span> <span class="nf">memoizer</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span><br/>        <span class="n">key</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">args</span><span class="p">)</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span><br/>        <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">cache</span><span class="p">:</span><br/>            <span class="n">cache</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><br/>        <span class="k">return</span> <span class="n">cache</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><br/><br/>    <span class="k">return</span> <span class="n">memoizer</span><br/><br/><span class="nd">@memoize</span><br/><span class="k">def</span> <span class="nf">expensive_fn</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span><br/>    <span class="k">return</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span>        <span class="c"># Not actually expensive!</span><br/></code></blockquote><p>This is great, and does what we want: repeated calls to expensive_fn with
    the same arguments will use the cached values instead of actually invoking
    the function.</p><p>But there's a potential problem: the cache dictionary is a global.  Don't be
    fooled by the fact that it isn't literally a global: it doesn't use the
    <span class="codeword">global</span> keyword, and it isn't a module-level variable.
    But it is global in the sense that there is only one cache dictionary for
    expensive_fn for the entire process.</p><p>Globals can interfere with disciplined testing.  One ideal of automated
    tests in a suite is that each test be isolated from all the others.  What
    happens in test1 shouldn't affect test99.  But here, if test1 and test99
    both call expensive_fn with arguments (1, 2), then test1 will run the
    function, but test99 will get the cached value.  Worse, if I run the
    complete suite, test99 gets a cached value, but if I run test99 alone, it
    runs the function.</p><p>This might not be a problem, if expensive_fn is truly a
    <a href="https://en.wikipedia.org/wiki/Pure_function">pure function</a>
    with no side effects.  But sometimes that's not the case.</p><p>I inherited a project that used @memoize to retrieve some fixed data from a
    web site. @memoize is great here because it means each resource will be
    fetched only once, no matter how the program uses them.  The test suite
    used <a href="https://betamax.readthedocs.org/en/latest/">Betamax</a> to
    fake the network access.</p><p>Betamax is great: it automatically monitors network access, and stores a
    "cassette" for each test case, which is a JSON record of what was requested
    and returned.  The next time the tests are run, the cassette is used, and
    the network access is faked.</p><p>The problem is that test1's cassette will have the network request for the
    memoized resource, and test99's cassette will not, because it never
    requested the resource, because @memoize made the request unnecessary.  Now
    if I run test99 by itself, it has no way to get the resource, and the test
    fails.  Test1 and test99 weren't properly isolated, because they shared the
    global cache of memoized values.</p><p>My solution was to use an @memoize that I could clear between tests.
    Instead of writing my own, I used the lru_cache decorator from functools (or from the functools32 if you are still using Python 2.7).
    It offers a .cache_clear function that can be used to clear all the values
    from the hidden global cache.  It's on each decorated function, so we have
    to keep a list of them:</p><blockquote class="code"><code><span class="kn">import</span> <span class="nn">functools</span><br/><br/><span class="c"># A list of all the memoized functions, so that</span><br/><span class="c"># `clear_memoized_values` can clear them all.</span><br/><span class="n">_memoized_functions</span> <span class="o">=</span> <span class="p">[]</span><br/><br/><span class="k">def</span> <span class="nf">memoize</span><span class="p">(</span><span class="n">func</span><span class="p">):</span><br/>    <span class="sd">"""Cache the value returned by a function call."""</span><br/>    <span class="n">func</span> <span class="o">=</span> <span class="n">functools</span><span class="o">.</span><span class="n">lru_cache</span><span class="p">()(</span><span class="n">func</span><span class="p">)</span><br/>    <span class="n">_memoized_functions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">func</span><span class="p">)</span><br/>    <span class="k">return</span> <span class="n">func</span><br/><br/><span class="k">def</span> <span class="nf">clear_memoized_values</span><span class="p">():</span><br/>    <span class="sd">"""Clear all the values saved by @memoize, to ensure isolated tests."""</span><br/>    <span class="k">for</span> <span class="n">func</span> <span class="ow">in</span> <span class="n">_memoized_functions</span><span class="p">:</span><br/>        <span class="n">func</span><span class="o">.</span><span class="n">cache_clear</span><span class="p">()</span><br/></code></blockquote><p>Now an automatic fixture (for py.test) or a setUp function, can clear the
    cache before each test:</p><blockquote class="code"><code><span class="c"># For py.test:</span><br/><br/><span class="nd">@pytest.fixture</span><span class="p">(</span><span class="n">autouse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span><br/><span class="k">def</span> <span class="nf">reset_all_memoized_functions</span><span class="p">():</span><br/>    <span class="sd">"""Clears the values cached by @memoize before each test."""</span><br/>    <span class="n">clear_memoized_values</span><span class="p">()</span><br/><br/><span class="c"># For unittest:</span><br/><br/><span class="k">class</span> <span class="nc">MyTestCaseBase</span><span class="p">(</span><span class="n">unittest</span><span class="o">.</span><span class="n">TestCase</span><span class="p">):</span><br/>    <span class="k">def</span> <span class="nf">setUp</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span><br/>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">setUp</span><span class="p">()</span><br/>        <span class="n">clear_memoized_values</span><span class="p">()</span><br/></code></blockquote><p>In truth, it might be better to distinguish between the various reasons for
    using @memoize.  A pure function might be fine to cache between tests, who
    cares when the value is computed?  But other uses clearly should be
    isolated.  @memoize isn't magic, you have to think about what it is doing
    for you, and when you want to have more control.</p></div></div></body></html>