<html><body><div><div class="content html_format">
      <i>Данная статья представляет собой перевод главы, обучающей работе с текстовыми данными, из официальной документации <a href="http://scikit-learn.org/0.15/tutorial/text_analytics/working_with_text_data.html">scikit-learn.</a> Начало статьи вы можете прочесть в <a href="http://habrahabr.ru/post/264339/">части 1</a>.</i>

<h3>Обучение классификатора</h3><p>
Теперь, когда мы выделили признаки, можно обучать классификатор предсказывать категорию текста. Давайте начнем с </p><a href="http://scikit-learn.org/stable/modules/naive_bayes.html#naive-bayes">Наивного Байесовского классификатора</a><p>, который станет прекрасной отправной точкой для нашей задачи. scikit-learn включает в себя несколько вариантов этого классификатора. Самый подходящий для подсчета слов — это его поли номинальный вариант:

</p><pre><code class="python">&gt;&gt;&gt; from sklearn.naive_bayes import MultinomialNB
&gt;&gt;&gt; clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target)</code></pre>
<a name="habracut"/><p>
Чтобы мы могли попытаться предсказать результаты на новом документе, нужно извлечь фичи (характерные признаки), используя почти такую же последовательность как и ранее. Разница состоит в том, используется метод transform вместо fit_transform из transformers, так как они уже были применены к нашей обучающей выборке:

</p><pre><code class="python">&gt;&gt;&gt; docs_new = ['God is love', 'OpenGL on the GPU is fast']
&gt;&gt;&gt; X_new_counts = count_vect.transform(docs_new)
&gt;&gt;&gt; X_new_tfidf = tfidf_transformer.transform(X_new_counts)

&gt;&gt;&gt; predicted = clf.predict(X_new_tfidf)

&gt;&gt;&gt; for doc, category in zip(docs_new, predicted):
...     print('%r =&gt; %s' % (doc, twenty_train.target_names[category]))
...
'God is love' =&gt; soc.religion.christian
'OpenGL on the GPU is fast' =&gt; comp.graphics</code></pre>

<h3>Создание конвейерной обработки</h3><p>
Чтобы с цепочкой vectorizer =&gt; transformer =&gt; classifier было проще работать, в scikit-learn есть класс Pipeline, который функционирует как составной (конвейерный) классификатор:

</p><pre><code class="python">&gt;&gt;&gt; from sklearn.pipeline import Pipeline
&gt;&gt;&gt; text_clf = Pipeline([('vect', CountVectorizer()),
...                      ('tfidf', TfidfTransformer()),
...                      ('clf', MultinomialNB()),
... ])</code></pre><p>
Название vect, tfidf and clf (классификатор) выбраны нами произвольно. Мы рассмотрим их использование ниже, в главе grid search. Теперь обучим модель с помощью всего 1 команды:

</p><pre><code class="python">&gt;&gt;&gt; text_clf = text_clf.fit(twenty_train.data, twenty_train.target)</code></pre>

<h3>Оценка производительности при работе на тестовой выборке</h3><p>
Оценка точности прогноза модели достаточно проста:

</p><pre><code class="python">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; twenty_test = fetch_20newsgroups(subset='test',
...     categories=categories, shuffle=True, random_state=42)
&gt;&gt;&gt; docs_test = twenty_test.data
&gt;&gt;&gt; predicted = text_clf.predict(docs_test)
&gt;&gt;&gt; np.mean(predicted == twenty_test.target)            
0.834...</code></pre><p>
Например, мы получили 83% точности. Давайте посмотрим, можем ли мы улучшить этот результат с помощью линейного метода опорных векторов </p><a href="http://scikit-learn.org/stable/modules/svm.html#svm">(support vector machine (SVM))</a><p>. Этот метод обычно считается лучшим из алгоритмов классификации текста (хотя, он немного медленнее чем наивный Байес). Мы можем сменить обучающуюся модель просто подсоединив другой объект классификации в наш конвейер:

</p><pre><code class="python">&gt;&gt;&gt; from sklearn.linear_model import SGDClassifier
&gt;&gt;&gt; text_clf = Pipeline([('vect', CountVectorizer()),
...                      ('tfidf', TfidfTransformer()),
...                      ('clf', SGDClassifier(loss='hinge', penalty='l2',
...                                            alpha=1e-3, n_iter=5, random_state=42)),
... ])
&gt;&gt;&gt; _ = text_clf.fit(twenty_train.data, twenty_train.target)
&gt;&gt;&gt; predicted = text_clf.predict(docs_test)
&gt;&gt;&gt; np.mean(predicted == twenty_test.target)            
0.912...</code></pre><p>
scikit-learn также предоставляет утилиты для более детального анализа результатов:

</p><pre><code class="python">&gt;&gt;&gt; from sklearn import metrics
&gt;&gt;&gt; print(metrics.classification_report(twenty_test.target, predicted,
...     target_names=twenty_test.target_names))
...                                         
                        precision    recall  f1-score   support

           alt.atheism       0.95      0.81      0.87       319
         comp.graphics       0.88      0.97      0.92       389
               sci.med       0.94      0.90      0.92       396
soc.religion.christian       0.90      0.95      0.93       398

           avg / total       0.92      0.91      0.91      1502


&gt;&gt;&gt; metrics.confusion_matrix(twenty_test.target, predicted)
array([[258,  11,  15,  35],
       [  4, 379,   3,   3],
       [  5,  33, 355,   3],
       [  5,  10,   4, 379]])</code></pre><p>
Как и ожидалось, матрица неточностей показывает, что тексты из выборки newsgroups об атеизме и христианстве модель чаще путает друг с другом, нежели чем с текстами про компьютерную графику.

</p><h3>Настройка параметров для использования grid search</h3><p>
Некоторые параметры мы уже посчитали, такие как use_idf в функции TfidfTransformer. Классификаторы, как правило, также имеют много параметров, например, MultinomialNB включает в себя коэффициент сглаживания alpha, а SGDClassifier имеет штрафной параметр alpha (метод штрафных функций), настраиваемую потерю и штрафные члены в целевой функции (см. раздел документации или используйте функцию подсказки Python, чтобы получить дополнительную информацию).</p><p>
Вместо поиска параметров различных компонентов в цепи, можно запустить поиск (методом полного перебора ) лучших параметров в сетке возможных значений. Мы опробовали все классификаторы на словах или биграммах, с или без idf, с штрафными параметрами 0,01 и 0,001 для SVM (метода опорных векторов):

</p><pre><code class="python">&gt;&gt;&gt; from sklearn.grid_search import GridSearchCV
&gt;&gt;&gt; parameters = {'vect__ngram_range': [(1, 1), (1, 2)],
...               'tfidf__use_idf': (True, False),
...               'clf__alpha': (1e-2, 1e-3),
... }</code></pre><p>
Очевидно, подобный поиск методом полного перебора может быть ресурсозатратным. Если в нашем распоряжении есть множество ядер процессора, мы можем запустить grid search, чтобы попробовать все комбинации параметров параллельно с параметром n_jobs. Если мы зададим этому параметру значение -1, grid search определит, как много ядер установлено, и задействует их все:

</p><pre><code class="python">&gt;&gt;&gt; gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)</code></pre><p>
Экземпляр grid search ведет себя как обычная модель scikit-learn. Давайте запустим поиск на малой части обучающей выборки, чтобы увеличить скорость обработки:

</p><pre><code class="python">&gt;&gt;&gt; gs_clf = gs_clf.fit(twenty_train.data[:400], twenty_train.target[:400])</code></pre><p>
В результате применения метода fit на объекте GridSearchCV мы получим классификатор, который можно использовать для выполнения функции predict:

</p><pre><code class="python">&gt;&gt;&gt; twenty_train.target_names[gs_clf.predict(['God is love'])]
'soc.religion.christian'</code></pre><p>
но с другой стороны, это очень большой и громоздкий объект. Мы можем все таки получить оптимальные параметры, изучая атрибут объекта grid_scores_, который является списком пар параметры\мера. Чтобы получить атрибуты мер, мы можем:

</p><pre><code class="python">&gt;&gt;&gt; best_parameters, score, _ = max(gs_clf.grid_scores_, key=lambda x: x[1])
&gt;&gt;&gt; for param_name in sorted(parameters.keys()):
...     print("%s: %r" % (param_name, best_parameters[param_name]))
...
clf__alpha: 0.001
tfidf__use_idf: True
vect__ngram_range: (1, 1)

&gt;&gt;&gt; score                                              
0.900...</code></pre>
<h3>Упражнения</h3><p>
Чтобы выполнить упражнения, скопируйте содержание папки ‘skeletons’ в новую папку с названием ‘workspace’:

</p><pre><code class="python">% cp -r skeletons workspace</code></pre><p>
ВЫ можете редактировать содержимое папки workspace, не боясь потерять исходные инструкции для упражнений.</p><p>
Затем откройте оболочку ipython и запустите незавершенный скрипт для упражнения:

</p><pre><code class="python">[1] %run workspace/exercise_XX_script.py arg1 arg2 arg3</code></pre><p>
Если было вызвано исключение, используйте %debug, чтобы запустить аварийную ipdb сессию.</p><p>
Очистите реализацию и повторяйте, пока не решите задачу.
</p><b>В каждом упражнении файлы skeleton содержат все необходимые инструкции импорта, шаблоны кода для загрузки данных и примеры для кода для оценки точности предсказывания модели.</b>

<h3>Упражнения 1: Определение языка</h3>
<ul>
<li>Напишите конвейер — текстовый классификатор, используя специальную предобработку и CharNGramAnalyzer. В качестве обучающей выборки используйте статьи из Wikipedia. </li>
<li>Оцените производительность на любой тестовой выборке, не совпадающей с обучающей.</li>
</ul><p>
ipython командная строка:
</p><pre><code class="python">%run workspace/exercise_01_language_train_model.py data/languages/paragraphs/</code></pre>

<h3>Упражнение 2: Анализ предпочтений на основе отзывов фильмов</h3>
<ul>
<li>Напишите конвейер — текстовый классификатор для классификации отзывов о фильмах на положительные и отрицательные.</li>
<li>Подберите подходящий набор параметров, используя grid search. </li>
<li>Оцените производительность на тестовой выборке.</li>
</ul><p>
ipython командная строка:
</p><pre><code class="python">%run workspace/exercise_02_sentiment.py data/movie_reviews/txt_sentoken/</code></pre>

<h3>Упражнения 3: Утилита — текстовый классификатор в командной строке (консольное приложение)</h3><p>
Используя результаты предыдущих упражнений и модуль cPickle стандартной библиотеки, напишите утилиту командной строки, которая определяет язык текста в stdin (ввод с клавиатуры) и определяет полярность (положительный или отрицательный), если текст написан на английском.

</p><h3>Что дальше?</h3><p>
В этой секции приведены некоторые советы, чтобы помочь вам глубже познакомиться с scikit-learn после прохождения упражнений:
</p>

      
      <p class="clear"/>
    </div>

    
  </div></body></html>