<html><body><div><div class="content html_format"><p>
      В предыдущей </p><a href="http://habrahabr.ru/post/221251/">статье</a><p> мы на основе общих друзей ВКонтакте строили граф, а сегодня поговорим о том, как получить список друзей, друзей друзей и так далее. Предполагается, что вы уже прочли предыдущую </p><a href="http://habrahabr.ru/post/221251/">статью</a><p>, и я не буду описывать все заново. Под хабракатом большие картинки и много текста.
</p><a name="habracut"/><p>
Начнем с того, что просто скачать все id пользователей достаточно легко, список валидных id можно найти в </p><a href="https://vk.com/catalog.php">Каталоге пользователей Вконтакте</a><p>. Наша же задача — получить список друзей выбранного нами id пользователя, их друзей и рекурсивно сколь угодно глубоко, в зависимости от указанной глубины. 
</p><p>
Код, опубликованный в статье, будет меняться с течением времени, поэтому более свежую версию можно найти в том же проекте на </p><a href="https://github.com/stleon/vk_friends">Github</a><p>. 
</p><p>
Как будем реализовывать:
</p><ul>
<li>Задаем нужную нам глубину</li>
<li>Отправляем исходные данные либо те id, которые надо исследовать на данной глубине</li>
<li>Получаем ответ</li>
</ul><p>
Что будем использовать:
</p><ul>
<li>Python 3.4</li>
<li>Хранимые процедуры в ВКонтакте</li>
</ul>
<h4>Задаем нужную нам глубину</h4><p>
Что нам потребуется в начале — это указать глубину (</p><b>deep</b><p>), с которой мы хотим работать. Сделать это можно сразу в </p><b>settings.py</b><p>:

</p><pre><code class="python">deep = 2 # такая строчка там уже есть
</code></pre>
<b>deep</b><p> равное 1 — это наши друзья, 2 — это друзья наших друзей и так далее. В итоге мы получим словарь, ключами которого будут id пользователей, а значениями — их список друзей. 
</p><p>
Не спешите выставлять большие значения глубины. При 14 моих исходных друзьях и глубине равной 2, количество ключей в словаре составило 2427, а при глубине, равной 3, у меня не хватило терпения дождаться завершения работы скрипта, на тот момент словарь насчитывал 223 908 ключей. По этой причине мы не будем визуализировать такой огромный граф, ведь вершинами будут ключи, а ребрами — значения.

</p><h4>Отправление данных</h4><p>
Добиться нужного нам результата поможет уже известный метод </p><a href="https://vk.com/dev/friends.get">friends.get</a><p>, который будет расположен в хранимой процедуре, имеющей следующий вид:

</p><pre><code class="javascript">var targets = Args.targets;
var all_friends = {};
var req;
var parametr = "";
var start = 0;
// из строки с целями вынимаем каждую цель
while(start&lt;=targets.length){
    if (targets.substr(start, 1) != "," &amp;&amp; start != targets.length){
        parametr = parametr + targets.substr(start, 1);
    }
    else {
        // сразу делаем запросы, как только вытащили id
        req = API.friends.get({"user_id":parametr});
        if (req) {
            all_friends = all_friends + [req];
        }
        else {
            all_friends = all_friends + [0];
        }
        parametr = "";
    }
    start = start + 1;
}
return all_friends;
</code></pre><p>
Напоминаю, что хранимую процедуру можно создать в </p><a href="https://vk.com/editapp?id=IDприложения&amp;section=functions">настройках приложения</a><p>, пишется она на </p><b>VkScript</b><p>, как и </p><b>execute</b><p>, документацию можно прочесть </p><a href="https://vk.com/dev/execute">здесь</a><p> и </p><a href="https://vk.com/pages.php?o=-1&amp;p=execute">здесь</a><p>.
</p><p>
Теперь о том, как она работает. Мы принимаем строку из 25 id, разделенных запятыми, вынимаем по одному id, делаем запрос к </p><b>friends.get</b><p>, а нужная нам информация будет приходить в словаре, где ключи — это id, а значения — список друзей данного id.
</p><p>
При первом запуске мы отправим хранимой процедуре список друзей текущего пользователя, id которого указан в настройках. Список будет разбит на несколько частей (N/25 — это и число запросов), связано это с ограничением количества обращений к API ВКонтакте. 

</p><h4>Получение ответа</h4><p>
Всю полученную информацию мы сохраняем в словаре, например:

</p><pre><code class="python">{1:(0, 2, 3, 4), 2: (0, 1, 3, 4), 3: (0, 1, 2)}
</code></pre><p>
Ключи 1, 2 и 3 были получены при глубине, равной 1. Предположим, что это и были все друзья указанного пользователя (0). 
</p><p>
Если глубина больше 1, то далее воспользуемся разностью множеств, первое из которых — значения словаря, а второе — его ключи. Таким образом, мы получим те id (в данном случае 0 и 4), которых нет в ключах, разобьем их опять на 25 частей и отправим хранимой процедуре.
</p><p>
Тогда в нашем словаре появятся 2 новых ключа:

</p><pre><code class="python">{1:(0, 2, 3, 4), 2: (0, 1, 3, 4), 3: (0, 1, 2), 0: (1, 2, 3), 4:(1, 2, ….)}
</code></pre><p>
Сам же метод </p><b>deep_friends()</b><p> выглядит следующим образом:

</p><pre><code class="python">def deep_friends(self, deep):
		result = {}

		def fill_result(friends):
			for i in VkFriends.parts(friends):
				r = requests.get(self.request_url('execute.deepFriends', 'targets=%s' % VkFriends.make_targets(i))).json()['response']
				for x, id in enumerate(i):
					result[id] = tuple(r[x]["items"]) if r[x] else None

		for i in range(deep):
			if result:
				# те айди, которых нет в ключах + не берем id:None
				fill_result(list(set([item for sublist in result.values() if sublist for item in sublist]) - set(result.keys())))
			else:
				fill_result(requests.get(self.request_url('friends.get', 'user_id=%s' % self.my_id)).json()['response']["items"])

		return result
</code></pre><p>
Конечно, это быстрее, чем кидать по одному id в </p><b>friends.get</b><p> без использования хранимой процедуры, но времени все равно занимает порядочно много. 
</p><p>
Если бы </p><b>friends.get</b><p> был похож на </p><b>users.get</b><p>, а именно мог принимать в качестве параметра </p><b>user_ids</b><p>, то есть перечисленные через запятую id, для которых нужно вернуть список друзей, а не по одному id, то код был бы намного проще, да и количество запросов было в разы меньше.

</p><h4>Слишком медленно</h4><p>
Возвращаясь к началу статьи, могу снова повторить — очень медленно. Хранимые процедуры не спасают, решение </p><a href="https://github.com/alxpy"> alxpy</a><p> с многопоточностью (спасибо ему за вклад и участие </p><s>хоть кому-то было интересно, кроме меня</s><p>) ускоряло на несколько секунд работу программы, но хотелось большего.
</p><p>
Мудрый совет получил от  </p><a href="http://habrahabr.ru/users/igrishaev/" class="user_link">igrishaev</a><p> — нужен какой-то мап-редьюс.
</p><p>
Дело в том, что ВКонтакте разрешает 25 запросов к API через </p><b>execute</b><p>, из этого следует, что если делать запросы с разных клиентов, то мы можем увеличить количество допустимых запросов. 5 тачек — это уже 125 запросов в секунду. Но и это далеко не так. Забегая вперед, скажу, что можно и еще быстрее, примерно будет выглядеть следующим образом (на каждой машине):

</p><pre><code class="python">while True:
	r = requests.get(request_url('execute.getMutual','source=%s&amp;targets=%s' % (my_id, make_targets(lst)),access_token=True)).json()
	if 'response' in r:
		r = r["response"]
		break
	else:
		time.sleep(delay)
</code></pre><p>
Если нам приходит сообщение об ошибке, то мы делаем запрос снова, спустя заданное количество секунд. Такой прием работает какое-то время, но затем ВКонтакте начинает присылать во всех ответах </p><b>None</b><p>, поэтому после каждого запроса честно будем ждать 1 секунду. Пока что.
</p><p>
Далее нам надо выбрать новые инструменты или же написать свои, чтобы реализовать задуманное. В итоге у нас должна получиться горизонтально масштабируемая система, принцип работы видится мне следующим образом:

</p><ul>
<li>Главный сервер получает от клиента его id ВКонтакте и код операции: либо вытащить всех общих друзей, либо рекурсивно прогуляться по списку друзей с указанной глубиной.</li>
<li>Далее в обоих случаях сервер делает запрос к API ВКонтакте — нам нужен список всех друзей пользователя. </li>
<li>Поскольку все сделано для того, чтобы мы пользовались по-максимуму возможностями хранимых процедур — здесь надо будет разделить список друзей на части, по 25 контактов в каждой. На самом деле по 75. Об этом чуть ниже.</li>
<li>У нас получится много частей, используя брокер сообщений будем доставлять каждую часть определенному получателю (producer-consumer).</li>
<li>Получатели будут принимать контакты, сразу делать запросы, возвращать результат поставщику. Да, вы правильно подумали про RPC. </li>
</ul><p>
А если вы видели эту картинку, то понимаете, на какой брокер сообщений я намекаю.

</p><p>
Как только все ответы приняты, объединяем их в один. Далее результат можно будет вывести на экран или вовсе сохранить, об этом позже.
</p><p>
Тут стоит заметить, что код изменится, и если вам было достаточно использовать предыдущую версию проекта, то она так и осталась в неизменном виде. Весь код, который будет ниже, относится к новому релизу.
</p><p>
В качестве брокера сообщений будем использовать </p><b>RabbitMQ</b><p>, асинхронной распределенной очереди заданий — </p><b>Celery</b><p>.
</p><p>
Для тех, кто никогда с ними не сталкивался, вот несколько полезных ссылок на материалы, которые советую вам прочитать:

</p>
<p>
Не надо бояться понять, хоть и говорят, что можно конкретно повернуть свою голову, когда начинаешь «думать не одним компьютером, а несколькими», но это вовсе не так. 
</p><p>
Если у вас Mac, как и у автора, то </p><b>RabbitMQ</b><p> шикарно ставится через </p><b>Homebrew</b><p>:

</p><pre><code class="bash">brew update
brew install rabbitmq
</code></pre>
<b>Celery</b><p> же ставится еще легче, используем третью ветку </p><b>Python</b><p>:

</p><pre><code class="bash">pip3 install Celery
</code></pre><p>
У меня </p><b>Celery</b><p> установлен на Linux Mint, а </p><b>RabbitMQ</b><p> — на Mac. С виндой, как обычно, проблемы — </p><s>тяжело найти, легко потерять</s><p> она почему-то все время не хотела возвращать response моему Mac.
</p><p>
Далее создадим </p><b>virtual host</b><p>, пользователя и дадим ему права:

</p><pre><code class="bash">rabbitmqctl add_vhost vk_friends
rabbitmqctl add_user user password
rabbitmqctl set_permissions -p vk_friends user ".*" ".*" ".*"
</code></pre><p>
В конфигурации </p><b>RabbitMQ</b><p> надо указать ip хоста, на котором он установлен:

</p><pre><code class="bash">vim /usr/local/etc/rabbitmq/rabbitmq-env.conf
NODE_IP_ADDRESS=192.168.1.14 // конкретно мой вариант
</code></pre><p>
Вот несколько возможных конфигураций, какую выбрать — решать вам. 

</p>
<p>
Если у вас роутер или еще что-то, полезно будет знать, что </p><b>RabbitMQ</b><p> использует 5672 порт, ну и сделать переадресацию в настройках вашего устройства. Скорее всего, если будете тестировать, то воркеров раскидаете по разным машинам, а им нужно будет использовать брокер, и, если не правильно настроите сеть, </p><b>Celery</b><p> до </p><b>RabbitMQ</b><p> так и не достучится.
</p><p>
Очень хорошей новостью является то, что ВКонтакте разрешает делать по 3 запроса в секунду с одного id. Умножим эти запросы на количество возможных обращений к API ВКонтакте (25), получим максимальное число обрабатываемых контактов в секунду (75).

</p><p>
Если у нас будет много воркеров, то настанет момент, когда начнем переходить за дозволенный лимит. Поэтому переменная</p><b> token</b><p> (в </p><b>settings.py</b><p>) теперь будет кортежем, содержащим в себе несколько токенов с разных id. Скрипт же будет при каждом запросе к ВКонтакте API выбирать один из них рандомным образом:

</p><pre><code class="python">def request_url(method_name, parameters, access_token=False):
	"""read https://vk.com/dev/api_requests"""

	req_url = 'https://api.vk.com/method/{method_name}?{parameters}&amp;v={api_v}'.format(
		method_name=method_name, api_v=api_v, parameters=parameters)

	if access_token:
		req_url = '{}&amp;access_token={token}'.format(req_url, token=random.choice(token))

	return req_url 
</code></pre><p>
В этом плане у вас не должно возникнуть сложностей, если есть несколько аккаунтов в ВКонтакте (можно напрячь друзей, родных), у меня не было проблем с 4 токенами и 3 воркерами.
</p><p>
Нет, вам никто не мешает использовать </p><b>time.sleep()</b><p>, или пример выше с while, но тогда готовьтесь получать сообщения об ошибках (возможны вообще пустые ответы — id:None), или подольше ждать. 
</p><p>
Самое интересное из файла </p><b>call.py</b><p>:

</p><pre><code class="python">def getMutual():
	all_friends = friends(my_id)
	c_friends = group(mutual_friends.s(i) for i in parts(list(all_friends[0].keys()), 75))().get()
	result = {k: v for d in c_friends for k, v in d.items()}
	return cleaner(result)

def getDeep():
	result = {}
	for i in range(deep):
		if result:
			# те айди, которых нет в ключах + не берем id:None
			lst = list(set([item for sublist in result.values() if sublist for item in sublist]) - set(result.keys()))
			d_friends = group(deep_friends.s(i) for i in parts(list(lst), 75))().get()
			result = {k: v for d in d_friends for k, v in d.items()}
			result.update(result)
		else:
			all_friends = friends(my_id)
			d_friends = group(deep_friends.s(i) for i in parts(list(all_friends[0].keys()), 75) )().get()
			result = {k: v for d in d_friends for k, v in d.items()}
			result.update(result)

	return cleaner(result)
</code></pre><p>
Как видите, в 2 функциях мы используем </p><a href="http://celery.readthedocs.org/en/latest/userguide/canvas.html#groups">groups()</a><p>, который параллельно запускает несколько заданий, после чего мы «склеиваем» ответ. Помните, как </p><b>deep_friends()</b><p> выглядел вначале (там уж очень старый пример — даже без многопоточности)? Смысл остался тем же — мы используем разность множеств.
</p><p>
И, наконец, </p><b>tasks.py</b><p>. Когда-нибудь эти замечательные функции объединятся в одну:

</p><pre><code class="python">@app.task
def mutual_friends(lst):
	"""
	read https://vk.com/dev/friends.getMutual and read https://vk.com/dev/execute
	"""
	result = {}
	for i in list(parts(lst, 25)):
		r = requests.get(request_url('execute.getMutual', 'source=%s&amp;targets=%s' % (my_id, make_targets(i)), access_token=True)).json()['response']	
		for x, vk_id in enumerate(i):
			result[vk_id] = tuple(i for i in r[x]) if r[x] else None
	return result

@app.task
def deep_friends(friends):
	result = {}
	for i in list(parts(friends, 25)):
		r = requests.get(request_url('execute.deepFriends', 'targets=%s' % make_targets(i), access_token=True)).json()["response"]
	
		for x, vk_id in enumerate(i):
			result[vk_id] = tuple(r[x]["items"]) if r[x] else None

	return result
</code></pre><p>
Когда все настроено, запускаем </p><b>RabbitMQ</b><p> командой:

</p><pre><code class="bash">rabbitmq-server
</code></pre><p>
Затем переходим в папку проекта и активируем воркера:

</p><pre><code class="bash">celery -A tasks worker --loglevel=info
</code></pre><p>
Теперь, чтобы получить и сохранить список общих или «глубинных» друзей, достаточно скомандовать в консоли:

</p><pre><code class="bash">python3 call.py
</code></pre>
<h4>О результатах измерений</h4><p>
Напомню, что у автора </p><a href="http://habrahabr.ru/post/216831/">статьи</a><p>, которая вдохновила меня на </p><a href="http://habrahabr.ru/post/221251/">первую часть</a><p>, </p><b>343 друга</b><p> (запрос на общих друзей) «обрабатывались» за </p><b>119 секунд</b><p>. 
</p><p>
Мой вариант из </p><a href="http://habrahabr.ru/post/221251/">предыдущей статьи</a><p> делал то же самое за </p><b>9 секунд</b><p>.
</p><p>
Сейчас у того автора другое число друзей — 308. Что же, придется сделать один лишний запрос для последних восьми id, потратить на него драгоценную секунду, хотя за ту же секунду можно обработать 75 id.
</p><p>
С одним воркером работа скрипта заняла </p><b>4.2 секунды</b><p>, с двумя воркерами — </p><b>2.2 секунды</b><p>. 
</p><p>
Если 119 округлим до 120, а 2.2 до 2, то мой вариант работает </p><b>в 60 раз быстрее</b><p>.
</p><p>
Что касается «глубинных друзей» (друзья моих друзей и так далее + тестируем на другом id, чтобы ждать меньше) — при глубине, равной 2, количество ключей в словаре составило 1 251. 
</p><p>
Время выполнение кода, приведенного в самом начале статьи, — </p><b>17.9 секунды</b><p>.
</p><p>
Одним воркером время выполнения скрипта — </p><b>15.1 секунды</b><p>, с двумя воркерами — </p><b> 8.2 секунды</b><p>. 
</p><p>
Таким образом, </p><b>deep_friends()</b><p> стал быстрее примерно </p><b>в 2.18 раза</b><p>. 
</p><p>
Да, не всегда результат такой радужный, иногда ответа на один запрос в ВКонтакте приходится ждать и по 10, и по 20 секунд (хотя частое время выполнения одного задания </p><b>1.2 — 1.6 секунд</b><p>), скорее всего, это связано с нагрузкой на сервис, ведь мы не одни во вселенной.

</p><p>
В итоге, чем больше воркеров сделать, тем быстрее будет обрабатываться результат. Не забудьте про мощность своего железа, дополнительные токены, сеть (например, у автора резко возрастало время выполнения скрипта, когда он юзал свой айфон в качестве точки доступа) и иные факторы.

</p><h4>Сохранение результата</h4><p>
Да, есть много графо-ориентированных БД. Если в дальнейшем (а оно так и будет), мы захотим анализировать полученные результаты, то все равно их надо будет где-то хранить до самого анализа, потом эти же результаты выгружать в память и производить с ними какие-нибудь действия. Не вижу смысла использовать какую-нибудь субд, если проект был бы коммерческим и нас интересовало, например, что происходит с графом конкретного пользователя на протяжении времени — то да, тут обязательна графо-ориентированная бд, но, поскольку заниматься анализом будем в «домашних условиях», </p><a href="https://docs.python.org/3.4/library/pickle.html">pickle</a><p> нам хватит вполне.
</p><p>
Перед сохранением словарей логично будет удалять из них ключи, значения которых </p><b>None</b><p>. Это заблокированные или удаленные аккаунты. Проще говоря, эти id будут присутствовать в графе, потому что они есть у кого-то в друзьях, ну а мы сэкономим на количестве ключей в словаре:

</p><pre><code class="python">def cleaner(dct):
	return {k:v for k, v in dct.items() if v != None}

def save_or_load(myfile, sv, smth=None):
	if sv and smth:
		pickle.dump(smth, open(myfile, "wb"))
	else:
		return pickle.load(open(myfile, "rb"))
</code></pre><p>
Как видно, если мы где-то сохранили результат, то где-то и должны его загрузить, дабы заново не собирать id.

</p><h4>Анализ графа</h4><p>
Чтобы не писать свой велосипед, воспользуемся довольно известным </p><b>networkx</b><p>, который сделает за нас всю </p><s>грязную</s><p> работу. Больше узнать про </p><b>networkx</b><p> вы можете из этой </p><a href="http://habrahabr.ru/post/125898/">статьи</a><p>.

</p><pre><code class="bash">pip3 install networkx
</code></pre><p>
Прежде чем начнем анализировать граф, нарисуем его. </p><b>networkx</b><p> для этого понадобится </p><b>matplotlib</b><p>: 

</p><pre><code class="bash">pip3 install matplotlib
</code></pre><p>
Далее нам надо создать сам граф. Вообще, есть 2 пути. 
</p><p>
Первый сожрет много оперативной памяти и вашего времени:

</p><pre><code class="python">def adder(self, node):
	if node not in self.graph.nodes():
		self.graph.add_node(node)

self.graph = nx.Graph()
	for k, v in self.dct.items():
		self.adder(k)
		for i in v:
			self.adder(i)
			self.graph.add_edge(k, i)
</code></pre><p>
И это не автор выжил из ума, нет. Подобный пример приводится на </p><a href="https://www.clear.rice.edu/comp200/resources/howto/networkx.shtml">странице</a><p> университета Райса (</p><b>Rice University</b><p>), под заголовком </p><i>Convert Dictionary Graph Representation into networkx Graph Representation</i><p>: 

</p><pre><code class="python">def dict2nx(aDictGraph):
    """ Converts the given dictionary representation of a graph, 
    aDictGraph, into a networkx DiGraph (directed graph) representation.   
    aDictGraph is a dictionary that maps nodes to its 
    neighbors (successors):  {node:[nodes]}
    A DiGraph object is returned.
    """
    g = nx.DiGraph()
    for node, neighbors in aDictGraph.items():
        g.add_node(node)  # in case there are nodes with no edges
        for neighbor in neighbors:
            g.add_edge(node, neighbor)
    return g 
</code></pre><p>
Можете поверить мне на слово, граф строился целый вечер, когда в нем было уже более 300 000 вершин, мое терпение лопнуло. </p><s>Если вы прошли <a href="https://www.coursera.org/course/interactivepython">курс</a> на Сoursera по Python от этого университета, то понимаете, о чем я. А я всем на курсе говорил, что не так людей учат, ну да ладно.</s>
<p>
Да, приводится пример для ориентированного графа, но суть остается той же — сначала добавляем ключи, делая их вершинами, потом делаем вершинами значения, и то если их еще нет в графе, а потом соединяем их ребрами (в моем варианте). 
</p><p>
А второй способ сделает все за секунды:

</p><pre><code class="python">self.graph = nx.from_dict_of_lists(self.dct)
</code></pre><p>
Код лежит в файле </p><b>graph.py</b><p>, чтобы нарисовать граф общих друзей достаточно запустить этот скрипт или же где-нибудь создать экземпляр класса </p><b>VkGraph()</b><p>, а затем вызвать его метод </p><b>draw_graph()</b><p>.
</p><img src="//habrastorage.org/files/d3a/f5b/c31/d3af5bc314db469da4010b85fefff3af.png"/><p>
Это граф общих друзей, всего 306 вершин и 2096 ребер. К сожалению, я ни разу не дизайнер (практически все настройки стандартные), но вы всегда сможете стилизовать граф «под себя». Вот пара ссылок:

</p><p>
А сам метод выглядит так:

</p><pre><code class="python">def draw_graph(self):
	plt.figure(figsize=(19,19), dpi=450,)
	nx.draw(self.graph, node_size=100, cmap=True)
	plt.savefig("%s graph.png" % datetime.now().strftime('%H:%M:%S %d-%m-%Y'))
</code></pre><p>
В итоге вы получаете картинку </p><b>date graph.png</b><p> в папке проекта. Не советую рисовать граф для глубинных друзей. При </p><b>308</b><p> друзьях и глубиной равной 2, в словаре оказалось более </p><b>145 000</b><p> ключей. А есть ведь еще и значения — кортежи с id, которых вряд ли будет мало.
</p><p>
Долго искал самый малосодержащий друзей профиль в ВКонтакте, хотя тут важнее — друзья-друзей. 10 начальных друзей (1 из них заблокированный и автоматически удалится), при нашей стандартной глубине (2), в словаре насчитывалось </p><b>1234</b><p> ключа и </p><b>517 174</b><p> id (из значений). Примерно </p><b>419</b><p> друзей у одного id. Да, там есть и общие друзья, когда построим граф, мы это поймем:

</p><pre><code class="python">deep_friends = VkGraph(d_friends_dct)
print('Количество вершин:', deep_friends.graph.number_of_nodes())
print('Количество ребер:', deep_friends.graph.number_of_edges())
</code></pre><p>
Вернет:

</p><pre><code class="bash">Количество вершин: 370341
Количество ребер: 512949
</code></pre><p>
С такими большими данными было бы неплохо поиграться. У </p><b>networkx</b><p> очень большой </p><a href="https://networkx.github.io/documentation/networkx-1.9/reference/algorithms.html">список алгоритмов</a><p>, которые можно применять к графам. Разберем </p><b>некоторые</b><p> из них.

</p><h5>Связный граф</h5><p>
Для начала определим, связный ли у нас граф:

</p><pre><code class="python">print('Связный граф?', nx.is_connected(deep_friends.graph))
</code></pre><p>
Связный граф — это такой граф, в котором любая пара вершин соединена маршрутом. 
</p><p>
Кстати, у того же самого id при глубине, равной 1, вот такой красивый граф, содержащий 1268 вершин и 1329 ребер:
</p><img src="//habrastorage.org/files/883/49f/429/88349f42920f4f378d79b895bfe4c767.png"/><p>
Вопрос знатокам. Раз у нас получается граф друзья-друзей, он по-любому должен быть связным. Не может быть такого, чтобы из ниоткуда появлялась вершина, которая не связана ни с одной из существующих. Однако мы видим справа одну вершину, которая не соединена ни с одной. Почему? Призываю сначала подумать, интереснее будет узнать истину. 

</p><div class="spoiler"><b class="spoiler_title">Правильный ответ</b><div class="spoiler_text"><p>Давайте разберемся. Сначала берется список друзей, и получается так, что есть у нас id X. Из-за которого граф несвязный. Далее мы делаем запрос на друзей этого X (в глубину ведь). Так вот если у X все друзья скрытые, то будет запись в словаре:</p>

<pre><code class="python">{X:(), ...}
</code></pre><p>
Когда будет строится граф, мы честно добавим вершину X, но никаких ребер у нее не будет. Да, чисто теоретически у вершины X должно быть ребро с вершиной, id которой указан в </p><b>settings.py</b><p>, но вы же внимательно читали — мы добавляем только то, что находится в словаре. Следовательно, при глубине, равной 2, мы получим в словаре id, указанный в настройках. И тогда у вершины X появятся ребра.
</p></div></div><p>
Будем считать, что у вас не будет такой ситуации, то есть скорее всего вы увидите </p><b>True</b><p>.

</p><h5>Диаметр, центр и радиус</h5><p>
Вспомним, что </p><b>диаметром графа</b><p> называется максимальное расстояние между двумя его вершинами. 

</p><pre><code class="python">print('Диамерт графа:', nx.diameter(deep_friends.graph))
</code></pre>
<b>Центр графа</b><p> — это любая вершина, такая, что расстояние от нее до наиболее отдаленной вершины минимально. Центром графа может быть одна вершина или несколько вершин. Или проще. Центр графа — вершина, эксцентриситет (расстояние от этой вершины до самой удаленной от нее) которой равен радиусу. 

</p><pre><code class="python">print('Центр графа:', nx.center(deep_friends.graph))
</code></pre><p>
Вернет список вершин, которые являются центром графа. Не удивляйтесь, если центром окажется id, указанный в </p><b>settings.py</b><p>.

</p><b>Радиус графа</b><p> — это наименьший из эксцентриситетов всех вершин.

</p><pre><code class="python">print('Радиус графа:', nx.radius(deep_friends.graph))
</code></pre>
<h5>Авторитетность или Page Rank</h5><p>
Этот тот самый </p><b>Page Rank</b><p>, о котором вы подумали. Как правило, алгоритм используется для веб-страничек или иных документов, связанных ссылками. Чем больше ссылок на страницу, тем она важнее. Но никто не запрещает использовать этот алгоритм для графов. Более точное и подходящее определение позаимствуем из этой </p><a href="http://geektimes.ru/post/81225/">статьи</a><p>:
</p><blockquote>Авторитетность в социальном графе можно анализировать разными способами. Самый простой — отсортировать участников по количеству входящих ребер. У кого больше — тот больше авторитетен. Такой способ годен для небольших графов. В поиске по Интернету Google в качестве одного из критериев для авторитетности страниц использует PageRank. Он вычисляется при помощи случайного блуждания по графу, где в качестве узлов — страницы, а ребро между узлами — если одна страница ссылается на другую. Случайный блуждатель двигается по графу и время от времени перемещается на случайный узел и начинает блуждание заново. PageRank равен доли пребывания на каком-то узле за все время блуждания. Чем он больше, тем узел более авторитетен.</blockquote>
<pre><code class="python">import operator
print('Page Rank:', sorted(nx.pagerank(deep_friends.graph).items(), key=operator.itemgetter(1), reverse=True))
</code></pre>
<h5>Коэффициент кластеризации</h5><p>
Цитируя Википедию:
</p><blockquote>Коэффициент кластеризация — это степень вероятности того, что два разных пользователя, связанные с конкретным индивидуумом, тоже связаны. </blockquote>
<pre><code class="python">print('Коэффициент кластеризации', nx.average_clustering(deep_friends.graph))
</code></pre><p>
Как видите, нет ничего сложного, и </p><b>networkx</b><p> предлагает еще много </p><a href="https://networkx.github.io/documentation/networkx-1.9/reference/algorithms.html">алгоритмов</a><p> (автор насчитал 148), которые можно применять к графам. Вам остается лишь выбрать нужный вам алгоритм и вызвать соответствующий метод в файле </p><b>graph.py</b><p>.

</p><h4>Итог</h4><p>
Мы сделали распределенную систему, позволяющую собирать и строить граф общих друзей в ВКонтакте, которая работает в 60 раз быстрее (в зависимости от количества воркеров), чем предложенный </p><a href="http://habrahabr.ru/post/216831/">вариант</a><p> от  </p><a href="http://habrahabr.ru/users/himura/" class="user_link">Himura</a><p>, также реализовали новую функцию — запрос всех «глубинных друзей», добавили возможность анализа построенных графов.
</p><p>
Если вы не хотите ставить дополнительное ПО и вам надо построить красивый граф общих друзей из предыдущей </p><a href="http://habrahabr.ru/post/221251/">статьи</a><p>, то </p><a href="https://github.com/stleon/vk_friends/releases/tag/v1.0.0">старый релиз</a><p> к вашим услугам. В нем вы также найдете старую версию получения списка друзей пользователя рекурсивно сколь угодно глубоко. 
</p><p>
Это вовсе не предел, будут продолжаться работы по увеличению быстродействия программы. 
</p><p>
По-прежнему жду от вас вкусных пулл-реквестов, особенно если вы занимаетесь визуализированием данных. Спасибо за внимание!

      
      </p><p class="clear"/>
    </div>

    
  </div></body></html>