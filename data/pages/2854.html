<html><body><div><div class="content html_format"><p>
      Доброго времени суток, уважаемые хабровчане! Сегодня я хотел бы поговорить о том, как не имея особого опыта в машинном обучении, можно попробовать свои силы в соревнованиях, проводимых </p><a href="http://www.kaggle.com">Kaggle</a><p>. 

</p><img src="https://habrastorage.org/files/0eb/4ea/4bc/0eb4ea4bc8174cf8845fd5aca2cb1fc6.png" alt="image"/>
<p>
Как вам уже, наверное, известно, Kaggle – это платформа для исследователей разных уровней, где они могут опробовать свои модели анализа данных на серьезных и актуальных задачах. Суть такого ресурса – не только в возможности получить неплохой денежный приз в случае, если именно ваша модель окажется лучшей, но и в том (а, это, пожалуй, гораздо важнее), чтобы набраться опыта и стать специалистом в области анализа данных и машинного обучения. Ведь самый важный вопрос, зачастую стоящий перед такого рода специалистами – где найти реальные задачи? Здесь их достаточно.
</p><p>
Мы попробуем поучаствовать в обучающем соревновании, не предусматривающем каких-либо поощрений, кроме опыта.
</p><a name="habracut"/><p>
Для этого мною была выбрана задача распознавания рукописных цифр из </p><a href="http://www.kaggle.com/c/digit-recognizer">выборки MNIST</a><p>. Немного сведений из </p><a href="http://en.wikipedia.org/wiki/MNIST_database#cite_note-Multideep-8">вики</a><p>. MNIST (Mixed National Institute of Standards and Technology database) является основной базой при тестировании систем распознавания образов, а также широко используемой для обучения и тестирования алгоритмов машинного обучения. Она была создана перегруппировкой образов из оригинальной базы NIST, которая являлась достаточно сложной для распознавания. Кроме этого, были выполнены определенные преобразования (образы были нормализованы и сглажены для получения градаций серого цвета). 
</p><p>
База MNIST состоит из 60000 образов для обучения и 10000 образов для тестирования. Написано большое количество статей, посвященных задаче распознавания MNIST, </p><a href="http://people.idsia.ch/~juergen/cvpr2012.pdf">например</a><p> (в данном случае авторы использовали иерархическую систему из сверточных нейронных сетей).
</p><p>
Оригинальная выборка представлена на </p><a href="http://yann.lecun.com/exdb/mnist/">сайте</a><p>.
</p><p>
На Kaggle представлена полная выборка MNIST, организованная немного по-другому. Здесь обучающая выборка включает в себя 42000 образов, а выборка тестирования – 28000. Тем не менее, по содержанию они эквивалентны. Каждый образ MNIST представлен картинкой 28Х28 пикселей с 256 градациями серого цвета. Пример нескольких неоднозначных в идентификации цифр представлен на картинке ниже.

</p><img src="https://habrastorage.org/files/26c/5f3/05b/26c5f305bbf24a7a806e21c6633cff24.jpg" alt="image"/>
<p>
Для создания своей модели нейронной сети для распознавания цифр воспользуемся интерпретатором </p><a href="https://www.python.org/">Рython</a><p> c установленным пакетом </p><a href="https://pythonhosted.org/nolearn/">nolearn 0.4</a><p>, а также numpy и scipy (для удовлетворения всех зависимостей).
</p><p>
Здесь мне очень помогла вводная статья, написанная Adrian Rosebrock в своем </p><a href="http://www.pyimagesearch.com/2014/09/22/getting-started-deep-learning-python/">блоге</a><p>. В ней даются вводные сведения о нейронных сетях глубокого доверия и их обучении, хотя сам автор при тестировании использует обычный многослойный персептрон архитектуры 784-300-10 без какого-либо предобучения. Так поступим и мы. Кстати, весьма подробно и на примере разных классических выборок рассматривается процесс использования пакета на страничке </p><a href="https://pythonhosted.org/nolearn/dbn.html">nolearn</a><p>.
</p><p>
Итак, следуя указаниям, которые даются в названных выше статьях, создадим свой многослойный персептрон, обучим его на загруженных и обработанных данных, а затем проведем тестирование.
</p><p>
Для начала создадим свой двухслойный персептрон архитектуры 784-300-10:

</p><pre><code class="python">from nolearn.dbn import DBN

net = DBN(
    [784, 300, 10],
    learn_rates=0.3,
    learn_rate_decays=0.9,
    epochs=10,
    verbose=1,
    )
</code></pre><p>
Здесь требуются некоторые пояснения. Первый параметр конструктора нейронной сети – список, содержащий количество входов и нейронов в каждом слое, </p><b>learn_rates</b><p> – скорость обучения, </p><b>learn_rate_decays</b><p> – множитель, задающий изменение скорости обучения после каждой эпохи, </p><b>epochs</b><p> – количество эпох обучения, </p><b>verbose</b><p> – флаг вывода подробного отчета процесса обучения.
</p><p>
После выполнения этой инструкции, необходимая модель будет создана и нам останется только загрузить данные. Kaggle предоставляет нам два файла: </p><b>train.csv</b><p> и </p><b>test.csv</b><p>, содержащие соответственно выборки для обучения и тестирования. Структура файлов простая – в первой строке содержится заголовок, далее следуют данные. Для train.csv каждая строка с данными предваряется соответствующей меткой – цифрой от 0 до 9, определяющей образ. В test.csv метка отсутствует.
</p><p>
Следующим этапом загрузим данные в массивы, воспользовавшись пакетом для работы с csv-файлами. Не забываем произвести нормировку:

</p><pre><code class="python">import csv
import numpy as np

with open('D:\\train.csv', 'rb') as f:
	data = list(csv.reader(f))
	
train_data = np.array(data[1:])
labels = train_data[:, 0].astype('float')
train_data = train_data[:, 1:].astype('float') / 255.0
</code></pre><p>
После этого обучаем нашу нейронную сеть на подготовленных данных:

</p><pre><code class="python">net.fit(train_data, labels)
</code></pre><p>
Сам процесс занимает некоторое время, определяемое количеством эпох обучения, заданным при конструировании нейронной сети. На каждой эпохе обучения на экран будут выводиться (при заданном параметре verbose) значения loss и err (значение функции потерь и ошибка).

</p><img src="https://habrastorage.org/files/b5d/ccb/b2f/b5dccbb2f8fd4debb24628ffd045fdba.png" alt="image"/>
<p>
После обучения все, что нам остается сделать – загрузить данные тестирования и сохранить предсказания для каждого образа из выборки тестирования в файл с расширением csv:

</p><pre><code class="python">with open('D:\\test.csv', 'rb') as f:
	data = list(csv.reader(f))

test_data = np.array(data[1:]).astype('float') / 255.0
preds = net.predict(test_data)

with open('D:\\submission.csv', 'wb') as f:
    fieldnames = ['ImageId', 'Label']
    writer = csv.DictWriter(f, fieldnames=fieldnames)
    writer.writeheader()
    i = 1
    for elem in preds:
        writer.writerow({'ImageId': i, 'Label': elem})
        i += 1
</code></pre><p>
Дальше загружаем полученный файл в систему тестирования (см. рисунок) и ждем.

</p><img src="https://habrastorage.org/files/b45/ff3/d83/b45ff3d83e86426b8f8d97b5e890ecd5.png" alt="image"/>
<p>
Готово! 176 место из более чем 500 участников. Для начала вполне неплохо. Теперь полученный результат можно попытаться улучшить, например, применив собственные разработки или модифицируя и подбирая параметры в nolearn. Благо времени достаточно: соревнование по MNIST’у неоднократно продлевали и теперь оно будет проходить до 31.12.2015. Удачи и спасибо, что прочитали эту статью.
      </p><p class="clear"/>
    </div>

    
  </div></body></html>