<html><body><div><div id="content">

            

            
        


            <div class="section">
              <h1>dsegmenter 0.0.1.dev1</h1>

              


<p>Collection of discourse segmenters (with pre-trained models for German)</p>

<p>
   <a href="http://pythonhosted.org/dsegmenter/">Package Documentation</a>
</p>






<a href="http://opensource.org/licenses/MIT" rel="nofollow"><img src="https://img.shields.io/badge/license-MIT-blue.svg"/>
</a>
<p>A collection of various discourse segmenters (with pre-trained models for German texts).</p>
<div id="description">
<h2>Description</h2>
<p>This python module currently comprises two discourse segmenters:
<strong>edseg</strong> and <strong>bparseg</strong>.</p>
<dl>
<dt><strong>edseg</strong></dt>
<dd>is a rule-based system that uses shallow discourse-oriented
parsing to determine boundaries of elementary discourse units in
text.  The rules are hard-coded in the <a href="https://github.com/WladimirSidorenko/DiscourseSegmenter/blob/master/dsegmenter/edseg/clause_segmentation.py" rel="nofollow">submodule’s file</a> and are
only applicable to German input.</dd>
<dt><strong>bparseg</strong></dt>
<dd>is an ML-based segmentation module that operates on
syntactic constituency trees (output from <a href="http://www.cis.uni-muenchen.de/~schmid/tools/BitPar/" rel="nofollow">BitPar</a>) and decides
whether a syntactic constituent initiates a discourse segment or not
using a pre-trained linear SVM model.  This model was trained on the
German <a href="http://www.lrec-conf.org/proceedings/lrec2014/pdf/579_Paper.pdf" rel="nofollow">PCC</a> corpus, but you can also train your own classifer for any
language using your own training data (cf. <tt>discourse_segmenter
<span class="pre">--help</span></tt> for further instructions on how to do that).</dd>
</dl>
<p><em>Since the current model is a serialized file and, therefore, likely  to be incompatible with future releases of `numpy`, we will probably  remove the model files from future versions of this package,  including source data instead and performing training during the  installation.</em></p>
</div>
<div id="installation">
<h2>Installation</h2>
<p>To install this package from the PyPi index, run</p>
<pre>pip install dsegmenter
</pre>
<p>Alternatively, you can also install it directly from the source
repository by executing:</p>
<pre>git clone git@github.com:WladimirSidorenko/DiscourseSegmenter.git
pip install -r DiscourseSegmenter/requirements.txt DiscourseSegmenter/ --user
</pre>
</div>
<div id="usage">
<h2>Usage</h2>
<p>After installation, you can import the module in your python scripts
(see an example <a href="https://github.com/WladimirSidorenko/DiscourseSegmenter/blob/master/scripts/discourse_segmenter" rel="nofollow">here</a>), e.g.:</p>
<pre><span class="kn">from</span> <span class="nn">dsegmenter.bparseg</span> <span class="kn">import</span> <span class="n">BparSegmenter</span>

<span class="n">segmenter</span> <span class="o">=</span> <span class="n">BparSegmenter</span><span class="p">()</span>
</pre>
<p>or, alternatively, also use the delivered front-end script
<cite>discourse_segmenter</cite> to process your parsed input data, e.g.:</p>
<pre>discourse_segmenter bparseg segment DiscourseSegmenter/examples/bpar/maz-8727.exb.bpar
</pre>
<p>Note that this script requires two mandatory arguments: the type of
the segmenter to use (<cite>bparseg</cite> in the above case) and the operation
to perform (which are specific to each segmenter).</p>
</div>


<a name="downloads"> </a>


<ul class="nodot">
  <li><strong>Downloads (All Versions):</strong></li>
  <li>
    <span>0</span> downloads in the last day
  </li>
  <li>
    <span>19</span> downloads in the last week
  </li>
  <li>
    <span>187</span> downloads in the last month
  </li>
</ul>









            </div>


          </div>
          </div></body></html>