<html><body><div><div class="vw-post-content clearfix" itemprop="articleBody"><p>In this post, we’re going to get our hands dirty with code- but before we do, let me introduce the example problems we’re going to solve today.</p>
<h3><span>1) Predicting House Prices</span></h3>
<p><a href="http://dataconomy.com/wp-content/uploads/2015/02/Linear-Regression-Implementation-in-Python.jpg"><img class="aligncenter size-full wp-image-12023" src="http://dataconomy.com/wp-content/uploads/2015/02/Linear-Regression-Implementation-in-Python.jpg" alt="Linear Regression Implementation in Python" srcset="http://dataconomy.com/wp-content/uploads/2015/02/Linear-Regression-Implementation-in-Python-300x143.jpg 300w, http://dataconomy.com/wp-content/uploads/2015/02/Linear-Regression-Implementation-in-Python-620x295.jpg 620w, http://dataconomy.com/wp-content/uploads/2015/02/Linear-Regression-Implementation-in-Python-360x171.jpg 360w, http://dataconomy.com/wp-content/uploads/2015/02/Linear-Regression-Implementation-in-Python-750x357.jpg 750w, http://dataconomy.com/wp-content/uploads/2015/02/Linear-Regression-Implementation-in-Python.jpg 1600w" sizes="(max-width: 1600px) 100vw, 1600px"/></a><br/>
We want to predict the values of particular houses, based on the square footage.</p>
<h3><span>2)Predicting Which TV Show Will Have More Viewers Next Week</span></h3>
<p><a href="http://dataconomy.com/wp-content/uploads/2015/02/Linear-Regression-Implementation-in-Python-Predicting-Viwers-Flash-v.-Arrow.jpg"><img class="aligncenter size-full wp-image-12024" src="http://dataconomy.com/wp-content/uploads/2015/02/Linear-Regression-Implementation-in-Python-Predicting-Viwers-Flash-v.-Arrow.jpg" alt="Linear Regression Implementation in Python Predicting Viwers Flash v. Arrow" srcset="http://dataconomy.com/wp-content/uploads/2015/02/Linear-Regression-Implementation-in-Python-Predicting-Viwers-Flash-v.-Arrow-300x169.jpg 300w, http://dataconomy.com/wp-content/uploads/2015/02/Linear-Regression-Implementation-in-Python-Predicting-Viwers-Flash-v.-Arrow-620x349.jpg 620w, http://dataconomy.com/wp-content/uploads/2015/02/Linear-Regression-Implementation-in-Python-Predicting-Viwers-Flash-v.-Arrow-360x203.jpg 360w, http://dataconomy.com/wp-content/uploads/2015/02/Linear-Regression-Implementation-in-Python-Predicting-Viwers-Flash-v.-Arrow.jpg 639w" sizes="(max-width: 639px) 100vw, 639px"/></a><br/>
The Flash and Arrow are my favourite TV shows. I want to find which show will have more viewers in the coming week.</p>
<h3><span>3) Replacing Missing Values in a Dataset</span></h3>
<p>Often we have to work with datasets with missing values; this is less of a hands-on walkthrough, but I’ll talk you through how you might go about replacing these values with linear regression.</p>
<h3><span>So, Let’s Dive Into the Coding (Nearly)</span></h3>
<p><em>Before we do, it would be a good idea to install the packages from my previous post, <a href="http://dataconomy.com/python-packages-for-data-mining/" target="_blank">Python Packages for Data Mining. </a></em></p>
<h3><span>1) Predicting House Prices</span></h3>
<p>We have the following dataset:</p>
<table class="tg">
<tbody>
<tr>
<th class="tg-hd22">Entry No.</th>
<th class="tg-hd22">Square_Feet</th>
<th class="tg-hd22">Price</th>
</tr>
<tr>
<td class="tg-031e">1</td>
<td class="tg-031e">150</td>
<td class="tg-031e">6450</td>
</tr>
<tr>
<td class="tg-e3zv">2</td>
<td class="tg-e3zv">200</td>
<td class="tg-e3zv">7450</td>
</tr>
<tr>
<td class="tg-031e">3</td>
<td class="tg-031e">250</td>
<td class="tg-031e">8450</td>
</tr>
<tr>
<td class="tg-031e">4</td>
<td class="tg-031e">300</td>
<td class="tg-031e">9450</td>
</tr>
<tr>
<td class="tg-031e">5</td>
<td class="tg-031e">350</td>
<td class="tg-031e">11450</td>
</tr>
<tr>
<td class="tg-031e">6</td>
<td class="tg-031e">400</td>
<td class="tg-031e">15450</td>
</tr>
<tr>
<td class="tg-031e">7</td>
<td class="tg-031e">600</td>
<td class="tg-031e">18450</td>
</tr>
</tbody>
</table>
<p><strong>Steps to Follow:</strong></p>
<ul>
<li>With <a href="http://dataaspirant.com/2014/10/02/linear-regression/" target="_blank">linear regression,</a> we know that we have to find a linearity within the data so we can get θ0 and θ1</li>
<li>Our hypothesis equation looks like this:</li>
</ul>
<p><a href="http://dataconomy.com/wp-content/uploads/2015/02/image-7.png"><img class="aligncenter size-full wp-image-12025" src="http://dataconomy.com/wp-content/uploads/2015/02/image-7.png" alt="image-7" srcset="http://dataconomy.com/wp-content/uploads/2015/02/image-7-300x48.png 300w, http://dataconomy.com/wp-content/uploads/2015/02/image-7-360x57.png 360w, http://dataconomy.com/wp-content/uploads/2015/02/image-7.png 389w" sizes="(max-width: 389px) 100vw, 389px"/></a><br/>
<b> Where:</b></p>
<ul>
<li>hθ(x) is the value price (which we are going to predicate) for particular square_feet  (means price is a linear function of square_feet)</li>
<li>θ0 is a constant</li>
<li>θ1 is the regression coefficient</li>
</ul>
<p>And now, to coding:</p>
<p><b>Step 1.</b></p>
<ul>
<li>Open your favourite text editor, and name a file <strong>predict_house_price.py.</strong></li>
<li>We’re going to use the following packages in our programme, so copy them into your <strong>predict_house_price.py </strong>file.</li>
</ul>
<p>[code language=”css”]# Required Packages<br/>
import matplotlib.pyplot as plt<br/>
import numpy as np<br/>
import pandas as pd<br/>
from sklearn import datasets, linear_model [/code]</p>
<ul>
<li>Just run your code once. If your program is error-free, then most of the work on Step 1 is done. If you face any errors , this means you missed some packages so head back to the <a href="http://dataconomy.com/python-packages-for-data-mining/" target="_blank">packages page.</a></li>
<li>Install all the packages in that blog post and run your code once again . This time hopefully you won’t face any problems.</li>
<li>Now that you’re programme is error-free, we can proceed to…</li>
</ul>
<p><strong>Step 2. </strong></p>
<ul>
<li>I stored our data set in to a .csv file, named <strong>input_data.csv</strong></li>
<li>So let’s write a function to get our data into X values ( square_feet) Y values (Price)</li>
</ul>
<p>[code language=”css”]# Function to get data<br/>
def get_data(file_name):<br/>
 data = pd.read_csv(file_name)<br/>
 X_parameter = []<br/>
 Y_parameter = []<br/>
 for single_square_feet ,single_price_value in zip(data[‘square_feet’],data[‘price’]):<br/>
       X_parameter.append([float(single_square_feet)])<br/>
       Y_parameter.append(float(single_price_value))<br/>
 return X_parameter,Y_parameter[/code]</p>
<p><b>Lines 3:</b> Reading .csv data into Pandas dataframe.<br/>
<b>Lines 6-9:</b> Converting Pandas dataframe data into X_parameter and Y_parameter data, and returning them.<br/>
So, let’s print out our X_parameters and Y_parameters:</p>
<p>[code language=”css”]X,Y = get_data(‘input_data.csv’)<br/>
print X<br/>
print Y[/code]</p>
<p><strong>Script Output:</strong><br/>
<span> [[150.0], [200.0], [250.0], [300.0], [350.0], [400.0], [600.0]]<br/>
[6450.0, 7450.0, 8450.0, 9450.0, 11450.0, 15450.0, 18450.0]<br/>
[Finished in 0.7s]</span></p>
<p><b> Step 3 </b><br/>
Now let’s fit our X_parameters and Y_parameters to Linear Regression model. We’re gonna write a function which we’ll take X_parameters ,Y_parameter and the value you gonna predict as input and return the θ0 ,θ1 and predicted value.</p>
<p>[code language=”css”]# Function for Fitting our data to Linear model<br/>
def linear_model_main(X_parameters,Y_parameters,predict_value):</p>
<p> # Create linear regression object<br/>
 regr = linear_model.LinearRegression()<br/>
 regr.fit(X_parameters, Y_parameters)<br/>
 predict_outcome = regr.predict(predict_value)<br/>
 predictions = {}<br/>
 predictions[‘intercept’] = regr.intercept_<br/>
 predictions[‘coefficient’] = regr.coef_<br/>
 predictions[‘predicted_value’] = predict_outcome<br/>
 return predictions [/code]</p>
<p><b>Lines 5-6:</b> First, we’re creating an linear model and the training it with our X_parameters and Y_parameters.<br/>
<b>Lines 8-12:</b> We’re creating one dictionary with name predictions and storing θ0 ,θ1 and predicted values, and returning predictions dictionary as an output.</p>
<p>So let’s call our function with predicting value as 700</p>
<p>[code language=”css”] X,Y = get_data(‘input_data.csv’)<br/>
predictvalue = 700<br/>
result = linear_model_main(X,Y,predictvalue)<br/>
print "Intercept value " , result[‘intercept’]<br/>
print "coefficient" , result[‘coefficient’]<br/>
print "Predicted value: ",result[‘predicted_value’] [/code]</p>
<p><strong>Script output:</strong> <span> Intercept value 1771.80851064<br/>
coefficient [ 28.77659574]<br/>
Predicted value: [ 21915.42553191]<br/>
[Finished in 0.7s] </span><br/>
Here, the Intercept value is just the θ0 value and coefficient value is the θ1 value.</p>
<p>We got the predicted value as 21915.4255- which means we’ve done our job of predicting the house price!</p>
<p>For checking purposes, we have to see how our data fits to linear regression. So we have to write a function which takes X_parameters and Y_parameters as input and show the linear line fitting for our data.</p>
<p>[code language=”css”]# Function to show the resutls of linear fit model<br/>
def show_linear_line(X_parameters,Y_parameters):<br/>
 # Create linear regression object<br/>
 regr = linear_model.LinearRegression()<br/>
 regr.fit(X_parameters, Y_parameters)<br/>
 plt.scatter(X_parameters,Y_parameters,color=’blue’)<br/>
 plt.plot(X_parameters,regr.predict(X_parameters),color=’red’,linewidth=4)<br/>
 plt.xticks(())<br/>
 plt.yticks(())<br/>
 plt.show() [/code]</p>
<p>So let’s call our show_linear_line function:</p>
<p>[code language=”css”] show_linear_line(X,Y)[/code]</p>
<p><b>Script Output:</b><br/>
<a href="http://dataconomy.com/wp-content/uploads/2015/02/Linear-Regression-Implementation-in-Python-Example-1-Output.png"><img class="aligncenter size-large wp-image-12026" src="http://dataconomy.com/wp-content/uploads/2015/02/Linear-Regression-Implementation-in-Python-Example-1-Output-620x527.png" alt="Linear Regression Implementation in Python Example 1 Output" srcset="http://dataconomy.com/wp-content/uploads/2015/02/Linear-Regression-Implementation-in-Python-Example-1-Output-300x255.png 300w, http://dataconomy.com/wp-content/uploads/2015/02/Linear-Regression-Implementation-in-Python-Example-1-Output-620x527.png 620w, http://dataconomy.com/wp-content/uploads/2015/02/Linear-Regression-Implementation-in-Python-Example-1-Output-360x306.png 360w, http://dataconomy.com/wp-content/uploads/2015/02/Linear-Regression-Implementation-in-Python-Example-1-Output.png 640w" sizes="(max-width: 620px) 100vw, 620px"/></a></p>
<h3><span>2)Predicting Which TV Show Will Have More Viewers Next Week</span></h3>
<p><a href="http://dataconomy.com/wp-content/uploads/2015/02/Linear-Regression-Implementation-in-Python-Predicting-Viwers-Flash-v.-Arrow-2.jpg"><img class="aligncenter size-large wp-image-12027" src="http://dataconomy.com/wp-content/uploads/2015/02/Linear-Regression-Implementation-in-Python-Predicting-Viwers-Flash-v.-Arrow-2-620x320.jpg" alt="Linear Regression Implementation in Python Predicting Viwers Flash v. Arrow 2" srcset="http://dataconomy.com/wp-content/uploads/2015/02/Linear-Regression-Implementation-in-Python-Predicting-Viwers-Flash-v.-Arrow-2-300x155.jpg 300w, http://dataconomy.com/wp-content/uploads/2015/02/Linear-Regression-Implementation-in-Python-Predicting-Viwers-Flash-v.-Arrow-2.jpg 620w, http://dataconomy.com/wp-content/uploads/2015/02/Linear-Regression-Implementation-in-Python-Predicting-Viwers-Flash-v.-Arrow-2-360x186.jpg 360w" sizes="(max-width: 620px) 100vw, 620px"/></a></p>
<p><i><b>    The Flash</b></i> is an American television series developed by writer/producers <a href="http://en.wikipedia.org/wiki/Greg_Berlanti" title="Greg Berlanti">Greg Berlanti</a>, <a href="http://en.wikipedia.org/wiki/Andrew_Kreisberg" title="Andrew Kreisberg">Andrew Kreisberg</a> and <a href="http://en.wikipedia.org/wiki/Geoff_Johns" title="Geoff Johns">Geoff Johns</a>, airing on <a href="http://en.wikipedia.org/wiki/The_CW" title="The CW">The CW</a>. It is based on the <a href="http://en.wikipedia.org/wiki/DC_Comics" title="DC Comics">DC Comics</a> character <a href="http://en.wikipedia.org/wiki/Flash_(Barry_Allen)" title="Flash (Barry Allen)">Flash (Barry Allen)</a>, a costumed superhero crime-fighter with the power to move at superhuman speeds, who was created by <a href="http://en.wikipedia.org/wiki/Robert_Kanigher" title="Robert Kanigher">Robert Kanigher</a>, <a href="http://en.wikipedia.org/wiki/John_Broome_(writer)" title="John Broome (writer)">John Broome</a> and<a href="http://en.wikipedia.org/wiki/Carmine_Infantino" title="Carmine Infantino">Carmine Infantino</a>. It is a spin-off from <i><a href="http://en.wikipedia.org/wiki/Arrow_(TV_series)" title="Arrow (TV series)">Arrow</a></i>, existing in the same <a href="http://en.wikipedia.org/wiki/Fictional_universe" title="Fictional universe">universe</a>. The <a href="http://en.wikipedia.org/wiki/Television_pilot" title="Television pilot">pilot</a> for the series was written by Berlanti, Kreisberg and Johns, and directed by <a href="http://en.wikipedia.org/wiki/David_Nutter" title="David Nutter">David Nutter</a>. The series premiered in North America on October 7, 2014, where the pilot became the most watched telecast for The CW.</p>
<p><i><b> Arrow</b></i> is an American television series developed by writer/producers <a href="http://en.wikipedia.org/wiki/Greg_Berlanti" title="Greg Berlanti">Greg Berlanti</a>, <a href="http://en.wikipedia.org/wiki/Marc_Guggenheim" title="Marc Guggenheim">Marc Guggenheim</a>, and <a href="http://en.wikipedia.org/wiki/Andrew_Kreisberg" title="Andrew Kreisberg">Andrew Kreisberg</a>. It is based on the <a href="http://en.wikipedia.org/wiki/DC_Comics" title="DC Comics">DC Comics</a> character<a href="http://en.wikipedia.org/wiki/Green_Arrow" title="Green Arrow">Green Arrow</a>, a costumed crime-fighter created by <a href="http://en.wikipedia.org/wiki/Mort_Weisinger" title="Mort Weisinger">Mort Weisinger</a> and <a href="http://en.wikipedia.org/wiki/George_Papp" title="George Papp">George Papp</a>. It premiered in North America on <a href="http://en.wikipedia.org/wiki/The_CW" title="The CW">The CW</a> on October 10, 2012, with international broadcasting taking place in late 2012. Primarily filmed in <a href="http://en.wikipedia.org/wiki/Vancouver,_British_Columbia" class="mw-redirect" title="Vancouver, British Columbia">Vancouver, British Columbia</a>, Canada, the series follows billionaire playboy Oliver Queen, portrayed by <a href="http://en.wikipedia.org/wiki/Stephen_Amell" title="Stephen Amell">Stephen Amell</a>, who, after five years of being stranded on a hostile island, returns home to fight crime and corruption as a secret vigilante whose weapon of choice is a bow and arrow. Unlike in the comic books, Queen does not initially go by the alias “Green Arrow”.</p>
<p>As both of these shows are tied for the title of my favourite TV show, I’m always interested to know which one is more popular with other people- and which one will ultimately win the ratings war.</p>
<p>So, lets write a program which predicts which TV Show will have more viewers.</p>
<p>We need a dataset which shows viewers for each episode. Luckly, I got this data from Wikipedia and prepared a .csv file. It’s looks like this.</p>
<table class="tg">
<tbody>
<tr>
<th class="tg-hd22">FLASH_EPISODE</th>
<th class="tg-hd22">FLASH_US_VIEWERS</th>
<th class="tg-hd22">ARROW_EPISODE</th>
<th class="tg-hd22">ARROW_US_VIEWERS</th>
</tr>
<tr>
<td class="tg-031e">1</td>
<td class="tg-031e">4.83</td>
<td class="tg-031e">1</td>
<td class="tg-031e">2.84</td>
</tr>
<tr>
<td class="tg-031e">2</td>
<td class="tg-031e">4.27</td>
<td class="tg-031e">2</td>
<td class="tg-031e">2.32</td>
</tr>
<tr>
<td class="tg-031e">3</td>
<td class="tg-031e">3.59</td>
<td class="tg-031e">3</td>
<td class="tg-031e">2.55</td>
</tr>
<tr>
<td class="tg-031e">4</td>
<td class="tg-031e">3.53</td>
<td class="tg-031e">4</td>
<td class="tg-031e">2.49</td>
</tr>
<tr>
<td class="tg-031e">5</td>
<td class="tg-031e">3.46</td>
<td class="tg-031e">5</td>
<td class="tg-031e">2.73</td>
</tr>
<tr>
<td class="tg-031e">6</td>
<td class="tg-031e">3.73</td>
<td class="tg-031e">6</td>
<td class="tg-031e">2.6</td>
</tr>
<tr>
<td class="tg-031e">7</td>
<td class="tg-031e">3.47</td>
<td class="tg-031e">7</td>
<td class="tg-031e">2.64</td>
</tr>
<tr>
<td class="tg-031e">8</td>
<td class="tg-031e">4.34</td>
<td class="tg-031e">8</td>
<td class="tg-031e">3.92</td>
</tr>
<tr>
<td class="tg-031e">9</td>
<td class="tg-031e">4.66</td>
<td class="tg-031e">9</td>
<td class="tg-031e">3.06</td>
</tr>
</tbody>
</table>
<p><em>(Viewers are in millions)</em></p>
<p><b>Steps to solving this problem:</b></p>
<ul>
<li>First we have to convert our data to X_parameters and Y_parameters, but here we have two X_parameters and Y_parameters. So, lets’s name them as flash_x_parameter, flash_y_parameter, arrow_x_parameter , arrow_y_parameter.</li>
<li>Then we have to fit our data to two different  linear regression models- first for Flash, and the other for Arrow.</li>
<li>Then we have to predict the number of viewers for next episode for both of the TV shows.</li>
<li>Then we can compare the results and we can guess which show will have more viewers.</li>
</ul>
<p><b> Step 1 </b><br/>
Let’s import our packages:</p>
<p>[code language=”css”]# Required Packages<br/>
import csv<br/>
import sys<br/>
import matplotlib.pyplot as plt<br/>
import numpy as np<br/>
import pandas as pd<br/>
from sklearn import datasets, linear_model [/code]</p>
<p><b>Step 2</b></p>
<p>Let’s write a function which will take our data set as input and returns flash_x_parameter,flash_y_parameter,arrow_x_parameter ,arrow_y_parameter values.</p>
<p>[code language=”css”]# Function to get data<br/>
def get_data(file_name):<br/>
 data = pd.read_csv(file_name)<br/>
 flash_x_parameter = []<br/>
 flash_y_parameter = []<br/>
 arrow_x_parameter = []<br/>
 arrow_y_parameter = []<br/>
 for x1,y1,x2,y2 in zip(data[‘flash_episode_number’],data[‘flash_us_viewers’],data[‘arrow_episode_number’],data[‘arrow_us_viewers’]):<br/>
 flash_x_parameter.append([float(x1)])<br/>
 flash_y_parameter.append(float(y1))<br/>
 arrow_x_parameter.append([float(x2)])<br/>
 arrow_y_parameter.append(float(y2))<br/>
 return flash_x_parameter,flash_y_parameter,arrow_x_parameter,arrow_y_parameter [/code]</p>
<p>Now we have our parameters, let’s write a function which will take these above parameters as input and gives an output that will predict which show will have more views.</p>
<p>[code language=”css”]# Function to know which Tv show will have more viewers<br/>
def more_viewers(x1,y1,x2,y2):<br/>
 regr1 = linear_model.LinearRegression()<br/>
 regr1.fit(x1, y1)<br/>
 predicted_value1 = regr1.predict(9)<br/>
 print predicted_value1<br/>
 regr2 = linear_model.LinearRegression()<br/>
 regr2.fit(x2, y2)<br/>
 predicted_value2 = regr2.predict(9)<br/>
 #print predicted_value1<br/>
 #print predicted_value2<br/>
 if predicted_value1 &gt; predicted_value2:<br/>
 print "The Flash Tv Show will have more viewers for next week"<br/>
 else:<br/>
 print "Arrow Tv Show will have more viewers for next week" [/code]</p>
<p>Let’s write every thing in one file. Open your editor, and name it as <strong>prediction.py</strong> and copy this total code into <strong>prediction.py</strong> file.</p>
<p>[code language=”css”]# Required Packages<br/>
import csv<br/>
import sys<br/>
import matplotlib.pyplot as plt<br/>
import numpy as np<br/>
import pandas as pd<br/>
from sklearn import datasets, linear_model</p>
<p># Function to get data<br/>
def get_data(file_name):<br/>
 data = pd.read_csv(file_name)<br/>
 flash_x_parameter = []<br/>
 flash_y_parameter = []<br/>
 arrow_x_parameter = []<br/>
 arrow_y_parameter = []<br/>
 for x1,y1,x2,y2 in zip(data[‘flash_episode_number’],data[‘flash_us_viewers’],data[‘arrow_episode_number’],data[‘arrow_us_viewers’]):<br/>
 flash_x_parameter.append([float(x1)])<br/>
 flash_y_parameter.append(float(y1))<br/>
 arrow_x_parameter.append([float(x2)])<br/>
 arrow_y_parameter.append(float(y2))<br/>
 return flash_x_parameter,flash_y_parameter,arrow_x_parameter,arrow_y_parameter</p>
<p># Function to know which Tv show will have more viewers<br/>
def more_viewers(x1,y1,x2,y2):<br/>
 regr1 = linear_model.LinearRegression()<br/>
 regr1.fit(x1, y1)<br/>
 predicted_value1 = regr1.predict(9)<br/>
 print predicted_value1<br/>
 regr2 = linear_model.LinearRegression()<br/>
 regr2.fit(x2, y2)<br/>
 predicted_value2 = regr2.predict(9)<br/>
 #print predicted_value1<br/>
 #print predicted_value2<br/>
 if predicted_value1 &gt; predicted_value2:<br/>
 print "The Flash Tv Show will have more viewers for next week"<br/>
 else:<br/>
 print "Arrow Tv Show will have more viewers for next week"</p>
<p>x1,y1,x2,y2 = get_data(‘input_data.csv’)<br/>
#print x1,y1,x2,y2<br/>
more_viewers(x1,y1,x2,y2) [/code]</p>
<p>You may be able to guess which show will have viewers from the data set- but run this programme to check it and see.</p>
<h3><span>3) Replacing Missing Values in a Dataset</span></h3>
<p>Sometimes, we have a situation where we have to do analysis on data which consists of missing values. Some people will remove these missing values and continue analysis, and some people replace them with min, max or mean value. Mean value is the best out of the three, but can use linear regression to replace those missing value very effectively.</p>
<p>This approach goes some thing like this.</p>
<p>First we have find in which column we’re gonna replace missing values and find which data in the other collumns the missing data depends on. Consider missing values column as Y_parameters and consider the columns on which this missing values more depend as X_parameters, and fit this data to Linear regression model. Now predict the missing values in missing values column by consider the columns on which this missing values column more depends.</p>
<p>Once this process is completed, we will get data without any missing values, leaving us free to analyse this data.</p>
<p>For practice, I’ll leave this problem to you so please kindly get some missing values data from online and solve this problem. Leave your comments once you’ve completed. I’d love to see your results.</p>
<p><strong>Small personal note:</strong></p>
<p>I want to share my personal experience with data mining. I remember in my introductory data mining classes, the instructor starts slow and explains some interesting areas where we can apply data mining and some very basic concepts. Then suddenly, the difficulty level would sky rocket. This made some of my classmates feel extremely frustrated and intimidated by the course, and ultimately killed their interest in data mining. So I want to avoid doing this in my blog posts. I want to make thing more easygoing; hence why I tried to use interesting examples, to make my readers more comfortable learning without getting bored or intimidated.</p>
<p>Thanks for reading this far- please leave your questions or suggestions in the comment box, and I’d be delighted to get back to you.</p>
<p><em>Originally posted on <a href="http://dataaspirant.com/" target="_blank">DataAspirant</a>.</em></p>
<p><a href="https://twitter.com/DataconomyMedia" class="twitter-follow-button" data-show-count="false" data-size="large">Follow @DataconomyMedia</a></p>
<p><em>Featured image courtesy of <a href="http://arrow.wikia.com/wiki/File:The_Flash_vs_Arrow_fan_screening_promo.png" target="_blank">Wikia</a>– this is promotional material for Arrow, and so is copyright of The CW Network.</em></p>
</div>

							
							</div></body></html>