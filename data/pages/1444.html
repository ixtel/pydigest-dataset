<html><body><div><div class="content html_format"><p>
      Пусть мы хотим вычислить десятимиллионное </p><a href="https://ru.wikipedia.org/wiki/%D0%A7%D0%B8%D1%81%D0%BB%D0%B0_%D0%A4%D0%B8%D0%B1%D0%BE%D0%BD%D0%B0%D1%87%D1%87%D0%B8">число Фибоначчи</a><p> программой на Python. Функция, использующая тривиальный алгоритм, на моём компьютере будет производить вычисления более 25 минут. Но если применить к функции специальный оптимизирующий декоратор, функция вычислит ответ всего за 18 секунд (</p><i>в 85 раз быстрее</i><p>):

</p><p>
Дело в том, что перед выполнением программы интерпретатор Python компилирует все её части в специальный байт-код. Используя метод, описанный хабрапользователем </p><a href="https://habrahabr.ru/users/skidanovalex/" class="user_link">SkidanovAlex</a><p>, данный декоратор анализирует получившийся байт-код функции и пытается оптимизировать применяющийся там алгоритм. Далее вы увидите, что эта оптимизация может ускорять программу не в определённое количество раз, а асимптотически. Так, чем больше будет количество итераций в цикле, тем в большее количество раз ускорится оптимизированная функция по сравнению с исходной.
</p><p>
Эта статья расскажет о том, в каких случаях и каким образом декоратору удаётся делать подобные оптимизации. Также вы сможете сами скачать и протестировать библиотеку </p><i>cpmoptimize</i><p>, содержащую данный декоратор.
</p><a name="habracut"/>
<h3>Теория</h3><p>
Два года назад </p><a href="https://habrahabr.ru/users/skidanovalex/" class="user_link">SkidanovAlex</a><p> опубликовал интересную статью с описанием интерпретатора ограниченного языка, который поддерживает следующие операции:
</p><pre><code class="python"># Присвоить переменной другую переменную или константу
x = y
x = 1

# Сложить или вычесть из переменной другую переменную или константу
x += y
x += 2
x -= y
x -= 3

# Умножить переменную на константу
x *= 4

# Запустить цикл с константным числом итераций
loop 100000
    ...
end
</code></pre><p>
Значения переменных в языке должны быть числами, их размер не ограничен (поддерживается </p><a href="https://ru.wikipedia.org/wiki/%D0%94%D0%BB%D0%B8%D0%BD%D0%BD%D0%B0%D1%8F_%D0%B0%D1%80%D0%B8%D1%84%D0%BC%D0%B5%D1%82%D0%B8%D0%BA%D0%B0">длинная арифметика</a><p>). На самом деле переменные хранятся как целые числа в Python, который переключается в режим длинной арифметики, если число выходит за границы аппаратно поддерживаемого четырёх- или восьмибайтового типа.
</p><p>
Рассмотрим случай, когда длинная арифметика не используется. Тогда время выполнения операций не будет зависеть от значений переменных, а значит в цикле все итерации будут выполняться за одинаковое время. Если выполнять такой код «в лоб», как в обычных интерпретаторах, цикл выполнится за время </p><img src="https://habrastorage.org/files/cb8/b51/c44/cb8b51c4455f429cb1c8780f093d6474.png"/><p>, где </p><i>n</i><p> — количество итераций. Другими словами, если код для </p><i>n</i><p> итераций работает за время </p><i>t</i><p>, то код для </p><img src="https://habrastorage.org/files/9fa/c09/665/9fac09665bc8458a9e36601413d1c852.png"/><p> итераций будет работать за время </p><img src="https://habrastorage.org/files/306/d33/cf6/306d33cf6f2c48379f7e891cf500deb3.png"/><p> (см. </p><a href="http://en.wikipedia.org/wiki/Time_complexity">сложность вычислений</a><p>).
</p><p>
Интерпретатор из </p><a href="http://habrahabr.ru/post/148901/">оригинальной статьи</a><p> представляет каждую поддерживаемую языком операцию с переменными в виде определённой матрицы, на которую умножается вектор с исходными значениями переменных. В результате умножения мы получаем вектор с новыми значениями переменных:

</p><img src="https://habrastorage.org/files/3b6/e12/ec6/3b6e12ec6c4b4ed083dca38f5c3d6b0f.png"/>
<p>
Таким образом, для выполнения последовательности операций нужно по очереди домножать вектор на матрицу, соответствующую очередной операции. Другой способ — пользуясь ассоциативностью, матрицы можно сперва умножить друг на друга, а потом умножить исходный вектор на получившееся произведение:

</p><img src="https://habrastorage.org/files/902/b25/58b/902b2558b1da4984925bc84dd028de65.png"/>
<p>
Для выполнения цикла мы должны вычислить число </p><i>n</i><p> — количество итераций в цикле, а также матрицу </p><i>B</i><p> — последовательное произведение матриц, соответствующих операциям из тела цикла. Затем нужно </p><i>n</i><p> раз умножить исходный вектор на матрицу </p><i>B</i><p>. Другой способ — можно сначала возвести матрицу </p><i>B</i><p> в степень </p><i>n</i><p>, а потом умножить вектор с переменными на результат:

</p><img src="https://habrastorage.org/files/1e8/dae/5bc/1e8dae5bcc874648abb3686adbc3274d.png"/>
<p>
Если при этом использовать алгоритм </p><a href="http://e-maxx.ru/algo/binary_pow">бинарного возведения в степень</a><p>, цикл можно будет выполнить за значительно меньшее время </p><img src="https://habrastorage.org/files/7ac/7f0/c52/7ac7f0c524f4424cb8e8ad8d199c6057.png"/><p>. Так, если код для </p><i>n</i><p> итераций работает за время </p><i>t</i><p>, то код для </p><img src="https://habrastorage.org/files/9fa/c09/665/9fac09665bc8458a9e36601413d1c852.png"/><p> итераций будет работать за время </p><img src="https://habrastorage.org/files/9e9/503/215/9e950321525a4c60a7ba20e9ebc590f7.png"/><p> (всего лишь в два раза медленнее, а не в </p><i>n</i><p> раз медленнее, как в предыдущем случае).
</p><p>
В итоге, как и было написано выше, чем больше будет количество итераций в цикле </p><i>n</i><p>, тем в большее количество раз ускоряется оптимизированная функция. Поэтому эффект от оптимизации будет особенно хорошо заметен для больших </p><i>n</i><p>.
</p><p>
Если длинная арифметика всё-таки используется, оценки времени выше могут быть неверны. Например, при вычислении </p><i>n</i><p>-го числа Фибоначчи значения переменных из итерации в итерацию становятся всё больше, и операции с ними замедляются. Асимптотическую оценку времени работы программы в таком случае сделать сложнее (нужно учитывать длину чисел в переменных на каждой итерации и используемые методы перемножения чисел) и здесь она приведена не будет. Тем не менее, после применения данного метода оптимизации асимптотика улучшается даже в таком случае. Это хорошо заметно на графике:

</p>
<h3>Идея</h3><p>
Если десятки лет назад программисту потребовалось бы умножить переменную в программе на 4, он использовал бы не операцию умножения, а её более быстрый эквивалент — битовый сдвиг влево на 2. Теперь компиляторы сами умеют делать подобные оптимизации. В борьбе за сокращение времени разработки появились языки с высоким уровнем абстракции, новые удобные технологии и библиотеки. При написании программ всё большую часть своего времени разработчики тратят на объяснение компьютеру того, </p><i>что</i><p> должна сделать программа (умножить число на 4), а не того, </p><i>как</i><p> ей это сделать эффективно (использовать битовый сдвиг). Таким образом, задача создания эффективного кода частично переносится на компиляторы и интерпретаторы.
</p><p>
Сейчас компиляторы умеют заменять различные операции на более эффективные, предсказывать значения выражений, удалять или менять местами части кода. Но компиляторы ещё не заменяют сам </p><i>алгоритм</i><p> вычислений, написанный человеком, на асимптотически более эффективный.
 </p><p>
Реализацию описываемого метода, представленную в оригинальной статье, проблематично использовать в реальных программах, так как для этого придётся переписать часть кода на специальный язык, а для взаимодействия с этим кодом придётся запускать сторонний скрипт с интерпретатором. Однако, автор статьи предлагает использовать свои наработки на практике в оптимизирующих компиляторах. Я попытался реализовать данный метод для оптимизации программ на Python в виде, действительно пригодном для использования в реальных проектах.
</p><p>
Если использовать написанную мной библиотеку, для применения оптимизации достаточно будет дописать перед функцией, которую нужно ускорить, одну строчку с применением специального декоратора. Этот декоратор самостоятельно оптимизирует циклы, если это возможно, и ни при каких обстоятельствах не «ломает» программу.

</p><h3>Примеры использования</h3><p>
Рассмотрим ряд задач, в которых может пригодиться наш декоратор.

</p><h4>Пример №1. Длинные циклы</h4><p>
Пусть у нас есть некоторая последовательность, соответствующая правилу, изображённому на схеме, и нам нужно вычислить её </p><i>n</i><p>-ый член:
</p><p>
В таком случае интуитивно понятно, как появляется очередной член последовательности, однако требуется время, чтобы придумать и доказать соответствующую ему математическую формулу. Тем не менее, мы можем написать тривиальный алгоритм, описывающий наше правило, и предложить компьютеру самому придумать, как быстро считать ответ на нашу задачу:
</p><pre><code class="python">from cpmoptimize import cpmoptimize, xrange

@cpmoptimize()
def f(n):
    step1 = 1
    step2 = 1
    res = 1
    for i in xrange(n):
        res += step2
        step2 += step1
        step1 += 1
    return res
</code></pre><p>
Интересно, что если запустить эту функцию для </p><img src="https://habrastorage.org/files/f98/b6e/192/f98b6e1925614bcf8ac02384beb73858.png"/><p>, внутри будет запущен цикл с </p><img src="https://habrastorage.org/files/8e7/a78/0ab/8e7a780ab22341d395aef9274df89a98.png"/><p> итераций. Без оптимизации такая функция не закончила бы работать ни за какой мыслимый промежуток времени, но с декоратором она выполняется меньше секунды, возвращая при этом правильный результат.

</p><h4>Пример №2. Числа Фибоначчи</h4><p>
Для быстрого вычисления </p><i>n</i><p>-го числа Фибоначчи есть быстрый, но нетривиальный </p><a href="http://e-maxx.ru/algo/fibonacci_numbers#8">алгоритм</a><p>, основанный на той же идее о возведении матриц в степень. Опытный разработчик может реализовать его за несколько минут. Если коду, где производятся подобные вычисления, не нужно работать быстро (например, если необходимо однократно вычислить число Фибоначчи с номером, меньшим 10 тысяч), для экономии своего рабочего времени разработчик, скорее всего, решит сэкономить усилия и за несколько секунд написать решение «в лоб».
</p><p>
Если программа всё-таки должна работать быстро, либо придётся приложить усилия и написать сложный алгоритм, либо же можно воспользоваться методом автоматической оптимизации, применив к функции наш декоратор. Если </p><i>n</i><p> достаточно велико, в обоих случаях производительность программ получится почти одинаковой, но во втором случае разработчик потратит меньше своего рабочего времени.
</p><p>
Вы можете сравнить время работы описанных методов ниже по таблицам и графикам для малых и для больших </p><i>n</i><p>.
</p><p>
Справедливости ради следует отметить, что для вычисления чисел Фибоначчи есть ещё один алгоритм, известный как </p><a href="http://nayuki.eigenstate.org/page/fast-fibonacci-algorithms">fast doubling</a><p>. Он несколько выигрывает предыдущие алгоритмы по времени, так как в нём исключены лишние сложения и умножения чисел. Время вычислений через этот алгоритм также представлено на графиках для сравнения.

</p>
<div class="spoiler"><b class="spoiler_title">Результаты измерений времени</b><div class="spoiler_text"><pre><code>Function "fib":

(*) Testcase "big":
+--------+----------+--------------+--------------+--------------+-------+
|  arg   | naive, s |    cpm, s    | matrices, s  | fast dbl, s  | match |
+--------+----------+--------------+--------------+--------------+-------+
|      0 |     0.00 | 0.00         | 0.00         | 0.00         |  True |
|  20000 |     0.01 | 0.00  (2.5x) | 0.00  (3.0x) | 0.00  (5.1x) |  True |
|  40000 |     0.03 | 0.01  (5.7x) | 0.00  (1.8x) | 0.00  (4.8x) |  True |
|  60000 |     0.06 | 0.01  (7.9x) | 0.01  (1.4x) | 0.00  (4.8x) |  True |
|  80000 |     0.11 | 0.01  (9.4x) | 0.01  (1.3x) | 0.00  (4.6x) |  True |
| 100000 |     0.16 | 0.01 (11.6x) | 0.01  (1.1x) | 0.00  (4.5x) |  True |
| 120000 |     0.23 | 0.02 (11.8x) | 0.02  (1.2x) | 0.00  (4.7x) |  True |
| 140000 |     0.32 | 0.02 (14.7x) | 0.02  (1.1x) | 0.00  (4.1x) |  True |
| 160000 |     0.40 | 0.03 (13.1x) | 0.03  (1.2x) | 0.01  (4.6x) |  True |
| 180000 |     0.51 | 0.03 (14.7x) | 0.03  (1.1x) | 0.01  (4.4x) |  True |
| 200000 |     0.62 | 0.04 (16.6x) | 0.03  (1.1x) | 0.01  (4.4x) |  True |
| 220000 |     0.75 | 0.05 (16.1x) | 0.04  (1.1x) | 0.01  (4.9x) |  True |
| 240000 |     0.89 | 0.05 (17.1x) | 0.05  (1.0x) | 0.01  (4.7x) |  True |
| 260000 |     1.04 | 0.06 (18.1x) | 0.06  (1.0x) | 0.01  (4.5x) |  True |
| 280000 |     1.20 | 0.06 (20.2x) | 0.06  (1.0x) | 0.01  (4.2x) |  True |
| 300000 |     1.38 | 0.07 (19.4x) | 0.07  (1.1x) | 0.02  (4.4x) |  True |
+--------+----------+--------------+--------------+--------------+-------+
</code></pre>
</div></div><p>
На практике мы можем встретится с более сложной ситуацией, если последовательность чисел вместо известной рекуррентной формулы:
</p><img src="https://habrastorage.org/files/065/f5e/7c1/065f5e7c17e246cf9e2e5b6cfc150ec4.png"/>
<p>
Задаётся несколько усложнённой формулой, например, такой:
</p><img src="https://habrastorage.org/files/b80/179/c6d/b80179c6d7634c379dabf745265eba89.png"/>
<p>
В таком случае мы не сможем найти реализацию вышеописанных алгоритмов в Интернете, а на то, чтобы вручную придумать алгоритм с возведением матриц в степень, уйдёт существенное время. Тем не менее, мы можем написать решение «в лоб» и применить декоратор, тогда компьютер придумает быстрый алгоритм за нас:
</p><pre><code class="python">from cpmoptimize import cpmoptimize

@cpmoptimize()
def f(n):
    prev3 = 0
    prev2 = 1
    prev1 = 1
    for i in xrange(3, n + 3):
        cur = 7 * (2 * prev1 + 3 * prev2) + 4 * prev3 + 5 * i + 6
        prev3, prev2, prev1 = prev2, prev1, cur
    return prev3
</code></pre>
<h4>Пример №3. Сумма геометрической прогрессии</h4><p>
Пусть нам необходимо вычислить сумму </p><i>count</i><p> членов геометрической прогрессии, для которой задан первый член </p><i>start</i><p> и знаменатель </p><i>coeff</i><p>. В данной задаче декоратор снова способен оптимизировать наше тривиальное решение:
</p><pre><code class="python">from cpmoptimize import cpmoptimize

@cpmoptimize()
def geom_sum(start, coeff, count):
    res = 0
    elem = start
    for i in xrange(count):
        res += elem
        elem *= coeff
    return res
</code></pre>

<h4>Пример №4. Возведение в степень</h4><p>
Пусть нам необходимо возвести число </p><i>a</i><p> в неотрицательную целую степень </p><i>n</i><p>. В такой задаче декоратор фактически будет заменять тривиальное решение на алгоритм </p><a href="http://e-maxx.ru/algo/binary_pow">бинарного возведения в степень</a><p>:
</p><pre><code class="python">from cpmoptimize import cpmoptimize

@cpmoptimize()
def power(a, n):
    res = 1
    for i in xrange(n):
        res *= a
    return res
</code></pre>

<h3>Ссылки для скачивания</h3><p>
Установить библиотеку можно с помощью </p><a href="https://pip.readthedocs.org/en/latest/">pip</a><p>:
</p><pre><code class="bash">sudo pip install cpmoptimize</code></pre><p>
Исходный код библиотеки с примерами доступен на </p><a href="http://goo.gl/cMi97F">github</a><p> под свободной лицензией MIT.

</p><b>UPD.</b><p> Пакет </p><a href="https://pypi.python.org/pypi/cpmoptimize">опубликован</a><p> в Python Package Index.
</p><p>
Примеры применения оптимизации находятся в папке "</p><i>tests/</i><p>". Каждый пример состоит из функции, представляющей решение «в лоб», её оптимизированного варианта, а также функций, представляющих известные сложные, но быстрые решения данной задачи. Эти функции помещены в скрипты, которые запускают их на различных группах тестов, замеряют время их работы и строят соответствующие таблицы. Если установлена библиотека </p><a href="http://matplotlib.org/">matplotlib</a><p>, скрипты также будут строить графики зависимости времени работы функций от входных данных (обычные или логарифмические) и сохранять их в папку "</p><i>tests/plots/</i><p>".

</p><h3>Описание библиотеки</h3><p>
При создании библиотеки я воспользовался тем, что байт-код программы, который создаёт интерпретатор Python, на этапе выполнения можно анализировать и изменять без вмешательства в интерпретатор, что даёт широкие возможности по расширению языка (см., например, </p><a href="http://habrahabr.ru/post/140356/">реализация конструкции goto</a><p>). Преимущества описываемого метода обычно проявляются при использовании длинной арифметики, которая также встроена в Python. 
</p><p>
По этим причинам реализация описываемой оптимизации в Python стала для меня более интересной задачей, хотя, конечно, её применение в компиляторах C++ позволило бы создавать ещё более быстрые программы. К тому же, оптимизированный декоратором код на Python, как правило, обгоняет код «в лоб» на C++ благодаря более хорошей асимптотике.
</p><p>
При модификации байт-кода я использовал модуль </p><a href="https://pypi.python.org/pypi/byteplay/0.2">byteplay</a><p>, предоставляющий удобный интерфейс для дизассемблирования и ассемблирования байт-кода. К сожалению, модуль ещё не был портирован на Python 3, поэтому весь проект я реализовывал на Python 2.7.
</p><p>
Название библиотеки </p><i><strong>cpmoptimize</strong></i><p> является сокращением от слов </p><i>"<b>c</b>ompute the <b>p</b>ower of a <b>m</b>atrix and <b>optimize</b>"</i><p>. Объём статьи не позволяет подробно рассказать о процессе анализа и модификации байт-кода, однако я постараюсь подробно описать, какие возможности предоставляет данная библиотека и на каких принципах основана её работа.

</p><h4>Собственный xrange</h4><p>
cpmoptimize.</p><strong>xrange</strong><p>(</p><i>stop</i><p>)</p><p>
cpmoptimize.</p><strong>xrange</strong><p>(</p><i>start</i><p>, </p><i>stop</i><p>[, </p><i>step</i><p>])
</p><p>
Встроенный тип </p><i>xrange</i><p> в Python 2 в целях оптимизации не поддерживает длинные целые типа </p><i>long</i><p> в качестве аргументов:
</p><pre><code class="python">&gt;&gt;&gt; xrange(10 ** 1000)
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
OverflowError: Python int too large to convert to C long
</code></pre><p>
Так как при использовании нашей библиотеки циклы с количеством операций порядка </p><img src="https://habrastorage.org/files/8e7/a78/0ab/8e7a780ab22341d395aef9274df89a98.png"/><p> могут выполняться менее, чем за секунду, и стать в программе обычным делом, библиотека предоставляет собственную реализацию типа </p><i>xrange</i><p> на чистом Python (внутри библиотеки она называется </p><i>CPMRange</i><p>). Она поддерживает все возможности обычного </p><i>xrange</i><p> и, кроме того, аргументы типа </p><i>long</i><p>. Такой код не приведёт к ошибкам и быстро вычислит правильный результат:
</p><pre><code class="python">from cpmoptimize import cpmoptimize, xrange

@cpmoptimize()
def f():
    res = 0
    for i in xrange(10 ** 1000):
        res += 3
    return res

print f()
</code></pre><p>
Тем не менее, если в вашем случае количество итераций в циклах невелико, вы можете продолжать использовать вместе с декоратором встроенный </p><i>xrange</i><p>.

</p><h4>Функция cpmoptimize</h4><p>
cpmoptimize.</p><strong>cpmoptimize</strong><p>(</p><i>strict</i><p>=False, </p><i>iters_limit</i><p>=5000, </p><i>types</i><p>=(int, long), </p><i>opt_min_rows</i><p>=True, </p><i>opt_clear_stack</i><p>=True)

</p><h5>Применение декоратора</h5><p>
Функция </p><i>cpmoptimize</i><p> принимает параметры производимой оптимизации и возвращает декоратор, учитывающий эти параметры, который и нужно применить к оптимизируемой функции. Это можно сделать, используя специальный синтаксис (с символом «собака») или без него:
</p><pre><code class="python">from cpmoptimize import cpmoptimize

@cpmoptimize()
def f(n):
    # Некоторый код

def naive_g(n):
    # Некоторый код

smart_g = cpmoptimize()(naive_g)
</code></pre><p>
Перед внесением изменений в байт-код исходная функция копируется. Таким образом, в коде выше функции </p><i>f</i><p> и </p><i>smart_g</i><p> в итоге окажутся оптимизированными, а </p><i>naive_g</i><p> — нет.

</p><h5>Поиск циклов for</h5><p>
Декоратор ищет в байт-коде функции стандартные циклы </p><i>for</i><p>, при этом циклы </p><i>while</i><p> и циклы </p><i>for</i><p> внутри генераторных и списковых выражений игнорируются. Вложенные циклы пока не поддерживаются (оптимизируется только самый внутренний цикл). Корректно обрабатываются конструкции </p><i>for-else</i><p>.

</p><h5>Допустимые типы</h5><p>
Декоратор не может оптимизировать цикл независимо от того, какие типы переменных используются в нём. Дело в том, что, например, Python позволяет определить тип, который при каждом умножении записывает строку в файл. В результате применения оптимизации количество сделанных в функции умножений могло бы измениться. Из-за этого количество строк в файле стало бы другим и оптимизация бы сломала программу.
</p><p>
Кроме того, при операциях с матрицами переменные складываются и умножаются неявным образом, потому типы переменных могут «перемешиваться». Если одна из констант или переменных имела бы тип </p><i>float</i><p>, те переменные, которые должны были бы после выполнения кода иметь тип </p><i>int</i><p>, могли бы тоже получить тип </p><i>float</i><p> (так как сложение </p><i>int</i><p> и </p><i>float</i><p> возвращает </p><i>float</i><p>). Такое поведение может вызвать ошибки в программе и также неприемлемо.
</p><p>
Чтобы избежать нежелательных побочных эффектов, декоратор оптимизирует цикл, только если все константы и переменные, используемые в нём, имеют </p><i>допустимый</i><p> тип. Изначально допустимыми типами являются </p><i>int</i><p> и </p><i>long</i><p>, а также унаследованные от них типы. Если одна из констант или переменных имеет тип </p><i>long</i><p>, те переменные, которые должны были бы после выполнения кода иметь тип </p><i>int</i><p>, могут тоже получить тип </p><i>long</i><p>. Однако, так как </p><i>int</i><p> и </p><i>long</i><p> в Python в достаточной степени взаимозаменяемы, это не должно приводить к ошибкам.
</p><p>
В случае, если вы хотите изменить набор допустимых типов (например, чтобы добавить поддержку </p><i>float</i><p>), вы должны передать кортеж из нужных типов в параметре </p><i><strong>types</strong></i><p>. Типы, входящие в этот кортеж или унаследованные от типов, входящих в этот кортеж, будут считаться допустимыми. На деле проверка того, что какое-либо значение </p><i>value</i><p> имеет допустимый тип, будет осуществляться с помощью выражения </p><i>isinstance(value, types)</i><p>.

</p><h5>Условия оптимизации цикла</h5><p>
Каждый найденный цикл должен удовлетворять ряду условий. Часть из них проверяется уже при применении декоратора:
</p><ol>
<li>Тело цикла должно состоять только из инструкций присваивания, унарных и бинарных операций, которые могут быть скомпонованы в сложные выражения. Оно не может содержать условий, вызовов других функций, операторов <i>return</i> и <i>yield</i> и т. д..</li>
<li>От операндов может требоваться условие <i>предсказуемости</i>: на каждой итерации цикла их значение должно быть одним и тем же, причём оно не должно зависеть от результатов каких-либо вычислений на предыдущей итерации. При этом:<br/>
<ul>
<li>Все операнды сложения и вычитания, а также операнд унарного минуса могут быть непредсказуемыми.</li>
<li>Хотя бы один операнд умножения должен быть предсказуем (аналогично тому, что в оригинальном интерпретаторе поддерживалось только умножение на константу).</li>
<li>Все операнды возведения в степень, операций деления и взятия остатка и побитовых операций должны быть предсказуемы.</li>
</ul></li>
<li>Все константы, используемые в цикле, должны иметь допустимый тип.</li>
</ol><p>
Если эти условия выполняются, перед циклом устанавливается «ловушка», которая проверит другую часть условий, при этом оригинальный байт-код цикла не удаляется. Так как в Python используется динамическая типизация, следующие условия могут быть проверены только непосредственно перед запуском цикла:
</p><ol>
<li>Объект, по которому проходится цикл, должен иметь стандартный тип <i>xrange</i> или его аналог из данной библиотеки <i>cpmoptimize.xrange</i>. При этом медленная функция <i>range</i>, возвращающая список, не поддерживается.</li>
<li>Значения всех переменных, используемых в цикле, имеют допустимый тип.</li>
</ol><p>
Если «ловушка» заключила, что оптимизация приемлема, будут рассчитаны необходимые матрицы, а затем значения используемых переменных изменятся на новые. Если оптимизацию выполнить нельзя, будет запущен оригинальный байт-код цикла.

</p><h5>Выражения и вынос кода за цикл</h5><p>
Несмотря на то, что описываемый метод не поддерживает операции возведения в степень и «побитового И», следующий код будет оптимизирован:
</p><pre><code class="python">@cpmoptimize()
def f(n, k):
    res = 0
    for i in xrange(n):
        m = 3
        res += ((k ** m) &amp; 676) + i
    return res
</code></pre><p>
При анализе байт-кода декоратор сделает вывод, что значения переменных </p><i>k</i><p> и </p><i>m</i><p> в выражении </p><i>(k ** m) &amp; 676</i><p> не зависят от того, на какой итерации цикла они используются, а значит не изменяется и значение всего выражения. Вычислять его на каждой итерации не нужно, достаточно вычислить это значение один раз. Поэтому соответствующие инструкции байт-кода можно вынести и исполнять их непосредственно перед запуском цикла, подставляя в цикле уже готовое значение. Код будет будто преобразован к следующему:
</p><pre><code class="python">@cpmoptimize()
def f(n, k):
    res = 0
    m = 3
    _const1 = (k ** m) &amp; 676
    for i in xrange(n):
        res += _const1 + i
    return res
</code></pre><p>
Такая техника известна как </p><i>вынос инвариантного кода за цикл</i><p> (</p><strong><i>loop-invariant code motion</i></strong><p>). Обратите внимание, что вынесенные значения вычисляются каждый раз при запуске функции, так как они могут зависеть от меняющихся глобальных переменных или параметров функции (как </p><i>_const1</i><p> в примере зависит от параметра </p><i>k</i><p>). Получившийся код теперь легко оптимизировать с помощью матриц.
</p><p>
Именно на этом этапе выполняется описанная выше проверка предсказуемости величин. Например, если бы один из операндов «побитового И» оказался бы непредсказуемым, эту операцию уже нельзя было бы вынести за цикл и оптимизация не могла бы быть применена.
</p><p>
Декоратор также частично поддерживает множественные присваивания. Если в них мало элементов, Python создаёт поддерживаемый декоратором байт-код без использования кортежей:
</p><pre><code class="python">a, b = b, a + b
</code></pre>
<h5>Порог iters_limit</h5><p>
На графиках выше вы могли заметить, что при малом количестве итераций оптимизированный цикл может работать медленнее обычного, так как в таком случае всё равно требуется определённое время на конструирование матриц и проверку типов. В случаях, когда необходимо, чтобы функция работала как можно быстрее и при маленьком количестве итераций, можно явно задать порог параметром </p><i><strong>iters_limit</strong></i><p>. Тогда «ловушка» перед запуском оптимизации проверит, сколько итераций предстоит выполнить циклу, и отменит оптимизацию, если это число не превышает заданный порог.
</p><p>
Изначально порог установлен в 5000 итераций. Его нельзя установить ниже, чем в 2 итерации.
</p><p>
Понятно, что наиболее выгодным значением порога является точка пересечения на графике линий, соответствующих времени работы оптимизированного и исходного вариантов функции. Если установить порог именно таким, функция сможет выбирать наиболее быстрый в данном случае алгоритм (оптимизированный или исходный):

</p>
<h5>Флаг strict</h5><p>
В некоторых случаях оптимизация должна быть обязательна применена. Так, если в цикле </p><img src="https://habrastorage.org/files/8e7/a78/0ab/8e7a780ab22341d395aef9274df89a98.png"/><p> итераций, без оптимизации программа попросту зависнет. На этот случай предусмотрен параметр </p><i><strong>strict</strong></i><p>. Изначально его значение равно </p><i>False</i><p>, но если его установить в </p><i>True</i><p>, то в случае, когда какой-либо из стандартных циклов </p><i>for</i><p> не был оптимизирован, будет возбуждено исключение.
</p><p>
Если то, что оптимизация неприменима, было обнаружено на этапе применения декоратора, сразу будет возбуждено исключение </p><i>cpmoptimize.recompiler.RecompilationError</i><p>. В примере в цикле умножаются две непредсказуемые переменные:
</p><pre><code class="python">&gt;&gt;&gt; from cpmoptimize import cpmoptimize
&gt;&gt;&gt;
&gt;&gt;&gt; @cpmoptimize(strict=True)
... def f(n, k):
...     res = 0
...     for i in xrange(n):
...         res += i * res
...     return res
... 
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
  File "cpmoptimize/__init__.py", line 100, in upgrade_func
    index += analyze_loop(settings, code, index) + 1
  File "cpmoptimize/__init__.py", line 59, in analyze_loop
    raise err
cpmoptimize.recompiler.RecompileError: Multiplication of two unpredictable values is unsupported
</code></pre><p>
Если то, что оптимизация неприменима, было обнаружено перед выполнением цикла (то есть если оказалось, что типы значений итератора или переменных не поддерживаются), будет возбуждено исключение </p><i>TypeError</i><p>:
</p><pre><code class="python">&gt;&gt;&gt; from cpmoptimize import cpmoptimize
&gt;&gt;&gt;
&gt;&gt;&gt; @cpmoptimize(strict=True)
... def f(iterable):
...     res = 0
...     for elem in iterable:
...         res += elem
...     return res
... 
&gt;&gt;&gt; f(xrange(30))
435
&gt;&gt;&gt; f(range(30))
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
  File "&lt;stdin&gt;", line 4, in f
  File "cpmoptimize/hook.py", line 170, in exec_loop
    raise err
TypeError: Iterator in optimized loops must have type "xrange" instead of &lt;type 'list'&gt;
</code></pre>
<h5>Опции дополнительной оптимизации</h5><p>
Два флага </p><i>opt_min_rows</i><p> и </p><i>opt_clear_stack</i><p> отвечают за использование дополнительных методов оптимизации при конструировании матриц. Изначально они включены, возможность их отключения присутствует только в демонстрационных целях (благодаря ей можно сравнивать эффективность этих методов).
</p><p>
При выполнении оптимизированного кода большую часть времени занимает перемножение длинных чисел в некоторых ячейках генерируемых матриц. Сравнительно с этим трудоёмким процессом время, расходуемое на перемножение всех остальных ячеек, пренебрежимо мало.
</p><p>
В процессе перекомпиляции выражений декоратор создаёт промежуточные, </p><i>виртуальные</i><p> переменные, отвечающие за позиции стека интерпретатора. После сложных вычислений в них могут оставаться длинные числа, которые уже сохранены в каких-то других, реальных переменных. Хранить эти значения второй раз нам уже не нужно, однако они остаются в ячейках матрицы и существенно тормозят работу программы, так как при умножении матриц мы вынуждены лишний раз перемножать эти длинные числа. Опция </p><i><strong>opt_clear_stack</strong></i><p> отвечает за очистку таких переменных: если по окончании их использования присваивать им ноль, длинные значения в них исчезнут.
</p><p>
Эта опция особенно эффективна, когда программа оперирует очень большими числами. Исключение лишних перемножений таких чисел позволяет ускорить программу более, чем в два раза.
</p><p>
Опция </p><i><strong>opt_min_rows</strong></i><p> включает минимизацию размера квадратных матриц, которые мы перемножаем. Из матриц исключаются ряды, соответствующие неиспользуемым и предсказуемым переменным. Если не используется сама переменная цикла, исключаются и ряды, отвечающие за поддержание её правильного значения. Чтобы не нарушить работу программы, после цикла всем этим переменным будут присвоены правильные конечные значения. Кроме того, в оригинальной статье вектор переменных дополнялся элементом, равным единице. Если ряд, соответствующий этому элементу, окажется неиспользуемым, он тоже будет исключён.
</p><p>
Эта опция может несколько ускорить программу для не очень больших </p><i>n</i><p>, когда числа ещё не стали очень длинными и размеры матрицы вносят ощутимый вклад во время работы программы.
</p><p>
Если применять обе опции одновременно, то виртуальные переменные начинают иметь предсказуемое (нулевое) значение, и </p><i>opt_min_rows</i><p> работает ещё эффективнее. Другими словами, эффективность обоих опций вместе больше, чем эффективность каждой из них по отдельности.
</p><p>
График ниже демонстрирует время работы программы для вычисления чисел Фибоначчи при отключении тех или иных опций (здесь "-m" — программа с отключённой </p><i>opt_min_rows</i><p>, "-c" — программа с отключённой </p><i>opt_clear_stack</i><p>, "-mc" — программа, где отключены обе опции сразу):

</p>
<h3>Что ещё можно реализовать?</h3>
<h4>Изменение набора операций</h4><p>
Будем говорить, что наш метод </p><i>поддерживает пару операций</i> <img src="https://habrastorage.org/files/5a3/ad8/0bf/5a3ad80bf17d436fa9adeacbf4318757.png"/><p>, если:
</p><ul>
<li>Мы можем выполнять операцию <img src="https://habrastorage.org/files/f81/b36/71e/f81b3671e9ba47249e0660d62d19366e.png"/> для двух переменных либо для переменной и константы;</li>
<li>Мы можем выполнять операцию <img src="https://habrastorage.org/files/2bd/0fd/f4a/2bd0fdf4a53e4bd0ade81dc4b4c809f0.png"/> для переменной и константы.</li>
</ul><p>
Нам уже известно, что метод поддерживает пару операций </p><img src="https://habrastorage.org/files/83b/7e7/bf7/83b7e7bf76cc4f118f88efe7fbd45764.png"/><p>. Действительно:
</p><ul>
<li>Мы можем складывать две переменные либо переменную и константу;</li>
<li>Мы можем умножать переменную на константу.</li>
</ul><p>
Именно эти операции на данный момент реализованы в оптимизирующем декораторе. Однако, оказывается, что описываемый метод поддерживает и другие пары операций, в том числе </p><img src="https://habrastorage.org/files/0f1/3f2/fb0/0f13f2fb0cb74cf4a22e826e5d0f67fc.png"/><p> (пару из умножения и операции возведения в степень).
</p><p>
Например, наша задача может состоять в том, чтобы найти </p><i>n</i><p>-е число в последовательности, задаваемой рекуррентным соотношением:
</p><img src="https://habrastorage.org/files/f2f/2de/b0e/f2f2deb0e62444298562020803616c4a.png"/>
<p>
Если бы наш декоратор поддерживал пару операций </p><img src="https://habrastorage.org/files/0f1/3f2/fb0/0f13f2fb0cb74cf4a22e826e5d0f67fc.png"/><p>, мы могли бы умножать переменную на другую переменную (но уже не могли бы складывать переменные). В таком случае следующее тривиальное решение этой задачи могло бы быть ускорено декоратором:
</p><pre><code class="python">def f(n):
    a = 1
    b = 1
    for i in xrange(n):
        a, b = b, a * b
    return a
</code></pre><p>
Можно доказать, что наш метод также поддерживает пары операций </p><img src="https://habrastorage.org/files/72d/97e/717/72d97e717cdc4cc4b6e24d7cdb525385.png"/><p>, </p><img src="https://habrastorage.org/files/a7b/a71/1ab/a7ba711ab305458ba7b9b6b13cda0cdf.png"/><p> и </p><img src="https://habrastorage.org/files/6e1/67b/9c1/6e167b9c1cd64219aaecdd4dafba1fb7.png"/><p> (здесь </p><i>and</i><p> — побитовое И, </p><i>or</i><p> — побитовое ИЛИ). В случае положительных чисел можно работать и с парами операций </p><img src="https://habrastorage.org/files/51c/033/b45/51c033b45c8b46a5869cf1745e7e38b6.png"/><p> и </p><img src="https://habrastorage.org/files/642/a2e/40f/642a2e40f6c5442c8276bef1960bd7b2.png"/><p>.
</p><p>
Для реализации поддержки операций </p><img src="https://habrastorage.org/files/0f1/3f2/fb0/0f13f2fb0cb74cf4a22e826e5d0f67fc.png"/><p> можно, например, оперировать не значениями переменных, а логарифмами этих значений. Тогда умножение переменных заменится сложением логарифмов, а возведение переменной в константную степень — умножением логарифма на константу. Таким образом мы сведём задачу к уже реализованному случаю с операциями </p><img src="https://habrastorage.org/files/83b/7e7/bf7/83b7e7bf76cc4f118f88efe7fbd45764.png"/><p>.
</p><p>
Объяснение того, как реализовать поддержку остальных указанных пар операций, содержит некоторое количество математичеких выкладок и достойно отдельной статьи. На данный момент лишь стоит упомянуть, что пары операции в определённой мере взаимозаменяемы.

</p><h4>Вложенные циклы</h4><p>
Доработав алгоритм анализа циклов в байт-коде, можно реализовать поддержку вложенных циклов, чтобы оптимизировать код, подобный такому:
</p><pre><code class="python">def f():
    res = 0
    for i in xrange(10 ** 50):
        for j in xrange(10 ** 100):
            res += i * 2 + j
    return res
</code></pre>
<h4>Предсказуемые условия</h4><p>
В следующем коде условие в теле цикла является предсказуемым. Можно ещё перед запуском цикла выяснить, истинно ли оно, и убрать невыполняющуюся ветку кода. Получившийся после этого код можно будет оптимизировать:
</p><pre><code class="python">def f(mode):
    res = 0
    for i in xrange(10 ** 50):
        if mode == 1:
            res += 3
        else:
            res += 5
    return res
</code></pre>
<h3>Выводы</h3><p>
Интерпретатор Python, вообще говоря, создаёт предсказуемый байт-код, который почти в точности соответствует тому исходному коду, который вы написали. Стандартно он не производит ни встраивания функций, ни разворачивания циклов, ни каких-либо других оптимизаций, требующих анализа поведения программы. Только с версии 2.6 CPython научился сворачивать константные арифметические выражения, но и эта возможность работает не всегда эффективно.
</p><p>
У этой ситуации есть несколько причин. Во-первых, анализ кода в общем случае в Python затруднителен, ведь проследить за типами данных можно только во время выполнения программы (что мы и делаем в нашем случае). Во-вторых, оптимизации, как правило, всё равно не позволяют Python достичь скорости чисто компилируемых языков, поэтому в случае, когда программе нужно работать очень быстро, предлагается просто писать её на более низкоуровневом языке.
</p><p>
Тем не менее, Python — гибкий язык, позволяющий при необходимости реализовать многие методы оптимизации самостоятельно без вмешательства в интерпретатор. Данная библиотека, а также другие проекты, перечисленные ниже, хорошо это иллюстрируют эту возможность.

</p><b>UPD.</b><p> Описание проекта теперь также доступно в виде </p><a href="http://www.slideshare.net/hx0/cpmoptimize">презентации</a><p> на SlideShare.

</p><h3>Смотрите также</h3><p>
Ниже я приведу ссылки на несколько других интересных проектов по ускорению выполнения программ на Python:
</p><ol>
<li><a href="http://pypy.org/">PyPy</a> — альтернативный интерпретатор Python с поддержкой <a href="https://ru.wikipedia.org/wiki/JIT-%D0%BA%D0%BE%D0%BC%D0%BF%D0%B8%D0%BB%D1%8F%D1%86%D0%B8%D1%8F">JIT-компиляции</a>, позволяющий, как правило, выполнять программы на Python существенно быстрее. Сам PyPy написан на языке RPython, для которого специально разработан транслятор в код на языке C.</li>
<li><a href="http://www.opennet.ru/opennews/art.shtml?num=40571">Pyston</a> — новый альтернативный интерпретатор Python, транслирующий код в промежуточное представление <a href="https://ru.wikipedia.org/wiki/Low_Level_Virtual_Machine">LLVM</a>, из которого он может быть оптимизирован средствами LLVM и выполнен с использованием JIT-компиляции.</li>
<li><a href="http://nuitka.net/">Nuitka</a> — компилятор Python. В отличие от упаковщика py2exe, который создаёт *.exe-файл, содержащий скрипт, интерпретатор и необходимые библиотеки, Nuitka действительно компилирует программы на Python в готовые исполняемые файлы.</li>
<li><a href="https://code.google.com/p/wpython2/">WPython</a> — модифицированный интерпретатор CPython 2.6.4 с более эффективной моделью байт-кода, умной системой сворачивания констант и переработанной виртуальной машиной.</li>
<li><a href="https://bitbucket.org/haypo/astoptimizer">astoptimizer</a> — библиотека, применяющая известные методы оптимизации перед компиляцией в байт-код путём анализа и изменения <a href="https://ru.wikipedia.org/wiki/%D0%90%D0%B1%D1%81%D1%82%D1%80%D0%B0%D0%BA%D1%82%D0%BD%D0%BE%D0%B5_%D1%81%D0%B8%D0%BD%D1%82%D0%B0%D0%BA%D1%81%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%BE%D0%B5_%D0%B4%D0%B5%D1%80%D0%B5%D0%B2%D0%BE">абстрактного синтаксического дерева</a>.</li>
<li><a href="https://pypi.python.org/pypi/promise/">promise</a> — библиотека, оптимизирующая байт-код, полагаясь на так называемые «обещания». Если программист обещает не делать определённого рода операций в своём коде, становится возможным применить те оптимизации, которые в общем случае применить было нельзя.</li>
<li><a href="http://forums.synapse-wireless.com/showthread.php?t=4655">foldy.py</a> — библиотека, анализирующая байт-код и выполняющая <i>сворачивание констант</i> (<i><strong>constant folding</strong></i>), то есть замену константных выражений на их значения, а также удаление неиспользуемых функций.</li>
<li><a href="http://code.activestate.com/recipes/277940-decorator-for-bindingconstants-at-compile-time/">Декоратор</a>, анализирующий байт-код и выполняющий <i>встраивание констант</i> (<i><strong>constant binding</strong></i>), то есть заменяющий поиск значения постоянной глобальной переменной по её имени на непосредственную загрузку соответствующей константы.</li>
</ol>
<b>UPD #1.</b><p> Пользователь </p><a href="https://habrahabr.ru/users/magik/" class="user_link">magik</a><p> предложил ещё несколько ссылок:
</p><ul>
<li><a href="http://www.numpy.org/">NumPy</a> — библиотека (с модулями для Python, написанными на Си), способная быстро производить вычисления с большими массивами и матрицами, а также использовать обширный набор высокоуровневых математических функций.</li>
<li><a href="http://numba.pydata.org/">Numba</a> — библиотека, ускоряющая программы, содержащие математические вычисления и операции с массивами. Оптимизация происходит за счёт JIT-компиляции (при использовании LLVM), которая преобразует код в родные инструкции CPU и GPU, а также за счёт некоторых других классических методов.</li>
<li><a href="https://github.com/pydata/numexpr">Numexpr</a> — библиотека, ускоряющая вычисления математических выражений через анализ и изменение соответствующего байт-кода. Выражения могут разбиваться на несколько частей, некоторые из которых могут пересчитываться реже, чем остальные, ускоряться за счёт распараллеливания кода и т. д..</li>
<li><a href="http://cython.org/">Cython</a> — оптимизирующий компилятор надмножества языка Python, позволяющий использовать в программе статическую типизацию и тесно взаимодействовать с кодом на C и C++.</li>
<li><a href="http://www.phi-node.com/2013/01/just-in-time-compilers-for-number.html">Статья с обзором</a> библиотек, позволяющих ускорить разнообразные вычисления в Python за счёт JIT-компиляции.</li>
</ul>
<b>UPD #2.</b><p> Пользователь </p><a href="https://habrahabr.ru/users/dunerat/" class="user_link">DuneRat</a><p> указал на ещё несколько проектов по компиляции Python: </p><a href="https://code.google.com/p/shedskin/">shedskin</a><p>, </p><a href="https://github.com/cosmo-ethz/hope">hope</a><p>, </p><a href="https://github.com/serge-sans-paille/pythran">pythran</a><p>.

      
      </p><p class="clear"/>
    </div>

    
  </div></body></html>