<html><body><div><div class="content html_format"><p>
      Всем привет! Меня зовут Сергей, и в Яндексе я работаю в команде автоматизации тестирования сервисов монетизации. Перед каждой командой, которая занимается задачами автоматизации тестирования, встает вопрос: «Какой [фреймворк|инструмент] выбрать для написания своих тестов?» В этом посте я хочу помочь вам на него ответить. Если быть конкретнее, речь пойдет об инструментах тестирования на языке Python, но многие из идей и выводов можно распространить на другие языки программирования, поскольку подходы часто не зависят от конкретной технологии.</p>

<a href="http://habrahabr.ru/company/yandex/blog/242795/"><img src="https://habrastorage.org/files/54e/5d1/310/54e5d1310790471ca78a084c7b15879a.png"/></a>
<p>
В Python существует множество инструментов для написания тестов и выбор между ними неочевиден. Я опишу интересные варианты использования PyTest и расскажу о его [плюсах|минусах|неявных возможностях]. В статье вы найдёте развёрнутый пример использования </p><a href="http://habrahabr.ru/company/yandex/blog/232697/">Allure</a><p>, который служит для создания простых и понятных отчётов автотестов. Также в примерах будет применяться фреймворк для написания матчеров — </p><a href="http://hamcrest.org/">Hamcrest</a><p> для Python. Надеюсь, что в итоге, те, кто сейчас в поиске инструментов для тестирования, смогут на основе изложенных примеров быстро внедрить функциональное тестирование в своем окружении. Те же, кто уже использует какой-то инструмент, смогут узнать новые подходы, варианты использования и концепции.
</p><a name="habracut"/><p>
Исторически так сложилось, что в нашем проекте обитает целый зоопарк технологий со сложными схемами взаимодействий друг с другом. При этом их API и функциональность только растут, так что нужно реализовывать интеграционные тесты.
</p><p>
Нам как автоматизаторам для налаживания оптимального процесса тестирования необходим максимально удобный и гибкий инструмент для написания тестов. Python был выбран потому, что он прост в освоении, код на нём, как правило, легко читается, и, что самое важное, — у него есть богатая стандартная библиотека и масса пакетов расширений.
</p><p>
Посмотрев же на список инструментов для функционального тестирования, невольно впадаешь в ступор и задумываешься о том, какой инструмент все-таки выбрать, чтобы быстро писать тесты, не иметь проблем с их поддержкой и легко обучать работе с ним новых сотрудников.
</p><p>
В своё время была возможность поэкспериментировать, и выбор пал на перспективный фреймворк PyTest. Тогда он ещё не был таким популярным, и его мало кто использовал. Нам понравилась концепция использования фикстур и написание тестов в виде обычного Python-модуля без использования API. В итоге PyTest выстрелил, и теперь мы имеем очень гибкое решение с множеством фич, например:

</p><ul>
<li>фикстуры в виде аргументов тестовых функций, которые позволяют отделить вспомогательную функциональность от самого теста;</li>
<li>встроенный assert, который отображает ошибку в удобном виде;</li>
<li>pytest.mark.parametrize для запуска тестов на разных наборах данных без дублирования кода;</li>
<li>возможность ставить метки на тесты, чтобы помечать падающие тесты или выделять долгоиграющие и запускать их отдельно;</li>
<li>поддержка JUnit отчетов с помощью аргумента --junit-xml, кроме этого способность генерировать отчеты в другом формате.</li>
</ul><p>
Теперь более подробно поговорим о том, как в PyTest работают фикстуры, параметризация, маркировка. Как с помощью PyHamcrest фреймворка писать свои матчеры и создавать результирующие отчеты, используя Allure.

</p><h3>Написание тестов</h3>
<h4>Фикстуры</h4><p>
В общепринятом смысле, </p><a href="http://en.wikipedia.org/wiki/Test_fixture#Software">фикстура</a><p> — это фиксированное состояние стенда, на котором выполняются тесты. Это так же относится к действию, приводящему систему в определенное состояние.
</p><p>
В </p><b>pytest</b><p> фикстурой называют функцию, обёрнутую в декоратор </p><code>@pytest.fixture.</code><p> Сама функция выполняется в тот момент, когда она нужна (перед тестовым классом, модулем или функцией) и когда возвращенное ей значение доступно в самом тесте. При этом фикстуры могут использовать другие фикстуры, кроме того можно определять время существования конкретной фикстуры: в текущей сессии, модуле, классе или функции. Они помогают нам содержать тесты в модульном виде. А при тестировании интеграции повторно использовать их из соседних тестовых библиотек. Гибкость и удобство их использования были одними из основных критериев выбора именно </p><b>pytest</b><p>. Чтобы воспользоваться фикстурой, нужно указать её имя в качестве параметра к тесту.
</p><p>
Фикстуры приходят на помощь, когда нужно:
</p><ul>
<li>сформировать тестируемые данные;</li>
<li>подготовить тестируемый стенд;</li>
<li>поменять поведение стенда;</li>
<li>написать <code>setUp/tearDown</code>;</li>
<li>собирать логи сервисов или <code>crashdump</code>;</li>
<li>использовать эмуляторы систем или заглушки;</li>
<li>и многое другое.</li>
</ul>
<h5>Тестируемый сервер</h5>
<p>
Далее в примерах будут описаны тесты, которые проверяют функционал веб-сервера на </p><a href="http://flask.pocoo.org">Flask</a><p>, ожидающий соединения на </p><code>8081</code><p> порту и принимающий </p><code>GET</code><p> запросы. Сервер берет строчку из параметра </p><code>text</code><p> и в ответе меняет каждое слово на его слово-перевертыш. Отдаётся json, если клиент умеет его принимать:

</p><pre><code class="python">import json
from flask import Flask, request, make_response as response

app = Flask(__name__)


@app.route("/")
def index():
    text = request.args.get('text')
    json_type = 'application/json'
    json_accepted = json_type in request.headers.get('Accept', '')
    if text:
        words = text.split()
        reversed_words = [word[::-1] for word in words]
        if json_accepted:
            res = response(json.dumps({'text': reversed_words}), 200)
        else:
            res = response(' '.join(reversed_words), 200)
    else:
        res = response('text not found', 501)
    res.headers['Content-Type'] = json_type if json_accepted else 'text/plain'
    return res

if __name__ == "__main__":
    app.run(host='0.0.0.0', port=8081)</code></pre>
<p>
Напишем тест для тестируемого сервера, который будет проверять его наличие на указанном порту. Проверим, что наш сервер существует. Для этого воспользуемся модулем socket. Создадим фикстуру, которая подготовит сокет и после окончания теста его закроет.

</p><pre><code class="python">import pytest
import socket as s


@pytest.fixture
def socket(request):
    _socket = s.socket(s.AF_INET, s.SOCK_STREAM)
    def socket_teardown():
        _socket.close()
    request.addfinalizer(socket_teardown)
    return _socket


def test_server_connect(socket):
    socket.connect(('localhost', 8081))
    assert socket</code></pre>
<p>
Но лучше воспользоваться новым декоратором </p><code>yield_fixture</code><p>, который представляет фикстуру в виде контекст-менеджера, реализующего </p><code>setUP/tearDown</code><p> и возвращающего объект.

</p><pre><code class="python">@pytest.yield_fixture
def socket():
    _socket = s.socket(s.AF_INET, s.SOCK_STREAM)
    yield _socket
    _socket.close()</code></pre>
<p>
Использование </p><code>yield_fixture</code><p> выглядит лаконичнее и понятнее. Надо отметить, что фикстуры по умолчанию имеют время существования </p><code>scope=function</code><p>. Это означает, что каждый запуск теста со своими параметрами вызывает новый экземпляр фикстуры.
</p><p>
Напишем для нашего теста фикстуру </p><code>Server</code><p>, описывающую, где находится тестируемый веб-сервер. Так как она возвращает объект, который хранит в себе статичную информацию, и нам не нужно генерировать это каждый раз, то поставим ей </p><code>scope=module</code><p>. Результат, который эта фикстура сгенерирует, закэшируется и будет существовать все время запуска текущего модуля:

</p><pre><code class="python">@pytest.fixture(scope='module')
def Server():
    class Dummy:
        host_port = 'localhost', 8081
        uri = 'http://%s:%s/' % host_port
    return Dummy


def test_server_connect(socket, Server):
    socket.connect(Server.host_port)
    assert socket</code></pre>
<p>
Также есть </p><code>scope=session</code><p> и </p><code>scope=class</code><p> — время существования фикстуры. И нельзя использовать внутри фикстуры с высоким уровнем фикстуры с более низким значением </p><code>scope=</code><p>.
</p><p>
Остерегайтесь использовать </p><code>autouse</code><p> фикстуры. Они опасны тем, что могут незаметно для вас изменить данные. Для гибкого их использования можно проверять наличие требуемой фикстуры для вызванного теста:

</p><pre><code class="python">@pytest.yield_fixture(scope='function', autouse=True)
def collect_logs(request):
    if 'Server' in request.fixturenames:
        with some_logfile_collector(SERVER_LOCATION):
            yield
    else:
        yield</code></pre>
<p>
Кроме всего прочего, можно указывать фикстуры на тестовые классы. В следующем примере есть класс, в котором тесты меняют время на тестовом стенде. Например, нам нужно, чтобы после каждого теста время обновлялось на текущее. В следующем примере фикстура </p><code>Service</code><p> возвращает объект тестируемого сервиса и имеет метод </p><code>set_time</code><p>, с помощью которого можно изменить дату и время:

</p><pre><code class="python">@pytest.yield_fixture
def reset_shifted_time(Service):
    yield
    Service.set_time(datetime.datetime.now())


@pytest.mark.usefixtures("reset_shifted_time")
class TestWithShiftedTime():
    def test_shift_milesecond(self, Service):
        Service.set_time()
        assert ...
    def test_shift_time_far_far_away(self, Service):
        Service.set_time()
        assert ...</code></pre>
<p>
Обычно небольшие фикстуры, специфичные для какой-либо ситуации, описываются внутри тестового модуля. Но если фикстура становится популярна среди многих тест-сьютов, то ее обычно выносят в специальный для </p><b>pytest</b><p> файл: </p><code>conftest.py</code><p>. После того, как фикстура описана в данном файле, она становится видимой для всех тестов, и не нужно делать </p><code>import</code><p>.

</p><h3>Матчеры</h3><p>
Очевидно, что тесты без проверок никому не нужны. При использовании </p><b>pytest</b><p> можно делать проверки самым простым способом — с помощью такого </p><a href="http://docs.oracle.com/javase/7/docs/api/java/util/regex/Matcher.html">матчера</a><p>, как </p><code>assert</code><p>. </p><a href="http://en.wikipedia.org/wiki/Assertion_(software_development)">Assert</a><p> — это стандартная инструкция в Python, которая проверяет утверждение, описанное в нем. Мы придерживаемся правила «В одном тесте — один </p><code>assert</code><p>». Оно позволяет тестировать определенную функциональность, не затрагивая шаги подготовки данных или приведение сервиса в нужное состояние. Если же в тесте используются шаги подготовки данных, которые могут вызвать ошибку, то лучше для них написать отдельный тест. Используя данную структуру, мы описываем ожидаемое поведение системы.
</p><p>
Если была обнаружена ошибка, то от теста требуется человекочитаемый отчет о запуске. И с недавних пор </p><b>pytest</b><p> стал поддерживать очень информативные </p><code>assert</code><p>-ы. Советую вам использовать их, пока не потребуется что-то более сложное.
</p><p>
Например, следующий тест:
</p><pre><code class="python">def test_dict():
    assert dict(foo='bar', baz=None).items() == list({'foo': 'bar'}.iteritems())</code></pre><p>
вернет развёрнутый ответ о том, где ошибка:
</p><pre><code class="python">E       assert [('foo', 'bar...('baz', None)] == [('foo', 'bar')]
E         Left contains more items, first extra item: ('baz', None)
</code></pre>
<p>
В тесте, проверяющем наш </p><i>Тестируемый сервер</i><p> на Flask, перепишем проверку внутри метода </p><code>test_server_connect</code><p> для более точного определения, что мы не ожидаем определенный </p><code>exception</code><p>. Для этого воспользуемся фреймворком </p><a href="https://github.com/hamcrest/PyHamcrest">PyHamcrest</a><p>:
</p><pre><code class="python">from hamcrest import *

SOCKET_ERROR = s.error

def test_server_connect(socket, Server):
    assert_that(calling(socket.connect).with_args(Server.host_port), is_not(raises(SOCKET_ERROR)))</code></pre>

<a href="http://en.wikipedia.org/wiki/Hamcrest">PyHamcrest</a><p> позволяет совмещать встроенные в него матчеры. Скомбинировав таким образом </p><code>has_property</code><p> и </p><code>contains_string,</code><p> получим удобные для использования простые матчеры:

</p><pre><code class="python">def has_content(item):
    return has_property('text', item if isinstance(item, BaseMatcher) else contains_string(item))

def has_status(status):
    return has_property('status_code', equal_to(status))</code></pre>
<p>
Далее нам потребуется написать матчеры, которые модифицируют проверяемое значение и передают его следующему указанному матчеру. Для этого напишем класс </p><code>BaseModifyMatcher</code><p>, формирующий такой матчер на основе атрибутов класса: </p><code>description</code><p> — описание матчера, </p><code>modify</code><p> — функция-модификатор проверяемого значения, </p><code>instance</code><p> — тип класса, который ожидается в модификаторе:

</p><pre><code class="python">from hamcrest.core.base_matcher import BaseMatcher


class BaseModifyMatcher(BaseMatcher):
    def __init__(self, item_matcher):
        self.item_matcher = item_matcher

    def _matches(self, item):
        if isinstance(item, self.instance) and item:
            self.new_item = self.modify(item)
            return self.item_matcher.matches(self.new_item)
        else:
            return False

    def describe_mismatch(self, item, mismatch_description):
        if isinstance(item, self.instance) and item:
            self.item_matcher.describe_mismatch(self.new_item, mismatch_description)
        else:
            mismatch_description.append_text('not %s, was: ' % self.instance) \
                                .append_text(repr(item))

    def describe_to(self, description):
        description.append_text(self.description) \
                   .append_text(' ') \
                   .append_description_of(self.item_matcher)</code></pre>
<p>
Мы знаем, что тестируемый сервер формирует ответ из перевернутых слов, переданных ему в параметре </p><code>text</code><p>. Используя </p><code>BaseModifyMatcher</code><p>, напишем матчер, который получит список из обычных слов и будет ожидать в ответе строчку из перевернутых слов:
</p><pre><code class="python">rom hamcrest.core.helpers.wrap_matcher import wrap_matcher

reverse_words = lambda words: [word[::-1] for word in words]


def contains_reversed_words(item_match):
    """
    Example:
        &gt;&gt;&gt; from hamcrest import *
        &gt;&gt;&gt; contains_reversed_words(contains_inanyorder('oof', 'rab')).matches("foo bar")
        True
    """
    class IsStringOfReversedWords(BaseModifyMatcher):
        description = 'string of reversed words'
        modify = lambda _, item: reverse_words(item.split())
        instance = basestring

    return IsStringOfReversedWords(wrap_matcher(item_match))</code></pre>
<p>
Следующий матчер, использующий </p><code>BaseModifyMatcher</code><p>, будет проверять наличие строчки содержащей json:

</p><pre><code class="python">import json as j

def is_json(item_match):
    """
    Example:
        &gt;&gt;&gt; from hamcrest import *
        &gt;&gt;&gt; is_json(has_entries('foo', contains('bar'))).matches('{"foo": ["bar"]}')
        True
    """
    class AsJson(BaseModifyMatcher):
        description = 'json with'
        modify = lambda _, item: j.loads(item)
        instance = basestring

    return AsJson(wrap_matcher(item_match))</code></pre>
<p>
Дополним тест, проверяющий наш </p><em>Тестируемый сервер</em><p> на Flask, ещё двумя тестами, которые будут проверяют, что формирует сервер в ответе при разных запросах. Для этого воспользуемся описанными выше матчерами </p><code>has_status</code><p>, </p><code>has_content</code><p> и </p><code>contains_reversed_words</code><p>:

</p><pre><code class="python">def test_server_response(Server):
    assert_that(requests.get(Server.uri), all_of(has_content('text not found'), has_status(501)))

def test_server_request(Server):
    text = 'Hello word!'
    assert_that(requests.get(Server.uri, params={'text': text}), all_of(
        has_content(contains_reversed_words(text.split())),
        has_status(200)
    ))</code></pre><p>
Про </p><em>Hamcrest</em><p> можно почитать на </p><a href="http://habrahabr.ru/company/yandex/blog/184634/">Хабре</a><p>. Ещё стоит обратить внимание на </p><a href="http://www.should-dsl.info/">should-dsl</a><p>.

</p><h3>Параметризация</h3>
<p>
Когда требуется запускать один и тот же тест с </p><a href="http://blogs.msdn.com/b/jledgard/archive/2003/11/03/53722.aspx">множеством разных параметров</a><p>, на помощь приходит </p><em>параметризация</em><p> тестовых данных. С помощью параметризации утилизируется повторяющийся код в тестах. Визуальное выделение списка параметров помогает повысить читаемость и дальнейшую поддержку. Фикстуры описывают систему, подготавливают её или приводят к требуемому состоянию. Параметризация же используется для формирования набора различных тестируемых параметров, описывающих тест-кейсы.
</p><p>
В </p><strong>PyTest</strong><p> параметризировать тесты нужно с помощью специального декоратора </p><code>@pytest.mark.parametrize</code><p>. Можно указать несколько параметров в одном </p><code>parametrize</code><p>. Если же параметры разбить на несколько </p><code>parametrize</code><p>, то они перемножаются.
</p><p>
Держать статические данные внутри теста — не очень хорошая практика. В примере теста который проверяет наш </p><em>Тестируемый сервер</em><p> на Flask, стоит параметризовать метод </p><code>test_server_request</code><p>, описав варианты параметра </p><code>text</code><p>:

</p><pre><code class="python">@pytest.mark.parametrize('text', ['Hello word!', ' 440 005 ', 'one_word'])
def test_server_request(text, Server):
    assert_that(requests.get(Server.uri, params={'text': text}), all_of(
        has_content(contains_reversed_words(text.split())),
        has_status(200)
    ))</code></pre><p>
Мы забыли проверять ответ </p><code>json</code><p>, если клиент его поддерживает. Перепишем тест, используя объекты вместо обычных параметров. Матчер будет меняться в зависимости от типа ответа. Советую давать более понятные названия матчерам:

</p><pre><code class="python">
class DefaultCase:
    def __init__(self, text):
        self.req = dict(
            params={'text': text},
            headers={},
        )
        self.match_string_of_reversed_words = all_of(
            has_content(contains_reversed_words(text.split())),
            has_status(200),
        )

class JSONCase(DefaultCase):
    def __init__(self, text):
        DefaultCase.__init__(self, text)
        self.req['headers'].update({'Accept': 'application/json'})

        self.match_string_of_reversed_words = all_of(
            has_content(is_json(has_entries('text', contains(*reverse_words(text.split()))))),
            has_status(200),
        )


@pytest.mark.parametrize('case', [testclazz(text)
                                  for text in 'Hello word!', ' 440 005 ', 'one_word'
                                  for testclazz in JSONCase, DefaultCase])
def test_server_request(case, Server):
    assert_that(requests.get(Server.uri, **case.req), case.match_string_of_reversed_words)

</code></pre>
<p>
Если запустить такой параметризованный тест с помощью команды </p><code>py.test -v test_server.py</code><p>, получим отчет:

</p><pre><code class="python">$ py.test -v test_server.py
============================= test session starts =============================
platform linux2 -- Python 2.7.3 -- py-1.4.20 -- pytest-2.5.2 -- /usr/bin/python
plugins: timeout, allure-adaptor
collected 8 items

test_server.py:26: test_server_connect PASSED
test_server.py:89: test_server_response PASSED
test_server.py:109: test_server_request[case0] PASSED
test_server.py:109: test_server_request[case1] PASSED
test_server.py:109: test_server_request[case2] PASSED
test_server.py:109: test_server_request[case3] PASSED
test_server.py:109: test_server_request[case4] PASSED
test_server.py:109: test_server_request[case5] PASSED

========================== 8 passed in 0.11 seconds ===========================</code></pre>
<p>
В таком отчете совершенно непонятно, какой параметр был использован в конкретном запуске.
</p><p>
Чтобы вывод был более понятным, нужно реализовать метод </p><code>__repr__</code><p> для класса </p><code>Case</code><p> и написать вспомогательный декоратор </p><code>idparametrize</code><p>, в котором воспользуемся дополнительным параметром </p><code>ids=</code><p> декоратора </p><code>pytest.mark.parametrize</code><p>:

</p><pre><code class="python">def idparametrize(name, values, fixture=False):
    return pytest.mark.parametrize(name, values, ids=map(repr, values), indirect=fixture)

class DefaultCase:
    def __init__(self, text):
        self.text = text
        self.req = dict(
            params={'text': self.text},
            headers={},
        )
        self.match_string_of_reversed_words = all_of(
            has_content(contains_reversed_words(self.text.split())),
            has_status(200),
        )

    def __repr__(self):
        return 'text="{text}", {cls}'.format(cls=self.__class__.__name__, text=self.text)

class JSONCase(DefaultCase):
    def __init__(self, text):
        DefaultCase.__init__(self, text)
        self.req['headers'].update({'Accept': 'application/json'})

        self.match_string_of_reversed_words = all_of(
            has_content(is_json(has_entries('text', contains(*reverse_words(text.split()))))),
            has_status(200),
        )

@idparametrize('case', [testclazz(text)
                        for text in 'Hello word!', ' 440 005 ', 'one_word'
                        for testclazz in JSONCase, DefaultCase])
def test_server_request(case, Server):
    assert_that(requests.get(Server.uri, **case.req), case.match_string_of_reversed_words)</code></pre>

<pre><code class="python">$ py.test -v test_server.py
============================= test session starts =============================
platform linux2 -- Python 2.7.3 -- py-1.4.20 -- pytest-2.5.2 -- /usr/bin/python
plugins: ordering, timeout, allure-adaptor, qabs-yadt
collected 8 items

test_server.py:26: test_server_connect PASSED
test_server.py:89: test_server_response PASSED
test_server.py:117: test_server_request[text="Hello word!", JSONCase] PASSED
test_server.py:117: test_server_request[text="Hello word!", DefaultCase] PASSED
test_server.py:117: test_server_request[text=" 440 005 ", JSONCase] PASSED
test_server.py:117: test_server_request[text=" 440 005 ", DefaultCase] PASSED
test_server.py:117: test_server_request[text="one_word", JSONCase] PASSED
test_server.py:117: test_server_request[text="one_word", DefaultCase] PASSED

========================== 8 passed in 0.12 seconds ===========================</code></pre>
<p>
Если посмотреть на код декоратора </p><code>idparametrize</code><p> и обратить внимание на параметр </p><code>fixture</code><p>, то видно, что можно параметризировать и фикстуры. В следующем примере проверим, что сервер отвечает правильно, как на реальном ip, так и на локальном. Для этого нужно немного подправить фикстуру </p><code>Server</code><p>, чтобы она умела принимать параметры:

</p><pre><code class="python">from collections import namedtuple

Srv = namedtuple('Server', 'host port')
REAL_IP = s.gethostbyname(s.gethostname())


@pytest.fixture
def Server(request):
    class Dummy:
        def __init__(self, srv):
            self.srv = srv

        @property
        def uri(self):
            return 'http://{host}:{port}/'.format(**self.srv._asdict())
    return Dummy(request.param)


@idparametrize('Server', [Srv('localhost', 8081), Srv(REAL_IP, 8081)], fixture=True)
@idparametrize('case', [Case('Hello word!'), Case('Hello word!', json=True)])
def test_server_request(case, Server):
    assert_that(requests.get(Server.uri, **case.req), case.match_string_of_reversed_words)</code></pre>

<h3>Маркировка</h3>
<p>
С помощью маркировки можно пометить тест как вызывающий ошибку, пропустить тест, либо добавить </p><em>user-defined</em><p> метку. Всё это метаданные для группировки, либо пометки необходимых тестов, кейсов или параметров. В случае группировки мы используем эту возможность для указания </p><em>severity</em><p> к тестам и классам, так как есть более и менее важные тесты.
</p><p>
В </p><strong>pytest</strong><p> тесты и параметры тестов можно помечать с помощью специального декоратора </p><code>@pytest.mark.MARK_NAME</code><p>. Например, каждый тестпак может идти по несколько минут, а то и более. Поэтому хотелось бы прогнать сначала критичные тесты и потом уже остальные:

</p><pre><code class="python">@pytest.mark.acceptance
def test_server_connect(socket, Server):
    assert_that(calling(socket.connect).with_args(Server.host_port), is_not(raises(SOCKET_ERROR)))

@pytest.mark.acceptance
def test_server_response(Server):
    assert_that(requests.get(Server.uri), all_of(has_content('text not found'), has_status(501)))

@pytest.mark.P1
def test_server_404(Server):
    assert_that(requests.get(Server.uri + 'not_found'), has_status(404))

@pytest.mark.P2
def test_server_simple_request(Server, SlowConnection):
    with SlowConnection(drop_packets=0.3):
        assert_that(requests.get(Server.uri + '?text=asdf'), has_content('fdsa'))</code></pre>
<p>
Тесты с такими маркировками можно использовать в CI. Например, в Jenkins можно создать </p><code>multi-configuration project</code><p>. Для этой задачи в разделе </p><code>Configuration Matrix</code><p> определяем </p><code>User-defined Axis</code><p> как </p><code>TESTPACK</code><p>, содержащую </p><code>['acceptance', 'P1', 'P2', 'other']</code><p>. Эта задача запускает тесты по очереди, причем, первым будут запущены </p><code>acceptance</code><p> тесты, и их успешное выполнение будет условием для запуска других тестов:

</p><pre><code class="python">#!/bin/bash
PYTEST="py.test $WORKSPACE/tests/functional/ $TEST_PARAMS --junitxml=report.xml --alluredir=reports"
if [ "$TESTPACK" = "other" ]
then
  $PYTEST -m "not acceptance and not P1 and not P2" || true
else
  $PYTEST -m $TESTPACK || true
fi</code></pre><p>
Другой тип маркировки — пометить тест как </p><code>xfail</code><p>. Кроме как пометить весь тест, можно помечать параметры тестов. Так в следующем примере при указании ipv6 адреса </p><code>host='::1',</code><p>, сервер не отвечает. Для решения этой проблемы нужно в коде сервера вместо </p><code>0.0.0.0</code><p> использовать </p><code>::</code><p>. Мы пока не будем это исправлять, чтобы посмотреть, как наш тест реагирует на такую ситуацию. Дополнительно можно описать причину в опциональном параметре </p><code>reason</code><p>. Этот текст появится в отчете о запуске:

</p><pre><code class="python">@pytest.yield_fixture
def Server(request):
    class Dummy:
        def __init__(self, srv):
            self.srv = srv
            self.conn = None

        @property
        def uri(self):
            return 'http://{host}:{port}/'.format(**self.srv._asdict())

        def connect(self):
            self.conn = s.create_connection((self.srv.host, self.srv.port))
            self.conn.sendall('HEAD /404 HTTP/1.0\r\n\r\n')
            self.conn.recv(1024)

        def close(self):
            if self.conn:
                self.conn.close()

    res = Dummy(request.param)
    yield res
    res.close()

SERVER_CASES = [
    pytest.mark.xfail(Srv('::1', 8081), reason='ipv6 desn`t work, use `::` instead of `0.0.0.0`'),
    Srv(REAL_IP, 8081),
]
@idparametrize('Server', SERVER_CASES, fixture=True)
def test_server(Server):
    assert_that(calling(Server.connect), is_not(raises(SOCKET_ERROR)))</code></pre><p>
Тесты и параметры можно пометить с помощью метки </p><code>pytest.mark.skipif()</code><p>. Она позволяет пропускать указанные тесты, используя определенное условие.

</p><h3>Выполнение и отладка</h3>
<h4>Запуск</h4><p>
Запустить тесты можно разными способами. Просто командой </p><code>py.test</code><p>, либо как модуль </p><code>python -m pytest</code><p>.
</p><p>
При запуске </p><strong>pytest</strong>
<ul>
<li>начинает сбор тестов, используя аргументы командной строки, которые указывают на директории или пути к файлам;</li>
<li>продолжает обзор рекурсивно внутри директорий, пока на наткнется на параметр <code>norecursedirs</code>;</li>
<li>все файлы, которые совпадают с <code>test_*.py</code> или <code>*_test.py</code>;</li>
<li>классы в имени, начинающиеся с <code>Test</code>, у которых нет метода <code>__init__</code>;</li>
<li>функции или методы классов, в именах которых стоит префикс <code>test_</code>;</li>
</ul><p>
Отдельно хочется отметить специальный </p><em>запускатор</em><p> тестов </p><a href="http://tox.readthedocs.org/en/latest/">tox</a><p>, с помощью которого можно хранить в одном месте все параметры запуска тестов. Для этого пишем конфиг </p><code>tox.ini</code><p> в корневой папке с тестами:

</p><pre><code class="python">[tox]
envlist=py27

[testenv]
deps=
    builders
    pytest
    pytest-allure-adaptor
    PyHamcrest
commands=
  py.test tests/functional/ \
    --junitxml=report.xml \
    --alluredir=reports \
    --verbose \
    {posargs}
</code></pre>
<p>
И далее одной командой запускам тесты: </p><code>tox</code><p>. Он сделает свой </p><code>virtualenv</code><p> в папке </p><code>.tox</code><p>, подтянет туда нужные для запуска тестов зависимости и в итоге запустит </p><strong>pytest</strong><p> с указанными в конфиге параметрами параметрами.
</p><p>
Альтернативно, если оформить тесты в виде модуля для python, то можно запускать </p><code>python setup.py test</code><p>. Для этого нужно оформить ваш </p><code>setup.py</code><p> в соответствии с </p><a href="http://pytest.org/latest/goodpractises.html#integration-with-setuptools-test-commands">документацией</a><p>.
</p><p>
Указывая docstring, как в примере выше про Allure, можно использовать </p><strong>pytest</strong><p> для проверки доктестов. Благо </p><strong>pytest</strong><p> имеет поддержку doctest, </p><a href="https://pypi.python.org/pypi/pytest-pep8">pep8</a><p>, unittest и nose: </p><code>py.test --pep8 --doctest-modules -v --junit-xml report.xml self_tests/ ft_lib/</code>
<p>
Дополнительно хотелось бы отметить, что </p><strong>pytest</strong><p> умеет запускать </p><a href="https://docs.python.org/2/library/unittest.html">UnitTest</a><p> и </p><a href="https://nose.readthedocs.org/en/latest/">nose</a><p> тесты.

</p><h3>Отладка</h3>
<img align="right" alt="pudb" src="https://habrastorage.org/files/bf4/f8e/445/bf4f8e4455b24c9f95a267d30bcd69db.png"/>
<p>
Как и обычный код, тесты нуждаются в отладке. Обычно она используется, если по </p><em>stacktrace</em><p> все ещё непонятно, почему тест упал со статусом </p><code>ERROR</code><p>. В </p><strong>pytest</strong><p> для этого существуют несколько подходов:
</p><ul>
<li>плагин для <a href="https://pypi.python.org/pypi/pytest-pycharm">PyCharm</a>;</li>
<li>написав <code>pytest.set_trace()</code> в любом месте вашего теста, можно сразу вываливаться в <code>pdb</code> в указанном месте;</li>
<li>можно просто настроить в своем IDE запуск с отладкой;</li>
<li>воспользоваться параметром <code>--pdb</code>, который запустит отладчик при возникновении ошибки;</li>
<li>либо писать <code>import pudb;pudb.set_trace()</code> перед подозрительными местами (главное при этом нужно не забыть добавить параметр <code>-s</code> в строку запуска теста).</li>
</ul>
<p>
Параметры </p><strong>pytest</strong><p>, которые помогают отлаживать тесты:
</p><ul>
<li><code>-k</code> когда вам нужно запустить какой-то отдельный тест. При этом надо учитывать, что если вы хотите запустить два теста или использовать дополнительные фильтры, то нужно соблюдать новый синтаксис этого параметра. <code>py.test -k "prepare or http and proxy" tests/functional/</code>;</li>
<li><code>-x</code> когда вам нужно прекратить выполнение тестов при первом упавшем тесте или ошибке;</li>
<li><code>--collect-only</code> когда вам нужно проверить правильность и количество сгенерированных параметров к тестам и сам список тестов, которые будут запущены (похоже на dry-run);</li>
<li><code>--no-magic</code> как бы намекает нам, что тут есть магия :)</li>
</ul>

<h3>Анализ результатов</h3><p>
Результирующий отчет — это полученный набор данных об успешно пройденных, пропущенных и упавших тестах. Упавшие тесты должны описывать состояние системы, шаги, приводящие систему к такому результату, параметры, при которых тест упал, и что ожидалось от системы при использовании этих параметров. В отчете также может быть указано: на каком стенде запускались тесты, какие стенды являются целью, какая версия тестовой библиотеки используется, версии тестируемых сервисов и сопутствующих им приложений, что за тестпак: </p><em>smoke</em><p> или </p><em>functional</em><p>, какой тестовый файл был запущен. Понятное дело, что такие отчеты должны быть простые и понятные для чтения.
</p><p>
У </p><strong>pytest</strong><p> есть хороший генератор </p><em>JUnit</em><p> отчетов, который очень просто интегрируется в </p><a href="https://wiki.jenkins-ci.org/display/JENKINS/xUnit+Plugin">Jenkins-CI</a><p>. Мы пользовались им, пока не появился замечательный фреймворк </p><a href="http://habrahabr.ru/company/yandex/blog/232697/">Allure</a><p>, для формирования более красивых отчетов с дополнительными возможностями.
</p><p>
Список статусов запуска теста в </p><strong>pytest</strong><p>:
</p><ul>
<li>PASSED — зелененький, успех, тест пройден;</li>
<li>FAILED — красненький, тест упал, ошибку вызвала конструкция <code>assert</code>;</li>
<li>ERROR — ошибка в тесте, произошла ошибка в фикстуре либо в синтаксисе и др., обычно не связано с конкретным тест кейсом;</li>
<li>SKIPPED — игнор, тест помечен каким либо образов <code>depends</code> или <code>pytest.mark.skip[if]</code> и он не запускается;</li>
<li>xfail — тест помечен и ожидаемое падение произошло, <code>assert</code> сработал как и ожидалось;</li>
<li>XPASS — тест, помеченный как <code>xfail</code> не упал. Плохо это или хорошо, нужно проверять тестировщику, и либо убирать метку, либо чинить параметры.</li>
</ul>
<p>
Чтобы начать использовать </p><a href="http://allure.qatools.ru/">Allure</a><p> вместе с </p><strong>PyTest</strong><p>, вам потребуется </p><a href="https://pypi.python.org/pypi/pytest-allure-adaptor">Allure плагин для PyTest</a><p>. В нем есть такие возможности, как:
</p><ul>
<li>использование Step'ов для выделения стадий при работе теста;</li>
<li>генерация description в заголовки каждого теста по его docstring;</li>
<li>создание attachment'ов, содержащих данные для последующего анализа;</li>
<li>и другое.</li>
</ul>
<p>
Step'ами можно сгруппировать действия, исполняемые в процессе теста, в отдельные блоки. Очень удобно их использовать в фикстурах, которые подготавливают стенд или меняют базу данных. Потом в отчете легко будет понять на какой стадии произошла ошибка и какие шаги были выполнены для данного тест-кейса.
</p><p>
Attachment'ы — это простое хранилище информации внутри отчета, в которое можно записать практически любые данные. Например, логи веб-сервера, отправленные запросы и полученные данные. Они удобно группируются с помощью Step'ов. Отображение сохраненных данных в отчете можно поменять с помощью параметра </p><code>type</code><p>. На данный момент attachemnt'ы могут понимать следующие типы: </p><code>txt</code><p>, </p><code>html</code><p>, </p><code>xml</code><p>, </p><code>png</code><p>, </p><code>jpg</code><p>, </p><code>json</code><p>.
</p><p>
В следующем примере используется специальная фикстура </p><code>error_if_wat</code><p>, которая падает с ошибкой, если в параметрах есть </p><code>ERROR_CONDITION</code><p>. Она получает данные из соседней фикстуры </p><code>Server</code><p>. Тест разделен на два шага </p><code>allure.step</code><p>. Первый проверяет соединение с помощью </p><code>socket</code><p>. Второй проверяет ответ сервера с помощью </p><code>requests</code><p>. Внутри второго шага мы сохраняем полученные от сервера данные используя </p><code>allure.attach</code><p>. Описание тесткейса с помощью </p><em>docstring</em><p>, позволит нам понять в сгенерированном отчете, что же делает данный тест.

</p><pre><code class="python">import allure

ERROR_CONDITION = None

@pytest.fixture
def error_if_wat(request):
    assert request.getfuncargvalue('Server').srv != ERROR_CONDITION

SERVER_CASES = [
    pytest.mark.xfail(Srv('::1', 8081), reason='ipv6 desn`t work, use `::` instead of `0.0.0.0`'),
    Srv('127.0.0.1', 8081),
    Srv('localhost', 80),
    ERROR_CONDITION,
]
@idparametrize('Server', SERVER_CASES, fixture=True)
def test_server(Server, error_if_wat):
    assert_that(calling(Server.connect), is_not(raises(SOCKET_ERROR)))
    """
    Step 1:
        Try connect to host, port,
        and check for not raises SOCKET_ERROR.

    Step 2:
        Check for server response 'text not found' message.
        Response status should be equal to 501.
    """
    with allure.step('Try connect'):
        assert_that(calling(Server.connect), is_not(raises(SOCKET_ERROR)))

    with allure.step('Check response'):
        response = requests.get(Server.uri)
        allure.attach('response_body', response.text, type='html')
        allure.attach('response_headers', j.dumps(dict(response.headers), indent=4), type='json')
        allure.attach('response_status', str(response.status_code))
        assert_that(response, all_of(has_content('text not found'), has_status(501)))</code></pre>
<p>
Запускается с помощью </p><code>py.test --alluredir=/var/tmp/allure/ test_server.py</code><p>.
</p><p>
Можно локально проверить, как это будет выглядеть на страничке, запустив следующие команды, если вы используете Ubuntu:

</p><pre><code class="python">sudo add-apt-repository ppa:yandex-qatools/allure-framework
sudo apt-get install yandex-allure-cli
allure generate -o /var/tmp/allure/output/ -- /var/tmp/allure/</code></pre><p>
В каталоге </p><code>/var/tmp/allure/output</code><p> будет сформирована структура файлов содержащая в себе детальный отчет. Для его отображения достаточно открыть файл </p><code>index.html</code><p>.

</p><img src="https://habrastorage.org/files/8ef/86a/679/8ef86a6798da4e2fb9e1e1dffc147fc0.png" alt="allure passed with headers"/><p>allure passed with headers
</p><p>
Если вы открываете отчет локально и у вас в браузере только серое окно с иконками, то вам нужно </p><a href="http://stackoverflow.com/questions/23997449/allure-report-nothing-shown-in-chrome">поправить политику безопасности</a><p>, так как allure использует javascript для отображения отчета.
</p><p>
В заключении расскажу вам, какие плагины мы используем постоянно, а какие только пробовали:

</p><ul>
<li><a href="https://bitbucket.org/basti/pytest-localserver/">PyTest-localserver</a> незаменим, когда нужно эмулировать какой либо из сервисов.</li>
<li><a href="https://pypi.python.org/pypi/pytest-timeout">PyTest-timeout</a> используем для тесткейсов, которые должны проверять таймауты сервисов.</li>
<li><a href="https://pypi.python.org/pypi/pytest-xdist">PyTest-xdist</a> — musthave, если вы хотите распараллелить запуск тестов.</li>
<li><a href="https://pypi.python.org/pypi/pytest-capturelog">PyTest-capturelog</a> удобен при тестировании кода, который использует модуль <code>logging</code>.</li>
<li><em>PyTester</em> используем постоянно, когда нужно проверить матчеры или написать тест на фикстуру и др. Уже входит в состав <strong>pytest</strong>.</li>
<li><a href="https://pypi.python.org/pypi/pytest-httpretty">PyTest-httpretty</a> перехватывает запросы на определенный <code>uri</code>, позволяя подставляет заранее заданный ответ. Вместо него используем <code>pytest-localserver</code></li>
<li><a href="https://pypi.python.org/pypi/pytest-ordering">PyTest-ordering</a> — отказались от использования. Как-то потребовалось сконфигурировать запуск тестов в определенной последовательности.</li>
<li><a href="https://pypi.python.org/pypi/pytest-incremental">PyTest-incremental</a> удобно, если вы используете статичный сервер, на котором крутятся тесты, и хотите, чтобы тесты запускались после изменений в коде. Мы перешли на Jenkins.</li>
</ul>
<p>
Кроме этого, существует хорошая </p><a href="http://pytest.org/latest/apiref.html">документация</a><p> для </p><strong>PyTest</strong><p>. Также советую вам посмотреть </p><a href="http://pythontesting.net/framework/pytest">несколько статей</a><p> про его использование.

      
      </p><p class="clear"/>
    </div>

    
  </div></body></html>