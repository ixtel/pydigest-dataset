<html><body><div><div id="article-content" class="article">
    <h1 class="title">Подключение celery к django</h1>
    <p/><p><a href="http://www.lexev.org/2014/django-celery-setup/"><img alt="Подключение celery к django" src="https://img-fotki.yandex.ru/get/2713/85893628.c66/0_15fca6_717ed393_M.jpg" title="Подключение celery к django"/></a></p>
<p>Для подключения <a href="http://www.celeryproject.org/">celery</a> к новому проекту так или иначе приходится подглядывать в предыдущие, чтобы вспомнить необходимые шаги: какие настройки задавать, как запускать, как останавливать и т.д.</p>
<p>Хочу собрать все в одном месте.</p>
<h3>Что нужно получить в итоге</h3>
<ol>
<li>Посредством celery добавить возможность django проекту выполнять задачи в фоне, чтобы не загружать текущий python процесс. Пример таких задач: отправка емейлов, работа со сторонним апи, долгие вычисления и т.д.</li>
<li>В качестве брокера используем <a href="http://redis.io/">redis</a>.</li>
<li>В админке нужно видеть все запущенные и выполненные задачи.</li>
<li>В админке нужно видеть статус текущих воркеров celery (online/offline).</li>
</ol>
<h3>Подключаем celery</h3>
<h4>Установим redis</h4>
<p>Для того, чтобы процессы django и celery могли общаться между собой, нужен посредник (broker), который будет передавать сообщения. В качестве этого брокера будем использовать redis. Это распространенное решение, redis быстр, легко устанавливается, требует мало памяти, надежен. Список всех возможных посредников можно посмотреть <a href="http://celery.readthedocs.org/en/latest/getting-started/brokers/#broker-overview">здесь</a>.</p>
<p>На всякий случай проверим сервер (все примеры на ubuntu):</p>
<pre><code>sudo apt-get update
sudo apt-get install build-essential
sudo apt-get install tcl8.5
</code></pre>
<p>Скачиваем последнюю версию <a href="http://redis.io/download/">отсюда</a>. На момент написания статьи это версия 2.8.17</p>
<pre><code>wget http://download.redis.io/releases/redis-2.8.17.tar.gz
tar xzf redis-2.8.17.tar.gz
cd redis-2.8.17
make
make test
sudo make install
cd utils
sudo ./install_server.sh
</code></pre>
<p>Запускаем redis сервер</p>
<pre><code>sudo service redis_6379 start
</code></pre>
<p>Если что, остановить его можно так</p>
<pre><code>sudo service redis_6379 stop
</code></pre>
<p>Чтобы redis запускался при загрузке системы, выполним команду</p>
<pre><code>sudo update-rc.d redis_6379 defaults
</code></pre>
<p>Так же нам понадобится python драйвер для redis, установим его:</p>
<pre><code>pip install redis
</code></pre>
<h4>Установка и настройка django-celery</h4>
<p>В принципе, сelery и django можно подружить не используя специальной библиотеки, следуя инструкциям из <a href="http://docs.celeryproject.org/en/latest/django/first-steps-with-django.html">документации</a>. Однако, для удобной интеграции celery в админку django проще установить специальное приложение <a href="https://pypi.python.org/pypi/django-celery">django-celery</a> (см. <a href="http://docs.celeryproject.org/en/latest/django/first-steps-with-django.html#using-the-django-orm-cache-as-a-result-backend">почему</a>).</p>
<pre><code>pip install django-celery
</code></pre>
<p>Добавляем такие настройки в settings.py:</p>
<pre><code>INSTALLED_APPS += ("djcelery", )

# адрес redis сервера
BROKER_URL = 'redis://localhost:6379/0'
# храним результаты выполнения задач так же в redis
CELERY_RESULT_BACKEND = 'redis://localhost:6379/0'
# в течение какого срока храним результаты, после чего они удаляются
CELERY_TASK_RESULT_EXPIRES = 7*86400  # 7 days
# это нужно для мониторинга наших воркеров
CELERY_SEND_EVENTS = True
# место хранения периодических задач (данные для планировщика)
CELERYBEAT_SCHEDULER = "djcelery.schedulers.DatabaseScheduler"

# в конец settings.py добавляем строчки
import djcelery
djcelery.setup_loader()
</code></pre>
<p>Создаем таблицы в базе. Eсли используем south, то</p>
<pre><code>$ python manage.py migrate djcelery
</code></pre>
<p>А если нет, то обычный syncdb</p>
<pre><code>$ python manage.py syncdb
</code></pre>
<h4>Создание задач</h4>
<p>Задачи создаются в файле <code>tasks.py</code>, который нужно положить в папочку приложения:</p>
<pre><code>- proj/
  - proj/__init__.py
  - proj/settings.py
  - proj/urls.py
- users/  # some app
  - users/__init__.py
  - users/models.py
  - users/views.py
  - users/tasks.py  # задачи для приложения users кладем сюда
- products/
  - products/__init__.py
  - products/models.py
  - products/views.py
  - products/tasks.py  # задачи для приложения products кладем сюда
- manage.py
</code></pre>
<p>Создадим простейшую задачу.</p>
<p>users/tasks.py:</p>
<pre><code># -*- coding: utf-8 -*-
from celery.task import task

@task(ignore_result=True, max_retries=1, default_retry_delay=10)
def just_print():
    print "Print from celery task"
</code></pre>
<h4>Запуск задач</h4>
<h5>Отладка</h5>
<p>Для проверки работы задач запускаем</p>
<ul>
<li><code>python manage.py runserver</code>  # проект django</li>
<li><code>python manage.py celery worker --concurrency=1</code>  # celery worker: процесс, который будет выполнять задачи</li>
<li><code>python manage.py celery beat</code>  # celery beat: процесс, который будет запускать периодические задачи</li>
</ul>
<p>Последние две команды можно объединить в одну (ключик <code>-B</code>):</p>
<pre><code>python manage.py celery worker -B --concurrency=1
</code></pre>
<p>Попробуем запустить нашу задачу <code>just_print</code>.
Условно можно выделить 2 способа вызова задачи:</p>
<ol>
<li>Планировщиком задач, вызывать через определенный интервал времени (например, каждые 10 секунд) или в определенное время (аналогично crontab)</li>
<li>Из кода, в нужном месте и при нужных условиях</li>
</ol>
<h5>Вызов задачи планировщиком</h5>
<p>Заходим в админку по адресу <a href="http://127.0.0.1:8000/admin/djcelery/periodictask/">http://{host}/admin/djcelery/periodictask/</a> и нажимаем "Add periodic task".
Заполняем поля как на фото ниже и сохраняем.</p>
<p><a href="https://img-fotki.yandex.ru/get/2714/85893628.c66/0_15fe67_b0ad7288_orig.png"><img alt="Создание периодичной задачи каждые 10 секунд" src="https://img-fotki.yandex.ru/get/2714/85893628.c66/0_15fe67_b0ad7288_XL.png" title="Создание периодичной задачи каждые 10 секунд"/></a></p>
<p>Для указания времени запуска, вместо интервала, делаем все то же самое, что и в предыдущем случае, только вместо Interval указываем Crontab:</p>
<p><a href="https://img-fotki.yandex.ru/get/6700/85893628.c66/0_15fe66_8c4b6564_orig.png"><img alt="Создание периодичной задачи в начале каждой минуты" src="https://img-fotki.yandex.ru/get/6700/85893628.c66/0_15fe66_8c4b6564_XL.png" title="Создание периодичной задачи в начале каждой минуты"/></a></p>
<h5>Замечание</h5>
<p>Периодические задачи можно создать автоматически при запуске проекта (при запуске процесса celery), чтобы не делать этого через админку вручную (но в админке они так же будут видны). Для этого их нужно указать в settings.py.</p>
<p>Каждые 10 секунд:</p>
<pre><code>CELERYBEAT_SCHEDULE = {
    'example-task': {
        'task': 'apps.users.tasks.just_print',
        'schedule': 10,  # в секундах, или timedelta(seconds=10)
    },
}
</code></pre>
<p>Раз в минуту (задача будет запускаться в 0 секунд каждой минуты):</p>
<pre><code>from celery.schedules import crontab
CELERYBEAT_SCHEDULE = {
    'example-task': {
        'task': 'apps.users.tasks.just_print',
        'schedule': crontab(),
    },
}
</code></pre>
<p>Или например каждую 7-ю минуту каждого часа:</p>
<pre><code>from celery.schedules import crontab
CELERYBEAT_SCHEDULE = {
    'example-task': {
        'task': 'apps.users.tasks.just_print',
        'schedule': crontab(minute=7),
    },
}
</code></pre>
<p>Подробности про создание периодических задач в settings.py в <a href="http://celery.readthedocs.org/en/latest/userguide/periodic-tasks.html">документации celery</a>.</p>
<p>Так же, можно пометить функцию декоратором <code>@periodic_task</code> вместо <code>@task</code>, и эта задача станет периодической. Период задается аргументом run_every, в качестве значения ему передается то же самое, что и для ключа 'schedule' в CELERYBEAT_SCHEDULE:</p>
<pre><code>from celery.task import periodic_task

@periodic_task(ignore_result=True, run_every=10)  # 10 секунд, или timedelta(seconds=10)
def just_print():
    print "Print from celery task"
</code></pre>
<p>или crontab</p>
<pre><code>from celery.task import periodic_task
from celery.schedules import crontab

@periodic_task(ignore_result=True, run_every=crontab())  # раз в минуту
def just_print():
    print "Print from celery task"
</code></pre>
<h5>Вызов задачи из кода</h5>
<p>Для вызова задачи из кода используется метод <a href="http://celery.readthedocs.org/en/latest/userguide/calling.html#basics"><code>.delay()</code></a>. Например, из view:</p>
<pre><code>from .tasks import just_print

class UserListView(ListView):
    model = User

    def get_context_data(self, **kwargs):
        just_print.delay()
        return super(UserListView, self).get_context_data(**kwargs)
</code></pre>
<h4>Мониторинг</h4>
<p>В админке в секции Djcelery видим строки <a href="http://127.0.0.1:8000/admin/djcelery/taskstate/">Tasks</a> и <a href="http://127.0.0.1:8000/admin/djcelery/workerstate/">Workers</a>.</p>
<p><a href="https://img-fotki.yandex.ru/get/6819/85893628.c66/0_15fe68_a4352d4f_orig.png"><img alt="Djcelery в админке" src="https://img-fotki.yandex.ru/get/6819/85893628.c66/0_15fe68_a4352d4f_XL.png" title="Djcelery в админке"/></a></p>
<p>Однако, сейчас они пустые. Чтобы там была информация о текущем состоянии воркеров и задач, нужно запустить celerycam:</p>
<pre><code>python manage.py celerycam --frequency=10.0
</code></pre>
<p>Теперь видим, что у нас работает 1 воркер:</p>
<p><a href="https://img-fotki.yandex.ru/get/3301/85893628.c66/0_15fe6b_a74622e4_orig.png"><img alt="Статус воркера в админке" src="https://img-fotki.yandex.ru/get/3301/85893628.c66/0_15fe6b_a74622e4_XL.png" title="Статус воркера в админке"/></a></p>
<p>И видим статус выполнения задач:</p>
<p><a href="https://img-fotki.yandex.ru/get/2914/85893628.c66/0_15fe6a_49533167_orig.png"><img alt="Статус выполнения задач в админке" src="https://img-fotki.yandex.ru/get/2914/85893628.c66/0_15fe6a_49533167_XL.png" title="Статус выполнения задач в админке"/></a></p>
<p>По умолчанию, celerycam удаляет старые задачи из Tasks по таким правилам:</p>
<ul>
<li>сборщик запускается с интервалом 1 час (см. <a href="https://github.com/celery/celery/blob/3.1/celery/events/snapshot.py#L40">код celery 3.1</a>, способа поменять этот интервал из настроек не нашел)</li>
<li>в каждом вызове сборщик удаляет задачи, превышающие установленное время жизни.</li>
</ul>
<p>Время жизни отчетов по задачам можно задать настройками в settings.py (ниже приведены значения по умолчанию):</p>
<pre><code>from datetime import timedelta

CELERYCAM_EXPIRE_SUCCESS = timedelta(days=1)
CELERYCAM_EXPIRE_ERROR = timedelta(days=3)
CELERYCAM_EXPIRE_PENDING = timedelta(days=5)
</code></pre>
<h4>Запуск в продакшн</h4>
<p>В продакшне процессы celery должны быть daemon'ами.</p>
<p>Для запуска/остановки всех процессов celery можно написать отдельный bash скрипт, а можно запускать с помощью supervisor. Итак, по порядку.</p>
<h5>Bash скрипты</h5>
<p>Запуск, celery_start.sh:</p>
<pre><code>#!/bin/bash
PYTHON=/path/to/bin/python
PROJECT_FOLDER=/project_dir/project/
PID_FOLDER=/path/to/pid/
LOGS_FOLDER=/path/to/logs/
BEAT_SHEDULE_FILE=/path/to/shedule/celerybeat-schedule  # celery beat need to store the last run times of the tasks in a local database file

$PYTHON ${PROJECT_FOLDER}manage.py celery worker --concurrency=1 --detach --pidfile=${PID_FOLDER}celery_worker.pid --logfile=${LOGS_FOLDER}celery_worker.log
$PYTHON ${PROJECT_FOLDER}manage.py celery beat --detach --pidfile=${PID_FOLDER}celery_beat.pid --logfile=${LOGS_FOLDER}celery_beat.log -s ${BEAT_SHEDULE_FILE}
$PYTHON ${PROJECT_FOLDER}manage.py celerycam --frequency=10.0 --detach --pidfile=${PID_FOLDER}celerycam.pid --logfile=${LOGS_FOLDER}celerycam.log
</code></pre>
<p>Остановка, celery_stop.sh:</p>
<pre><code>#!/bin/bash
PYTHON=/path/to/bin/python
PID_FOLDER=/path/to/pid/

$PYTHON -m celery multi stopwait worker1 --pidfile=${PID_FOLDER}celerycam.pid
$PYTHON -m celery multi stopwait worker1 --pidfile=${PID_FOLDER}celery_beat.pid
$PYTHON -m celery multi stopwait worker1 --pidfile=${PID_FOLDER}celery_worker.pid
</code></pre>
<h4>supervisord</h4>
<p>Лучше всего запустить celery процессы под контролем <a href="http://supervisord.org/">supervisord</a>.</p>
<p>Для этого создаем где-нибудь у себя в проекте такие файлы (например, в папке deploy):</p>
<p>supervisor.celeryd.conf</p>
<pre><code>[program:djangoproject.celeryd]
command=/path/to/bin/python /path/to/django_project/manage.py celeryd --concurrency=1
user=www-data
numprocs=1
directory=/path/to/django_project
stdout_logfile=/path/to/log/celery_worker.log
stderr_logfile=/path/to/log/celery_worker.log
autostart=true
autorestart=true
startsecs=10
stopwaitsecs = 120
priority=998
</code></pre>
<p>supervisor.celerybeat.conf</p>
<pre><code>[program:djangoproject.celerybeat]
command=/path/to/bin/python /path/to/django_project/manage.py celery beat -s /path/to/celerybeat-schedule
user=www-data
numprocs=1
directory=/path/to/django_project
stdout_logfile=/path/to/log/celery_beat.log
stderr_logfile=/path/to/log/celery_beat.log
autostart=true
autorestart=true
startsecs=10
stopwaitsecs = 120
priority=998
</code></pre>
<p>supervisor.celerycam.conf</p>
<pre><code>[program:djangoproject.celerycam]
command=/path/to/bin/python /path/to/django_project/manage.py celerycam --frequency=10.0
user=www-data
numprocs=1
directory=/path/to/django_project
stdout_logfile=/path/to/log/celerycam.log
stderr_logfile=/path/to/log/celerycam.log
autostart=true
autorestart=true
startsecs=10
stopwaitsecs = 120
priority=998
</code></pre>
<p>Заменяем все <code>/path/to/</code> на нужные для конкретного проекта, а так же указываем нужного юзера, под которым будут запускаться процессы celery.</p>
<p>Теперь создадим symlink на наши файлы конфигурации в папке /etc/supervisor/conf.d/, чтобы supervisor знал о них:</p>
<pre><code>cd /etc/supervisor/conf.d
sudo ln -s /path/to/django_project/deploy/supervisor.celeryd.conf
sudo ln -s /path/to/django_project/deploy/supervisor.celerybeat.conf
sudo ln -s /path/to/django_project/deploy/supervisor.celerycam.conf
</code></pre>
<p>И перезапустим supervisor</p>
<pre><code>sudo supervisorctl reload
</code></pre>
<p>Проверим, что все нужные процессы запущены:</p>
<pre><code>ps aux | grep python
</code></pre>
<h4>Прочее</h4>
<p>Если в админке зайти в периодические задачи (<a href="http://127.0.0.1:8000/admin/djcelery/periodictask/">http://{host}/admin/djcelery/periodictask/</a>), то увидим там celery.backend_cleanup:</p>
<p><a href="https://img-fotki.yandex.ru/get/10/85893628.c66/0_15fe69_fe0539e0_orig.png"><img alt="celery.backend_cleanup" src="https://img-fotki.yandex.ru/get/10/85893628.c66/0_15fe69_fe0539e0_XL.png" title="celery.backend_cleanup"/></a></p>
<p>Эта задача подчищает все устаревшие результаты задач, которые хранятся в базе данных. Устаревшие - это те, которые старше указанного нами интервала времени в <code>settings.CELERY_TASK_RESULT_EXPIRES</code>. Но, т.к. результаты задач мы храним в redis, а не в базе данных, то данная периодическая задача нам не важна. Т.о. ее можно удалить. Redis сама удаляет те значения, время жизни которых истекло.</p>
</div>






</div></body></html>