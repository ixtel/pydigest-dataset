<html><body><div><div class="css-entry"> 
                     										
                                
                   

            
				                                                                                                             	      	        			                             <h1 dir="ltr">Julia vs Python</h1>

<p dir="ltr">Should we ditch Python and other languages in favor of Julia for technical computing?  That's certainly a thought that comes to mind when one looks at the benchmarks on <a href="http://julialang.org/">http<wbr>://j<wbr>ulia<wbr>lang<wbr>.org<wbr>/.<wbr> </wbr></wbr></wbr></wbr></wbr></wbr></a> Python and other high level languages are way behind in term of speed.  The first question that came to my mind was different however: did the Julia team wrote Python benchmarks the best way for Python? </p>

<p dir="ltr">My take on this kind of cross language comparison is that the benchmarks should be defined by tasks to perform, then have language experts write the best code they can to perform these tasks.  If the code is all written by one language team, then there is a risk that other languages aren't used at best.</p>

<p dir="ltr">One thing the Julia team did right is to publish on github the <a href="https://github.com/JuliaLang/julia/tree/master/test/perf/micro">code they used</a>.  In particular, the Python code can be found <a href="https://github.com/JuliaLang/julia/blob/master/test/perf/micro/perf.py">here</a>. </p>

<p dir="ltr">A first look at this code confirms the bias I was afraid of.  The code is written in a C style with heavy use of loops over arrays and lists.  This is not the best way to use Python.</p>

<p dir="ltr">I won't blame the Julia team, as I have been guilty of the exact same bias.  But I learned the hard lesson: loops on arrays or lists should be avoided at almost any cost as they are really slow in Python, see <a href="https://www.ibm.com/developerworks/community/blogs/jfp/entry/Python_Is_Not_C?lang=en">Python is not C</a>.</p>

<p dir="ltr">Given this bias towards C style, the interesting question (to me at least) is whether we can improve these benchmarks with a better use of Python and its tools? </p>

<p dir="ltr">Before I give the answer below, let me say that I am in no way trying to downplay Julia.  It is certainly a language worth monitoring as it is further developed and improved.  I just want to have a look at the Python side of things.  Actually, I am using this as an excuse to explore various Python tools that can be used to make code run faster. </p>

<p dir="ltr">In what follows I use Python 3.5.1 with <a href="https://www.google.fr/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwi1n9KroLfJAhXFuhQKHbMhA-8QFggeMAA&amp;url=https%3A%2F%2Fwww.continuum.io%2Fdownloads&amp;usg=AFQjCNH5KKA7CTASoQKpNBeQAV2xSKKTrQ">Anaconda</a> on a Windows machine.  The notebook containing the complete code for all benchmarks below is available <a href="https://gist.github.com/jfpuget/b53f1e15a37aba5944ad">on github</a> and on <a href="http://nbviewer.jupyter.org/gist/jfpuget/b53f1e15a37aba5944ad">nbviewer</a>.</p>

<p dir="ltr">Comments on various social media make me add this: I am not writing any C code here: if you're not convinced, then try to find any semicolon. All the tools used in this blog run in the standard CPython implementation available in Anaconda or other distributions.  All the code below runs in <a href="https://gist.github.com/jfpuget/b53f1e15a37aba5944ad">a single notebook</a>.  I tried to use the Julia micro performance file from <a href="https://github.com/JuliaLang/julia/blob/master/test/perf/micro/perf.jl">github</a> but it does not run as is with Julia 0.4.2.  I had to edit it and replace @timeit by @time to make it run.  I also had to add calls to the timed functions before timing them, otherwise the compilation time was included.  I ran it with the Julia command line interface, on the same machine as the one used to run Python.</p>

<h2 dir="ltr">Timing Code</h2>

<p dir="ltr">The first benchmark Julia team used is a naive coding of the Fibonacci function. </p>

<blockquote dir="ltr">
<pre dir="ltr">
<span class="k">def</span> <span class="nf">fib</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">n</span><span class="o">&lt;</span><span class="mi">2</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">n</span>
    <span class="k">return</span> <span class="n">fib</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">+</span><span class="n">fib</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span></pre>
</blockquote>

<p dir="ltr">This function grows rapidly with n, for instance:</p>

<p dir="ltr"><span>fib(100) = 3542<wbr>2484<wbr>8179<wbr>2619<wbr>1507<wbr>5</wbr></wbr></wbr></wbr></wbr></span></p>

<p dir="ltr">Note how Python arbitrary precision comes in handy.  Coding the same in a language like C would some coding effort to avoid integer overflow.  In Julia one would have to use the BigInt type.</p>

<p dir="ltr">All the Julia benchmarks are about running times.  Here are the timings with and without BigInt in Julia</p>

<p dir="ltr"><span>  0.000080 seconds (149 allocations: 10.167 KB)<br/>
  0.012717 seconds (262.69 k allocations: 4.342 MB)</span></p>

<p dir="ltr">One way to get running times in Python notebooks is to use the magic <span>%timeit</span>.  For instance, typing</p>

<blockquote dir="ltr">
<pre>
<span class="o">%</span><span class="k">timeit</span> fib(20)</pre>
</blockquote>

<p dir="ltr">in a new cell and executing it outputs</p>

<p dir="ltr"><span>100 loops, best of 3: 3.77 ms per loop</span></p>

<p dir="ltr">It means that the timer did the following:</p>

<ol dir="ltr">
	<li>Run <span>fib(20)</span> one hundred times, store the total running time</li>
	<li>Run <span>fib(20)</span> one hundred times, store the total running time</li>
	<li>Run <span>fib(20)</span> one hundred times, store the total running time</li>
	<li>Get the smallest running time from the three runs, divide it by 100, and outputs the result as the best running time for <span>fib(20)</span></li>
</ol>

<p dir="ltr">The sizes of loops (100  and 3 here) are automatically adjusted by the timer.  They may change depending on how fast the timed code runs.</p>

<p dir="ltr">Python timing compares very favorably against Julia timing when BigInt are used: 3 milliseconds vs 12 milliseconds.  Python is 4 times faster than Julia when arbitrary precision is used. </p>

<p dir="ltr">However, Python is way slower than Julia's default 64 bits integers.  Let's see how we can force the use of 64 bits integers in Python.</p>

<h2 dir="ltr">Compiling With Cython</h2>

<p dir="ltr">One way to do it is to use the <a href="http://docs.cython.org/">Cython</a> compiler.  This compiler is written in Python.  It can be installed via</p>

<p dir="ltr"><span>pip install Cython</span></p>

<p dir="ltr">If you use Anaconda, the installation is different.  As it is a bit tricky I wrote a blog entry about it: <a href="https://www.ibm.com/developerworks/community/blogs/jfp/entry/Installing_Cython_On_Anaconda_On_Windows?lang=en" target="_blank">Inst<wbr>alli<wbr>ng C<wbr>ytho<wbr>n Fo<wbr>r An<wbr>acon<wbr>da O<wbr>n Wi<wbr>ndow<wbr>s</wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></a></p>

<p dir="ltr">Once installed, we load Cython in the notebook with the <span>%load_ext</span> magic:</p>

<blockquote dir="ltr">
<pre>
<span class="o">%</span><span class="k">load_ext</span> Cython</pre>
</blockquote>

<p dir="ltr">We can then compile code in our notebook.  All we have to do is to put all the code we want to compile in one cell, including the required import statements, and start that cell with the cell magic <span>%%cython</span>:</p>

<blockquote dir="ltr">
<pre>
<span class="o">%%</span><span class="n">cython</span>
<span class="k">def</span> <span class="nf">fib_cython</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">n</span><span class="o">&lt;</span><span class="mf">2</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">n</span>
    <span class="k">return</span> <span class="n">fib_<wbr>cyth<wbr>o<wbr>n</wbr></wbr></wbr></span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mf"><wbr>1</wbr></span><span class="p">)</span><span class="o">+</span><span class="n">f<wbr>ib_c<wbr>ytho<wbr>n</wbr></wbr></wbr></span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mf"><wbr>2</wbr></span><span class="p">)</span></pre>
</blockquote>

<p dir="ltr">Executing that cell compiles the code seamlessly.  We use a slightly different name for our function to reflect that it is compiled with Cython.  Of course, there is no need to do this in general.  We could have replaced the previous function by a compiled function of the same name.</p>

<p dir="ltr">Timing it yields</p>

<p dir="ltr"><span>1000 loops, best of 3: 1.47 ms per loop</span></p>

<p dir="ltr">Wow, more than 2 times faster than the original Python code!  We are now 9 times faster than Julia with BigInt.</p>

<p dir="ltr">We can also try with static typing.  We declare the function with the keyword <span>cpdef</span> instead of <span>def</span>.  It allows us to type the parameters of the function with their corresponding C types.  Our code becomes.</p>

<blockquote dir="ltr">
<pre>
<span class="o">%%</span><span class="n">cython</span>
</pre>

<p> </p>

<pre>
<span class="k">cpdef</span> <span class="kt">long</span> <span class="nf">fib_<wbr>cyth<wbr>on_t<wbr>yp<wbr>e</wbr></wbr></wbr></wbr></span><span class="p">(</span><span class="nb">lo<wbr>n<wbr>g</wbr></wbr></span> <span class="n">n</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">n</span><span class="o">&lt;</span><span class="mf">2</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">n</span>
    <span class="k">return</span> <span class="n">fib_<wbr>cyth<wbr>on_t<wbr>yp<wbr>e</wbr></wbr></wbr></wbr></span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mf"><wbr>1</wbr></span><span class="p">)</span><span class="o">+</span><span class="n">f<wbr>ib_c<wbr>ytho<wbr>n_ty<wbr>p<wbr>e</wbr></wbr></wbr></wbr></wbr></span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mf"><wbr>2</wbr></span><span class="p">)</span></pre>
</blockquote>

<p dir="ltr">After executing that cell, timing it yields</p>

<p dir="ltr"><span>10000 loops, best of 3: 24.4 µs per loop</span></p>

<p dir="ltr">Amazing, we're now at 24 micro seconds, about 150 times faster than the original benchmark !   This compares favorably with the 80 microseconds used by Julia.</p>

<p dir="ltr">One can argue that static typing defeats the purpose of Python.  I kind of agree with that in general, and we will see later a way to avoid this without sacrificing performance.  But I don't think this is the issue here.  The Fibonacci function is meant to be called with integers.  What we lose with static typing is the arbitrary precision that Python provides.  In the case of Fibonacci, using the C type <span>long</span> limits the size of the input parameter because too large parameters would result in integer overflow. </p>

<p dir="ltr">Note that Julia computation is done with 64 bits integers too, hence comparing our statically typed version with that of Julia is fair. </p>

<h2 dir="ltr">Caching Computation</h2>

<p dir="ltr">We can do better while keeping Python arbitrary precision.  The <span>fib</span> function repeats the same computation many times.  For instance, <span>fib(20)</span> will call<span> fib(19)</span> and <span>fib(18)</span>.  In turn, <span>fib(19)</span> will call <span>fib(18)</span> and <span>fib(17)</span>.  As a result<span> fib(18)</span> will be called twice.  A little analysis shows that <span>fib(17)</span> will be called 3 times, and <span>fib(16)</span> five times, etc. </p>

<p dir="ltr">In Python 3, we can avoid these repeated computations using the functools standard library. </p>

<blockquote dir="ltr">
<pre>
<span class="kn">from</span> <span class="nn">functools</span> <span class="k">import</span> <span class="n">lru_cache</span> <span class="k">as</span> <span class="n">cache</span>

<span class="nd">@cac<wbr>h<wbr>e</wbr></wbr></span><span class="p">(</span><span class="n">ma<wbr>xsiz<wbr>e</wbr></wbr></span><span class="o">=</span><span class="kc">No<wbr>n<wbr>e</wbr></wbr></span><span class="p">)</span>
<span class="k">def</span> <span class="nf">fib_cache</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">n</span><span class="o">&lt;</span><span class="mi">2</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">n</span>
    <span class="k">return</span> <span class="n">fib_<wbr>cach<wbr>e</wbr></wbr></span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi"><wbr>1</wbr></span><span class="p">)</span><span class="o">+</span><span class="n">f<wbr>ib_c<wbr>ach<wbr>e</wbr></wbr></wbr></span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi"><wbr>2</wbr></span><span class="p">)</span></pre>
</blockquote>

<p dir="ltr">Timing this function yields:</p>

<p dir="ltr"><span>1000000 loops, best of 3: 127 ns per loop</span></p>

<p dir="ltr">This is an additional 190 times speedup, and about 30,000 times faster than the original ¨Python code!  I find it impressive given we merely add an annotation to the recursive function.</p>

<p dir="ltr">This automated cache isn't available with Python 2.7.  We need to transform the code explicitly in order to avoid duplicate computation in that case.</p>

<blockquote dir="ltr">
<pre>
<span class="k">def</span> <span class="nf">fib_seq</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">n</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">n</span>
    <span class="n">a</span><span class="p">,</span><span class="n">b</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span><span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">a</span><span class="p">,</span><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">+</span><span class="n">b</span><span class="p">,</span><span class="n">a</span>
    <span class="k">return</span> <span class="n">a</span>    </pre>
</blockquote>

<p dir="ltr">Note that this code makes use of Python ability to simultaneously assign two local variables.  Timing it yields</p>

<p dir="ltr"><span>1000000 loops, best of 3: 1.81 µs per loop</span></p>

<p dir="ltr">Another 20 times speedup!  Let us compile our function, with and without static typing.  Note how we use the <span>cdef</span> keyword to type local variables.</p>

<blockquote dir="ltr">
<pre>
<span class="o">%%</span><span class="n">cython</span>

<span class="k">def</span> <span class="nf">fib_seq_cython</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">n</span> <span class="o">&lt;</span> <span class="mf">2</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">n</span>
    <span class="n">a</span><span class="p">,</span><span class="n">b</span> <span class="o">=</span> <span class="mf">1</span><span class="p">,</span><span class="mf">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mf">1</span><span class="p">):</span>
        <span class="n">a</span><span class="p">,</span><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">+</span><span class="n">b</span><span class="p">,</span><span class="n">a</span>
    <span class="k">return</span> <span class="n">a</span>    

<span class="k">cpdef</span> <span class="kt">long</span> <span class="nf">fib_<wbr>seq_<wbr>cyth<wbr>on_t<wbr>yp<wbr>e</wbr></wbr></wbr></wbr></wbr></span><span class="p">(</span><span class="nb">lo<wbr>n<wbr>g</wbr></wbr></span> <span class="n">n</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">n</span> <span class="o">&lt;</span> <span class="mf">2</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">n</span>
    <span class="k">cdef</span> <span class="kt">long</span> <span class="nf">a</span><span class="p">,</span><span class="nf">b</span>
    <span class="n">a</span><span class="p">,</span><span class="n">b</span> <span class="o">=</span> <span class="mf">1</span><span class="p">,</span><span class="mf">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mf">1</span><span class="p">):</span>
        <span class="n">a</span><span class="p">,</span><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">+</span><span class="n">b</span><span class="p">,</span><span class="n">a</span>
    <span class="k">return</span> <span class="n">a</span></pre>
</blockquote>

<p dir="ltr">We can time both versions in one cell:</p>

<blockquote dir="ltr">
<pre>
<span class="o">%</span><span class="k">timeit</span> fib_seq_cython(20)
<span class="o">%</span><span class="k">timeit</span> fib_<wbr>seq_<wbr>cyth<wbr>on_t<wbr>ype(<wbr>20<wbr>)</wbr></wbr></wbr></wbr></wbr></wbr></pre>
</blockquote>

<p dir="ltr">It yields</p>

<p dir="ltr"><span>1000000 loops, best of 3: 953 ns per loop </span></p>

<p dir="ltr"><span>10000000 loops, best of 3: 82 ns per loop</span></p>

<p dir="ltr">We are now at 82 nano seconds with the statically typed code, about <em>45,000</em>  times faster than the original benchmark! </p>

<p dir="ltr">If we want to compute the Fibonacci number for arbitrary input, then we should stick to the untyped version, which runs with a respectable<em> 30,000</em> times  speedup.  Not so bad isn't it?</p>

<h2 dir="ltr">Compiling With Numba</h2>

<p dir="ltr">Let us use another tool called <a href="http://numba.pydata.org/">Numba</a>.  It is a just in time (jit) compiler for a subset of Python.  It does not work yet on all of Python, but when it does work it can do marvels. </p>

<p dir="ltr">Installing it can be cumbersome.  I recommend that you use a Python distribution like <a href="https://www.google.fr/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwi1n9KroLfJAhXFuhQKHbMhA-8QFggeMAA&amp;url=https%3A%2F%2Fwww.continuum.io%2Fdownloads&amp;usg=AFQjCNH5KKA7CTASoQKpNBeQAV2xSKKTrQ">Anaconda</a> or a <a href="https://www.ibm.com/developerworks/community/blogs/jfp/entry/Using_Docker_Machine_On_Windows?lang=en">Docker image</a> where Numba is already installed.  Once installed, we import its jit compiler:</p>

<blockquote dir="ltr">
<pre>
<span class="kn">from</span> <span class="nn">numba</span> <span class="k">import</span> <span class="n">jit</span></pre>
</blockquote>

<p dir="ltr">Using it is very simple.  We only need to add a decoration to the functions we want to compile.  Our code becomes:</p>

<blockquote dir="ltr">
<pre>
<span class="nd">@jit</span>
<span class="k">def</span> <span class="nf">fib_seq_numba</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">n</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">n</span>
    <span class="n">a</span><span class="p">,</span><span class="n">b</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span><span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">a</span><span class="p">,</span><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">+</span><span class="n">b</span><span class="p">,</span><span class="n">a</span>
    <span class="k">return</span> <span class="n">a</span>    </pre>
</blockquote>

<p dir="ltr">Timing it yields</p>

<p dir="ltr"><span>1000000 loops, best of 3: 216 ns per loop</span></p>

<p dir="ltr">We are faster than the untyped Cython code, and about <em>17,000</em> times faster than the original Python code! </p>

<h2 dir="ltr">Using Numpy</h2>

<p dir="ltr">Let's now look at the second benchmark.  It is an implementation of the quicksort algorithm.  Julia team used that Python code:</p>

<blockquote dir="ltr">
<pre>
<span class="k">def</span> <span class="nf">qsort_kernel</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">lo</span><span class="p">,</span> <span class="n">hi</span><span class="p">):</span>
    <span class="n">i</span> <span class="o">=</span> <span class="n">lo</span>
    <span class="n">j</span> <span class="o">=</span> <span class="n">hi</span>
    <span class="k">while</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">hi</span><span class="p">:</span>
        <span class="n">pivot</span> <span class="o">=</span> <span class="n">a</span><span class="p">[(</span><span class="n">lo</span><span class="o">+</span><span class="n">hi</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">]</span>
        <span class="k">while</span> <span class="n">i</span> <span class="o">&lt;=</span> <span class="n">j</span><span class="p">:</span>
            <span class="k">while</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">pivot</span><span class="p">:</span>
                <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">while</span> <span class="n">a</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">pivot</span><span class="p">:</span>
                <span class="n">j</span> <span class="o">-=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;=</span> <span class="n">j</span><span class="p">:</span>
                <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">a</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">j</span> <span class="o">-=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">lo</span> <span class="o">&lt;</span> <span class="n">j</span><span class="p">:</span>
            <span class="n">qsort_kernel</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">lo</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span>
        <span class="n">lo</span> <span class="o">=</span> <span class="n">i</span>
        <span class="n">j</span> <span class="o">=</span> <span class="n">hi</span>
    <span class="k">return</span> <span class="n">a</span>
</pre>
</blockquote>

<p dir="ltr">I wrapped their benchmarking code in a function:</p>

<blockquote dir="ltr">
<pre>
<span class="kn">import</span> <span class="nn">random</span></pre>

<p> </p>

<pre>
<span class="k">def</span> <span class="nf">benchmark_qsort</span><span class="p">():</span>
    <span class="n">lst</span> <span class="o">=</span> <span class="p">[</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">5000</span><span class="p">)</span> <span class="p">]</span>
    <span class="n">qsort_kernel</span><span class="p">(</span><span class="n">lst</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">lst</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span></pre>
</blockquote>

<p dir="ltr">Timing it yields:</p>

<p dir="ltr"><span>100 loops, best of 3: 17.7 ms per loop</span></p>

<p dir="ltr">The above code is really like C code.  Cython should do well on it.  Besides using Cython and static typing, let us use Numpy arrays instead of lists.  Indeed, <a href="http://www.numpy.org/">Numpy</a> arrays are faster than Python lists when their size is large, say thousands of elements or more. </p>

<p dir="ltr">Installing Numpy can take a while, I recommend you use <a href="https://www.google.fr/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwi1n9KroLfJAhXFuhQKHbMhA-8QFggeMAA&amp;url=https%3A%2F%2Fwww.continuum.io%2Fdownloads&amp;usg=AFQjCNH5KKA7CTASoQKpNBeQAV2xSKKTrQ">Anaconda</a> or a <a href="https://www.ibm.com/developerworks/community/blogs/jfp/entry/Using_Docker_Machine_On_Windows?lang=en">Docker image</a> where the Python scientific stack is already installed. </p>

<p dir="ltr">When using Cython, we need to import Numpy in the cell to which Cython is applied. Numpy arrays are declared with a special syntax indicating the type of elements of arrays, and the number of dimensions of the array (1D, 2D, etc).  The decorators tell Cython to remove bound checking.</p>

<blockquote dir="ltr">
<pre>
<span class="o">%%</span><span class="n">cython</span>
<span class="k">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="k">import</span> <span class="nn">cython</span>

<span class="nd">@cyt<wbr>ho<wbr>n</wbr></wbr></span><span class="o">.</span><span class="n">bo<wbr>unds<wbr>chec<wbr>k</wbr></wbr></wbr></span><span class="p">(</span><span class="bp">Fa<wbr>ls<wbr>e</wbr></wbr></span><span class="p">)</span>
<span class="nd">@cyt<wbr>ho<wbr>n</wbr></wbr></span><span class="o">.</span><span class="n">wr<wbr>apar<wbr>oun<wbr>d</wbr></wbr></wbr></span><span class="p">(</span><span class="bp">Fa<wbr>ls<wbr>e</wbr></wbr></span><span class="p">)</span>
<span class="k">cdef</span> <span class="kt">double</span>[<span class="p">:]</span> \
<span class="n">qsor<wbr>t_ke<wbr>rnel<wbr>_cyt<wbr>hon_<wbr>nump<wbr>y_ty<wbr>p<wbr>e</wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></span><span class="p">(</span><span class="n">do<wbr>ubl<wbr>e</wbr></wbr></span><span class="p">[:<wbr>]</wbr></span> <span class="n">a</span><span class="p">,</span> \
                               <span class="nb">long</span> <span class="n">lo</span><span class="p">,</span> \
                               <span class="nb">long</span> <span class="n">hi</span><span class="p">):</span>
    <span class="k">cdef</span><span class="p">:</span> 
        <span class="nb">long</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span>
        <span class="n">double</span> <span class="n">pivot</span>
    <span class="n">i</span> <span class="o">=</span> <span class="n">lo</span>
    <span class="n">j</span> <span class="o">=</span> <span class="n">hi</span>
    <span class="k">while</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">hi</span><span class="p">:</span>
        <span class="n">pivot</span> <span class="o">=</span> <span class="n">a</span><span class="p">[(</span><span class="n">lo</span><span class="o">+</span><span class="n">hi</span><span class="p">)</span> <span class="o">//</span> <span class="mf">2</span><span class="p">]</span>
        <span class="k">while</span> <span class="n">i</span> <span class="o">&lt;=</span> <span class="n">j</span><span class="p">:</span>
            <span class="k">while</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">pivot</span><span class="p">:</span>
                <span class="n">i</span> <span class="o">+=</span> <span class="mf">1</span>
            <span class="k">while</span> <span class="n">a</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">pivot</span><span class="p">:</span>
                <span class="n">j</span> <span class="o">-=</span> <span class="mf">1</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;=</span> <span class="n">j</span><span class="p">:</span>
                <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">a</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="n">i</span> <span class="o">+=</span> <span class="mf">1</span>
                <span class="n">j</span> <span class="o">-=</span> <span class="mf">1</span>
        <span class="k">if</span> <span class="n">lo</span> <span class="o">&lt;</span> <span class="n">j</span><span class="p">:</span>
            <span class="n">qsor<wbr>t_ke<wbr>rnel<wbr>_cyt<wbr>hon_<wbr>nump<wbr>y_ty<wbr>p<wbr>e</wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">lo</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span>
        <span class="n">lo</span> <span class="o">=</span> <span class="n">i</span>
        <span class="n">j</span> <span class="o">=</span> <span class="n">hi</span>
    <span class="k">return</span> <span class="n">a</span>

<span class="k">def</span> <span class="nf">benc<wbr>hmar<wbr>k_qs<wbr>ort_<wbr>nump<wbr>y_cy<wbr>tho<wbr>n</wbr></wbr></wbr></wbr></wbr></wbr></wbr></span><span class="p">()<wbr>:</wbr></span>
    <span class="n">lst</span> <span class="o">=</span> <span class="n">n<wbr>p</wbr></span><span class="o">.</span><span class="n">ra<wbr>ndo<wbr>m</wbr></wbr></span><span class="o">.</span><span class="n">ra<wbr>n<wbr>d</wbr></wbr></span><span class="p">(</span><span class="mf">50<wbr>0<wbr>0</wbr></wbr></span><span class="p">)</span>
    <span class="n">qsor<wbr>t_ke<wbr>rnel<wbr>_cyt<wbr>hon_<wbr>nump<wbr>y_ty<wbr>p<wbr>e</wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></span><span class="p">(</span><span class="n">ls<wbr>t</wbr></span><span class="p">,</span> <span class="mf">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">lst</span><span class="p">)</span><span class="o">-</span><span class="mf">1</span><span class="p">)</span></pre>
</blockquote>

<p dir="ltr">Timing the <span>benc<wbr>hmar<wbr>k_qs<wbr>ort_<wbr>nump<wbr>y_cy<wbr>thon<wbr>(<wbr>)</wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></span> function yields</p>

<p dir="ltr"><span>1000 loops, best of 3: 772 µs per loop</span></p>

<p dir="ltr">We are about 23 times faster than the original benchmark, but this is still not the best way to use Python.  The best way is to use the Numpy built-in <span>sort()</span> function.  Its default behavior is to use the quick sort algorithm.  Timing this code</p>

<blockquote dir="ltr">
<pre>
<span class="k">def</span> <span class="nf">benc<wbr>hmar<wbr>k_so<wbr>rt_n<wbr>ump<wbr>y</wbr></wbr></wbr></wbr></wbr></span><span class="p">()<wbr>:</wbr></span>
    <span class="n">lst</span> <span class="o">=</span> <span class="n">n<wbr>p</wbr></span><span class="o">.</span><span class="n">ra<wbr>ndo<wbr>m</wbr></wbr></span><span class="o">.</span><span class="n">ra<wbr>n<wbr>d</wbr></wbr></span><span class="p">(</span><span class="mi">50<wbr>0<wbr>0</wbr></wbr></span><span class="p">)</span>
    <span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">lst</span><span class="p">)</span></pre>
</blockquote>

<p dir="ltr">yields</p>

<p dir="ltr"><span>1000 loops, best of 3: 306 µs per loop</span></p>

<p dir="ltr">We are now 58 times faster than the original benchmark!  Julia takes 419 micro seconds on that benchmark, hence compiled Python is 40% faster.</p>

<p dir="ltr">I know, some readers will say that I am not comparing apple to apple.  I disagree.  Remember, the task at hand is to sort an input array using the host language in the best possible way.  In this case, the best possible way is to use a built-in function. </p>

<h2 dir="ltr">Profiling Code</h2>

<p dir="ltr">Let use now look at a third example, computing the Mandelbrot set.  Julia team used this Python code:</p>

<blockquote dir="ltr">
<pre>
<span class="k">def</span> <span class="nf">mandel</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="n">maxiter</span> <span class="o">=</span> <span class="mi">80</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">z</span>
    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">maxiter</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">z</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">n</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="o">*</span><span class="n">z</span> <span class="o">+</span> <span class="n">c</span>
    <span class="k">return</span> <span class="n">maxiter</span>

<span class="k">def</span> <span class="nf">mandelperf</span><span class="p">():</span>
    <span class="n">r1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">26</span><span class="p">)</span>
    <span class="n">r2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mi">21</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">mandel</span><span class="p">(</span><span class="nb">complex</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">i</span><span class="p">))</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">r1</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">r2</span><span class="p">]</span></pre>

<p> </p>

<pre>
<span class="k">assert</span> <span class="nb">sum</span><span class="p">(</span><span class="n">mandelperf</span><span class="p">())</span> <span class="o">==</span> <span class="mi">14791</span></pre>
</blockquote>

<p dir="ltr">The last line is a sanity check.  Timing the <span>mandelperf()</span> function yields:</p>

<p dir="ltr"><span>100 loops, best of 3: 6.57 ms per loop </span></p>

<p dir="ltr">Using Cython yields:</p>

<p dir="ltr"><span>100 loops, best of 3: 3.6 ms per loop</span></p>

<p dir="ltr">Not bad, but we can do better using Numba.  Unfortunately, Numba does not compile list comprehensions yet.  Therefore we cannot apply it to the second function, but we can apply it to the first one.  Our code looks like this.</p>

<blockquote dir="ltr">
<pre>
<span class="nd">@jit</span>
<span class="k">def</span> <span class="nf">mandel_numba</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="n">maxiter</span> <span class="o">=</span> <span class="mi">80</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">z</span>
    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">maxiter</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">z</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">n</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="o">*</span><span class="n">z</span> <span class="o">+</span> <span class="n">c</span>
    <span class="k">return</span> <span class="n">maxiter</span>

<span class="k">def</span> <span class="nf">mandelperf_numba</span><span class="p">():</span>
    <span class="n">r1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">26</span><span class="p">)</span>
    <span class="n">r2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mi">21</span><span class="p">)</span>
<span class="k">    return</span> <span class="p">[</span><span class="n">mandel</span><span class="p">(</span><span class="nb">complex</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">i</span><span class="p">))</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">r1</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">r2</span><span class="p">]</span></pre>
</blockquote>

<p dir="ltr">Timing it yields</p>

<p dir="ltr"><span>1000 loops, best of 3: 481 µs per loop</span></p>

<p dir="ltr">Not bad, four times faster than Cython, and 9 times faster than the original Python code! </p>

<p dir="ltr">Can we do more?  One way to know is to profile the code.  The built-in <span>%prun</span> profiler is not precise enough here, and we must use a better profiler known as <a href="https://github.com/rkern/line_profiler">line_profiler</a>.  It can be installed via pip:</p>

<p dir="ltr"><span>pip install line_profiler</span></p>

<p dir="ltr">Once installed, we load it:</p>

<blockquote dir="ltr">
<pre>
<span class="o">%</span><span class="k">load_ext</span> line_profiler</pre>
</blockquote>

<p dir="ltr">We can then profile the function using a magic:</p>

<blockquote dir="ltr">
<pre>
<span class="o">%</span><span class="k">lprun</span> -s -f mandelperf_numba mandelperf_numba()</pre>
</blockquote>

<p dir="ltr">It outputs the following in a pop up window.</p>

<p dir="ltr"><span>Timer unit: 1e-06 s</span></p>

<p dir="ltr"><span>Total time: 0.003666 s<br/>
File: &lt;ipy<wbr>thon<wbr>-inp<wbr>ut-1<wbr>02-e<wbr>6043<wbr>a616<wbr>7d6&gt;<br/>
Function: mandelperf_numba at line 11</wbr></wbr></wbr></wbr></wbr></wbr></wbr></span></p>

<p dir="ltr"><span>Line #      Hits         Time  Per Hit   % Time  Line Contents<br/>
====<wbr>====<wbr>====<wbr>====<wbr>====<wbr>====<wbr>====<wbr>====<wbr>====<wbr>====<wbr>====<wbr>====<wbr>====<wbr>====<wbr>====<wbr>==<br/>
    11  <wbr>    <wbr>    <wbr>    <wbr>    <wbr>    <wbr>    <wbr>    <wbr>    <wbr>    <wbr>     def mandelperf_numba():<br/>
    12         1         1994   1994.0     54.4      r1 = np.linspace(-2.0, 0.5, 26)<br/>
    13         1          267    267.0      7.3      r2 = np.linspace(-1.0, 1.0, 21)<br/>
    14         1         1405   1405.0     38.3      return [man<wbr>del_<wbr>numb<wbr>a(co<wbr>mple<wbr>x(r, i)) for r in r1 for i in r2]</wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></span></p>

<p dir="ltr">We see that the bulk of the time is spent in the first and last lines of our <span>mandelperf_numba()</span> function.  The last line is a bit complex, let us break it into two pieces, and profile again:</p>

<blockquote dir="ltr">
<pre>
<span class="k">def</span> <span class="nf">mandelperf_numba</span><span class="p">():</span>
    <span class="n">r1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">26</span><span class="p">)</span>
    <span class="n">r2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mi">21</span><span class="p">)</span>
    <span class="n">c3</span> <span class="o">=</span> <span class="p">[</span><span class="nb">complex</span><span class="p">(</span><span class="n">r</span><span class="p">,</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">r1</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">r2</span><span class="p">]</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">mandel_numba</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">c3</span><span class="p">]</span></pre>
</blockquote>

<p dir="ltr">Profiler output becomes</p>

<p dir="ltr"><span>Timer unit: 1e-06 s</span></p>

<p dir="ltr"><span>Total time: 0.002002 s<br/>
File: &lt;ipy<wbr>thon<wbr>-inp<wbr>ut-1<wbr>13-b<wbr>a7b0<wbr>44b2<wbr>c6c&gt;<br/>
Function: mandelperf_numba at line 11</wbr></wbr></wbr></wbr></wbr></wbr></wbr></span></p>

<p dir="ltr"><span>Line #      Hits         Time  Per Hit   % Time  Line Contents<br/>
====<wbr>====<wbr>====<wbr>====<wbr>====<wbr>====<wbr>====<wbr>====<wbr>====<wbr>====<wbr>====<wbr>====<wbr>====<wbr>====<wbr>====<wbr>==<br/>
    11  <wbr>    <wbr>    <wbr>    <wbr>    <wbr>    <wbr>    <wbr>    <wbr>    <wbr>    <wbr>     def mandelperf_numba():<br/>
    12         1          678    678.0     33.9      r1 = np.linspace(-2.0, 0.5, 26)<br/>
    13         1          235    235.0     11.7      r2 = np.linspace(-1.0, 1.0, 21)<br/>
    14         1          617    617.0     30.8      c3 = [complex(r, i) for r in r1 for i in r2]<br/>
    15         1          472    472.0     23.6      return [mandel_numba(c) for c in c3]</wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></span></p>

<p dir="ltr">We see that the calls to the function <span>mandel_numba()</span> takes only one fourth of the total time.  The rest of the time is spent in the <span>mandelperf_numba()</span> function.  Optimizing it is worthwhile.</p>

<h2 dir="ltr">Using Numpy Again</h2>

<p dir="ltr">Using Cython isn't helping much here, and Numba does not apply.  One way out of this dilemma is to use Numpy again.  We will replace the following by Numpy code that produces an equivalent result.</p>

<p dir="ltr"><span>    return [ma<wbr>n<wbr/>del<wbr>_<wbr/>num<wbr>b<wbr/>a(c<wbr>o<wbr/>mpl<wbr>e<wbr/>x(r<wbr>, i)) for r in r1 for i in r2]</wbr></wbr></wbr></wbr></wbr></wbr></span></p>

<p dir="ltr">This code is building what is known as a 2D mesh.  It computes the complex number representation of points whose coordinates are given by <span>r1</span> and <span>r2</span>.  Point <em>P</em><sub><em>ij</em></sub> coordinates are <span>r1[i]</span> and <span>r2[j]</span>.  <em>P</em><sub><em>ij</em></sub> is represented by the complex number <span>r1[i] + 1j*r2[j]</span> where the special constant <span>1j </span>represents the unitary imaginary number <em>i. </em></p>

<p dir="ltr">We can code this computation directly:</p>

<blockquote dir="ltr">
<pre>
<span class="nd">@jit</span>
<span class="k">def</span> <span class="nf">mand<wbr>elpe<wbr>rf_n<wbr>umba<wbr>_mes<wbr>h</wbr></wbr></wbr></wbr></wbr></span><span class="p">()<wbr>:</wbr></span>
    <span class="n">width</span> <span class="o">=</span> <span class="mi">26</span>
    <span class="n">height</span> <span class="o">=</span> <span class="mi">21</span>
    <span class="n">r1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">width</span><span class="p">)</span>
    <span class="n">r2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">height</span><span class="p">)</span>
    <span class="n">mandel_set</span> <span class="o">=</span> <span class="n">n<wbr>p</wbr></span><span class="o">.</span><span class="n">em<wbr>pt<wbr>y</wbr></wbr></span><span class="p">(<wbr>(</wbr></span><span class="n">wid<wbr>t<wbr>h</wbr></wbr></span><span class="p">,</span><span class="n">he<wbr>igh<wbr>t</wbr></wbr></span><span class="p">)<wbr>,</wbr></span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">width</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">height</span><span class="p">):</span>
            <span class="n">mandel_set</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">mandel_numba</span><span class="p">(</span><span class="n">r1</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="n">j</span><span class="o">*</span><span class="n">r2</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">mandel_set</span></pre>
</blockquote>

<p dir="ltr">Note that I changed the return value to be a 2D array of integers.  That's closer to what we need if we were to display the result.</p>

<p dir="ltr">Timing it yields</p>

<p dir="ltr"><span>10000 loops, best of 3: 126 µs per loop </span></p>

<p dir="ltr">We are about 50 times faster than the original Python code!  Julia takes 196 micro seconds on that benchmark, hence compiled Python is 60% faster.</p>

<p dir="ltr">[Edited on February 2, 2016].  We can do even better in Python, see <a href="https://www.ibm.com/developerworks/community/blogs/jfp/entry/How_To_Compute_Mandelbrodt_Set_Quickly?lang=en">How <wbr>To Q<wbr>uick<wbr>ly C<wbr>ompu<wbr>te M<wbr>ande<wbr>lbro<wbr>t Se<wbr>t In<wbr> Pyt<wbr>hon<wbr>.</wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></a></p>

<h2 dir="ltr">Vectorizing</h2>

<p dir="ltr">Let us look at another example.  I am not sure about what is measured to be honest, but here is the code the Julia team used .</p>

<blockquote dir="ltr">
<pre>
<span class="k">def</span> <span class="nf">parse_int</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1000</span><span class="p">):</span>
        <span class="n">n</span> <span class="o">=</span> <span class="n">rand<wbr>o<wbr>m</wbr></wbr></span><span class="o">.</span><span class="n">ra<wbr>ndin<wbr>t</wbr></wbr></span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi"><wbr>2</wbr></span><span class="o">*<wbr>*</wbr></span><span class="mi">3<wbr>2</wbr></span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">s</span> <span class="o">=</span> <span class="nb">hex</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
        <span class="n">m</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="mi">16</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">m</span> <span class="o">==</span> <span class="n">n</span></pre>
</blockquote>

<p dir="ltr">Actually Julia's team code has an extra instruction that strips the ending<span> 'L' </span>in case it is present.  That line is required for my Anaconda install, but it is not required for my Python 3 install, therefore I removed it.  The original code is:</p>

<blockquote dir="ltr">
<pre>
<span class="k">def</span> <span class="nf">parse_int</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1000</span><span class="p">):</span>
        <span class="n">n</span> <span class="o">=</span> <span class="n">rand<wbr>o<wbr>m</wbr></wbr></span><span class="o">.</span><span class="n">ra<wbr>ndin<wbr>t</wbr></wbr></span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi"><wbr>2</wbr></span><span class="o">*<wbr>*</wbr></span><span class="mi">3<wbr>2</wbr></span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">s</span> <span class="o">=</span> <span class="nb">hex</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">s</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">==</span><span class="s1">'L'</span><span class="p">:</span>
            <span class="n">s</span> <span class="o">=</span> <span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>    
        <span class="n">m</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="mi">16</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">m</span> <span class="o">==</span> <span class="n">n</span></pre>
</blockquote>

<p dir="ltr">Timing the modified code yields:</p>

<p dir="ltr"><span>100 loops, best of 3: 3.29 ms per loop</span></p>

<p dir="ltr">Neither Numba nor Cython seem to help.</p>

<p dir="ltr">As I was puzzled by this benchmark, I profiled the original code.  Here is the result:</p>

<p dir="ltr"><span>Timer unit: 1e-06 s</span></p>

<p dir="ltr"><span>Total time: 0.013807 s<br/>
File: &lt;ipy<wbr>thon<wbr>-inp<wbr>ut-3<wbr>-1d9<wbr>9550<wbr>5b17<wbr>6&gt;<br/>
Function: parse_int at line 1</wbr></wbr></wbr></wbr></wbr></wbr></wbr></span></p>

<p dir="ltr"><span>Line #      Hits         Time  Per Hit   % Time  Line Contents<br/>
====<wbr>====<wbr>====<wbr>====<wbr>====<wbr>====<wbr>====<wbr>====<wbr>====<wbr>====<wbr>====<wbr>====<wbr>====<wbr>====<wbr>====<wbr>==<br/>
     1   <wbr>    <wbr>    <wbr>    <wbr>    <wbr>    <wbr>    <wbr>    <wbr>    <wbr>    <wbr>    def parse_int():<br/>
     2      1000          699      0.7      5.1      for i in range(1,1000):<br/>
     3       999         9149      9.2     66.3          n = rand<wbr>om.r<wbr>andi<wbr>nt(0<wbr>,2**<wbr>32-1<wbr>)<br/>
     4       999         1024      1.0      7.4          s = hex(n)<br/>
     5       999          863      0.9      6.3          if s[-1]=='L':<br/>
     6   <wbr>    <wbr>    <wbr>    <wbr>    <wbr>    <wbr>    <wbr>    <wbr>    <wbr>    <wbr>    <wbr>    <wbr>    <wbr>    s = s[0:-1]<br/>
     7       999         1334      1.3      9.7          m = int(s,16)<br/>
     8       999          738      0.7      5.3          assert m == n</wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></span></p>

<p dir="ltr"> </p>

<p dir="ltr">We see that most of the time is in generating the random numbers.  I am not sure this was the intent of the benchmark...</p>

<p dir="ltr">One way to speed this up is to move the generation of random numbers out of the loop using Numpy.  We create an array of random numbers in one step.  Given Numpy uses C ints, we must limit the largest value to 2^31 - 1.</p>

<blockquote dir="ltr">
<pre>
<span class="k">def</span> <span class="nf">parse_int_vec</span><span class="p">():</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">n<wbr>p</wbr></span><span class="o">.</span><span class="n">ra<wbr>ndo<wbr>m</wbr></wbr></span><span class="o">.</span><span class="n">ra<wbr>ndin<wbr>t</wbr></wbr></span><span class="p">(</span><span class="mi">2</span><span class="o">^</span><span class="mi"><wbr>3<wbr>1</wbr></wbr></span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n"><wbr>siz<wbr>e</wbr></wbr></span><span class="o">=</span><span class="mi">10<wbr>0<wbr>0</wbr></wbr></span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1000</span><span class="p">):</span>
        <span class="n">ni</span> <span class="o">=</span> <span class="n">n</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">s</span> <span class="o">=</span> <span class="nb">hex</span><span class="p">(</span><span class="n">ni</span><span class="p">)</span>
        <span class="n">m</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="mi">16</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">m</span> <span class="o">==</span> <span class="n">ni</span></pre>
</blockquote>

<p dir="ltr">Timing it yields:</p>

<p dir="ltr"><span>1000 loops, best of 3: 848 µs per loop</span></p>

<p dir="ltr">Not bad, 4 times faster and close to the Cython code speed.</p>

<p dir="ltr">Once we have an array it seems silly to loop over it to apply the <span>hex()</span> and the <span>int()</span> functions one element at a time.  Good news it that Numpy provides a way to apply functions to an array rather than in a loop, namely the <span>numpy.vectorize() </span>function.  This function takes as input a function that operate one one object at a time  It returns a new function that operates on an array.</p>

<blockquote dir="ltr">
<pre>
<span class="n">vhex</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vectorize</span><span class="p">(</span><span class="nb">hex</span><span class="p">)</span>
<span class="n">vint</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vectorize</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">parse_int_numpy</span><span class="p">():</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">n<wbr>p</wbr></span><span class="o">.</span><span class="n">ra<wbr>ndo<wbr>m</wbr></wbr></span><span class="o">.</span><span class="n">ra<wbr>ndin<wbr>t</wbr></wbr></span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi"><wbr>2</wbr></span><span class="o">*<wbr>*</wbr></span><span class="mi">3<wbr>1</wbr></span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi"><wbr>100<wbr>0</wbr></wbr></span><span class="p">)</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">vhex</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">vint</span><span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="mi">16</span><span class="p">)</span>
    <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">m</span> <span class="o">==</span> <span class="n">n</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">s</span>
</pre>
</blockquote>

<p dir="ltr">This code runs a bit faster, and nearly as fast as the Cython code:</p>

<p dir="ltr"><span>1000 loops, best of 3: 733 µs per loop</span></p>

<p dir="ltr">Cython can be used to sped this up.</p>

<blockquote dir="ltr">
<pre>
<span class="o">%%</span><span class="n">cython</span>
<span class="k">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="k">import</span> <span class="nn">cython</span>

<span class="nd">@cyt<wbr>ho<wbr>n</wbr></wbr></span><span class="o">.</span><span class="n">bo<wbr>unds<wbr>chec<wbr>k</wbr></wbr></wbr></span><span class="p">(</span><span class="bp">Fa<wbr>ls<wbr>e</wbr></wbr></span><span class="p">)</span>
<span class="nd">@cyt<wbr>ho<wbr>n</wbr></wbr></span><span class="o">.</span><span class="n">wr<wbr>apar<wbr>oun<wbr>d</wbr></wbr></wbr></span><span class="p">(</span><span class="bp">Fa<wbr>ls<wbr>e</wbr></wbr></span><span class="p">)</span>
<span class="k">cpdef</span> <span class="nf">pars<wbr>e_in<wbr>t_ve<wbr>c_cy<wbr>tho<wbr>n</wbr></wbr></wbr></wbr></wbr></span><span class="p">()<wbr>:</wbr></span>
    <span class="k">cdef</span><span class="p">:</span>
        <span class="nb">int</span> <span class="n">i</span><span class="p">,</span><span class="n">m</span>
        <span class="nb">int</span><span class="p">[:]</span> <span class="n">n</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">n<wbr>p</wbr></span><span class="o">.</span><span class="n">ra<wbr>ndo<wbr>m</wbr></wbr></span><span class="o">.</span><span class="n">ra<wbr>ndin<wbr>t</wbr></wbr></span><span class="p">(</span><span class="mf">0</span><span class="p">,</span><span class="mf"><wbr>2</wbr></span><span class="o">*<wbr>*</wbr></span><span class="mf">3<wbr>1</wbr></span><span class="o">-</span><span class="mf">1</span><span class="p">,</span><span class="mf"><wbr>100<wbr>0</wbr></wbr></span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mf">1</span><span class="p">,</span><span class="mf">1000</span><span class="p">):</span>
        <span class="n">m</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">hex</span><span class="p">(</span><span class="n">n</span><span class="p">[</span><span class="n">i</span><span class="p">]),</span><span class="mf">16</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">m</span> <span class="o">==</span> <span class="n">n</span><span class="p">[</span><span class="n">i</span><span class="p">]</span></pre>
</blockquote>

<p dir="ltr">Timing it yields.</p>

<p dir="ltr"><span>1000 loops, best of 3: 472 µs per loop</span></p>

<h2 dir="ltr">Summary</h2>

<p dir="ltr">We have described above how to speed up 4 of the examples used by the Julia team.  There are 3 more:</p>

<ul dir="ltr">
	<li>pisum can run 29 times faster with Numba. </li>
	<li>randmatstat can be made 2 times faster by better use of Numpy. </li>
	<li>randmatmul is so simple that no tool can be applied to it. </li>
</ul>

<p dir="ltr">The notebook containing complete code for all 7 examples is available <a href="https://gist.github.com/jfpuget/b53f1e15a37aba5944ad">on github</a> and on <a href="http://nbviewer.jupyter.org/gist/jfpuget/b53f1e15a37aba5944ad">nbviewer</a>.</p>

<p dir="ltr">Let's summarize in a table where we are.  We display the speedup we get between the original Python code and the optimized one.  We also display the tools we used  for each of the benchmark example used by the Julia team.</p>

<p dir="ltr"> </p>

<table border="1" dir="ltr">
	<tbody>
		<tr>
			<td>Time in micro seconds</td>
			<td>Julia</td>
			<td>
			<p>Python</p>

			<p>Optimized</p>
			</td>
			<td>Python Original</td>
			<td>Julia / Python Optimized</td>
			<td>Numpy</td>
			<td>Numba</td>
			<td>Cython</td>
		</tr>
		<tr>
			<td>
			<p>Fibonacci<br/>
			64 bits</p>
			</td>
			<td>80</td>
			<td>24</td>
			<td>NA</td>
			<td>3.8</td>
			<td> </td>
			<td> </td>
			<td>X</td>
		</tr>
		<tr>
			<td>Fib BigInt</td>
			<td>12,717</td>
			<td>1,470</td>
			<td>3,770</td>
			<td>8.7</td>
			<td> </td>
			<td> </td>
			<td> </td>
		</tr>
		<tr>
			<td>quicksort</td>
			<td>419</td>
			<td>306</td>
			<td>17,700</td>
			<td>1.4</td>
			<td>X</td>
			<td> </td>
			<td>X</td>
		</tr>
		<tr>
			<td>Mandelbrot</td>
			<td>196</td>
			<td>126</td>
			<td>6,570</td>
			<td>1.6</td>
			<td>X</td>
			<td>X</td>
			<td> </td>
		</tr>
		<tr>
			<td>pisum</td>
			<td>34,783</td>
			<td>20,400</td>
			<td>926,000</td>
			<td>1.7</td>
			<td> </td>
			<td>X</td>
			<td> </td>
		</tr>
		<tr>
			<td>randmatmul</td>
			<td>95,975</td>
			<td>83,7000</td>
			<td>83,700</td>
			<td>1.1</td>
			<td>X</td>
			<td> </td>
			<td> </td>
		</tr>
		<tr>
			<td>parse int</td>
			<td>244</td>
			<td>472</td>
			<td>3,290</td>
			<td>0.5</td>
			<td>X</td>
			<td> </td>
			<td>X</td>
		</tr>
		<tr>
			<td>randmatstat</td>
			<td>14,544</td>
			<td>83,200</td>
			<td>160,000</td>
			<td>0.2</td>
			<td>X</td>
			<td> </td>
			<td> </td>
		</tr>
	</tbody>
</table>

<p dir="ltr"> </p>

<p dir="ltr">This table shows that optimized Python code is faster than Julia for the first 6 examples, and slower for the last 2.  Note that for Fibonacci I used the recursive code to be fair.  </p>

<p dir="ltr">I do not think that these micro benchmarks provide a definite answer about which language is fastest.  For instance, the randmatstat example deals with 5x5 matrices.  Using Numpy arrays for that is an overkill.  One should benchmark with way larger matrices. </p>

<p dir="ltr">I believe that one should benchmark languages on more complex code.  A good example is given in <a href="http://tullo.ch/articles/python-vs-julia/">Pyth<wbr>on v<wbr>s Ju<wbr>lia <wbr>- an<wbr> exa<wbr>mple<wbr> fro<wbr>m ma<wbr>chin<wbr>e le<wbr>arni<wbr>ng.  </wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></a>In that article, Julia seems to outperform Cython.  If I have time I'll give it a try with Numba.</p>

<p dir="ltr">Anyway, it is fair to say that on the micro benchmark, Python performance matches Julia performance when the right tools are used.  Conversely, we can also say that Julia's performance matches that of compiled Python.  This in itself is interesting given Julia does it without any need to annotate or modify the code.</p>

<h2 dir="ltr">Takeway</h2>

<p dir="ltr">Let's pause for a moment.  We have seen a number of tools that should be used when Python code performance is critical:</p>

<ul dir="ltr">
	<li>Profiling with line_profiler.</li>
	<li>Writing better Python code to avoid unnecessary computation.</li>
	<li>Using vectorized operations and broadcasting with Numpy.</li>
	<li>Compiling with Cython or Numba.</li>
</ul>

<p dir="ltr">Use these tools to get a feel of where they are useful.  At the same time, use these tools wisely.  Profile your code so that you can focus on where optimization is worth it.  Indeed, rewriting code to make it faster can sometime obfuscate it or make it less versatile.  Therefore, only do this when the resulting speedup is worth it.   Donald Knuth once captured nicely this advice :</p>

<p dir="ltr"><em>” We should forget about small efficiencies, say about 97% of the time: premature optimization is the root of all evil.”</em></p>

<p dir="ltr">Note however that Knuth's quote does not mean optimization isn't worth it, see for inst<wbr>ance<wbr> <a href="http://www.joshbarczak.com/blog/?p=580">Sto<wbr>p Mi<wbr>squo<wbr>ting<wbr> Don<wbr>ald <wbr>Knut<wbr>h<wbr>!</wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></a> and <a href="http://joeduffyblog.com/2010/09/06/the-premature-optimization-is-evil-myth/">The <wbr>'pre<wbr>matu<wbr>re o<wbr>ptim<wbr>izat<wbr>ion <wbr>is e<wbr>vil'<wbr> myt<wbr>h</wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></wbr></a>. </wbr></wbr></p>

<p dir="ltr">Python code can, and should be, optimized when and where it makes sense.</p>

<p dir="ltr">Let me conclude with a list of interesting articles discussing the tools I used and more:</p>



<p dir="ltr"><strong>Update on december 16, 2015.</strong> Python 3.4 has a built-in cache that can greatly speed up Fibonacci() function.  I updated the post to show its use.</p>

<p dir="ltr"><strong>Update on December 17, 2015.</strong>  Added running times for Julia 0.4.2 on the same machine where Python was run. </p>

<p dir="ltr"><strong>Update on Feb 2, 2016.</strong>  Added the code <a href="https://gist.github.com/jfpuget/b53f1e15a37aba5944ad">on github</a> and on <a href="http://nbviewer.jupyter.org/gist/jfpuget/b53f1e15a37aba5944ad">nbviewer</a>., and updated timings with Python 3.5.1.</p>

<p dir="ltr"> </p>           
                                	              		            			
			   <span class="min-tags" role="list">
				Tags:&amp;nbsp
			       			        <span role="listitem">
					<a href="https://www.ibm.com/developerworks/community/blogs/jfp?tags=numpy&amp;lang=en" title="numpy">numpy</a>
				</span>
							        <span role="listitem">
					<a href="https://www.ibm.com/developerworks/community/blogs/jfp?tags=python&amp;lang=en" title="python">python</a>
				</span>
							        <span role="listitem">
					<a href="https://www.ibm.com/developerworks/community/blogs/jfp?tags=numba&amp;lang=en" title="numba">numba</a>
				</span>
							        <span role="listitem">
					<a href="https://www.ibm.com/developerworks/community/blogs/jfp?tags=julia&amp;lang=en" title="julia">julia</a>
				</span>
							        <span role="listitem">
					<a href="https://www.ibm.com/developerworks/community/blogs/jfp?tags=cython&amp;lang=en" title="cython">cython</a>
				</span>
							  </span>
			                     <p/>

                    
                                                                  
                                                   
           <p/>
           
	        </div>
 		</div></body></html>