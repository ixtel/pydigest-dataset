<html><body><div><div class="section">
              <h1>tabutils 0.27.2</h1>

              


<p>A (tabular) data processing toolkit</p><p>








tabutils: A Python toolkit for processing tabular data</p><p>======================================================</p><p>|travis| |versions| |pypi|</p><p>Index</p><p>-----</p><p>`Introduction`_ | `Requirements`_ | `Motivation`_ | `Usage`_ | `Interoperability`_ |</p><p>`Installation`_ | `Project Structure`_ | `Design Principles`_ | `Readers`_ |</p><p>`Scripts`_ | `Contributing`_ | `Credits`_ | `License`_</p><p>Introduction</p><p>------------</p><p>**tabutils** is a Python `library`_ for reading and processing tabular data.</p><p>It has a functional programming style API, excels at reading, large files,</p><p>and can process 10+ file types.</p><p>With tabutils, you can</p><p>- Read csv/xls/xlsx/mdb/dbf files, and more!</p><p>- Type cast records (date, float, text...)</p><p>- Process Uñicôdë text</p><p>- Lazily stream files by default</p><p>- and much more...</p><p>Requirements</p><p>------------</p><p>tabutils has been tested and is known to work on Python 2.7, 3.4, and 3.5;</p><p>PyPy 4.0; and PyPy3 2.4</p><p>Optional Dependencies</p><p>^^^^^^^^^^^^^^^^^^^^^</p><p>==================================  ==============  ==============================  =======================</p><p>Function                            Dependency      Installation                    File type / extension</p><p>==================================  ==============  ==============================  =======================</p><p>``tabutils.io.read_mdb``            `mdbtools`_     ``sudo port install mdbtools``  Microsoft Access / mdb</p><p>``tabutils.io.read_html``           `lxml`_ [#]_    ``pip install lxml``            HTML / html</p><p>``tabutils.convert.records2array``  `NumPy`_ [#]_   ``pip install numpy``           n/a</p><p>``tabutils.convert.records2df``     `pandas`_       ``pip install pandas``          n/a</p><p>==================================  ==============  ==============================  =======================</p><p>Notes</p><p>^^^^^</p><p>.. [#] If ``lxml`` isn't present, ``read_html`` will default to the builtin Python html reader</p><p>.. [#] ``records2array`` can be used without ``numpy`` by passing ``native=True`` in the function call. This will convert ``records`` into a list of native ``array.array`` objects.</p><p>Motivation</p><p>----------</p><p>pandas is great, but installing it isn't exactly a `walk in the park`_. It also</p><p>doesn't play nice with `PyPy`_. `csvkit`_ is an equally useful project, but it</p><p>doesn't expose the same API when used as `a library`_ as it does via the command</p><p>line. I designed **tabutils** to provide much of same functionality as</p><p>pandas and csvkit, while using functional programming methods.</p><p>A simple data processing example is shown below:</p><p>First create a simple csv file (in bash)</p><p>.. code-block:: bash</p><p>    echo 'col1,col2,col3\nhello,5/4/82,1\none,1/1/15,2\nhappy,7/1/92,3\n' &gt; data.csv</p><p>Now we can read the file, manipulate the data a bit, and write the manipulated</p><p>data back to a new file.</p><p>.. code-block:: python</p><p>    from tabutils import io, process as pr, convert as cv</p><p>    from io import open</p><p>    # Load the csv file</p><p>    records = io.read_csv('data.csv')</p><p>    # `records` are iterators over the rows</p><p>    row = next(records)</p><p>    row</p><p>    &gt;&gt;&gt; {'col1': 'hello', 'col2': '5/4/82', 'col3': '1'}</p><p>    # Let's replace the first row so as not to loose any data</p><p>    records = pr.prepend(records, row)</p><p>    # Guess column types. Note: `detect_types` returns a new `records`</p><p>    # generator since it consumes rows during type detection</p><p>    records, result = pr.detect_types(records)</p><p>    {t['id']: t['type'] for t in result['types']}</p><p>    &gt;&gt;&gt; {'col1': 'text', 'col2': 'date', 'col3': 'int'}</p><p>    # Now type cast the records. Note: most `tabutils.process` functions return</p><p>    # generators, so lets wrap the result in a list to view the data</p><p>    casted = list(pr.type_cast(records, result['types']))</p><p>    casted[0]</p><p>    &gt;&gt;&gt; {'col1': 'hello', 'col2': datetime.date(1982, 5, 4), 'col3': 1}</p><p>    # Cut out the first column of data and merge the rows to get the max value</p><p>    # of the remaining columns. Note: since `merge` (by definition) will always</p><p>    # contain just one row, it is returned as is (not wrapped in a generator)</p><p>    cut_recs = pr.cut(casted, ['col1'], exclude=True)</p><p>    merged = pr.merge(cut_recs, pred=bool, op=max)</p><p>    merged</p><p>    &gt;&gt;&gt; {'col2': datetime.date(2015, 1, 1), 'col3': 3}</p><p>    # Now write merged data back to a new csv file.</p><p>    io.write('out.csv', cv.records2csv(merged))</p><p>    # View the result</p><p>    with open('out.csv', 'utf-8') as f:</p><p>        f.read()</p><p>    &gt;&gt;&gt; 'col2,col3\n2015-01-01,3\n'</p><p>Usage</p><p>-----</p><p>tabutils is intended to be used directly as a Python library.</p><p>Usage Index</p><p>^^^^^^^^^^^</p><p>- `Reading data`_</p><p>- `Processing data`_</p><p>  + `Numerical analysis (à la pandas)`_</p><p>  + `Text processing (à la csvkit)`_</p><p>  + `Geo processing (à la mapbox)`_</p><p>- `Writing data`_</p><p>- `Cookbook`_</p><p>Reading data</p><p>^^^^^^^^^^^^</p><p>tabutils can read both filepaths and file-like objects. Additionally, all readers</p><p>return equivalent `records` iterators, i.e., a generator of dictionaries with</p><p>keys corresponding to the column names.</p><p>.. code-block:: python</p><p>    from io import open, StringIO</p><p>    from tabutils import io</p><p>    """Read a filepath"""</p><p>    records = io.read_json('path/to/file.json')</p><p>    """Read a file like object and de-duplicate the header"""</p><p>    f = StringIO('col,col\nhello,world\n')</p><p>    records = io.read_csv(f, dedupe=True)</p><p>    """View the first row"""</p><p>    next(records)</p><p>    &gt;&gt;&gt; {'col': 'hello', 'col_2': 'world'}</p><p>    """Read the 1st sheet of an xls file object opened in text mode."""</p><p>    # Also, santize the header names by converting them to lowercase and</p><p>    # replacing whitespace and invalid characters with `_`.</p><p>    with open('path/to/file.xls', 'utf-8') as f:</p><p>        for row in io.read_xls(f, sanitize=True):</p><p>            # do something with the `row`</p><p>            pass</p><p>    """Read the 2nd sheet of an xlsx file object opened in binary mode"""</p><p>    # Note: sheets are zero indexed</p><p>    with open('path/to/file.xlsx') as f:</p><p>        records = io.read_xls(f, encoding='utf-8', sheet=1)</p><p>        first_row = next(records)</p><p>        # do something with the `first_row`</p><p>    """Read any recognized file"""</p><p>    records = io.read('path/to/file.geojson')</p><p>    f.seek(0)</p><p>    records = io.read(f, ext='csv', dedupe=True)</p><p>Please see `Readers`_ for a complete list of available readers and recognized</p><p>file types.</p><p>Processing data</p><p>^^^^^^^^^^^^^^^</p><p>Numerical analysis (à la pandas) [#]_</p><p>~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</p><p>In the following example, ``pandas`` equivalent methods are preceded by ``--&gt;``,</p><p>and command output is preceded by ``&gt;&gt;&gt;``.</p><p>.. code-block:: python</p><p>    import itertools as it</p><p>    import random</p><p>    from io import StringIO</p><p>    from tabutils import io, process as pr, convert as cv, stats</p><p>    # Create some data in the same structure as what the various `read...`</p><p>    # functions output</p><p>    header = ['A', 'B', 'C', 'D']</p><p>    data = [(random.random() for _ in range(4)) for x in range(7)]</p><p>    df = [dict(zip(header, d)) for d in data]</p><p>    df[0]</p><p>    &gt;&gt;&gt; {'A': 0.53908..., 'B': 0.28919..., 'C': 0.03003..., 'D': 0.65363...}</p><p>    """Sort records by the value of column `B` --&gt; df.sort_values(by='B')"""</p><p>    next(pr.sort(df, 'B'))</p><p>    &gt;&gt;&gt; {'A': 0.53520..., 'B': 0.06763..., 'C': 0.02351..., 'D': 0.80529...}</p><p>    """Select column `A` --&gt; df['A']"""</p><p>    next(pr.cut(df, ['A']))</p><p>    &gt;&gt;&gt; {'A': 0.53908170489952006}</p><p>    """Select the first the rows of data --&gt; df[0:3]"""</p><p>    len(list(it.islice(df, 3)))</p><p>    &gt;&gt;&gt; 3</p><p>    """Select all data whose value for column `A` is less than 0.5</p><p>    --&gt; df[df.A &lt; 0.5]</p><p>    """</p><p>    next(pr.tfilter(df, 'A', lambda x: x &lt; 0.5))</p><p>    &gt;&gt;&gt; {'A': 0.21000..., 'B': 0.25727..., 'C': 0.39719..., 'D': 0.64157...}</p><p>    # Note: since `aggregate` and `merge` (by definition) return just one row,</p><p>    # they return them as is (not wrapped in a generator).</p><p>    """Calculate the mean of column `A` across all data --&gt; df.mean()['A']"""</p><p>    pr.aggregate(df, 'A', stats.mean)['A']</p><p>    &gt;&gt;&gt; 0.5410437473067938</p><p>    """Calculate the sum of each column across all data --&gt; df.sum()"""</p><p>    pr.merge(df, pred=bool, op=sum)</p><p>    &gt;&gt;&gt; {'A': 3.78730..., 'C': 2.82875..., 'B': 3.14195..., 'D': 5.26330...}</p><p>Text processing (à la csvkit) [#]_</p><p>~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</p><p>In the following example, ``csvkit`` equivalent commands are preceded by ``--&gt;``,</p><p>and command output is preceded by ``&gt;&gt;&gt;``.</p><p>First create a few simple csv files (in bash)</p><p>.. code-block:: bash</p><p>    echo 'col_1,col_2,col_3\n1,dill,male\n2,bob,male\n3,jane,female' &gt; file1.csv</p><p>    echo 'col_1,col_2,col_3\n4,tom,male\n5,dick,male\n6,jill,female' &gt; file2.csv</p><p>Now we can read the files, manipulate the data, convert the manipulated data to</p><p>json, and write the json back to a new file. Also, note that since all readers</p><p>return equivalent `records` iterators, you can use them interchangeably (in</p><p>place of ``read_csv``) to open any supported file. E.g., ``read_xls``,</p><p>``read_sqlite``, etc.</p><p>.. code-block:: python</p><p>    import itertools as it</p><p>    from tabutils import io, process as pr, convert as cv</p><p>    """Combine the files into one iterator</p><p>    --&gt; csvstack file1.csv file2.csv</p><p>    """</p><p>    records = io.join('file1.csv', 'file2.csv')</p><p>    next(records)</p><p>    &gt;&gt;&gt; {'col_1': '1', 'col_2': 'dill', 'col_3': 'male'}</p><p>    next(it.islice(records, 4, None))</p><p>    &gt;&gt;&gt; {'col_1': '6', 'col_2': 'jill', 'col_3': 'female'}</p><p>    # Now let's create a persistant records list</p><p>    records = list(io.read_csv('file1.csv'))</p><p>    """Sort records by the value of column `col_2`</p><p>    --&gt; csvsort -c col_2 file1.csv</p><p>    """</p><p>    next(pr.sort(records, 'col_2'))</p><p>    &gt;&gt;&gt; {'col_1': '2', 'col_2': 'bob', 'col_3': 'male'</p><p>    """Select column `col_2` --&gt; csvcut -c col_2 file1.csv"""</p><p>    next(pr.cut(records, ['col_2']))</p><p>    &gt;&gt;&gt; {'col_2': 'dill'}</p><p>    """Select all data whose value for column `col_2` contains `jan`</p><p>    --&gt; csvgrep -c col_2 -m jan file1.csv</p><p>    """</p><p>    next(pr.grep(records, [{'pattern': 'jan'}], ['col_2']))</p><p>    &gt;&gt;&gt; {'col_1': '3', 'col_2': 'jane', 'col_3': 'female'}</p><p>    """Convert a csv file to json --&gt; csvjson -i 4 file1.csv"""</p><p>    io.write('file.json', cv.records2json(records))</p><p>    # View the result</p><p>    with open('file.json', 'utf-8') as f:</p><p>        f.read()</p><p>    &gt;&gt;&gt; '[{"col_1": "1", "col_2": "dill", "col_3": "male"}, {"col_1": "2",</p><p>    ... "col_2": "bob", "col_3": "male"}, {"col_1": "3", "col_2": "jane",</p><p>    ... "col_3": "female"}]'</p><p>Geo processing (à la mapbox) [#]_</p><p>~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</p><p>In the following example, ``mapbox`` equivalent commands are preceded by ``--&gt;``,</p><p>and command output is preceded by ``&gt;&gt;&gt;``.</p><p>First create a geojson file (in bash)</p><p>.. code-block:: bash</p><p>    echo '{"type": "FeatureCollection","features": [' &gt; file.geojson</p><p>    echo '{"type": "Feature", "id": 11, "geometry": {"type": "Point", "coordinates": [10, 20]}},' &gt;&gt; file.geojson</p><p>    echo '{"type": "Feature", "id": 12, "geometry": {"type": "Point", "coordinates": [5, 15]}}]}' &gt;&gt; file.geojson</p><p>Now we can open the file, split the data by id, and finally convert the split data</p><p>to a new geojson file-like object.</p><p>.. code-block:: python</p><p>    from tabutils import io, process as pr, convert as cv</p><p>    # Load the geojson file and peek at the results</p><p>    records, peek = pr.peek(io.read_geojson('file.geojson'))</p><p>    peek[0]</p><p>    &gt;&gt;&gt; {'lat': 20, 'type': 'Point', 'lon': 10, 'id': 11}</p><p>    """Split the records by feature ``id`` and select the first feature</p><p>    --&gt; geojsplit -k id file.geojson</p><p>    """</p><p>    splits = pr.split(records, 'id')</p><p>    feature_records, name = next(splits)</p><p>    name</p><p>    &gt;&gt;&gt; 11</p><p>    """Convert the feature records into a GeoJSON file-like object"""</p><p>    geojson = cv.records2geojson(feature_records)</p><p>    geojson.readline()</p><p>    &gt;&gt;&gt; '{"type": "FeatureCollection", "bbox": [10, 20, 10, 20], "features": '</p><p>    ... '[{"type": "Feature", "id": 11, "geometry": {"type": "Point", '</p><p>    ... '"coordinates": [10, 20]}, "properties": {"id": 11}}], "crs": {"type": '</p><p>    ... '"name", "properties": {"name": "urn:ogc:def:crs:OGC:1.3:CRS84"}}}'</p><p>    # Note: you can also write back to a file as shown previously</p><p>    # io.write('file.geojson', geojson)</p><p>Writing data</p><p>^^^^^^^^^^^^</p><p>tabutils can persist ``records`` to disk via the following functions:</p><p>- ``tabutils.convert.records2csv``</p><p>- ``tabutils.convert.records2json``</p><p>- ``tabutils.convert.records2geojson``</p><p>Each function returns a file-like object that you can write to disk via</p><p>``tabutils.io.write('/path/to/file', result)``.</p><p>.. code-block:: python</p><p>    from tabutils import io, convert as cv</p><p>    from io import StringIO, open</p><p>    # First let's create a simple tsv file like object</p><p>    f = StringIO('col1\tcol2\nhello\tworld\n')</p><p>    f.seek(0)</p><p>    # Next create a records list so we can reuse it</p><p>    records = list(io.read_tsv(f))</p><p>    records[0]</p><p>    &gt;&gt;&gt; {'col1': 'hello', 'col2': 'world'}</p><p>    # Now we're ready to write the records data to file</p><p>    """Create a csv file like object"""</p><p>    cv.records2csv(records).readline()</p><p>    &gt;&gt;&gt; 'col1,col2\n'</p><p>    """Create a json file like object"""</p><p>    cv.records2json(records).readline()</p><p>    &gt;&gt;&gt; '[{"col1": "hello", "col2": "world"}]'</p><p>    """Write back csv to a filepath"""</p><p>    io.write('file.csv', cv.records2csv(records))</p><p>    with open('file.csv', 'utf-8') as f_in:</p><p>        f_in.read()</p><p>    &gt;&gt;&gt; 'col1,col2\nhello,world\n'</p><p>    """Write back json to a filepath"""</p><p>    io.write('file.json', cv.records2json(records))</p><p>    with open('file.json', 'utf-8') as f_in:</p><p>        f_in.readline()</p><p>    &gt;&gt;&gt; '[{"col1": "hello", "col2": "world"}]'</p><p>Cookbook</p><p>^^^^^^^^</p><p>Please see the `cookbook guide`_ for more examples.</p><p>Notes</p><p>^^^^^</p><p>.. [#] http://pandas.pydata.org/pandas-docs/stable/10min.html#min</p><p>.. [#] https://csvkit.readthedocs.org/en/0.9.1/cli.html#processing</p><p>.. [#] https://github.com/mapbox?utf8=%E2%9C%93&amp;query=geojson</p><p>Interoperability</p><p>----------------</p><p>tabutils plays nicely with NumPy and friends out of the box</p><p>setup</p><p>^^^^^</p><p>.. code-block:: python</p><p>    from tabutils import process as pr</p><p>    # First create some records and types. Also, convert the records to a list</p><p>    # so we can reuse them.</p><p>    records = [{'a': 'one', 'b': 2}, {'a': 'five', 'b': 10, 'c': 20.1}]</p><p>    records, result = pr.detect_types(records)</p><p>    records, types = list(records), result['types']</p><p>    types</p><p>    &gt;&gt;&gt; [</p><p>    ...     {'type': 'text', 'id': 'a'},</p><p>    ...     {'type': 'int', 'id': 'b'},</p><p>    ...     {'type': 'float', 'id': 'c'}]</p><p>from records to pandas.DataFrame to records</p><p>^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^</p><p>.. code-block:: python</p><p>    import pandas as pd</p><p>    from tabutils import convert as cv</p><p>    """Convert the records to a DataFrame"""</p><p>    df = cv.records2df(records, types)</p><p>    df</p><p>    &gt;&gt;&gt;         a   b   c</p><p>    ... 0   one   2   NaN</p><p>    ... 1  five  10  20.1</p><p>    # Alternatively, you can do `pd.DataFrame(records)`</p><p>    """Convert the DataFrame back to records"""</p><p>    next(cv.df2records(df))</p><p>    &gt;&gt;&gt; {'a': 'one', 'b': 2, 'c': nan}</p><p>from records to arrays to records</p><p>^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^</p><p>.. code-block:: python</p><p>    import numpy as np</p><p>    from array import array</p><p>    from tabutils import convert as cv</p><p>    """Convert records to a structured array"""</p><p>    recarray = cv.records2array(records, types)</p><p>    recarray</p><p>    &gt;&gt;&gt; rec.array([('one', 2, nan), ('five', 10, 20.100000381469727)],</p><p>    ...           dtype=[('a', 'O'), ('b', '&lt;i4'), ('c',="" '&lt;f4')])&lt;br=""&gt;    recarray.b</p><p>    &gt;&gt;&gt; array([ 2, 10], dtype=int32)</p><p>    """Convert records to a native array"""</p><p>    narray = cv.records2array(records, types, native=True)</p><p>    narray</p><p>    &gt;&gt;&gt; [[array('u', 'a'), array('u', 'b'), array('u', 'c')],</p><p>    ... [array('u', 'one'), array('u', 'five')],</p><p>    ... array('i', [2, 10]),</p><p>    ... array('f', [0.0, 20.100000381469727])]</p><p>    """Convert a 2-D NumPy array to a records generator"""</p><p>    data = np.array([[1, 2, 3], [4, 5, 6]], np.int32)</p><p>    data</p><p>    &gt;&gt;&gt; array([[1, 2, 3],</p><p>    ...        [4, 5, 6]], dtype=int32)</p><p>    next(cv.array2records(data))</p><p>    &gt;&gt;&gt; {'column_1': 1, 'column_2': 2, 'column_3': 3}</p><p>    """Convert the structured array back to a records generator"""</p><p>    next(cv.array2records(recarray))</p><p>    &gt;&gt;&gt; {'a': 'one', 'b': 2, 'c': nan}</p><p>    """Convert the native array back to records generator"""</p><p>    next(cv.array2records(narray, native=True))</p><p>    {'a': 'one', 'b': 2, 'c': 0.0}</p><p>Installation</p><p>------------</p><p>(You are using a `virtualenv`_, right?)</p><p>At the command line, install tabutils using either ``pip`` (*recommended*)</p><p>.. code-block:: bash</p><p>    pip install tabutils</p><p>or ``easy_install``</p><p>.. code-block:: bash</p><p>    easy_install tabutils</p><p>Please see the `installation doc`_ for more details.</p><p>Project Structure</p><p>-----------------</p><p>.. code-block:: bash</p><p>    ┌── AUTHORS.rst</p><p>    ├── CHANGES.rst</p><p>    ├── CONTRIBUTING.rst</p><p>    ├── INSTALLATION.rst</p><p>    ├── LICENSE</p><p>    ├── MANIFEST.in</p><p>    ├── Makefile</p><p>    ├── README.rst</p><p>    ├── TODO.rst</p><p>    ├── data</p><p>    │   ├── converted</p><p>    │   │   ├── dbf.csv</p><p>    │   │   ├── fixed.csv</p><p>    │   │   ├── geo.csv</p><p>    │   │   ├── geojson.csv</p><p>    │   │   ├── json.csv</p><p>    │   │   ├── json_multiline.csv</p><p>    │   │   └── sheet_2.csv</p><p>    │   └── test</p><p>    │       ├── fixed.txt</p><p>    │       ├── fixed_w_header.txt</p><p>    │       ├── iris.csv</p><p>    │       ├── irismeta.csv</p><p>    │       ├── latin1.csv</p><p>    │       ├── mac_newlines.csv</p><p>    │       ├── newline.json</p><p>    │       ├── no_header_row.csv</p><p>    │       ├── test.csv</p><p>    │       ├── test.dbf</p><p>    │       ├── test.geojson</p><p>    │       ├── test.html</p><p>    │       ├── test.json</p><p>    │       ├── test.mdb</p><p>    │       ├── test.sqlite</p><p>    │       ├── test.tsv</p><p>    │       ├── test.xls</p><p>    │       ├── test.xlsx</p><p>    │       ├── test.yml</p><p>    │       ├── utf16_big.csv</p><p>    │       ├── utf16_little.csv</p><p>    │       └── utf8.csv</p><p>    ├── dev-requirements.txt</p><p>    ├── examples.py</p><p>    ├── helpers</p><p>    │   ├── check-stage</p><p>    │   ├── clean</p><p>    │   ├── pippy</p><p>    │   ├── srcdist</p><p>    │   └── wheel</p><p>    ├── manage.py</p><p>    ├── py2-requirements.txt</p><p>    ├── requirements.txt</p><p>    ├── setup.cfg</p><p>    ├── setup.py</p><p>    ├── tabutils</p><p>    │   ├── __init__.py</p><p>    │   ├── convert.py</p><p>    │   ├── dbf.py</p><p>    │   ├── fntools.py</p><p>    │   ├── io.py</p><p>    │   ├── process.py</p><p>    │   ├── stats.py</p><p>    │   ├── typetools.py</p><p>    │   └── unicsv.py</p><p>    ├── tests</p><p>    │   ├── __init__.py</p><p>    │   ├── standard.rc</p><p>    │   ├── test_fntools.py</p><p>    │   ├── test_io.py</p><p>    │   └── test_process.py</p><p>    └── tox.ini</p><p>Design Principles</p><p>-----------------</p><p>- prefer functions over objects</p><p>- provide enough functionality out of the box to easily implement the most common data analysis use cases</p><p>- make conversion between ``records``, ``arrays``, and ``DataFrames`` dead simple</p><p>- whenever possible, lazily read objects and stream the result [#]_</p><p>.. [#] Notable exceptions are ``tabutils.process.group``, ``tabutils.process.sort``, ``tabutils.io.read_dbf``, ``tabutils.io.read_yaml``, and ``tabutils.io.read_html``. These functions read the entire contents into memory up front.</p><p>Readers</p><p>-------</p><p>tabutils' available readers are outlined below:</p><p>+-----------------------+-------------------------+----------------+</p><p>| File type             | Recognized extension(s) | Default reader |</p><p>+=======================+=========================+================+</p><p>| Comma separated file  | csv                     | read_csv       |</p><p>+-----------------------+-------------------------+----------------+</p><p>| dBASE/FoxBASE         | dbf                     | read_dbf       |</p><p>+-----------------------+-------------------------+----------------+</p><p>| Fixed width file      | fixed                   | read_fixed_fmt |</p><p>+-----------------------+-------------------------+----------------+</p><p>| GeoJSON               | geojson, geojson.json   | read_geojson   |</p><p>+-----------------------+-------------------------+----------------+</p><p>| HTML table            | html                    | read_html      |</p><p>+-----------------------+-------------------------+----------------+</p><p>| JSON                  | json                    | read_json      |</p><p>+-----------------------+-------------------------+----------------+</p><p>| Microsoft Access      | mdb                     | read_mdb       |</p><p>+-----------------------+-------------------------+----------------+</p><p>| SQLite                | sqlite                  | read_sqlite    |</p><p>+-----------------------+-------------------------+----------------+</p><p>| Tab separated file    | tsv                     | read_tsv       |</p><p>+-----------------------+-------------------------+----------------+</p><p>| Microsoft Excel       | xls, xlsx               | read_xls       |</p><p>+-----------------------+-------------------------+----------------+</p><p>| YAML                  | yml, yaml               | read_yaml      |</p><p>+-----------------------+-------------------------+----------------+</p><p>Alternatively, tabutils provides a universal reader which will select the</p><p>appropriate reader based on the file extension as specified in the above</p><p>table.</p><p>.. code-block:: python</p><p>    from io import open</p><p>    from tabutils import io</p><p>    records1 = io.read('path/to/file.csv')</p><p>    records2 = io.read('path/to/file.xls')</p><p>    with open('path/to/file.json', encoding='utf-8') as f:</p><p>        records3 = io.read(f, ext='json')</p><p>Args</p><p>^^^^</p><p>Most readers take as their first argument, either a file path or file like object.</p><p>The notable execption is ``read_mdb`` which only accepts a file path.</p><p>File like objects should be opened using Python's stdlib ``io.open``. If the file</p><p>is opened in binary mode ``io.open('/path/to/file')``, be sure to pass the proper</p><p>encoding if it is anything other than ``utf-8``, e.g.,</p><p>.. code-block:: python</p><p>    from io import open</p><p>    from tabutils import io</p><p>    with open('path/to/file.xlsx') as f:</p><p>        records = io.read_xls(f, encoding='latin-1')</p><p>Kwargs</p><p>^^^^^^</p><p>While each reader has kwargs specific to itself, the following table outlines</p><p>the most common ones.</p><p>==========  ====  =======================================  =======  =====================================================================================================</p><p>kwarg       type  description                              default  implementing readers</p><p>==========  ====  =======================================  =======  =====================================================================================================</p><p>mode        str   File open mode                           rU       read_csv, read_fixed_fmt, read_geojson, read_html, read_json, read_tsv, read_xls, read_yaml</p><p>encoding    str   File encoding                            utf-8    read_csv, read_dbf, read_fixed_fmt, read_geojson, read_html, read_json, read_tsv, read_xls, read_yaml</p><p>has_header  bool  Data has a header row?                   True     read_csv, read_fixed_fmt, read_tsv, read_xls</p><p>first_row   int   First row to read (zero indexed)         0        read_csv, read_fixed_fmt, read_tsv, read_xls</p><p>first_col   int   First column to read (zero indexed)      0        read_csv, read_fixed_fmt, read_tsv, read_xls</p><p>sanitize    bool  Underscorify and lowercase field names?  False    read_csv, read_dbf, read_fixed_fmt, read_html, read_mdb, read_tsv, read_xls</p><p>dedupe      bool  Deduplicate field names?                 False    read_csv, read_fixed_fmt, read_html, read_mdb, read_tsv, read_xls</p><p>sheet       int   Sheet to read (zero indexed)             0        read_xls</p><p>table       int   Table to read (zero indexed)             0        read_dbf, read_html, read_mdb, read_sqlite</p><p>==========  ====  =======================================  =======  =====================================================================================================</p><p>Scripts</p><p>-------</p><p>tabutils comes with a built in task manager ``manage.py``</p><p>Setup</p><p>^^^^^</p><p>.. code-block:: bash</p><p>    pip install -r dev-requirements.txt</p><p>Examples</p><p>^^^^^^^^</p><p>*Run python linter and nose tests*</p><p>.. code-block:: bash</p><p>    manage lint</p><p>    manage test</p><p>Contributing</p><p>------------</p><p>Please mimic the coding style/conventions used in this repo.</p><p>If you add new classes or functions, please add the appropriate doc blocks with</p><p>examples. Also, make sure the python linter and nose tests pass.</p><p>Please see the `contributing doc`_ for more details.</p><p>Credits</p><p>-------</p><p>Shoutouts to `csvkit`_, `messytables`_, and `pandas`_ for heavily inspiring tabutils.</p><p>License</p><p>-------</p><p>tabutils is distributed under the `MIT License`_.</p><p>.. |travis| image:: https://img.shields.io/travis/reubano/tabutils/master.svg</p><p>    :target: https://travis-ci.org/reubano/tabutils</p><p>.. |versions| image:: https://img.shields.io/pypi/pyversions/tabutils.svg</p><p>    :target: https://pypi.python.org/pypi/tabutils</p><p>.. |pypi| image:: https://img.shields.io/pypi/v/tabutils.svg</p><p>    :target: https://pypi.python.org/pypi/tabutils</p><p>.. _mdbtools: http://sourceforge.net/projects/mdbtools/</p><p>.. _lxml: http://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-a-parser</p><p>.. _library: #usage</p><p>.. _NumPy: https://github.com/numpy/numpy</p><p>.. _a library: https://csvkit.readthedocs.org/en/0.9.1/api/csvkit.py3.html</p><p>.. _PyPy: https://github.com/pydata/pandas/issues/9532</p><p>.. _walk in the park: http://pandas.pydata.org/pandas-docs/stable/install.html#installing-pandas-with-anaconda</p><p>.. _csvkit: https://github.com/onyxfish/csvkit</p><p>.. _messytables: https://github.com/okfn/messytables</p><p>.. _pandas: https://github.com/pydata/pandas</p><p>.. _MIT License: http://opensource.org/licenses/MIT</p><p>.. _virtualenv: http://www.virtualenv.org/en/latest/index.html</p><p>.. _contributing doc: https://github.com/reubano/tabutils/blob/master/CONTRIBUTING.rst</p><p>.. _installation doc: https://github.com/reubano/tabutils/blob/master/INSTALLATION.rst</p><p>.. _cookbook guide: https://github.com/reubano/tabutils/blob/master/COOKBOOK.rst</p><p>=========</p><p>Changelog</p><p>=========</p><p>Here you can find the recent changes to pygogo..</p><p>.. changelog::</p><p>    :version: dev</p><p>    :released: Ongoing</p><p>    .. change::</p><p>        :tags:  docs</p><p>        Updated CHANGES.</p><p>.. changelog::</p><p>    :version: 0.1.0</p><p>    :released: 2015-12-05</p><p>    .. change::</p><p>        :tags: docs</p><p>        First release on PyPi.</p><p>.. todo:: vim: set filetype=rst:

</p><a name="downloads"> </a>


<ul class="nodot">
  <li><strong>Downloads (All Versions):</strong></li>
  <li>
    <span>0</span> downloads in the last day
  </li>
  <li>
    <span>177</span> downloads in the last week
  </li>
  <li>
    <span>1497</span> downloads in the last month
  </li>
</ul>



<ul class="nodot">
 <li>
  <strong>Author:</strong>
  <span>Reuben Cummings</span>
 </li>

 

 


 <li>
  <strong>Home Page:</strong>
  
  <a href="https://github.com/reubano/tabutils">https://github.com/reubano/tabutils</a>
 </li>


 

 <li>
  <strong>Download URL:</strong>
  
  <a href="https://github.com/reubano/tabutils/archive/v0.27.2.tar.gz">https://github.com/reubano/tabutils/archive/v0.27.2.tar.gz</a>
 </li>


 <li>
  <strong>Keywords:</strong>
  <span>tabutils,A,(tabular),data,processing,toolkit</span>
 </li>

 <li>
  <strong>License:</strong>
  
  
  <span>MIT</span>
  
 </li>

 <li>
  <strong>Platform:</strong>
  <span>MacOS X,Windows,Linux</span>
 </li>


 
 
 

 <li>
  <strong>Categories</strong>
  
 </li>



 <li>
   <strong>Requires Distributions</strong>
   <ul class="nodot">
     <li>
       <a href="https://pypi.python.org/pypi/future">future (&gt;=0.15.2); python_version&lt;"3.0"</a>
        
     </li>
     <li>
       <a href="https://pypi.python.org/pypi/xlrd">xlrd (&gt;=0.9.3,&lt;0.10.0)</a>
        
     </li>
     <li>
       <a href="https://pypi.python.org/pypi/six">six (&gt;=1.9.0,&lt;2.0.0)</a>
        
     </li>
     <li>
       <a href="https://pypi.python.org/pypi/requests">requests (&gt;=2.8.1,&lt;3.0.0)</a>
        
     </li>
     <li>
       <a href="https://pypi.python.org/pypi/python-slugify">python-slugify (&gt;=0.0.7,&lt;0.1.0)</a>
        
     </li>
     <li>
       <a href="https://pypi.python.org/pypi/python-dateutil">python-dateutil (&gt;=2.4.2,&lt;3.0.0)</a>
        
     </li>
     <li>
       <a href="https://pypi.python.org/pypi/pkutils">pkutils (&gt;=0.12.4,&lt;0.13.0)</a>
        
     </li>
     <li>
       <a href="https://pypi.python.org/pypi/ijson">ijson (&gt;=2.2,&lt;3.0)</a>
        
     </li>
     <li>
       <a href="https://pypi.python.org/pypi/dbfread">dbfread (==2.0.4)</a>
        
     </li>
     <li>
       <a href="https://pypi.python.org/pypi/chardet">chardet (&gt;=2.3.0,&lt;3.0.0)</a>
        
     </li>
     <li>
       <a href="https://pypi.python.org/pypi/beautifulsoup4">beautifulsoup4 (&gt;=4.4.1,&lt;5.0.0)</a>
        
     </li>
     <li>
       <a href="https://pypi.python.org/pypi/PyYAML">PyYAML (&gt;=3.11,&lt;4.0)</a>
        
     </li>
   </ul>
 </li>

 

 

 

 


 <li>
  <strong>Package Index Owner:</strong>
  <span>reubano</span>
 </li>

 

 <li>
  <strong><a href="http://usefulinc.com/doap">DOAP</a> record:</strong>
  <a href="/pypi?:action=doap&amp;name=tabutils&amp;version=0.27.2">tabutils-0.27.2.xml</a>
 </li>

</ul>





            </div>


          </div></body></html>