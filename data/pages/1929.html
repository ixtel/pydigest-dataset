<html><body><div><div id="article_text">
    <p>Slow unit tests can lead to tests not getting run as often as they should. Unit tests often are run before builds on continuous integration systems so deployments can also be slowed down by lengthy or poorly-patched tests.</p>
<p>There are various techniques for speeding up tests including patching methods (which should be done for isolation anyway), isolating specific tests for execution or exclusion, background watch processes running application-specific tests when relevant files are saved, etc...</p>
<p>I've seen a number of code bases where the application code is out-numbered by the testing code 4:1. Even if the tests could finish in two minutes it's still a two minute delay for deployment.</p>
<p><a class="reference external" href="https://pypi.python.org/pypi/pytest-xdist">pytest-xdist</a> was recently pointed out to me as a utility to speed up tests. It can break up tests into separate batches and run them concurrently on separate databases.</p>
<p>I decided to create a small project and try <cite>pytest-xdist</cite> out. You can find my example project on <a class="reference external" href="https://bitbucket.org/marklit/fast_tests/src">Bitbucket</a>.</p>
<div class="section" id="a-short-test">
<h2>A short test</h2>
<p>These are the requirements I installed:</p>
<div class="highlight"><pre><span class="nv">$ </span>pip install <span class="nv">Django</span><span class="o">==</span>1.7.1 <span class="se">\</span>
              pytest-django<span class="o">==</span>2.7.0 <span class="se">\</span>
              pytest-xdist<span class="o">==</span>1.11 <span class="se">\</span>
              pytest-cov<span class="o">==</span>1.8.0
</pre></div>
<p><a class="reference external" href="http://pytest.org/latest/index.html">pytest</a> is the main tool being used. <cite>pytest-xdist</cite> and <cite>pytest-cov</cite> are plugins used to speed up testing and run coverage utilities respectively.</p>
<p>I created a small model and wrote some unit tests for that model that would take at least 800 milliseconds each to run.</p>
<p>example/models.py:</p>
<div class="highlight"><pre><span class="kn">from</span> <span class="nn">django.db</span> <span class="kn">import</span> <span class="n">models</span>


<span class="k">class</span> <span class="nc">Candidate</span><span class="p">(</span><span class="n">models</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
    <span class="n">first_name</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">CharField</span><span class="p">(</span><span class="n">max_length</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
    <span class="n">last_name</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">CharField</span><span class="p">(</span><span class="n">max_length</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
<p>example/tests.py:</p>
<div class="highlight"><pre><span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">sleep</span>

<span class="kn">from</span> <span class="nn">django.test</span> <span class="kn">import</span> <span class="n">TestCase</span>

<span class="kn">from</span> <span class="nn">.models</span> <span class="kn">import</span> <span class="n">Candidate</span>


<span class="k">class</span> <span class="nc">ModelTests</span><span class="p">(</span><span class="n">TestCase</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">test_1</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">candidate</span> <span class="o">=</span> <span class="n">Candidate</span><span class="p">(</span><span class="n">first_name</span><span class="o">=</span><span class="s">'Mark'</span><span class="p">,</span> <span class="n">last_name</span><span class="o">=</span><span class="s">'Lit'</span><span class="p">)</span>
        <span class="n">candidate</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

        <span class="n">sleep</span><span class="p">(</span><span class="mf">0.8</span><span class="p">)</span> <span class="c"># 800 milliseconds</span>

        <span class="n">candidate</span> <span class="o">=</span> <span class="n">Candidate</span><span class="o">.</span><span class="n">objects</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">first_name</span><span class="o">=</span><span class="s">'Mark'</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="n">candidate</span><span class="o">.</span><span class="n">first_name</span><span class="p">,</span> <span class="s">'Mark'</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">test_2</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_1</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">test_3</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_1</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">test_4</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_1</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">test_5</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_1</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">test_6</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_1</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">test_7</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_1</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertTrue</span><span class="p">(</span><span class="bp">False</span><span class="p">,</span> <span class="s">'False positive'</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">test_8</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_1</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">test_9</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_1</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">test_10</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_1</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">test_11</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_1</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">test_12</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_1</span><span class="p">()</span>
</pre></div>
</div>
<div class="section" id="a-significant-speed-improvement">
<h2>A significant speed improvement</h2>
<p>I first ran the regular Django test runner to see how long it would take to complete and demonstrate the test failure is reported properly.</p>
<div class="highlight"><pre><span class="nv">$ </span>python manage.py <span class="nb">test</span>
Creating <span class="nb">test </span>database <span class="k">for</span> <span class="nb">alias</span> <span class="s1">'default'</span>...
.........F..
<span class="o">======================================================================</span>
FAIL: test_7 <span class="o">(</span>example.tests.ModelTests<span class="o">)</span>
----------------------------------------------------------------------
Traceback <span class="o">(</span>most recent call last<span class="o">)</span>:
  File <span class="s2">"/home/mark/fast_tests/example/tests.py"</span>, line 36, in test_7
    self.assertTrue<span class="o">(</span>False, <span class="s1">'False positive'</span><span class="o">)</span>
AssertionError: False positive

----------------------------------------------------------------------
Ran <span class="m">12</span> tests in 9.662s

FAILED <span class="o">(</span><span class="nv">failures</span><span class="o">=</span>1<span class="o">)</span>
Destroying <span class="nb">test </span>database <span class="k">for</span> <span class="nb">alias</span> <span class="s1">'default'</span>...
</pre></div>
<p>It showed the failure and finished testing in 9.662 seconds.</p>
<p>I then created a <cite>pytest.ini</cite> file with the following contents:</p>
<div class="highlight"><pre><span class="o">[</span>pytest<span class="o">]</span>
<span class="nv">python_files</span><span class="o">=</span>tests.py
<span class="nv">DJANGO_SETTINGS_MODULE</span><span class="o">=</span>fast_tests.settings
</pre></div>
<p>And then ran <cite>py.test</cite> with 3 parallel processes:</p>
<div class="highlight"><pre><span class="nv">$ </span>py.test -n <span class="nv">3</span>

<span class="o">===================================</span> <span class="nb">test </span>session <span class="nv">starts</span> <span class="o">====================================</span>
platform linux2 -- Python 2.7.6 -- py-1.4.26 -- pytest-2.6.4
plugins: xdist, django
gw0 <span class="o">[</span>12<span class="o">]</span> / gw1 <span class="o">[</span>12<span class="o">]</span> / gw2 <span class="o">[</span>12<span class="o">]</span>
scheduling tests via LoadScheduling
...........F
<span class="o">=========================================</span> <span class="nv">FAILURES</span> <span class="o">=========================================</span>
____________________________________ ModelTests.test_7 _____________________________________
<span class="o">[</span>gw1<span class="o">]</span> linux2 -- Python 2.7.6 /home/mark/.virtualenvs/fast_tests/bin/python
<span class="nv">self</span> <span class="o">=</span> &lt;example.tests.ModelTests <span class="nv">testMethod</span><span class="o">=</span>test_7&gt;

    def test_7<span class="o">(</span>self<span class="o">)</span>:
        self.test_1<span class="o">()</span>
&gt;       self.assertTrue<span class="o">(</span>False, <span class="s1">'False positive'</span><span class="o">)</span>
E       AssertionError: False positive

example/tests.py:36: <span class="nv">AssertionError</span>
<span class="o">===========================</span> <span class="m">1</span> failed, <span class="m">11</span> passed in 2.82 <span class="nv">seconds</span> <span class="o">============================</span>
</pre></div>
<p>It ran the same set of tests and reported the failure 3.4 times faster than the regular Django test runner.</p>
</div>
<div class="section" id="coverage">
<h2>Coverage</h2>
<p><cite>py.test</cite> has a <a class="reference external" href="https://pypi.python.org/pypi/pytest-cov">pytest-cov</a> plugin which adds support for running tests with the <a class="reference external" href="http://nedbatchelder.com/code/coverage/">coverage</a> tool. The coverage tool generates a <cite>.coverage</cite> file which holds statistics on how many lines of your code base (which were seen by coverage) were hit at least one when running the testing suite.</p>
<p>You can also also ask for <cite>.py,cover</cite> files to be generated along side your source code files. These are annotated files showing which lines have and have not been hit by your tests and lines which were deemed to be non-statement lines and were skipped.</p>
<div class="highlight"><pre><span class="nv">$ </span>py.test -n3 --cov . --cov-report annotate
</pre></div>
<p><cite>coverage</cite> supports returning an error code if a certain percentage of lines were not hit. Below I check to see if less than 95% percent of the lines where hit:</p>
<div class="highlight"><pre><span class="nv">$ </span>coverage report --fail-under<span class="o">=</span>95
Name                              Stmts   Miss  Cover
-----------------------------------------------------
example/__init__                      <span class="m">0</span>      <span class="m">0</span>   100%
example/admin                         <span class="m">1</span>      <span class="m">0</span>   100%
example/migrations/0001_initial       <span class="m">5</span>      <span class="m">0</span>   100%
example/migrations/__init__           <span class="m">0</span>      <span class="m">0</span>   100%
example/models                        <span class="m">4</span>      <span class="m">0</span>   100%
example/tests                        <span class="m">33</span>      <span class="m">0</span>   100%
example/views                         <span class="m">1</span>      <span class="m">1</span>     0%
fast_tests/__init__                   <span class="m">0</span>      <span class="m">0</span>   100%
fast_tests/settings                  <span class="m">17</span>      <span class="m">0</span>   100%
fast_tests/urls                       <span class="m">3</span>      <span class="m">3</span>     0%
fast_tests/wsgi                       <span class="m">4</span>      <span class="m">4</span>     0%
manage                                <span class="m">6</span>      <span class="m">6</span>     0%
-----------------------------------------------------
TOTAL                                <span class="m">74</span>     <span class="m">14</span>    81%
</pre></div>
<p>Only 81% were hit so the exit code will be 127:</p>

<p>If I lower the threshold to 80% exit code 0 is returned:</p>
<div class="highlight"><pre><span class="nv">$ </span>coverage report --fail-under<span class="o">=</span>80
...
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$?</span>
0
</pre></div>
</div>

  </div>

   <div id="support_text"><p>
    Thank you for taking the time to read this post. If you're considering using </p><a href="https://www.digitalocean.com/?refcode=074ce6598105">Digital Ocean</a><p>, the hosting provider this blog is hosted on, please consider using </p><a href="https://www.digitalocean.com/?refcode=074ce6598105">this link to sign up</a><p>.
  </p></div>


  
</div></body></html>