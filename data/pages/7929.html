<html><body><div><article class="markdown-body entry-content" itemprop="text"><h1><a id="user-content-neural-art-in-tensorflow" class="anchor" href="#neural-art-in-tensorflow" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>"Neural Art" in TensorFlow</h1>

<p>An implementation of <a href="http://arxiv.org/abs/1508.06576">"A neural algorithm of Artistic style"</a> in TensorFlow, for</p>

<ul>
<li>Introductory, hackable demos for TensorFlow, and</li>
<li>Demonstrating the use of importing various Caffe cnn models (VGG and illustration2vec) in TF.</li>
</ul>

<p>In this work, I put effort in putting the code simple as possible, for being a good introductory code to TF. For this reason, I also implemented very basic uses of TensorBoard (the visualizer). I also aimed on demonstrating the use of importing various Caffe models from *.caffemodel files into TensorFlow, especially models that seemed not to be imported by anybody yet in TF (as far as I know). Based on <a href="https://github.com/ethereon/caffe-tensorflow">https://github.com/ethereon/caffe-tensorflow</a>, I modified the importer so that it can import illustration2vec (<a href="http://illustration2vec.net/">http://illustration2vec.net/</a>), which is another CNN available as a Caffe model. Using different CNNs yields different results, which reflects the characteristics of the model.</p>

<p>In the Neural Art problem setting, the weights of the CNN are fixed, and the input image into the CNN is the only "trainable" variable, making the code easy to understand (the optimized/trained image is the output image). I hope this example serves as a good introduction to TensorFlow as well as for entertainment purposes.</p>

<p><a href="/woodrush/neural-art-tf/blob/master/vgg_result.png" target="_blank"><img src="/woodrush/neural-art-tf/raw/master/vgg_result.png"/></a></p>

<p>(VGG, default settings, 70 iterations)</p>

<p><a href="/woodrush/neural-art-tf/blob/master/i2v_result.png" target="_blank"><img src="/woodrush/neural-art-tf/raw/master/i2v_result.png"/></a></p>

<p>(illustration2vec, width=500, beta=10000, 100 iterations)</p>

<h2><a id="user-content-usage" class="anchor" href="#usage" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Usage</h2>

<h3><a id="user-content-step-0-prepare-the-caffe-model" class="anchor" href="#step-0-prepare-the-caffe-model" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Step 0: Prepare the Caffe model</h3>

<p>First, download either the VGG model or the illustration2vec model (*.caffemodel), along with the prototxt (*.prototxt):</p>



<p>Then, convert the model to a binary format recognizable to TensorFlow:</p>

<pre><code>python ./kaffe/kaffe.py [path.prototxt] [path.caffemodel] [output-path]
</code></pre>

<p>Note that Caffe is <em>not</em> required for conversion.</p>

<p>The converter included in this repo (all code inside ./kaffe) is a modified version of (an old version of) <a href="https://github.com/ethereon/caffe-tensorflow">https://github.com/ethereon/caffe-tensorflow</a> . The converter is modified to be capable of handling the illusration2vec neural network. Since the newer version of the converter requires preprocessing with the Caffe framework for old-format Caffe models (at the time of writing), I have included the converter which is based on the older code, which is capable of handling old-format Caffe models. </p>

<h3><a id="user-content-step-1-neural-art" class="anchor" href="#step-1-neural-art" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Step 1: Neural Art</h3>

<pre><code>python neural-art-tf.py
</code></pre>

<p>Running <code>neural-art-tf.py</code> without options yields the default settings and input images. Available options are:</p>

<ul>
<li><code>-m, --model</code>:      Model type - Use <code>vgg</code> or <code>i2v</code></li>
<li><code>-mp, --modelpath</code>: Model file path - The path to the converted Caffe model in Step 0</li>
<li><code>-c, --content</code>:    Content image path</li>
<li><code>-s, --style</code>:      Style image path</li>
<li><code>-w, --width</code>:      Output image width</li>
<li><code>-i, --iters</code>:      Number of iterations</li>
<li><code>-a, --alpha</code>:      alpha (content weight)</li>
<li><code>-b, --beta</code>:       beta (style weight)</li>
</ul>

<p>For example:</p>

<pre><code>python neural-art-tf.py -m vgg -mp ./vgg -c ./images/sd.jpg -s ./images/style.jpg -w 800
</code></pre>

<p>You can view the progress on tensorboard by running</p>

<pre><code>tensorboard --logdir=/tmp/na-logs
</code></pre>

<h2><a id="user-content-references" class="anchor" href="#references" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>References</h2>


</article>
  </div></body></html>