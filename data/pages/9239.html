<html><body><div><div class="entry-content">
		<p>In the <a href="https://orenmn.wordpress.com/2016/01/02/understanding-cpython-by-patching-part-2/">previous post</a>, we have started exploring CPython in order to find a way to turn the default base of integer literals in Python source code from decimal to hexadecimal. (The last post ended with a short recap. Feel free to check it out for a fast recall.)<br/>
Without further preparations, we would continue right where we have stopped last time.</p>
<p>So, we found out <i>parsetok</i> in Parser\parsetok.c does the tokenizing and the parsing. For this purpose, it receives a pointer to a tok_state struct (i.e. a tokenizer struct) that contains (among others) the Python source code string. <i>parsetok</i> is a little big, but we are not intimidated:</p>
<pre class="brush: cpp; title: ; notranslate" title="">
/* Parse input coming from the given tokenizer structure.
   Return error code. */

static node *
parsetok(struct tok_state *tok, grammar *g, int start, perrdetail *err_ret,
         int *flags)
{
    parser_state *ps;
    node *n;
    ...
    if ((ps = PyParser_New(g, start)) == NULL) {
        ...
    }
    ...
    for (;;) {
        char *a, *b;
        int type;
        size_t len;
        char *str;
        ...
        type = PyTokenizer_Get(tok, &amp;a, &amp;b);
        if (type == ERRORTOKEN) {
            err_ret-&gt;error = tok-&gt;done;
            break;
        }
        ...
        len = b - a; /* XXX this may compute NULL - NULL */
        ...
        if (len &gt; 0)
            strncpy(str, a, len);
        str[len] = '\0';
        ...
        if ((err_ret-&gt;error =
             PyParser_AddToken(ps, (int)type, str,
                               tok-&gt;lineno, col_offset,
                               &amp;(err_ret-&gt;expected))) != E_OK) {
            ...
        }
    }

    if (err_ret-&gt;error == E_DONE) {
        n = ps-&gt;p_tree;
        ps-&gt;p_tree = NULL;
        ...
    }
    else
        n = NULL;
    ...
    PyTokenizer_Free(tok);

    return n;
}
</pre>
<p>Cool.<br/>
First, <i>PyParser_New</i> is called to create a parser_state struct (i.e. a parser struct), which also contains an empty CST. Then, in a loop, <i>PyTokenizer_Get</i> is called to get the next token’s string and type (in my humble opinion, ‘token_str_start_ptr’ and ‘token_str_end_ptr’ would have been more suitable names for the variables ‘a’ and ‘b’). If the token is valid (type != ERRORTOKEN), <i>PyParser_AddToken</i> is called to add the token to our CST. When there are no more tokens left, the tokenizing and parsing are completed. Subsequently, the tokenizer is freed, and the CST is returned.</p>
<p>We search for ‘PyTokenizer_Get’, and find it in Parser\tokenizer.c:</p>
<pre class="brush: cpp; title: ; notranslate" title="">
int
PyTokenizer_Get(struct tok_state *tok, char **p_start, char **p_end)
{
    int result = tok_get(tok, p_start, p_end);
    ...
    return result;
}
</pre>
<p>Ok, we go straight to <i>tok_get</i> (which is also in Parser\tokenizer.c), and…</p>
<p>Oh my.<br/>
<i>tok_get</i> is almost 500 lines of code. This is it. The tokenizing function. This is going to be a hell of a dive…<br/>
Well, actually we don’t feel like drowning today, so we would split it to some smaller dives:</p>
<pre class="brush: cpp; title: ; notranslate" title="">
/* Get next token, after space stripping etc. */

static int
tok_get(struct tok_state *tok, char **p_start, char **p_end)
{
    int c;
    ...
    /* Get indentation level */
    if (tok-&gt;atbol) {
        ...
        tok-&gt;atbol = 0;
        for (;;) {
            c = tok_nextc(tok);
            if (c == ' ')
                ...
            else if (c == '\t') {
                ...
            }
            else if (c == '\014') /* Control-L (formfeed) */
                ...
            else
                break;
        }
        tok_backup(tok, c);
        ...
    }
    
    tok-&gt;start = tok-&gt;cur;

    /* Return pending indents/dedents */
    if (tok-&gt;pendin != 0) {
        if (tok-&gt;pendin &lt; 0) {
            tok-&gt;pendin++;
            return DEDENT;
        }
        else {
            tok-&gt;pendin--;
            return INDENT;
        }
    }
    ...
    /* Skip spaces */
    do {
        c = tok_nextc(tok);
    } while (c == ' ' || c == '\t' || c == '\014');

    /* Set start of current token */
    tok-&gt;start = tok-&gt;cur - 1;

    /* Skip comment */
    if (c == '#')
        while (c != EOF &amp;&amp; c != '\n')
            c = tok_nextc(tok);

    /* Check for EOF and errors now */
    if (c == EOF) {
        return tok-&gt;done == E_EOF ? ENDMARKER : ERRORTOKEN;
    }
</pre>
<p>First, if the tokenizer’s atbol (which stands for ‘at begin of line’) flag is set, spaces and tabs are counted. This is done by calling <i>tok_nextc</i> repeatedly to get the next char from the tokenizer, until a char other than a space or a tab is encountered, and then calling <i>tok_backup</i> to restore the extra char consumed by <i>tok_nextc</i>.<br/>
If any erroneous indentation is spotted, ERRORTOKEN is returned (I have removed those checks).<br/>
Otherwise, if the indentation of this line is bigger or smaller than the last one, either INDENT or DEDENT is returned respectively.</p>
<p>After that, <i>tok_nextc</i> is again called repeatedly in order to skip spaces and tabs. There are some states in which we might or might not reach this spaces-skipping code:</p>
<ol>
<li>This token is at the beginning of a line:
<ol>
<li>This line’s indentation is invalid, and so ERRORTOKEN is returned before we reach here.</li>
<li>This line’s indentation is valid but different than the previous line, and so either INDENT or DEDENT is returned before we reach here.</li>
<li>This line’s indentation is the same as the previous line, so we reach here after consuming all indentation spaces, and there aren’t any more spaces to skip.</li>
</ol>
</li>
<li>This token is in the middle or at the end of a line.</li>
</ol>
<p>Indeed, if we encounter any spaces here, we must be in the middle or at the end of a line, where spaces are meaningless, and thus they are just skipped.</p>
<p>Later, everything from a ‘#’ char until a new line or until the end of the file is skipped, as it is simply a comment.<br/>
Finally (for this brief dive), if EOF is reached, <i>tok_get</i> returns.</p>
<p>Just to make sure it does what we think it does, we search for ‘tok_nextc’, and find its definition and <i>tok_backup</i>‘s definition next to each other, also in Parser\tokenizer.c. <i>tok_nextc</i> is quite long, but its comment is good enough for us:</p>
<pre class="brush: cpp; title: ; notranslate" title="">
/* Get next char, updating state; error code goes into tok-&gt;done */

static int
tok_nextc(struct tok_state *tok)
{
    ...
}


/* Back-up one character */

static void
tok_backup(struct tok_state *tok, int c)
{
    if (c != EOF) {
        if (--tok-&gt;cur &lt; tok-&gt;buf)
            Py_FatalError("tok_backup: beginning of buffer");
        if (*tok-&gt;cur != c)
            *tok-&gt;cur = c;
    }
}
</pre>
<p><i>tok_backup</i> is kind of straight forward. tok-&gt;cur is decremented, but if it was already pointing to the beginning of the buffer, something, obviously, is terribly wrong, so a fatal error is raised. Now, in case the previous char is not already the char we wanted to restore, it is overwritten. We are having trouble figuring out why that should ever happen, but whatever.</p>
<p>Back to <i>tok_get</i>, it seems like we are finally starting to deal with chars that aren’t white-spaces:</p>
<pre class="brush: cpp; title: ; notranslate" title="">
    ...
    /* Identifier (most frequent token!) */
    ...
    if (is_potential_identifier_start(c)) {
        /* Process b"", r"", u"", br"" and rb"" */
        ...
        while (1) {
            if (!(saw_b || saw_u) &amp;&amp; (c == 'b' || c == 'B'))
                ...
            else if (!(saw_b || saw_u || saw_r) &amp;&amp; (c == 'u' || c == 'U'))
                ...
            else if (!(saw_r || saw_u) &amp;&amp; (c == 'r' || c == 'R'))
                ...
            else
                break;
            c = tok_nextc(tok);
            if (c == '"' || c == '\'')
                goto letter_quote;
        }
        while (is_potential_identifier_char(c)) {
            ...
            c = tok_nextc(tok);
        }
        tok_backup(tok, c);
        ...
        *p_start = tok-&gt;start;
        *p_end = tok-&gt;cur;
        ...
        return NAME;
    }

</pre>
<p>We take a quick look at <i>is_potential_identifier_start</i> and <i>is_potential_identifier_char</i>, which turn out to be two simple macros (also defined in Parser\tokenizer.c), that do exactly as their names claim.</p>
<pre class="brush: cpp; title: ; notranslate" title="">
#define is_potential_identifier_start(c) (\
              (c &gt;= 'a' &amp;&amp; c &lt;= 'z')\
               || (c &gt;= 'A' &amp;&amp; c &lt;= 'Z')\
               || c == '_'\
               || (c &gt;= 128))

#define is_potential_identifier_char(c) (\
              (c &gt;= 'a' &amp;&amp; c &lt;= 'z')\
               || (c &gt;= 'A' &amp;&amp; c &lt;= 'Z')\
               || (c &gt;= '0' &amp;&amp; c &lt;= '9')\
               || c == '_'\
               || (c &gt;= 128))
</pre>
<p>Back to <i>tok_get</i>, if <i>is_potential_identifier_start</i> returns true, a clever while loop checks whether it is actually some combination of a string or bytes literal prefix followed by an apostrophe or a quotation mark. If it is, it could only be a string or bytes literal, so we jump to letter_quote, which would treat the token as a potential string or bytes literal. </p>
<p>Now that we know this token must be an identifier or a keyword, we consume chars until we reach the end of the token. This is done by calling <i>tok_nextc</i> and <i>is_potential_identifier_char</i> repeatedly, until <i>is_potential_identifier_char</i> returns false. Subsequently, <i>tok_backup</i> is called to restore the extra char that was consumed.</p>
<p>At this point, we have the whole token, so we can determine whether this is a valid ‘async’ or ‘await’ keyword (which is done by some checks I have removed). Otherwise, it must be an identifier or another keyword, so NAME is returned.</p>
<p>We wonder why ‘async’ and ‘await’ receive such a special treatment, as it seems any other keyword (e.g. ‘if’, ‘else’) would be classified as a NAME token. We could probably find some smart answer in a PEP, but we would leave that for another time.</p>
<p>Anyway, we continue exploring <i>tok_get</i>:</p>
<pre class="brush: cpp; title: ; notranslate" title="">
    /* Newline */
    if (c == '\n') {
        ...
        return NEWLINE;
    }

    /* Period or number starting with period? */
    if (c == '.') {
        ...
        return DOT;
    }

    /* Number */
    if (isdigit(c)) {
        if (c == '0') {
            /* Hex, octal or binary -- maybe. */
            c = tok_nextc(tok);
            if (c == '.')
                goto fraction;
            if (c == 'j' || c == 'J')
                goto imaginary;
            if (c == 'x' || c == 'X') {

                /* Hex */
                c = tok_nextc(tok);
                if (!isxdigit(c)) {
                    tok-&gt;done = E_TOKEN;
                    tok_backup(tok, c);
                    return ERRORTOKEN;
                }
                do {
                    c = tok_nextc(tok);
                } while (isxdigit(c));
            }
            else if (c == 'o' || c == 'O') {
                /* Octal */
                c = tok_nextc(tok);
                if (c &lt; '0' || c &gt;= '8') {
                    tok-&gt;done = E_TOKEN;
                    tok_backup(tok, c);
                    return ERRORTOKEN;
                }
                do {
                    c = tok_nextc(tok);
                } while ('0' &lt;= c &amp;&amp; c &lt; '8');
            }
            else if (c == 'b' || c == 'B') {
                /* Binary */
                c = tok_nextc(tok);
                if (c != '0' &amp;&amp; c != '1') {
                    tok-&gt;done = E_TOKEN;
                    tok_backup(tok, c);
                    return ERRORTOKEN;
                }
                do {
                    c = tok_nextc(tok);
                } while (c == '0' || c == '1');
            }
            else {
                int nonzero = 0;
                /* maybe old-style octal; c is first char of it */
                /* in any case, allow '0' as a literal */
                while (c == '0')
                    c = tok_nextc(tok);
                while (isdigit(c)) {
                    nonzero = 1;
                    c = tok_nextc(tok);
                }
                if (c == '.')
                    goto fraction;
                else if (c == 'e' || c == 'E')
                    goto exponent;
                else if (c == 'j' || c == 'J')
                    goto imaginary;
                else if (nonzero) {
                    tok-&gt;done = E_TOKEN;
                    tok_backup(tok, c);
                    return ERRORTOKEN;
                }
            }
        }
</pre>
<p>Next, if the token is a new line or a period, NEWLINE or DOT is returned, respectively.</p>
<p>And then…<br/>
Unbelievable.<br/>
We actually got to where <i>tok_get</i> identifies a NUMBER token.<br/>
<i>isdigit</i> is called to check whether the first char of the token is a digit. If it is, then it could only be a number. First thing first, if this char is a zero, we would check for some special cases of number literals that start with a zero.</p>
<p>We call <i>tok_nextc</i> to get the next char, and check whether it is a dot. If it is, it could only be a fraction, so we jump to the code that handles fraction literals.<br/>
Then, we check whether the char following the leading zero is the letter ‘j’. If it is, it is the imaginary number zero, so we jump the code that handles imaginary number literals (which probably does kind of nothing, as the letter ‘j’ must be the last char in an imaginary number literal).</p>
<p>Later, we check whether our number token starts with any of the three prefixes: Hex, octal or binary. If indeed it starts with any of those prefixes, <i>tok_nextc</i> is called again, and the next char of the token is checked. If the char is invalid in that number base, <i>tok_backup</i> is called to restore the invalid char (it is not a part of this token, even though it is invalid), and ERRORTOKEN is returned. Otherwise, it must be a valid NUMBER token, so <i>tok_nextc</i> is called repeatedly to consume all following digits (in that number base), and reach the end of the token.</p>
<p>Now we have the required knowledge to understand the following behavior:</p>
<pre class="brush: python; title: ; notranslate" title="">
&gt;&gt;&gt; 0x123g
  File "&lt;stdin&gt;", line 1
    0x123g
         ^
SyntaxError: invalid syntax
&gt;&gt;&gt; 0xg
  File "&lt;stdin&gt;", line 1
    0xg
     ^
SyntaxError: invalid token 
</pre>
<p>In the first one, the tokenizer identified the NUMBER token ‘0x123’ and the NAME token ‘g’. Then CPython tried to make sense of the syntax, but failed, and so raised an error saying ‘invalid syntax’.<br/>
In the second one, the tokenizer identified a token starting with a hex prefix (‘0x’), and concluded it must be a NUMBER token, but then realized the hex prefix is followed by a char which is not a hex digit. Therefore, it raised an error saying ‘invalid token’.</p>
<p>Back to <i>tok_get</i>.<br/>
If the starting zero is not of a prefix, it is a leading zero in a NUMBER token, which is exactly the same as multiple leading zeros in a NUMBER token, so we might as well call <i>tok_nextc</i> repeatedly to consume all leading zeros.</p>
<p>After that, <i>tok_nextc</i> and isdigit are called repeatedly to consume all decimal digits, until a dot (which means it is a fraction), the letter ‘e’ (which means it is a number with an exponent part) or the letter ‘j’ (which means it is an imaginary number). If the decimal digits are followed by any of these 3, we jump to the appropriate code. </p>
<p>Wait a moment… We have already checked for a dot and the letter ‘j’ earlier! Looks like the first time was completely redundant. (I have opened an issue about that in CPython’s bug tracker.)</p>
<p>At last, if the token is a non-zero number that starts with leading zeros, and it is not any of those 3 special cases, <i>tok_backup</i> is called to restore the extra char that was consumed, and ERRORTOKEN is returned.<br/>
This sounds a little weird, so we try it out in our interpreter, and realize that indeed everything works exactly like that:</p>
<pre class="brush: python; title: ; notranslate" title="">
&gt;&gt;&gt; 00000004
  File "&lt;stdin&gt;", line 1
    00000004
           ^
SyntaxError: invalid token
&gt;&gt;&gt; 00000004e3
4000.0
&gt;&gt;&gt; 00000004j
4j
&gt;&gt;&gt; 00000004.
4.0
&gt;&gt;&gt; 00000004.3
4.3
&gt;&gt;&gt; 0000000
0
&gt;&gt;&gt; 0000000.0
0.0
</pre>
<p>Maybe the ‘maybe old-style octal’ comment is related to that odd behavior. We google ‘python PEP octal’, and the first result is <a href="https://www.python.org/dev/peps/pep-3127/">PEP 3127</a>, which explains that in the ancient Python 2 (the wording is mine, of course), leading zeros in a number literal were the same as adding the ‘0o’ octal prefix. The old and wise core developers had decided this behavior had been confusing, and deprecated it.<br/>
It seems a little weird that numbers with an exponent part, fractions and imaginary numbers are still allowed to start with leading zeros, but whatever.</p>
<p>All right, so we are done with numbers that start with a zero. Let’s go back to <i>tok_get</i>, and examine the way other numbers are treated:</p>
<pre class="brush: cpp; title: ; notranslate" title="">
        else {
            /* Decimal */
            do {
                c = tok_nextc(tok);
            } while (isdigit(c));
            {
                /* Accept floating point numbers. */
                if (c == '.') {
        fraction:
                    /* Fraction */
                    do {
                        c = tok_nextc(tok);
                    } while (isdigit(c));
                }
                if (c == 'e' || c == 'E') {
                    int e;
                  exponent:
                    e = c;
                    /* Exponent part */
                    c = tok_nextc(tok);
                    if (c == '+' || c == '-') {
                        c = tok_nextc(tok);
                        if (!isdigit(c)) {
                            tok-&gt;done = E_TOKEN;
                            tok_backup(tok, c);
                            return ERRORTOKEN;
                        }
                    } else if (!isdigit(c)) {
                        tok_backup(tok, c);
                        tok_backup(tok, e);
                        *p_start = tok-&gt;start;
                        *p_end = tok-&gt;cur;
                        return NUMBER;
                    }
                    do {
                        c = tok_nextc(tok);
                    } while (isdigit(c));
                }
                if (c == 'j' || c == 'J')
                    /* Imaginary part */
        imaginary:
                    c = tok_nextc(tok);
            }
        }
        tok_backup(tok, c);
        *p_start = tok-&gt;start;
        *p_end = tok-&gt;cur;
        return NUMBER;
    }
    ...
}
</pre>
<p>If this else block is reached, the token starts with a decimal digit other than zero, which means it could only be a decimal number. So <i>tok_nextc</i> and <i>isdigit</i> are called repeatedly to consume all following decimal digits.<br/>
If the next char is a dot, it must be a fraction, and so <i>tok_nextc</i> and <i>isdigit</i> are again called repeatedly to consumed all decimal digits of the fractional part. </p>
<p>Then, if the next char is the letter ‘e’, it might be a NUMBER token with an exponent part. Now, there are some options:</p>
<ol>
<li>The letter ‘e’ is followed by a plus or a minus, which means it must be a number with an exponent part:
<ol>
<li>The plus or minus is followed by a decimal digit, i.e. this token is definitely a NUMBER token with a valid exponent part.</li>
<li>The plus or minus is followed by a char which is not a decimal digit. This is considered illegal, so that char is restored (as it is not a part of the invalid token), and ERRORTOKEN is returned.</li>
</ol>
</li>
<li>The letter ‘e’ is followed by a char which is neither a sign symbol nor a decimal digit. This means the NUMBER token didn’t have an exponent part after all. Thus, <i>tok_backup</i> is called twice, to restore both that char and the letter ‘e’, and NUMBER is returned.</li>
<li>The letter ‘e’ is followed by a decimal digit, which means it is indeed a NUMBER token with a valid exponent part.</li>
</ol>
<p>If we reach the do-while loop after the else-if block, it is already known to be a NUMBER token with a valid exponent part, so <i>tok_nextc</i> and <i>isdigit</i> are called repeatedly to consume all of the decimal digits of the exponent part.</p>
<p>Personally, I find the following behavior somewhat arbitrary:</p>
<pre class="brush: python; title: ; notranslate" title="">
SyntaxError: invalid token
&gt;&gt;&gt; 123expelliarmus
  File "&lt;stdin&gt;", line 1
    123expelliarmus
                  ^
SyntaxError: invalid syntax
&gt;&gt;&gt; 123e+xpelliarmus
  File "&lt;stdin&gt;", line 1
    123e+xpelliarmus
        ^
SyntaxError: invalid token
</pre>
<p>In the first one, the tokenizer determines it is the NUMBER token ‘123’ followed by the NAME token ‘expelliarmus’ (it is only later that CPython realizes this is a syntax error).<br/>
In the second one, the tokenizer identifies the potential NUMBER token ‘123e+’, and then determines it is an ERRORTOKEN, because the plus is not followed by a decimal digit.<br/>
Hmph. Why not make the tokenizer classify the first one also as an ERRORTOKEN? Well then…</p>
<p>At last, if the NUMBER token (whatever kind of a NUMBER token it is) ends with the letter ‘j’, it is an imaginary number. After confirming the NUMBER token really is an imaginary number, <i>tok_nextc</i> is called to consume another char. This is done because all other flows reach the shared return code with an extra char consumed, so in order to make the call to <i>tok_backup</i> also a part of the shared code, the imaginary number flow must align with all other flows, and consume an extra char.<br/>
And then, finally, NUMBER is returned.</p>
<p>Phew.<br/>
Tokenizing is not an easy task, and that was only a NUMBER token.</p>
<p>Hmmm… after all that exploration, we realize CPython happily accepts some strange number literals, so to make sure we didn’t get it all wrong, we try them out in the interpreter:</p>
<pre class="brush: python; title: ; notranslate" title="">
&gt;&gt;&gt; 243.j
243j
&gt;&gt;&gt; 123.e2
12300.0
</pre>
<p>Whatever…</p>
<p>Anyway, it looks like we are ready for our first patch.<br/>
We want the tokenizer to identify a hex integer literal without any prefix as a NUMBER token. Also, we don’t want to mix hex integer literals with fractions or imaginary numbers (we don’t have to worry about mixing with numbers that have an exponent part, as the letter ‘e’ would be treated as a hex digit anyway).</p>
<p>Therefore, if our patched tokenizer identifies a hex integer literal without a prefix, it shouldn’t accept a dot or the letter ‘j’ as part of the token. However, if it identifies a decimal integer literal without a prefix, it should treat it as a decimal integer literal (i.e. accept a fraction and or an imaginary number).</p>
<p>Someway, this turned out to be quite a small patch:</p>
<pre class="brush: cpp; title: ; notranslate" title="">
        else {
            /* origComment: Decimal */
            /* orenmnComment: Hex or Decimal */
            int orenmn_is_hex_int_literal = 0;
            do {
                c = tok_nextc(tok);
                if (isxdigit(c) &amp;&amp; !isdigit(c))
                    orenmn_is_hex_int_literal = 1;
            // origLine: } while (isdigit(c));
            } while (isxdigit(c));  // orenmnLine
            // origLine: {
            if (!orenmn_is_hex_int_literal) {
                /* Accept floating point numbers. */
                if (c == '.') {
        fraction:
                    /* Fraction */
                    do {
                        c = tok_nextc(tok);
                    } while (isdigit(c));
                }
                if (c == 'e' || c == 'E') {
                    int e;
                  exponent:
                    e = c;
                    /* Exponent part */
                    c = tok_nextc(tok);
                    if (c == '+' || c == '-') {
                        c = tok_nextc(tok);
                        if (!isdigit(c)) {
                            tok-&gt;done = E_TOKEN;
                            tok_backup(tok, c);
                            return ERRORTOKEN;
                        }
                    } else if (!isdigit(c)) {
                        tok_backup(tok, c);
                        tok_backup(tok, e);
                        *p_start = tok-&gt;start;
                        *p_end = tok-&gt;cur;
                        return NUMBER;
                    }
                    do {
                        c = tok_nextc(tok);
                    } while (isdigit(c));
                }
                if (c == 'j' || c == 'J')
                    /* Imaginary part */
        imaginary:
                    c = tok_nextc(tok);
            }
        }
</pre>
<p>We build our <a href="https://github.com/orenmn/orenmnCpython/tree/958ba98b727bf2ec788a1dcfa18a5d203b60f52a">patched CPython</a>, and get the following behavior:</p>
<pre class="brush: python; title: ; notranslate" title="">
&gt;&gt;&gt; 2f3
ValueError: could not convert string to float: 2f3
&gt;&gt;&gt; 2f3j
  File "&lt;stdin&gt;", line 1
    2f3j
       ^
SyntaxError: invalid syntax
&gt;&gt;&gt; 243j
243j
&gt;&gt;&gt; 2f3.
  File "&lt;stdin&gt;", line 1
    2f3.
       ^
SyntaxError: invalid syntax
&gt;&gt;&gt; 243.
243.0
&gt;&gt;&gt; 2f3.j
ValueError: could not convert string to float: 2f3
&gt;&gt;&gt; 243.j
243j
&gt;&gt;&gt; 2f3.123e2j
  File "&lt;stdin&gt;", line 1
    2f3.123e2j
             ^
SyntaxError: invalid syntax
&gt;&gt;&gt; 243.123e2j
24312.3j
&gt;&gt;&gt; 3e8
300000000.0
&gt;&gt;&gt; 3e8a
ValueError: could not convert string to float: 3e8a
</pre>
<p>Well, at least we have got some of it right (looks like hex integer literals actually don’t mix with fractions and imaginary numbers).<br/>
But why did CPython try to convert ‘2f3’ and ‘3e8a’ into floats?<br/>
This has probably happened because the functions that do the parsing (or those that do the transforming of the CST into an AST) had received a supposedly valid NUMBER token, which is not really that valid. Yet.</p>
<p>And thus, again, we must end this post abruptly, as it too became longer than it had any right to be. As usual, we would continue our journey on the next post.</p>
<p><a href="https://orenmn.wordpress.com/2016/01/16/understanding-cpython-by-patching-part-4/">part 4</a></p>
<div id="jp-post-flair" class="sharedaddy sd-like-enabled sd-sharing-enabled"><div class="sharedaddy sd-block sd-like jetpack-likes-widget-wrapper jetpack-likes-widget-unloaded" id="like-post-wrapper-104378497-572-56d5c7f00a139" data-src="//widgets.wp.com/likes/#blog_id=104378497&amp;post_id=572&amp;origin=orenmn.wordpress.com&amp;obj_id=104378497-572-56d5c7f00a139" data-name="like-post-frame-104378497-572-56d5c7f00a139"><h3 class="sd-title">Like this:</h3><p class="likes-widget-placeholder post-likes-widget-placeholder"><span class="button"><span>Like</span></span> <span class="loading">Loading...</span></p><span class="sd-text-color"/><a class="sd-link-color"/></div></div>			</div>

	</div></body></html>