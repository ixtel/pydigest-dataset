<html><body><div><div class="content html_format"><p>
      Персональные рекомендации позволяют познакомить пользователя с объектами, о которых он, возможно, никогда не знал (и не узнал бы), но которые могут ему понравиться с учетом его интересов, предпочтений и поведенческих свойств. Однако, часто пользователь ищет не новый объект, а, к примеру, объект A похожий на объект B («Форсаж 2» похож на «Форсаж»), или объект A, который приобретается/потребляется с объектом B (сыр с вином, пиво с детским питанием, гречка с тушенкой и т.д.). Построить такие рекомендации позволяют неперсонализированные рекомендательные системы (НРС). </p>

<div><img src="https://habrastorage.org/files/754/aee/b98/754aeeb989fa4f4c970cd9242d6486b7.png"/></div><p>
Рекомендовать похожие/сопутствующие объекты можно, ориентируясь на знания об объектах (свойства, теги, параметры) или на знания о действиях, связанных с объектами (покупки, просмотры, клики). Преимуществом первого способа является то, что он позволяет достаточно точно определить похожие по свойствам объекты («Форсаж 2» и «Форсаж» — похожие актеры, похожий жанр, похожие теги, ...). Однако данный способ не сможет порекомендовать сопутствующие объекты: сыр и вино. Еще одним недостатком этого способа является тот факт, что для разметки всех объектов, доступных на сервисе, требуется не мало усилий.
</p><p>
В то же время почти каждый сервис логирует информацию о том, какой пользователь просмотрел/купил/кликнул какой объект. Данной информации достаточно для построения НРС, которая позволит рекомендовать как похожие, так и сопутствующие объекты. 
</p><p>
Под катом описан метод ассоциаций, позволяющий построить неперсонализированные рекомендации, основываясь лишь на данных о действиях над объектами. Там же код на Python, позволяющий применить метод для большого объема данных.
</p><a name="habracut"/>
<h4><font>Построение неперсонализированных рекомендаций</font></h4><p>
Для начала рассмотрим базовый алгоритм построения неперсонализированных рекомендаций. Предположим, что у нас есть объекты — фильмы и пользователи. Пользователи просматривают фильмы. Нашими исходными данными является разреженная матрица D (фильмы x пользователи). Если пользователь u просмотрел фильм f, то в соответствующей ячейке матрицы D стоит 1.
</p><p>
Для того чтобы найти фильмы, похожие на заданный фильм f необходимо знать схожесть фильма f со всеми остальными фильмами. Данные о схожести хранятся в матрице S (фильмы x фильмы).
</p><p>
Базовый алгоритм построения неперсонализированных рекомендаций выглядит следующим образом:

</p><ol>
<li>для заданного фильма f найти соответствующую ему строку R в матрице S;</li>
<li>выбрать из строки R множество наиболее похожих на f фильмов — FR;</li>
<li>FR и есть непресонализированные рекомендации (похожие/сопутствующие).</li>
</ol>
<h4><font>Метод схожести</font></h4><p>
Из описанного видно, что рекомендации и их качество зависят только от способа построения матрицы S, а если быть точнее — от способа определения схожести двух фильмов.
</p><p>
Как определить схожесть фильмов x и y, если их посмотрело множество пользователей X и Y соответственно? Наиболее простое решение — </p><a href="http://en.wikipedia.org/wiki/Jaccard_index">Коэффициент Жаккара</a><p>, который вычисляет схожесть двух объектов (x и y) как: 

</p><img src="https://habrastorage.org/files/42d/737/24c/42d73724c60540f7bc47b3a40e9b67aa.png"/>
<p>
Здесь числитель — количество пользователей, просмотревших как фильм x, так и фильм y. Знаменатель — количество пользователей, которые просмотрели или фильм x или фильм y.
</p><p>
Вычисленное значение является симметричным: x похож на y также, как y похож на x. Если же мы хотим сделать коэффициент асимметричным, то можно поменять формулу на следующую: 

</p><img src="https://habrastorage.org/files/c0c/e6c/867/c0ce6c8679c54fe1a9fcb106e5a03ed1.png"/>
<p>
На первый взгляд данный метод является идеальным: он увеличивает значение схожести фильмам, которые смотрят вместе, и нормализует метрику относительно количества пользователей, которые просмотрели фильм.

</p><h4><font>«Проблема Гарри Поттера» или «банановая ловушка»</font></h4><p>
Рассмотрим указанную выше формулу для случая, когда объект y очень популярен (например, фильм о Гарри Поттере). Так как фильм очень популярен и его смотрело много людей, то sim(x, y) будет стремиться к 1 почти для всех фильмов x. Это значит, что фильм y будет похож на все фильмы, а это в большинстве случаев плохо. Вряд ли «Гарри Поттер» будет похож на фильм «Зеленый слоник». 
</p><p>
«Проблему Гарри Поттера» также называют «банановой ловушкой»(banana trap). Предположим, что некоторый магазин пытается увеличить прибыль путем рекомендации покупателю товаров, которые часто берут вместе с тем, что покупатель собирается приобрести. Одним из наиболее покупаемых товаров в продуктовом магазине являются бананы. Используя формулу выше, система будет рекомендовать всем покупателям приобрести бананы. Бананы будут покупаться — все хорошо. Но это плохие рекомендации, так как бананы покупались бы и без рекомендаций. Рекомендуя бананы, мы уменьшаем прибыль как минимум на один удачно рекомендованный товар, отличный от бананов.

</p><h4><font>Метод ассоциаций</font></h4><p>
Очевидно, что формулу надо модифицировать таким образом, чтобы объект x делал объект y более привлекательным. Т.е. нужно учитывать не только то, что объекты x и y берут вместе, но и то, что объект x не берут без y.
</p><p>
Модифицируем формулу схожести следующим образом: 

</p><img src="https://habrastorage.org/files/efb/f41/795/efbf417956e744918a924f67a9df5541.png"/>
<p>
Здесь !X — это множество пользователей, которые не просмотрели фильм x. Если y — очень популярный объект, то знаменатель в формуле будет большим. Тогда значение схожести будет меньше, а рекомендации будут более релевантными. Данный метод называется методом ассоциаций.

</p><h4><font>Сравнение методов</font></h4><p>
Для сравнения работы метода ассоциаций и коэффициента Жаккара рассмотрим поиск похожих фильмов с использованием этих двух методов по следующим исходным данным.
</p><table>
<tr>
<th>фильмы\пользователи</th>
<th>А</th>
<th>B</th>
<th>C</th>
<th>D</th>
<th>E</th>
</tr>
<tr>
<th>1. Гарри Поттер и философский камень</th>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<th>2. Хоббит: Нежданное путешествие</th>
<td>1</td>
<td>1</td>
<td/>
<td/>
<td>1</td>
</tr>
<tr>
<th>3. Хоббит: Пустошь Смауга</th>
<td>1</td>
<td>1</td>
<td/>
<td>1</td>
<td/>
</tr>
<tr>
<th>4. Хроники Нарнии: Принц Каспиан</th>
<td/>
<td/>
<td>1</td>
<td/>
<td/>
</tr>
<tr>
<th>5. Сердце дракона</th>
<td/>
<td/>
<td/>
<td/>
<td>1</td>
</tr>
</table><p>Матрица схожести, построенная с помощью асимметричного коэффициента Жаккара, выглядит следующим образом (диагональ зануляем, чтобы не рекомендовать исходный фильм):
</p><table>
<tr>
<th>фильмы\фильмы</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
</tr>
<tr>
<th>1 </th>
<td>0</td>
<td>0,6</td>
<td>0,6</td>
<td>0,2</td>
<td>0,2</td>
</tr>
<tr>
<th>2</th>
<td>1</td>
<td>0</td>
<td>0,667</td>
<td>0</td>
<td>0,333</td>
</tr>
<tr>
<th>3 </th>
<td>1</td>
<td>0,667</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<th>4 </th>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<th>5 </th>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
</table><p>Матрица схожести для метода ассоциаций будет выглядеть следующим образом (помимо диагонали зануляем бесконечности — случаи, когда </p><img src="https://habrastorage.org/files/550/1e4/873/5501e48739ba41c391d8bb3f5f41960f.png"/><p>).
</p><table>
<tr>
<th>фильмы\фильмы</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
</tr>
<tr>
<th>1</th>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<th>2</th>
<td>1,5</td>
<td>0</td>
<td>2</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<th>3</th>
<td>1,5</td>
<td>2</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<th>4</th>
<td>0,25</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<th>5</th>
<td>0,25</td>
<td>0,5</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
</table><p>Как видно из матрицы схожести, метод ассоциаций позволяет учесть сверхпопулярность фильма «Гарри Поттер и философский камень». При построении рекомендаций методом ассоциаций для фильма «Хоббит: Нежданное путешествие» вес «Гарри Поттера» (1,5) будет меньше, чем вес более релевантного фильма «Хоббит: Пустошь Смауга» (2). 

</p><h4><font>Реализация</font></h4><p>
Ниже приведена функция для построения матрицы схожести на базе метода ассоциаций. Функция написана на Python с использованием scipy и scikit-learn. Данная реализация позволяет быстро и без особых затрат вычислить матрицу схожести для большого объема исходных данных.
</p><p>
Так как в пределах одной строки матрицы значения |X| и |!X| не меняются, а схожие объекты будут находиться в пределах одной строки, то |X| и |!X| были опущены при вычислении метрики ассоциации. Конечная формула метрики выглядит так: 

</p><img src="https://habrastorage.org/files/bb1/e6a/079/bb1e6a07919d4191b04bf4d4f9aa8757.png"/>

<pre><code class="python">def get_item_item_association_matrix(sp_matrix):
    """Простой способ построения матрицы ассоциаций
    
    :param sp_matrix: матрица с исходными данными о просмотрах (фильмы x пользователи)
    :return: матрица схожести фильмов (фильмы x фильмы)
    """
    watched_x_and_y = sp_matrix.dot(sp_matrix.T).tocsr()
    watched_x = csr_matrix(sp_matrix.sum(axis=1))
    magic = binarize(watched_x_and_y).multiply(watched_x.T)
    watched_not_x_and_y = magic - watched_x_and_y
    rows, cols = watched_not_x_and_y.nonzero()
    data_in_same_pos = watched_x_and_y[rows, cols].A.reshape(-1)
    return csr_matrix((data_in_same_pos / watched_not_x_and_y.data, (rows, cols)), watched_x_and_y.shape)
</code></pre>
<h4><font>Заключение</font></h4><p>
Метод ассоциаций является всего лишь одним из способов построения неперсонализированных рекомендаций. Как и для любого другого метода, перед его применением нужно решить ряд вопросов:
</p><p>
 — определить минимальное количество данных, при котором можно применять метод;</p><p>
 — определить пороговое значение метрики ассоциации;</p><p>
 — определить, что делать, если у рекомендованных объектов значение метрики ассоциации меньше порогового;</p><p>
 — и т.д.
</p><p>
Из перечисленного следует, что метод ассоциаций может быть применен не для всех объектов. Поэтому его стоит комбинировать с одним или более методов построения неперсонализированных рекомендаций. Такой подход позволит создавать хорошие рекомендации независимо от количества данных о пользователе или объекте. 
</p><p>
P.S. Удачных рекомендаций!

      
      </p><p class="clear"/>
    </div>

    
  </div></body></html>