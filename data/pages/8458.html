<html><body><div><article class="markdown-body entry-content" itemprop="text"><p><a href="https://travis-ci.org/danijar/layered"><img src="https://camo.githubusercontent.com/809e70b4ddbcb2b92d2b7c9572c651c455bd189e/68747470733a2f2f7472617669732d63692e6f72672f64616e696a61722f6c6179657265642e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/danijar/layered.svg?branch=master"/></a>
<a href="https://codeclimate.com/github/danijar/layered"><img src="https://camo.githubusercontent.com/59e2997fc928c3dd1ddb30f50cc82d617e57a7ce/68747470733a2f2f636f6465636c696d6174652e636f6d2f6769746875622f64616e696a61722f6c6179657265642f6261646765732f6770612e737667" alt="Code Climate" data-canonical-src="https://codeclimate.com/github/danijar/layered/badges/gpa.svg"/></a>
<a href="https://pypi.python.org/pypi/layered"><img src="https://camo.githubusercontent.com/b21d93d0d3ff5e7e92284f40684511400a1b0bdd/68747470733a2f2f696d672e736869656c64732e696f2f707970692f64772f6c6179657265642e737667" alt="PyPI Downloads" data-canonical-src="https://img.shields.io/pypi/dw/layered.svg"/></a>
<a href="https://layered.readthedocs.org/en/latest/"><img src="https://camo.githubusercontent.com/b6913ba18483a8d22fc6f72342a0d0353ca3bcfc/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f7069702f62616467652f" alt="Documentation" data-canonical-src="https://readthedocs.org/projects/pip/badge/"/></a></p>

<h1><a id="user-content-layered" class="anchor" href="#layered" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Layered</h1>

<p>This project is aims to be a clean reference implementation of feed forward
neural networks. It's written in Python 3 and published under the MIT license.
I started this project as part of my efforts to understand the concepts of deep
learning. You can use this repository as guidance if you want to implement
neural networks what I highly recommend if you are interested in understanding
them.</p>

<p>Please don't hestitate to send feedback and ideas to me at <a href="mailto:mail@danijar.com">mail@danijar.com</a> and
open issues if something's not working.</p>

<h2><a id="user-content-instructions" class="anchor" href="#instructions" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Instructions</h2>

<p>This will train a network with 1.3M weights to classify handwritten digits and
visualize the progress. After a couple of minutes, the error should drop below
3%. To install globally, just skip the first command. Solutions to all reported
problems can be found in the troubleshooting section.</p>

<div class="highlight highlight-source-shell"><pre>virtualenv <span class="pl-c1">.</span> -p python3 --system-site-packages <span class="pl-k">&amp;&amp;</span> <span class="pl-c1">source</span> bin/activate
pip3 install layered
curl -o mnist.yaml -L http://git.io/vBPOH
layered mnist.yaml -v</pre></div>

<h3><a id="user-content-problem-definition" class="anchor" href="#problem-definition" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Problem Definition</h3>

<p>Learning problems are defined in YAML files and it's easy to create your own.
An overview of available cost and activation functions is available a few
sections below.</p>

<div class="highlight highlight-source-yaml"><pre><span class="pl-s"><span class="pl-ent">dataset:</span> <span class="pl-s">Mnist</span></span>
<span class="pl-s"><span class="pl-ent">cost:</span> <span class="pl-s">CrossEntropy</span></span>
<span class="pl-s"><span class="pl-ent">layers:</span></span>
<span class="pl-s">- <span class="pl-ent">activation:</span> <span class="pl-s">Identity</span></span>
  <span class="pl-c1"><span class="pl-ent">size:</span> 784</span>
<span class="pl-s">- <span class="pl-ent">activation:</span> <span class="pl-s">Relu</span></span>
  <span class="pl-c1"><span class="pl-ent">size:</span> 700</span>
<span class="pl-s">- <span class="pl-ent">activation:</span> <span class="pl-s">Relu</span></span>
  <span class="pl-c1"><span class="pl-ent">size:</span> 700</span>
<span class="pl-s">- <span class="pl-ent">activation:</span> <span class="pl-s">Relu</span></span>
  <span class="pl-c1"><span class="pl-ent">size:</span> 400</span>
<span class="pl-s">- <span class="pl-ent">activation:</span> <span class="pl-s">Softmax</span></span>
  <span class="pl-c1"><span class="pl-ent">size:</span> 10</span>
<span class="pl-c1"><span class="pl-ent">epochs:</span> 5</span>
<span class="pl-c1"><span class="pl-ent">batch_size:</span> 32</span>
<span class="pl-c1"><span class="pl-ent">learning_rate:</span> 0.01</span>
<span class="pl-c1"><span class="pl-ent">momentum:</span> 0.9</span>
<span class="pl-c1"><span class="pl-ent">weight_scale:</span> 0.01</span>
<span class="pl-c1"><span class="pl-ent">weight_decay:</span> 0</span>
<span class="pl-c1"><span class="pl-ent">evaluate_every:</span> 5000</span></pre></div>

<h3><a id="user-content-command-line-arguments" class="anchor" href="#command-line-arguments" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Command Line Arguments</h3>

<pre><code>layered [-h] [-v] [-l weights.npy] [-s weights.npy] problem.yaml
</code></pre>

<table><thead>
<tr>
<th align="left">Short</th>
<th align="left">Long</th>
<th align="left">Description</th>
</tr>
</thead><tbody>
<tr>
<td align="left"><code>-h</code></td>
<td align="left"><code>--help</code></td>
<td align="left">Print usage instructions</td>
</tr>
<tr>
<td align="left"><code>-v</code></td>
<td align="left"><code>--visual</code></td>
<td align="left">Show a diagram of trainig costs and testing error</td>
</tr>
<tr>
<td align="left"><code>-l</code></td>
<td align="left"><code>--load</code></td>
<td align="left">Path to load learned weights from at startup</td>
</tr>
<tr>
<td align="left"><code>-s</code></td>
<td align="left"><code>--save</code></td>
<td align="left">Path to dump the learned weights at each evaluation</td>
</tr>
</tbody></table>

<h3><a id="user-content-contribution" class="anchor" href="#contribution" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Contribution</h3>

<p>Optionally, create a virtual environment. Then install the dependencies. The
last command is just to see if everything's working.</p>

<div class="highlight highlight-source-shell"><pre>git clone https://github.com/danijar/layered.git <span class="pl-k">&amp;&amp;</span> <span class="pl-c1">cd</span> layered
virtualenv <span class="pl-c1">.</span> -p python3 --system-site-packages <span class="pl-k">&amp;&amp;</span> <span class="pl-c1">source</span> bin/activate
pip3 install -e <span class="pl-c1">.</span>
python3 -m layered problem/modulo.yaml -v</pre></div>

<p>Now you can start playing around with the code. For pull requests, please
squash the changes to a single commit and ensure that the linters and tests are
passing.</p>



<p>If you have questions, feel free to contact me.</p>

<h2><a id="user-content-advanced-guide" class="anchor" href="#advanced-guide" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Advanced Guide</h2>

<p>In this guide you will learn how to create and train models manually rather
than using the problem definitions to gain more insight into training neural
networks. Let's start!</p>

<h3><a id="user-content-step-1-network-definition" class="anchor" href="#step-1-network-definition" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Step 1: Network Definition</h3>

<p>A network is defined by its layers. The parameters for a layer are the amount
of neurons and the activation function. The first layer has the identity
function since we don't want to already modify the input data before feeding it
in.</p>

<div class="highlight highlight-source-python"><pre><span class="pl-k">from</span> layered.network <span class="pl-k">import</span> Network
<span class="pl-k">from</span> layered.activation <span class="pl-k">import</span> Identity, Relu, Softmax

num_inputs <span class="pl-k">=</span> <span class="pl-c1">784</span>
num_outputs <span class="pl-k">=</span> <span class="pl-c1">10</span>

network <span class="pl-k">=</span> Network([
    Layer(num_inputs, Identity),
    Layer(<span class="pl-c1">700</span>, Relu),
    Layer(<span class="pl-c1">500</span>, Relu),
    Layer(<span class="pl-c1">300</span>, Relu),
    Layer(num_outputs, Softmax),
])</pre></div>

<h3><a id="user-content-step-2-activation-functions" class="anchor" href="#step-2-activation-functions" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Step 2: Activation Functions</h3>

<table><thead>
<tr>
<th>Function</th>
<th>Description</th>
<th align="center">Definition</th>
<th>__________Graph__________</th>
</tr>
</thead><tbody>
<tr>
<td>Identity</td>
<td>Don't transform the incoming data. That's what you would expect at input layers.</td>
<td align="center">x</td>
<td><a href="/danijar/layered/blob/master/image/identity.png" target="_blank"><img src="/danijar/layered/raw/master/image/identity.png" alt="Identity"/></a></td>
</tr>
<tr>
<td>Relu</td>
<td>Fast non-linear function that has proven to be effective in deep networks.</td>
<td align="center">max(0, x)</td>
<td><a href="/danijar/layered/blob/master/image/relu.png" target="_blank"><img src="/danijar/layered/raw/master/image/relu.png" alt="Relu"/></a></td>
</tr>
<tr>
<td>Sigmoid</td>
<td>The de facto standard activation before Relu came up. Smoothly maps the incoming activation into a range from zero to one.</td>
<td align="center">1 / (1 + exp(-x))</td>
<td><a href="/danijar/layered/blob/master/image/sigmoid.png" target="_blank"><img src="/danijar/layered/raw/master/image/sigmoid.png" alt="Sigmoid"/></a></td>
</tr>
<tr>
<td>Softmax</td>
<td>Smooth activation function where the outgoing activations sum up to one. It's commonly used for output layers in classification because the outgoing activations can be interpreted as probabilities.</td>
<td align="center">exp(x) / sum(exp(x))</td>
<td><a href="/danijar/layered/blob/master/image/softmax.png" target="_blank"><img src="/danijar/layered/raw/master/image/softmax.png" alt="Softmax"/></a></td>
</tr>
</tbody></table>

<h3><a id="user-content-step-3-weight-initialization" class="anchor" href="#step-3-weight-initialization" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Step 3: Weight Initialization</h3>

<p>The weight matrices of the network are handed to algorithms like
backpropagation, gradient decent and weight decay. If the initial weights of a
neural network would be zero, no activation would be passed to the deeper
layers. So we start with random values sampled from a normal distribution.</p>

<div class="highlight highlight-source-python"><pre><span class="pl-k">from</span> layered.network <span class="pl-k">import</span> Matrices

weights <span class="pl-k">=</span> Matrices(network.shapes)
weights.flat <span class="pl-k">=</span> np.random.normal(<span class="pl-c1">0</span>, weight_scale, <span class="pl-c1">len</span>(weights.flat))</pre></div>

<h3><a id="user-content-step-4-optimization-algorithm" class="anchor" href="#step-4-optimization-algorithm" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Step 4: Optimization Algorithm</h3>

<p>Now let's learn good weights with standard backpropagation and gradient decent.
The classes for this can be imported from the <code>gradient</code> and <code>optimization</code>
modules. We also need a cost function.</p>

<div class="highlight highlight-source-python"><pre><span class="pl-k">from</span> layered.cost <span class="pl-k">import</span> SquaredError
<span class="pl-k">from</span> layered.gradient <span class="pl-k">import</span> Backprop
<span class="pl-k">from</span> layered.optimization <span class="pl-k">import</span> GradientDecent

backprop <span class="pl-k">=</span> Backprop(network, <span class="pl-v">cost</span><span class="pl-k">=</span>SquaredError())
decent <span class="pl-k">=</span> GradientDecent()</pre></div>

<h3><a id="user-content-step-5-cost-functions" class="anchor" href="#step-5-cost-functions" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Step 5: Cost Functions</h3>

<table><thead>
<tr>
<th>Function</th>
<th>Description</th>
<th align="center">Definition</th>
<th>__________Graph__________</th>
</tr>
</thead><tbody>
<tr>
<td>SquaredError</td>
<td>The most common cost function. The difference is squared to always be positive and penalize large errors stronger.</td>
<td align="center">(pred - target) ^ 2 / 2</td>
<td><a href="/danijar/layered/blob/master/image/squared-error.png" target="_blank"><img src="/danijar/layered/raw/master/image/squared-error.png" alt="Squared Error"/></a></td>
</tr>
<tr>
<td>CrossEntropy</td>
<td>Logistic cost function useful for classification tasks. Commonly used in conjunction with Softmax output layers.</td>
<td align="center">-((target * log(pred)) + (1 - target) * log(1 - pred))</td>
<td><a href="/danijar/layered/blob/master/image/cross-entropy.png" target="_blank"><img src="/danijar/layered/raw/master/image/cross-entropy.png" alt="Cross Entropy"/></a></td>
</tr>
</tbody></table>

<h3><a id="user-content-step-6-dataset-and-training" class="anchor" href="#step-6-dataset-and-training" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Step 6: Dataset and Training</h3>

<p>Datasets are automatically downloaded and cached. We just iterate over the
training examples and train the weights on them.</p>

<div class="highlight highlight-source-python"><pre><span class="pl-k">from</span> layered.dataset <span class="pl-k">import</span> Mnist

dataset <span class="pl-k">=</span> Mnist()
<span class="pl-k">for</span> example <span class="pl-k">in</span> dataset.training:
    gradient <span class="pl-k">=</span> backprop(weights, example)
    weights <span class="pl-k">=</span> decent(weights, gradient, <span class="pl-v">learning_rate</span><span class="pl-k">=</span><span class="pl-c1">0.1</span>)</pre></div>

<h3><a id="user-content-step-7-evaluation" class="anchor" href="#step-7-evaluation" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Step 7: Evaluation</h3>

<p>Finally, we want to see what our network has learned. We do this by letting the
network predict classes for the testing examples. The strongest class is the
model's best bet, thus the <code>np.argmax</code>.</p>

<div class="highlight highlight-source-python"><pre><span class="pl-k">import</span> numpy <span class="pl-k">as</span> np

error <span class="pl-k">=</span> <span class="pl-c1">0</span>
<span class="pl-k">for</span> example <span class="pl-k">in</span> dataset.testing:
    prediction <span class="pl-k">=</span> network.feed(weights, example.data)
    <span class="pl-k">if</span> np.argmax(prediction) <span class="pl-k">!=</span> np.argmax(example.target):
        error <span class="pl-k">+=</span> <span class="pl-c1">1</span> <span class="pl-k">/</span> <span class="pl-c1">len</span>(dataset.testing)
<span class="pl-c1">print</span>(<span class="pl-s"><span class="pl-pds">'</span>Testing error<span class="pl-pds">'</span></span>, <span class="pl-c1">round</span>(<span class="pl-c1">100</span> <span class="pl-k">*</span> error, <span class="pl-c1">2</span>), <span class="pl-s"><span class="pl-pds">'</span>%<span class="pl-pds">'</span></span>)</pre></div>

<h2><a id="user-content-troubleshooting" class="anchor" href="#troubleshooting" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Troubleshooting</h2>

<h3><a id="user-content-failed-building-wheel" class="anchor" href="#failed-building-wheel" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Failed building wheel</h3>

<p>You can safely ignore this messages during installation.</p>

<h3><a id="user-content-python-is-not-installed-as-a-framework" class="anchor" href="#python-is-not-installed-as-a-framework" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Python is not installed as a framework</h3>

<p>If you get this error on Mac, don't create a virtualenv and install layered
globally with <code>sudo pip3 install layered</code>.</p>

<h3><a id="user-content-crash-at-startup" class="anchor" href="#crash-at-startup" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Crash at startup</h3>

<p>Install or reinstall <code>python3-matplotlib</code> or equivalent using your package
manager. Check if matplotlib works outside of the virtualenv.</p>

<div class="highlight highlight-source-python"><pre><span class="pl-k">import</span> matplotlib.pyplot <span class="pl-k">as</span> plt
plt.plt([<span class="pl-c1">1</span>, <span class="pl-c1">2</span>, <span class="pl-c1">3</span>, <span class="pl-c1">4</span>])
plt.show()</pre></div>

<p>Ensure you create your virtualenv with <code>--system-site-packages</code>.</p>

<h3><a id="user-content-did-you-encounter-another-problem" class="anchor" href="#did-you-encounter-another-problem" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Did you encounter another problem?</h3>

<p>Please <a href="https://github.com/danijar/layered/issues">open an issue</a>.</p>
</article>
  </div></body></html>