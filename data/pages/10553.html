<html><body><div><div class="post-text" itemprop="text">
<p>I highly recommend that you take a look at the <a href="https://github.com/pydata/xarray" rel="nofollow"><code>xarray</code></a> and <a href="https://github.com/dask/dask" rel="nofollow"><code>dask</code></a> projects.   Using these powerful tools will allow you to easily split up the computation in chunks.  This brings up two advantages: you can compute on data which does not fit in memory, and you can use all of the cores in your machine for better performance.  You can optimize the performance by appropriately choosing the chunk size (see <a href="http://xarray.pydata.org/en/stable/dask.html" rel="nofollow">documentation</a>).</p>

<p>You can load your data from netCDF by doing something as simple as </p>

<pre><code>import xarray as xr
ds = xr.open_dataset(path_file)
</code></pre>

<p>If you want to chunk your data in years along the time dimension, then you specify the <code>chunks</code> parameter (assuming that the year coordinate is named 'year'):</p>

<pre><code>ds = xr.open_dataset(path_file, chunks={'year': 10})
</code></pre>

<p>Since the other coordinates do not appear in the <code>chunks</code> dict,  then a single chunk will be used for them.  (See more details in the documentation <a href="http://xarray.pydata.org/en/stable/dask.html" rel="nofollow">here</a>.).  This will be useful for your first requirement, where you want to multiply each year by a 2D array.  You would simply do: </p>

<pre><code>ds['new_var'] = ds['var_name'] * arr_2d
</code></pre>

<p>Now, <code>xarray</code> and <code>dask</code> are computing your result <em>lazily</em>.  In order to trigger the actual computation, you can simply ask <code>xarray</code> to save your result back to netCDF:</p>

<pre><code>ds.to_netcdf(new_file)
</code></pre>

<p>The computation gets triggered through <code>dask</code>, which takes care of splitting the processing out in chunks and thus enables working with data that does not fit in memory.  In addition, <code>dask</code> will take care of using all your processor cores for computing chunks.  </p>

<p>The <code>xarray</code> and <code>dask</code> projects still don't handle nicely situations where chunks do not "align" well for parallel computation.  Since in this case we chunked only in the 'year' dimension, we expect to have no issues. </p>

<p>If you want to add two different netCDF files together, it is as simple as:</p>

<pre><code>ds1 = xr.open_dataset(path_file1, chunks={'year': 10})
ds2 = xr.open_dataset(path_file2, chunks={'year': 10})
(ds1 + ds2).to_netcdf(new_file)
</code></pre>

<p/>

<p>I have provided a fully working example using <a href="https://www.unidata.ucar.edu/software/netcdf/examples/ECMWF_ERA-40_subset.nc" rel="nofollow">a dataset available online</a>. </p>

<pre><code>In [1]:

import xarray as xr
import numpy as np

# Load sample data and strip out most of it:
ds = xr.open_dataset('ECMWF_ERA-40_subset.nc', chunks = {'time': 4})
ds.attrs = {}
ds = ds[['latitude', 'longitude', 'time', 'tcw']]
ds

Out[1]:

&lt;xarray.Dataset&gt;
Dimensions:    (latitude: 73, longitude: 144, time: 62)
Coordinates:
  * latitude   (latitude) float32 90.0 87.5 85.0 82.5 80.0 77.5 75.0 72.5 ...
  * longitude  (longitude) float32 0.0 2.5 5.0 7.5 10.0 12.5 15.0 17.5 20.0 ...
  * time       (time) datetime64[ns] 2002-07-01T12:00:00 2002-07-01T18:00:00 ...
Data variables:
    tcw        (time, latitude, longitude) float64 10.15 10.15 10.15 10.15 ...

In [2]:

arr2d = np.ones((73, 144)) * 3.
arr2d.shape

Out[2]:

(73, 144)

In [3]:

myds = ds
myds['new_var'] = ds['tcw'] * arr2d

In [4]:

myds

Out[4]:

&lt;xarray.Dataset&gt;
Dimensions:    (latitude: 73, longitude: 144, time: 62)
Coordinates:
  * latitude   (latitude) float32 90.0 87.5 85.0 82.5 80.0 77.5 75.0 72.5 ...
  * longitude  (longitude) float32 0.0 2.5 5.0 7.5 10.0 12.5 15.0 17.5 20.0 ...
  * time       (time) datetime64[ns] 2002-07-01T12:00:00 2002-07-01T18:00:00 ...
Data variables:
    tcw        (time, latitude, longitude) float64 10.15 10.15 10.15 10.15 ...
    new_var    (time, latitude, longitude) float64 30.46 30.46 30.46 30.46 ...

In [5]:

myds.to_netcdf('myds.nc')
xr.open_dataset('myds.nc')

Out[5]:

&lt;xarray.Dataset&gt;
Dimensions:    (latitude: 73, longitude: 144, time: 62)
Coordinates:
  * latitude   (latitude) float32 90.0 87.5 85.0 82.5 80.0 77.5 75.0 72.5 ...
  * longitude  (longitude) float32 0.0 2.5 5.0 7.5 10.0 12.5 15.0 17.5 20.0 ...
  * time       (time) datetime64[ns] 2002-07-01T12:00:00 2002-07-01T18:00:00 ...
Data variables:
    tcw        (time, latitude, longitude) float64 10.15 10.15 10.15 10.15 ...
    new_var    (time, latitude, longitude) float64 30.46 30.46 30.46 30.46 ...

In [6]:

(myds + myds).to_netcdf('myds2.nc')
xr.open_dataset('myds2.nc')

Out[6]:

&lt;xarray.Dataset&gt;
Dimensions:    (latitude: 73, longitude: 144, time: 62)
Coordinates:
  * time       (time) datetime64[ns] 2002-07-01T12:00:00 2002-07-01T18:00:00 ...
  * latitude   (latitude) float32 90.0 87.5 85.0 82.5 80.0 77.5 75.0 72.5 ...
  * longitude  (longitude) float32 0.0 2.5 5.0 7.5 10.0 12.5 15.0 17.5 20.0 ...
Data variables:
    tcw        (time, latitude, longitude) float64 20.31 20.31 20.31 20.31 ...
    new_var    (time, latitude, longitude) float64 60.92 60.92 60.92 60.92 ...
</code></pre>
    </div>
    </div></body></html>