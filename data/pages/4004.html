<html><body><div><div class="entry-content">
						<p>In spring 2014 Python 3.4 shipped a provisional package (asyncio) which according to the <a href="https://docs.python.org/3/library/asyncio.html">docs</a> “<em>provides infrastructure for writing single-threaded concurrent code using coroutines, multiplexing I/O access over sockets and other resources, running network clients and servers, and other related primitives</em>“. I can’t possibly cover everything in this article but I can introduce some of the things you can do with it. As per <a href="http://www.giantflyingsaucer.com/blog/?p=5469">my New’s Years resolution</a> I’ll be building these examples using Python 3.4.2 (Asyncio has been ported back to Python 3.3 now as well).</p>
<p><span id="more-5557"/></p>
<p>Keep in mind these are fun/simple examples to play with and I won’t spend a lot of time explaining tasks, coroutines and futures, etc. The <a href="https://docs.python.org/3/library/asyncio.html">Python 3 docs</a> are very, very good in this regard.</p>
<p>For the first example Let’s do one of the most simple examples possible and for that we will use <a href="https://docs.python.org/3/library/asyncio-task.html#asyncio.Task">asyncio.Task</a>. Lets create our coroutine first by <a href="https://docs.python.org/3/library/asyncio-task.html#asyncio.coroutine">defining it with a decorator</a> and adding an event loop.</p>
<pre class="brush: python; title: ; notranslate" title="">
import asyncio

@asyncio.coroutine
def my_coroutine(seconds_to_sleep=3):
    print('my_coroutine sleeping for: {0} seconds'.format(seconds_to_sleep))
    yield from asyncio.sleep(seconds_to_sleep)


loop = asyncio.get_event_loop()
loop.run_until_complete(
    asyncio.gather(my_coroutine())
)
loop.close()
</pre>
<p>If you run that you should see something similar to this:</p>
<pre class="brush: plain; title: ; notranslate" title="">
my_coroutine sleeping for: 3 seconds
</pre>
<p>Not that impressive and its actually not really possible to see any kind of async action going on. We can fix this by adding a few more tasks and modifying our coroutine like this:</p>
<pre class="brush: python; title: ; notranslate" title="">
import asyncio

@asyncio.coroutine
def my_coroutine(task_name, seconds_to_sleep=3):
    print('{0} sleeping for: {1} seconds'.format(task_name, seconds_to_sleep))
    yield from asyncio.sleep(seconds_to_sleep)
    print('{0} is finished'.format(task_name))


loop = asyncio.get_event_loop()
tasks = [
    my_coroutine('task1', 4),
    my_coroutine('task2', 3),
    my_coroutine('task3', 2)]
loop.run_until_complete(asyncio.wait(tasks))
loop.close()
</pre>
<p>You can now see I added a list of tasks to execute and each has a different sleep setting. According to the sleep setting <strong>task3</strong> should finish first, then <strong>task2</strong>, and finally <strong>task1</strong>. None of these should block the other tasks. The output should be similar to this:</p>
<pre class="brush: plain; title: ; notranslate" title="">
task1 sleeping for: 4 seconds
task2 sleeping for: 3 seconds
task3 sleeping for: 2 seconds
task3 is finished
task2 is finished
task1 is finished
</pre>
<p>Let’s move onto <a href="https://docs.python.org/3/library/asyncio-task.html#asyncio.Future">Futures</a> and a <a href="https://docs.python.org/3/library/asyncio-task.html#asyncio.Future.add_done_callback">callback when the task is done</a>. </p>
<pre class="brush: python; title: ; notranslate" title="">
import asyncio

@asyncio.coroutine
def my_coroutine(future, task_name, seconds_to_sleep=3):
    print('{0} sleeping for: {1} seconds'.format(task_name, seconds_to_sleep))
    yield from asyncio.sleep(seconds_to_sleep)
    future.set_result('{0} is finished'.format(task_name))


def got_result(future):
    print(future.result())

loop = asyncio.get_event_loop()
future1 = asyncio.Future()
future2 = asyncio.Future()

tasks = [
    my_coroutine(future1, 'task1', 3),
    my_coroutine(future2, 'task2', 1)]

future1.add_done_callback(got_result)
future2.add_done_callback(got_result)

loop.run_until_complete(asyncio.wait(tasks))
loop.close()
</pre>
<p>If you run that code you should see something like this:</p>
<pre class="brush: plain; title: ; notranslate" title="">
task1 sleeping for: 3 seconds
task2 sleeping for: 1 seconds
task2 is finished
task1 is finished
</pre>
<p>This is pretty neat in the sense you could easily have this go execute some I/O bound tasks like fetching data over the local network or Internet. Once you’ve collected the data you can then set the result with the Future’s <a href="https://docs.python.org/3/library/asyncio-task.html#asyncio.Future.set_result">set_result</a>.</p>
<p>Let’s continue with a typical example people like to show which is an application that can fetch the contents of several websites at once. I’m going to use <a href="https://github.com/KeepSafe/aiohttp">aiohttp</a> which can be installed easily:</p>
<pre class="brush: plain; title: ; notranslate" title="">
$ pip install aiohttp
</pre>
<p>The code will look like this:</p>
<pre class="brush: python; title: ; notranslate" title="">
import asyncio
import aiohttp

@asyncio.coroutine
def fetch_page(url):
    response = yield from aiohttp.request('GET', url)
    assert response.status == 200
    content = yield from response.read()
    print('URL: {0}:  Content: {1}'.format(url, content))


loop = asyncio.get_event_loop()
tasks = [
    fetch_page('http://google.com'),
    fetch_page('http://cnn.com'),
    fetch_page('http://twitter.com')]
loop.run_until_complete(asyncio.wait(tasks))
loop.close()

for task in tasks:
    print(task)
</pre>
<p>If you run that you’ll see output like this (I chopped out the actual HTML content as its too long):</p>
<pre class="brush: plain; title: ; notranslate" title="">
URL: http://google.com:  Content: b'&lt;!doctype html&gt; ...'
URL: http://cnn.com:  Content: b'&lt;!DOCTYPE html&gt; ...'
URL: http://twitter.com:  Content: b'&lt;!DOCTYPE html&gt; ...'
&lt;Task finished coro=&lt;fetch_page() done, defined at /Users/chadlung/PythonProjects/async-fetch/src/app.py:5&gt; result=None&gt;
&lt;Task finished coro=&lt;fetch_page() done, defined at /Users/chadlung/PythonProjects/async-fetch/src/app.py:5&gt; result=None&gt;
&lt;Task finished coro=&lt;fetch_page() done, defined at /Users/chadlung/PythonProjects/async-fetch/src/app.py:5&gt; result=None&gt;
</pre>
<p>Looking at the results it might look like this still happened synchronously since the results (in the example above) came back in the order we dispatched them. So, lets go ahead and prove that this actually happened asynchronously by injecting a delay on the call to <strong>cnn.com </strong>. We can modify the code like so:</p>
<pre class="brush: python; title: ; notranslate" title="">
import asyncio
import aiohttp

@asyncio.coroutine
def fetch_page(url, pause=False):
    if pause:
        yield from asyncio.sleep(2)

    response = yield from aiohttp.request('GET', url)
    assert response.status == 200
    content = yield from response.read()
    print('URL: {0}:  Content: {1}'.format(url, content))


loop = asyncio.get_event_loop()
tasks = [
    fetch_page('http://google.com'),
    fetch_page('http://cnn.com', True),
    fetch_page('http://twitter.com')]
loop.run_until_complete(asyncio.wait(tasks))
loop.close()

for task in tasks:
    print(task)
</pre>
<p>Now I’ve added an optional 2 second pause before fetching the website’s contents. You can see that the CNN call is not blocking the other calls (tasks) and the order coming back will most likely be similar to this:</p>
<pre class="brush: plain; title: ; notranslate" title="">
URL: http://google.com:  Content: b'&lt;!doctype html&gt; ...'
URL: http://twitter.com:  Content: b'&lt;!DOCTYPE html&gt; ...'
URL: http://cnn.com:  Content: b'&lt;!DOCTYPE html&gt; ...'
</pre>
<p>The final example will use the <a href="https://docs.python.org/3/library/asyncio-queue.html#queues">asyncio.queue</a> to add some work to a queue and have then get processed.</p>
<pre class="brush: python; title: ; notranslate" title="">
import asyncio

@asyncio.coroutine
def do_work(task_name, work_queue):
    while not work_queue.empty():
        queue_item = yield from work_queue.get()
        print('{0} grabbed item: {1}'.format(task_name, queue_item))
        yield from asyncio.sleep(0.5)


if __name__ == "__main__":
    q = asyncio.Queue()

    for x in range(20):
        q.put_nowait(x)

    print(q)

    loop = asyncio.get_event_loop()

    tasks = [
        asyncio.async(do_work('task1', q)),
        asyncio.async(do_work('task2', q)),
        asyncio.async(do_work('task3', q))]

    loop.run_until_complete(asyncio.wait(tasks))
    loop.close()
</pre>
<p>First off I added 20 items (0-19) to a queue. From there we just create a coroutine that can accept an asyncio.queue and then grab items off of the queue to process. If you run the program the output should be similar to this:</p>
<pre class="brush: plain; title: ; notranslate" title="">
&lt;Queue maxsize=0 _queue=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]&gt;
task1 grabbed item: 0
task2 grabbed item: 1
task3 grabbed item: 2
task1 grabbed item: 3
task2 grabbed item: 4
task3 grabbed item: 5
task1 grabbed item: 6
task2 grabbed item: 7
task3 grabbed item: 8
task1 grabbed item: 9
task2 grabbed item: 10
task3 grabbed item: 11
task1 grabbed item: 12
task2 grabbed item: 13
task3 grabbed item: 14
task1 grabbed item: 15
task2 grabbed item: 16
task3 grabbed item: 17
task1 grabbed item: 18
task2 grabbed item: 19
</pre>
<p>These examples are just the tip of the iceberg of what is possible with the new <a href="https://docs.python.org/3/library/asyncio.html">Python asyncio package</a>. As more people begin to discover it and find out where it can be applied I expect to see <a href="http://asyncio.org/">a lot of additional libraries</a> making use of it. Where I work right now asyncio is soon going to be applied to handle massive delete traffic to a very large object store with the help of <a href="http://kafka.apache.org/">Apache Kafka</a>. Just one more example of how Python is capable of scaling to “<em>Cloud Levels</em>” with the right planning and design to the problem.</p>


											</div>


					</div></body></html>