<html><body><div><article class="markdown-body entry-content" itemprop="text"><h1><a id="user-content-visual-search-server" class="anchor" href="#visual-search-server" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Visual Search Server</h1>

<p>A simple implementation of Visual Search using TensorFlow, InceptionV3 model and AWS GPU instances.</p>

<p>This codebase implements a simple visual indexing and search system, using features derived from Google's inception 
model trained on the imagenet data. The easist way to use it is to launch following AMI using GPU enabled g2 instances.
It already contains features computed on ~450,000 images (female fashion), the feature computation took 22 hours on 
a spot AWS g2 (single GPU) instance. i.e. ~ 230,000 images / 1 $ . Since I did not use batching, it might be possible to 
get even better performance.</p>

<p>The code implements two methods, a server that handles image search, and a simple indexer that extracts pool3 features.
Nearest neighbor search can be performed in an approximate manner using nearpy (faster) or using exact methods (slower).</p>

<p><a href="/AKSHAYUBHAT/VisualSearchServer/blob/master/appcode/static/alpha3.png" target="_blank"><img src="/AKSHAYUBHAT/VisualSearchServer/raw/master/appcode/static/alpha3.png" alt="Alpha Screenshot" title="Alpha Screenshot"/></a>     </p>

<h4><a id="user-content-run-server" class="anchor" href="#run-server" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Run server</h4>

<p>The easiest way to use the code is to launch "ami-537b2339" in AWS North Virginia (us-east-1) region.<br/>
The AMI contains 450,000 images and computed index. Make sure that you keep port 9000 open.
Once logged in run following commands.</p>

<pre><code>  cd server
  git pull
  sudo pip install fabric
  python server.py &amp;
  tail -f logs/server.log
</code></pre>

<h4><a id="user-content-index-images" class="anchor" href="#index-images" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Index images</h4>

<p>We strongly recommended using IAM roles, rather than manually entering credentials.</p>



<h4><a id="user-content-following-libraries--templates-are-used" class="anchor" href="#following-libraries--templates-are-used" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Following libraries &amp; templates are used:</h4>

<ol>
<li><a href="https://almsaeedstudio.com/">https://almsaeedstudio.com/</a></li>
<li><a href="http://fabricjs.com/kitchensink/">http://fabricjs.com/kitchensink/</a></li>
<li><a href="https://github.com/karpathy/convnetjs">https://github.com/karpathy/convnetjs</a></li>
<li><a href="https://www.tensorflow.org/">https://www.tensorflow.org/</a> </li>
<li><a href="http://nearpy.io/">http://nearpy.io/</a></li>
</ol>

<p>License:<br/>
Copyright 2015, Cornell University. </p>
</article>
  </div></body></html>