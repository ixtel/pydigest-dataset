<html><body><div><div itemprop="articleBody" class="article-body"><p>Yesterday I was pulling down some stock data from Yahoo, with the goal of building out a machine learning training set using <a href="http://spark.apache.org/">Spark</a> and <a href="http://cassandra.apache.org/">Cassandra</a>.  If you haven't tried Cassandra yet, it's a database built for high availability and linear scalability.  I've got a intro talk up <a href="https://www.youtube.com/watch?v=W45Ysb9b6oE">here</a>.  Spark is another apache project that kicks Cassandra into overdrive by providing a framework for batch analytics, streaming, and machine learning.  On the way is support for graph operations which makes me giddy.</p>
<p>One thing at a time though.  Before I get too deep into it, I just wanted to pull down and store the raw data on disk.  Looking through the Pandas documentation, I came across HDF5.  HDF5 lets me treat a local file as a hash and work directly with DataFrames.  Very cool.</p>
<p>Let's install requirements.  I use virtual environments for everything, I suggest you do too.  To learn more about that and other useful Python topics please read <a href="http://rustyrazorblade.com/2014/08/python-for-programmers/">Python for Programmers</a>.</p>

<p>Cython is required for building extensions:</p>




<p>I grabbed the source from the <a href="http://www.hdfgroup.org/HDF5/release/obtainsrc.html#conf">HDF5 site</a> and did:</p>
<div class="highlight"><pre>./configure --prefix=/usr/local
make
sudo make install
</pre></div>


<p>You'll need the python library for hdf5 as well:</p>




<p>This isn't installed by default with Pandas, you'll have to install it separately:</p>



<p>Once you've installed the requirements, this is about as simple as it gets:</p>
<div class="highlight"><pre><span class="kn">import</span> <span class="nn">pandas</span>
<span class="kn">from</span> <span class="nn">pandas</span> <span class="kn">import</span> <span class="n">HDFStore</span>

<span class="c"># .... some helper functions here, omitted for brevity .....</span>

<span class="n">store</span> <span class="o">=</span> <span class="n">HDFStore</span><span class="p">(</span><span class="s">"stocks.h5"</span><span class="p">)</span> <span class="c"># filename of the hdf5 file</span>

<span class="k">for</span> <span class="n">stock</span> <span class="ow">in</span> <span class="n">stocks</span><span class="p">():</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">print</span> <span class="s">"Looking up {}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">stock</span><span class="p">)</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">get_history</span><span class="p">(</span><span class="n">stock</span><span class="p">)</span> <span class="c"># i do fetching and use Pandas to turn the result into a DataFrame in here</span>
        <span class="n">store</span><span class="p">[</span><span class="n">stock</span><span class="p">]</span> <span class="o">=</span> <span class="n">response</span> <span class="c"># treat hdf5 handle like a hash</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="k">print</span> <span class="s">"FAIL {}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">stock</span><span class="p">)</span>
</pre></div>


<p>You can see that working with HDF5 is about as trivial as working with a hash.  What I really like is how trivial it is to read and write from this file using Pandas.  It's nice to have some local persistance for small datasets that doesn't require running a server.</p>
<p>Next I'll be playing with scikit-learn and Spark to try to extract some useful information from this dataset.</p></div>
	</div></body></html>