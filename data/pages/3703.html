<html><body><div><div class="entry-content">
			<p>In our last post, <a href="https://www.paypal-engineering.com/2014/12/10/10-myths-of-enterprise-python/" target="_blank">Ten Myths of Enterprise Python</a>, we promised a deeper dive into how our Python Infrastructure works here at PayPal and eBay. There is a problem, though. There are only so many details we can cover, and at the end of the day, it’s just so much better to show than to tell.</p>
<p>So without further ado, we’re pleased to introduce <a href="https://github.com/paypal/support" target="_blank"><strong>SuPPort</strong></a>, an in-development distillation of our PayPal Python Infrastructure.</p>
<p>Started in 2010, Python Infrastructure initially powered PayPal’s internal price-setting interfaces, then grew to support payment orchestration interfaces, and now in 2015 it supports dozens of projects at PayPal and eBay, having handled billions of production-critical requests for a wide range of teams and tiers. So what does it mean to distill this functionality into SuPPort?</p>
<p><a name="#open-source"/> SuPPort is an <a href="https://en.wikipedia.org/wiki/Event-driven_architecture" target="_blank">event-driven</a> server framework designed for building scalable and maintainable services and clients. It’s built on top of several open-source technologies, so before we dig into the workings of SuPPort, we ought to showcase its foundations:</p>

<p>Some or all of these may be new to many developers, but all-in-all they comprise a powerful set of functionality. With power comes complexity, and while Python as a language strives for technical convergence, there are many ways to approach the problem of developing, scaling, and maintaining components. SuPPort is one way gevent and the libraries above have been used to build functional services and products with anywhere from 100 requests per day to 100 requests per second and beyond.</p>
<p><a name="#enterprise"/></p>
<h2>Enterprise Ideals, Flexible Features</h2>
<p>Many motivations have gone into building up a Python stack at PayPal, but as in any enterprise environment, we continuously aim to achieve the following:</p>

<p>Of course organizations of all sizes want these features as well, but the key difference is that large organizations like PayPal usually end up building <em><strong>more</strong></em>. All while demanding a higher degree of redundancy and risk mitigation from their processes. This often results in great cost in terms of both hardware and developer productivity. Fortunately for us, Python can be very efficient in both respects.</p>
<p>So, let’s take a stroll through a selection of SuPPort’s feature set in the context of these criteria! Note that if you’re unfamiliar with evented programming, nonblocking sockets, and gevent in particular, some of this may seem quite foreign. <a href="http://sdiehl.github.io/gevent-tutorial/" target="_blank">The gevent tutorial</a> is a good entry point for the intermediate Python programmer, which can be supplemented with <a title="Intro to Server Architectures" href="http://berb.github.io/diploma-thesis/original/042_serverarch.html" target="_blank">this well-illustrated introduction to server architectures</a>.</p>

<p>Python usage here at PayPal has spread to virtually every imaginable use case: administrative interfaces, midtier services, operations automation, developer tools, batch jobs; you name it, Python has filled a gap in that area. This legacy has resulted in a few rather interesting abstractions exposed in SuPPort.</p>

<p>PayPal has hundreds of services across several tiers. Interoperating between these means having to implement over half a dozen network protocols. The <code>BufferedSocket</code> type eliminated our inevitable code duplication, handling a lot of the nitty-gritty of making a socket into a parser-friendly data source, while retaining timeouts for keeping communications responsive. A must-have primitive for any gevent protocol implementer.</p>

<p>Errors happen in live environments. DNS requests fail. Packets are lost. Latency spikes. TCP handshakes are slow. SSL handshakes are slower. Clients rarely handle these problems gracefully. This is why SuPPort includes the <code>ConnectionManager</code>, which provides robust error handling code for all of these cases with consistent logging and monitoring. It also provides a central point of configuration for timeouts and host fallbacks.</p>

<p>As part of a large organization, we can afford to add more machines, and are even required to keep a certain level of redundancy and idle hardware. And while DevOps is catching on in many larger-scale environments, there are many cases in enterprise environments where developers are <em>not allowed</em> to attend to their production code.</p>
<p>SuPPort currently comes with all the same general-purpose introspection capabilities that PayPal Python developers enjoy, meaning that we get you as much structured information about your application as possible without actually requiring login privileges. Of course almost every aspect of this is configurable, to suit a wide variety of environments from development to production.</p>

<p>Python famously has no global scope: all values are namespaced in module scope. But there are still plenty of aspects of the runtime that are global. Some are out of our control, like the OS-assigned process ID, or the VM-managed garbage collection counters. Others aspects are in our control, and best practice in concurrent programming is to keep these as well-managed as possible.</p>
<p>SuPPort uses a system of Contexts to explicitly manage nonlocal state, eliminating difficult-to-track implicit global state for many core functions. This has the added benefit of creating opportunities to centrally manage and monitor debugging data and statistics (some charts of which are shown below), all made available through the <a href="#metaapplication">MetaApplication</a>, detailed further down.</p>
<div id="attachment_1313" class="wp-caption alignleft"><a href="https://www.paypal-engineering.com/wordpress/wp-content/uploads/2015/03/accept_ssl_charts.png" target="_blank"><img class="wp-image-1313" src="https://www.paypal-engineering.com/wordpress/wp-content/uploads/2015/03/accept_ssl_charts.png" alt="Accept SSL Charts"/></a><p class="wp-caption-text">Charting quantiles and recent timings for incoming SSL connections from a remote service.</p></div>
<div id="attachment_1312" class="wp-caption alignleft"><a href="https://www.paypal-engineering.com/wordpress/wp-content/uploads/2015/03/meta_stats_table.png" target="_blank"><img class="wp-image-1312" src="https://www.paypal-engineering.com/wordpress/wp-content/uploads/2015/03/meta_stats_table.png" alt="SuPPort Stats table"/></a><p class="wp-caption-text">Values are also available in table-based and JSON formats, for easy human and machine readability.</p></div>

<p>While not exclusively a web server framework, SuPPort leverages its strong roots in the web to provide both a web-based user interface and API full of useful runtime information.</p>
<p>As you can see below, there is a lot of information exposed through this default interface. This is partly because of restricted environments not allowing local login on machines, and another part is the relative convenience of a browser for most developers. Not pictured is the feature that the same information is available in JSON format for easy programmatic consumption. Because this application is such a rich source of information, we recommend using SuPPort to run it on a separate port which can be firewalled accordingly, as seen <a href="https://github.com/paypal/support/blob/master/examples/basic_wsgi.py" target="_blank">in this example</a>.</p>
<div id="attachment_1314" class="wp-caption alignleft"><a href="https://www.paypal-engineering.com/wordpress/wp-content/uploads/2015/03/meta_app_1.png" target="_blank"><img class="wp-image-1314" src="https://www.paypal-engineering.com/wordpress/wp-content/uploads/2015/03/meta_app_1.png" alt="MetaApplication Screenshot #1"/></a><p class="wp-caption-text"><em>A screenshot of the MetaApplication, showing load averages and other basic information, as well as subroutes to further info.</em></p></div>
<div id="attachment_1315" class="wp-caption alignleft"><a href="https://www.paypal-engineering.com/wordpress/wp-content/uploads/2015/03/meta_app_2.png" target="_blank"><img class="wp-image-1315" src="https://www.paypal-engineering.com/wordpress/wp-content/uploads/2015/03/meta_app_2.png" alt="MetaApplication Screenshot 2"/></a><p class="wp-caption-text">Another shot of the MetaApplication, showing process and runtime info</p></div>
<p> </p>

<p>At the end of the day, reliability over long periods of time is what earns a stack approval and adoption. At this point, the SuPPort architecture has a billion production requests under its belt here at PayPal, but on the way we put it through the proverbial paces. At various points, we have tested and confirmed several edge behaviors. Here are just a few key characteristics of a well-behaved application:</p>
<ul>
<li><strong>Gracefully sheds traffic</strong> under load (no unbounded queues here)</li>
<li>Can and has run at <strong>90%+ CPU load for days</strong> at a time</li>
<li>Is <strong>free</strong> from framework memory leaks</li>
<li>Is <strong>robust to</strong> memory leakage in user code</li>
</ul>
<p>To illustrate, a live service handling millions of requests per day had a version of OpenSSL installed which was leaking memory on every handshake. Thanks to preemptive worker cycling on excessive process memory usage, no intervention was required and no customers were impacted. The worker cycling was noted in the logs, the leak was traced to OpenSSL, and operations was notified. The problem was fixed with the next regularly scheduled release rather than being handled as a crisis.</p>

<p>One of the first and sometimes only ways that people experience gevent is through <a href="https://en.wikipedia.org/wiki/Monkey_patch" target="_blank">monkeypatching</a>. At the top of your main module <a href="http://www.gevent.org/intro.html#monkey-patching" target="_blank">you issue a call to gevent</a> that automatically swaps out virtually all system libraries with their cooperatively concurrent ones. This sort of magic is relatively rare in Python programming, and rightfully so. Implicit activities like this can have unexpected consequences. SuPPort is a no-monkeypatching approach to gevent. If you want to implement your own network-level code, it is best to use <code>gevent.socket</code> directly. If you want gevent-incompatible libraries to work with gevent, best to use SuPPort’s gevent-based threading capabilities.</p>

<blockquote><p>“Threads? In my gevent? I thought the whole point of greenlets and gevent was to eliminate evil, evil threads!” <cite>–Countless strawmen</cite></p></blockquote>
<p>Originating in <a href="http://www.stackless.com/" target="_blank">Stackless</a> and ported over in 2004 by <a href="http://pyvideo.org/speaker/334/armin-rigo" target="_blank">Armin Rigo</a> (of <a href="http://pypy.org/" target="_blank">PyPy</a> fame), <a href="https://greenlet.readthedocs.org/en/latest/" target="_blank">greenlets</a> are mature and powerful concurrency primitives. We wanted to add that power to the process- and thread-based world of POSIX. There’s no point running from standard OS capabilities; threads have their place. Many architectures adopt a <a href="https://www.usenix.org/legacy/publications/library/proceedings/osdi99/full_papers/banga/banga_html/node3.html" target="_blank">thread-per-request or process-per-request model</a>, but the last thing we want is the number of threads going up as load increases. Threads are expensive; each thread adds a bit of contention to the mix, and in many environments the memory overhead alone, typically 4-8MB per thread, presents a problem. At just a few kilobytes apiece, greenlet’s microthreads are three orders of magnitude less costly.</p>
<p>Furthermore, thread usage in our architecture is hardly about parallelism; we use worker processes for that. In the SuPPort world, threads are about preemption. Cooperative greenlets are much more efficient overall, but sometimes you really do need guarantees about responsiveness.</p>
<p>One excellent example of how threads provide this responsiveness is the <a href="#thread-queue-server" target="_blank"><code>ThreadQueueServer</code></a> detailed below. But first, there are two built-in <code>Threadpools</code> with decorators worth highlighting, <code>io_bound</code> and <code>cpu_bound</code>:</p>

<p>This decorator is primarily used to wrap opaque clients built without affordances for cooperative concurrent IO. We use this to wrap <a href="https://pypi.python.org/pypi/cx_Oracle" target="_blank"><code>cx_Oracle</code></a> and other C-based clients that are built for thread-based parallelization. Other major use cases for <code>io_bound</code> is when getting input from standard input (<code>stdin</code>) and files.</p>
<div id="attachment_1328" class="wp-caption alignnone"><a href="https://www.paypal-engineering.com/wordpress/wp-content/uploads/2015/03/workercloseup.png" target="_blank"><img class="wp-image-1328" src="https://www.paypal-engineering.com/wordpress/wp-content/uploads/2015/03/workercloseup.png" alt="A rough sketch of what threads inside a worker look like. The outer box is a process, inner boxes are threads/threadpools, and each text label refers to a coroutine/greenlet."/></a><p class="wp-caption-text">A rough sketch of what threads inside a worker look like. The outer box is a process, inner boxes are threads/threadpools, and each text label refers to a coroutine/greenlet.</p></div>

<p>The <code>cpu_bound</code> decorator is used to wrap expensive operations that would halt the event loop for too long. We use it to wrap long-running cryptography and serialization tasks, such as decrypting private SSL certificates or loading huge blobs of XML and JSON. Because the majority of use cases’ implementations do not release the Global Interpreter Lock, the <code>cpu_bound</code> ThreadPool is actually just a pool of one thread, to minimize CPU contention from multiple unparallelizable CPU-intensive tasks.</p>
<p>It’s worth noting that some deserialization tasks are not worth the overhead of dispatching to a separate thread. If the data to be deserialized is very short or a result is already cached. For these cases, we have the <code>cpu_bound_if</code> decorator, which conditionally dispatches to the thread, yielding slightly higher responsiveness for low-complexity requests.</p>
<p>Also note that both of these decorators are reentrant, making dispatch idempotent. If you decorate a function that itself eventually calls a decorated function, performance won’t pay the thread dispatch tax twice.</p>

<p>The <code>ThreadQueueServer</code> exists as an enhanced approach to pulling new connections off of a server’s listening socket. It’s SuPPort’s way of incorporating an industry-standard practice, commonly associated with <a href="http://nginx.org/en/" target="_blank">nginx</a> and <a href="http://httpd.apache.org/" target="_blank">Apache</a>, into the gevent WSGI server world.</p>
<p>If you’ve read this far into the post, you’re probably familiar with <a href="http://linuxgazette.net/129/saha.html" target="_blank">the standard multi-worker preforking server architecture</a>; a parent process opens a listening socket, forks one or more children that inherit the socket, and the kernel manages which worker gets which incoming client connection.</p>
<div id="attachment_1316" class="wp-caption alignnone"><a href="https://www.paypal-engineering.com/wordpress/wp-content/uploads/2015/03/arch2.png" target="_blank"><img class="wp-image-1316" src="https://www.paypal-engineering.com/wordpress/wp-content/uploads/2015/03/arch2.png" alt="Preforking architecture"/></a><p class="wp-caption-text">Basic preforking architecture. The OS balances traffic between workers, monitored by an arbiter.</p></div>
<p>The problem with this approach is that it generally results in inefficient distribution of connections, and can lead to some workers being overloaded while others have cycles to spare. Plus, all worker processes are woken up by the kernel in a race to accept a single inbound connection, in what’s commonly referred to as <a href="https://en.wikipedia.org/wiki/Thundering_herd_problem" target="_blank"><em>the thundering herd</em></a>.</p>
<p>The solution implemented here uses a thread that sleeps on accept, removing connections from the kernel’s listen queue as soon as possible, then explicitly pushing accepted connections to the main event loop. The ability to inspect this user-space connection queue enables not only even distribution but also intelligent behavior under high load, such as closing incoming connections when the backlog gets too long. This fail-fast approach prevents the kernel from holding open fully-established connections that cannot be reached in a reasonable amount of time. This backpressure takes the wait out of client failure scenarios leading to a more responsive extrinsic system, as well.</p>

<p>The sections above highlight just a small selection of the features already in SuPPort, and there are many more to cover in future posts. In addition to those, we will also be distilling more code from our internal codebase out into the open. Among these we are particularly excited about:</p>
<ul>
<li>Enhanced human-readable structured logging</li>
<li>Advanced network security functionality based on OpenSSL</li>
<li>Distributed online statistics collection</li>
<li>Additional generalizations for TCP client infrastructure</li>
</ul>
<p>And of course, more tests! As soon as we get a couple more features distilled out, we’ll start porting out more than the skeleton tests we have now. Suffice to say, we’re really looking forward to expanding our set of codified concurrent software learnings, and incorporating as much community feedback as possible, so don’t forget to <a href="https://www.paypal-engineering.com/feed/">subscribe to the blog</a> and <a href="https://github.com/paypal/support" target="_blank">the SuPPort repo on GitHub</a>.</p>
<p><a href="https://github.com/mahmoud" target="_blank">Mahmoud Hashemi</a>, <a href="https://github.com/doublereedkurt" target="_blank">Kurt Rose</a>, <a href="https://github.com/markrwilliams" target="_blank">Mark Williams</a>, and <a href="https://github.com/lanstin" target="_blank">Chris Lane</a></p>

		<p class="really_simple_share_clearfix"/>					</div>
		
		</div></body></html>