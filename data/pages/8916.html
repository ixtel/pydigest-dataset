<html><body><div><article class="markdown-body entry-content" itemprop="text"><h2><a id="user-content-generative-handwriting-demo-using-tensorflow" class="anchor" href="#generative-handwriting-demo-using-tensorflow" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Generative Handwriting Demo using TensorFlow</h2>

<p><a href="https://camo.githubusercontent.com/c264d82c0a5d19a3bc8975e561a2ebecdc9eddb4/68747470733a2f2f63646e2e7261776769742e636f6d2f686172646d6172752f77726974652d726e6e2d74656e736f72666c6f772f6d61737465722f7376672f6578616d706c652e737667" target="_blank"><img src="https://camo.githubusercontent.com/c264d82c0a5d19a3bc8975e561a2ebecdc9eddb4/68747470733a2f2f63646e2e7261776769742e636f6d2f686172646d6172752f77726974652d726e6e2d74656e736f72666c6f772f6d61737465722f7376672f6578616d706c652e737667" alt="example" data-canonical-src="https://cdn.rawgit.com/hardmaru/write-rnn-tensorflow/master/svg/example.svg"/></a></p>

<p><a href="https://camo.githubusercontent.com/940c5aff37a4f926992894d9f8154c21596a926d/68747470733a2f2f63646e2e7261776769742e636f6d2f686172646d6172752f77726974652d726e6e2d74656e736f72666c6f772f6d61737465722f7376672f6d616e795f6578616d706c65732e737667" target="_blank"><img src="https://camo.githubusercontent.com/940c5aff37a4f926992894d9f8154c21596a926d/68747470733a2f2f63646e2e7261776769742e636f6d2f686172646d6172752f77726974652d726e6e2d74656e736f72666c6f772f6d61737465722f7376672f6d616e795f6578616d706c65732e737667" alt="example" data-canonical-src="https://cdn.rawgit.com/hardmaru/write-rnn-tensorflow/master/svg/many_examples.svg"/></a></p>

<p>An attempt to implement the random handwriting generation portion of Alex Graves' <a href="http://arxiv.org/abs/1308.0850">paper</a>.</p>

<p>See my blog post at <a href="http://blog.otoro.net/2015/12/12/handwriting-generation-demo-in-tensorflow">blog.otoro.net</a> for more information.</p>

<h3><a id="user-content-how-to-use" class="anchor" href="#how-to-use" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>How to use</h3>

<p>I tested the implementation on TensorFlow 0.50.  I also used the following libraries to help:</p>

<pre><code>svgwrite
IPython.display.SVG
IPython.display.display
xml.etree.ElementTree
argparse
cPickle
</code></pre>

<h3><a id="user-content-training" class="anchor" href="#training" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Training</h3>

<p>You will need permission from <a href="http://www.iam.unibe.ch/fki/databases/iam-on-line-handwriting-database">these wonderful people</a> people to get the IAM On-Line Handwriting data.  Unzip <code>lineStrokes-all.tar.gz</code> into the data subdirectory, so that you end up with <code>data/lineStrokes/a01</code>, <code>data/lineStrokes/a02</code>, etc.  Afterwards, running <code>python train.py</code> will start the training process.</p>

<p>A number of flags can be set for training if you wish to experiment with the parameters.  The default values are in <code>train.py</code></p>

<pre><code>--rnn_size RNN_SIZE             size of RNN hidden state
--num_layers NUM_LAYERS         number of layers in the RNN
--model MODEL                   rnn, gru, or lstm
--batch_size BATCH_SIZE         minibatch size
--seq_length SEQ_LENGTH         RNN sequence length
--num_epochs NUM_EPOCHS         number of epochs
--save_every SAVE_EVERY         save frequency
--grad_clip GRAD_CLIP           clip gradients at this value
--learning_rate LEARNING_RATE   learning rate
--decay_rate DECAY_RATE         decay rate for rmsprop
--num_mixture NUM_MIXTURE       number of gaussian mixtures
--data_scale DATA_SCALE         factor to scale raw data down by
--keep_prob KEEP_PROB           dropout keep probability
</code></pre>

<h3><a id="user-content-generating-a-handwriting-sample" class="anchor" href="#generating-a-handwriting-sample" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>Generating a Handwriting Sample</h3>

<p>I've included a pretrained model in <code>/save</code> so it should work out of the box.  Running <code>python sample.py --filename example_name --sample_length 1000</code> will generate 4 .svg files for each example, with 1000 points.</p>

<h3><a id="user-content-ipython-interactive-session" class="anchor" href="#ipython-interactive-session" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>IPython interactive session.</h3>

<p>If you wish to experiment with this code interactively, just run <code>%run -i sample.py</code> in an IPython console, and then the following code is an example on how to generate samples and show them inside IPython.</p>

<pre><code>[strokes, params] = model.sample(sess, 800)
draw_strokes(strokes, factor=8, svg_filename = 'sample.normal.svg')
draw_strokes_random_color(strokes, factor=8, svg_filename = 'sample.color.svg')
draw_strokes_random_color(strokes, factor=8, per_stroke_mode = False, svg_filename = 'sample.multi_color.svg')
draw_strokes_eos_weighted(strokes, params, factor=8, svg_filename = 'sample.eos.svg')
draw_strokes_pdf(strokes, params, factor=8, svg_filename = 'sample.pdf.svg')

</code></pre>

<p><a href="https://camo.githubusercontent.com/3ccd227ae5e8bcc28130b19e7c6f708d7e6be620/68747470733a2f2f63646e2e7261776769742e636f6d2f686172646d6172752f77726974652d726e6e2d74656e736f72666c6f772f6d61737465722f7376672f6578616d706c65312e6e6f726d616c2e737667" target="_blank"><img src="https://camo.githubusercontent.com/3ccd227ae5e8bcc28130b19e7c6f708d7e6be620/68747470733a2f2f63646e2e7261776769742e636f6d2f686172646d6172752f77726974652d726e6e2d74656e736f72666c6f772f6d61737465722f7376672f6578616d706c65312e6e6f726d616c2e737667" alt="example1a" data-canonical-src="https://cdn.rawgit.com/hardmaru/write-rnn-tensorflow/master/svg/example1.normal.svg"/></a>
<a href="https://camo.githubusercontent.com/e8ef0824a6a5c4d5054ac5bf01a674bb456d1b9a/68747470733a2f2f63646e2e7261776769742e636f6d2f686172646d6172752f77726974652d726e6e2d74656e736f72666c6f772f6d61737465722f7376672f6578616d706c65312e636f6c6f722e737667" target="_blank"><img src="https://camo.githubusercontent.com/e8ef0824a6a5c4d5054ac5bf01a674bb456d1b9a/68747470733a2f2f63646e2e7261776769742e636f6d2f686172646d6172752f77726974652d726e6e2d74656e736f72666c6f772f6d61737465722f7376672f6578616d706c65312e636f6c6f722e737667" alt="example1b" data-canonical-src="https://cdn.rawgit.com/hardmaru/write-rnn-tensorflow/master/svg/example1.color.svg"/></a>
<a href="https://camo.githubusercontent.com/48a5509e5dd1212396c066ac09676fe8da32f159/68747470733a2f2f63646e2e7261776769742e636f6d2f686172646d6172752f77726974652d726e6e2d74656e736f72666c6f772f6d61737465722f7376672f6578616d706c65312e6d756c74695f636f6c6f722e737667" target="_blank"><img src="https://camo.githubusercontent.com/48a5509e5dd1212396c066ac09676fe8da32f159/68747470733a2f2f63646e2e7261776769742e636f6d2f686172646d6172752f77726974652d726e6e2d74656e736f72666c6f772f6d61737465722f7376672f6578616d706c65312e6d756c74695f636f6c6f722e737667" alt="example1c" data-canonical-src="https://cdn.rawgit.com/hardmaru/write-rnn-tensorflow/master/svg/example1.multi_color.svg"/></a>
<a href="https://camo.githubusercontent.com/740aabbd4d0d8cc82607990384227c17ce4c56f6/68747470733a2f2f63646e2e7261776769742e636f6d2f686172646d6172752f77726974652d726e6e2d74656e736f72666c6f772f6d61737465722f7376672f6578616d706c65312e656f735f7064662e737667" target="_blank"><img src="https://camo.githubusercontent.com/740aabbd4d0d8cc82607990384227c17ce4c56f6/68747470733a2f2f63646e2e7261776769742e636f6d2f686172646d6172752f77726974652d726e6e2d74656e736f72666c6f772f6d61737465722f7376672f6578616d706c65312e656f735f7064662e737667" alt="example1d" data-canonical-src="https://cdn.rawgit.com/hardmaru/write-rnn-tensorflow/master/svg/example1.eos_pdf.svg"/></a>
<a href="https://camo.githubusercontent.com/c2ab87137a605810d1a6c9ae25d44cba88893ac8/68747470733a2f2f63646e2e7261776769742e636f6d2f686172646d6172752f77726974652d726e6e2d74656e736f72666c6f772f6d61737465722f7376672f6578616d706c65312e7064662e737667" target="_blank"><img src="https://camo.githubusercontent.com/c2ab87137a605810d1a6c9ae25d44cba88893ac8/68747470733a2f2f63646e2e7261776769742e636f6d2f686172646d6172752f77726974652d726e6e2d74656e736f72666c6f772f6d61737465722f7376672f6578616d706c65312e7064662e737667" alt="example1e" data-canonical-src="https://cdn.rawgit.com/hardmaru/write-rnn-tensorflow/master/svg/example1.pdf.svg"/></a></p>

<p>Have fun-</p>

<h2><a id="user-content-license" class="anchor" href="#license" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" role="img" version="1.1" viewbox="0 0 16 16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"/></svg></a>License</h2>

<p>MIT</p>
</article>
  </div></body></html>